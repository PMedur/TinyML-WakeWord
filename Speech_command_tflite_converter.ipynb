{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import lite\n",
    "from tensorflow.keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_1_filename = 'models/best_model_1_fold_10.h5'\n",
    "best_model_2_filename = 'models/best_model_2_fold_10.h5'\n",
    "best_model_3_filename = 'models/best_model_3_fold_4.h5'\n",
    "best_model_4_filename = 'models/best_model_4_fold_2.h5'\n",
    "best_model_5_filename = 'models/best_model_5_fold_4.h5'\n",
    "best_model_6_filename = 'models/best_model_6_fold_10.h5'\n",
    "best_model_7_filename = 'models/best_model_7_fold_7.h5'\n",
    "best_model_8_filename = 'models/best_model_8_fold_6.h5'\n",
    "best_model_9_filename = 'models/best_model_9_fold_3.h5'\n",
    "best_model_10_filename = 'models/best_model_10_fold_2.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "keras_model_filename = 'models/best_model_1_fold_10.h5'\n",
    "tflite_filename = 'wake_word_stop_lite_1.tflite'\n",
    "c_model_name = 'wake_word_stop_1_h' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory usage: svmem(total=16701485056, available=6082228224, percent=63.6, used=10084945920, free=323686400, active=11170242560, inactive=3501506560, buffers=215302144, cached=6077550592, shared=185769984, slab=850468864)\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "# Provera trenutne upotrebe memorije\n",
    "print(f\"Current memory usage: {psutil.virtual_memory()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "# Pokretanje Garbage Collector-a\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Oslobađanje memorije TensorFlow sesije\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Keras model from models/best_model_10_fold_2.h5\n",
      "Converting Keras model to TF Lite format...\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp6rzu6d0d/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp6rzu6d0d/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion successful.\n",
      "Saving TF Lite model to wake_word_stop_lite_10.tflite\n",
      "TF Lite model is saved at wake_word_stop_lite_10.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 23:25:12.110221: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-06-12 23:25:12.110242: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-06-12 23:25:12.110406: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp6rzu6d0d\n",
      "2024-06-12 23:25:12.111550: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-06-12 23:25:12.111560: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp6rzu6d0d\n",
      "2024-06-12 23:25:12.114604: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-06-12 23:25:12.158876: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp6rzu6d0d\n",
      "2024-06-12 23:25:12.173990: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 63585 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 8, Total Ops 24, % non-converted = 33.33 %\n",
      " * 8 ARITH ops\n",
      "\n",
      "- arith.constant:    8 occurrences  (f32: 7, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 3)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 3)\n",
      "  (uq_8: 3)\n",
      "  (f32: 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import lite\n",
    "from tensorflow.keras import models\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Parameters\n",
    "keras_model_filename = 'models/best_model_10_fold_2.h5'\n",
    "tflite_filename = 'wake_word_stop_lite_10.tflite'\n",
    "c_model_name = 'wake_word_stop_10_h'\n",
    "\n",
    "try:\n",
    "    # Proverite i kreirajte direktorijum ako ne postoji\n",
    "    keras_model_path = Path(keras_model_filename)\n",
    "    if not keras_model_path.is_file():\n",
    "        raise FileNotFoundError(f\"Keras model file '{keras_model_filename}' not found.\")\n",
    "\n",
    "    # Učitajte Keras model\n",
    "    print(f\"Loading Keras model from {keras_model_filename}\")\n",
    "    model = models.load_model(keras_model_filename, custom_objects={'precision_m': precision_m, 'recall_m': recall_m, 'f1_m': f1_m})\n",
    "\n",
    "    # Konvertujte model u TF Lite format\n",
    "    print(\"Converting Keras model to TF Lite format...\")\n",
    "    converter = lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    # converter.target_spec.supported_types = [tf.float16]\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "    # converter.allow_custom_ops=True\n",
    "    tflite_model = converter.convert()\n",
    "    print(\"Conversion successful.\")\n",
    "\n",
    "    # Proverite i kreirajte direktorijum za čuvanje konvertovanog modela\n",
    "    tflite_model_path = Path(tflite_filename)\n",
    "    tflite_model_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Sačuvajte konvertovani TF Lite model\n",
    "    print(f\"Saving TF Lite model to {tflite_filename}\")\n",
    "    with open(tflite_filename, 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "\n",
    "    print(f\"TF Lite model is saved at {tflite_filename}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert model to TF Lite model\n",
    "model = models.load_model(keras_model_filename)\n",
    "converter = lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "#converter.target_spec.supported_types = [tf.float16]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "#converter.allow_custom_ops=True\n",
    "tflite_model = converter.convert()\n",
    "open(tflite_filename, 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Convert some hex value into an array for C programming\n",
    "def hex_to_c_array(hex_data, var_name):\n",
    "\n",
    "  c_str = ''\n",
    "\n",
    "  # Create header guard\n",
    "  c_str += '#ifndef ' + var_name.upper() + '_H\\n'\n",
    "  c_str += '#define ' + var_name.upper() + '_H\\n\\n'\n",
    "\n",
    "  # Add array length at top of file\n",
    "  c_str += '\\nunsigned int ' + var_name + '_len = ' + str(len(hex_data)) + ';\\n'\n",
    "\n",
    "  # Declare C variable\n",
    "  c_str += 'unsigned char ' + var_name + '[] = {'\n",
    "  hex_array = []\n",
    "  for i, val in enumerate(hex_data) :\n",
    "\n",
    "    # Construct string from hex\n",
    "    hex_str = format(val, '#04x')\n",
    "\n",
    "    # Add formatting so each line stays within 80 characters\n",
    "    if (i + 1) < len(hex_data):\n",
    "      hex_str += ','\n",
    "    if (i + 1) % 12 == 0:\n",
    "      hex_str += '\\n '\n",
    "    hex_array.append(hex_str)\n",
    "\n",
    "  # Add closing brace\n",
    "  c_str += '\\n ' + format(' '.join(hex_array)) + '\\n};\\n\\n'\n",
    "\n",
    "  # Close out header guard\n",
    "  c_str += '#endif //' + var_name.upper() + '_H'\n",
    "\n",
    "  return c_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_filename = 'wake_word_stop_lite_10.tflite'\n",
    "c_model_name = 'wake_word_stop_10_h'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write TFLite model to a C source (or header) file\n",
    "with open(c_model_name + '.h', 'w') as file:\n",
    "  file.write(hex_to_c_array(tflite_model, c_model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function #2: converting to tfLite\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def convert_tflite_to_header(tflite_path, output_header_path):\n",
    "\n",
    "    with open(tflite_path, 'rb') as tflite_file:\n",
    "        tflite_content = tflite_file.read()\n",
    "    \n",
    "    \n",
    "    hex_lines = [', '.join([f'0x{byte:02x}' for byte in tflite_content[i:i+12]]) for i in range(0, len(tflite_content), 12)]\n",
    "    \n",
    "    \n",
    "    hex_array = ',\\n  '.join(hex_lines)\n",
    "    \n",
    "    \n",
    "    with open(output_header_path, 'w') as header_file:\n",
    "        \n",
    "        header_file.write('const unsigned char model[] = {\\n  ')\n",
    "        header_file.write(f'{hex_array}\\n')\n",
    "        header_file.write('};\\n\\n')\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    tflite_path = 'wake_word_stop_lite.tflite'\n",
    "    output_header_path = '2_wake_word_stop_h.h'\n",
    "\n",
    "    convert_tflite_to_header(tflite_path, output_header_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
