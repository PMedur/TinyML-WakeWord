{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-17 17:16:43.450391: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-17 17:16:43.450475: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-17 17:16:43.501595: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-17 17:16:43.607824: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-17 17:16:44.647303: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isdir, join\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback\n",
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.layers as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stop', 'up', 'learn', 'bird', 'follow', 'wow', 'on', 'marvin', 'tree', 'no', 'dog', 'happy', 'off', 'down', 'six', 'sheila', 'bed', 'seven', 'visual', 'four', 'right', 'five', 'cat', 'house', 'left', 'go', 'eight', 'forward', 'one', 'yes', 'two', 'backward', 'nine', 'three', 'zero']\n"
     ]
    }
   ],
   "source": [
    "# Create list of all targets\n",
    "dataset_path = '/home/pmedur/strojnoUcenje/env/bin/TorchAudio/SpeechCommands/speech_commands_v0.02 (copy)'\n",
    "all_targets = all_targets = [name for name in listdir(dataset_path) if isdir(join(dataset_path, name))]\n",
    "all_targets.remove('_background_noise_')\n",
    "all_targets.remove('.ipynb_checkpoints')\n",
    "#all_targets.remove('pozdrav')\n",
    "print(all_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "feature_sets_path = '/home/pmedur/strojnoUcenje/env/bin/Tensorflow_speech_recognition/tflite-speech-recognition-master'\n",
    "feature_sets_filename = 'all_targets_mfcc_sets.npz'\n",
    "model_1_filename = 'wake_word_stop_model_1.h5'\n",
    "model_2_filename = 'wake_word_stop_model_2.h5'\n",
    "model_3_filename = 'wake_word_stop_model_3.h5'\n",
    "model_4_filename = 'wake_word_stop_model_4.h5'\n",
    "model_5_filename = 'wake_word_stop_model_5.h5'\n",
    "model_6_filename = 'wake_word_stop_model_6.h5'\n",
    "model_7_filename = 'wake_word_stop_model_7.h5'\n",
    "model_8_filename = 'wake_word_stop_model_8.h5'\n",
    "model_9_filename = 'wake_word_stop_model_9.h5'\n",
    "model_10_filename = 'wake_word_stop_model_10.h5'\n",
    "model_q_filename = 'wake_word_stop_model_q.h5'\n",
    "wake_word = 'go'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x_train', 'y_train', 'x_val', 'y_val', 'x_test', 'y_test']\n"
     ]
    }
   ],
   "source": [
    "# Loading feature sets\n",
    "feature_sets = np.load(join(feature_sets_path, feature_sets_filename))\n",
    "print(feature_sets.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning feature sets\n",
    "x_train = feature_sets['x_train']\n",
    "y_train = feature_sets['y_train']\n",
    "x_val = feature_sets['x_val']\n",
    "y_val = feature_sets['y_val']\n",
    "x_test = feature_sets['x_test']\n",
    "y_test = feature_sets['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77441, 16, 16)\n",
      "(9689, 16, 16)\n",
      "(9726, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9689 77441 9726\n",
      "2480384 19824896 2489856\n"
     ]
    }
   ],
   "source": [
    "print(y_val.size, y_train.size, y_test.size)\n",
    "print(x_val.size, x_train.size, x_test.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9689,) (77441,) (9726,)\n",
      "(9689, 16, 16) (77441, 16, 16) (9726, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "print(y_val.shape, y_train.shape, y_test.shape)\n",
    "print(x_val.shape, x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting ground truth arrays to one wake word (1) and 'other' (0)\n",
    "wake_word_index = all_targets.index(wake_word)\n",
    "y_train = np.equal(y_train, wake_word_index).astype('float64')\n",
    "y_val = np.equal(y_val, wake_word_index).astype('float64')\n",
    "y_test = np.equal(y_test, wake_word_index).astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03612343895138817\n",
      "0.9638765610486119\n"
     ]
    }
   ],
   "source": [
    "# Percentage of 'go' appear in validation labels\n",
    "print(sum(y_val) / len(y_val))\n",
    "print(1 - sum(y_val) / len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.036602920008225376\n",
      "0.9633970799917746\n"
     ]
    }
   ],
   "source": [
    "print(sum(y_test) / len(y_test))\n",
    "print(1 - sum(y_test) / len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN for TF expects (batch, height, width, channels)\n",
    "x_train = x_train.reshape(x_train.shape[0], \n",
    "                          x_train.shape[1], \n",
    "                          x_train.shape[2], \n",
    "                          1)\n",
    "x_val = x_val.reshape(x_val.shape[0], \n",
    "                      x_val.shape[1], \n",
    "                      x_val.shape[2], \n",
    "                      1)\n",
    "x_test = x_test.reshape(x_test.shape[0], \n",
    "                        x_test.shape[1], \n",
    "                        x_test.shape[2], \n",
    "                        1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9689,) (77441,) (9726,)\n",
      "(9689, 16, 16, 1) (77441, 16, 16, 1) (9726, 16, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_val.shape, y_train.shape, y_test.shape)\n",
    "print(x_val.shape, x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "# Input shape for CNN is size of MFCC of 1 sample\n",
    "sample_shape = x_test.shape[1:]\n",
    "print(sample_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def g_mean(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    g_mean = (sensitivity * specificity) ** 0.5\n",
    "    return g_mean\n",
    "\n",
    "# Custom callback to save metrics\n",
    "class MetricsHistory(Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.history = {'acc': [], 'precision_m': [], 'recall_m': [], 'f1_m': []}\n",
    "        self.best_metrics = {'acc': 0, 'precision_m': 0, 'recall_m': 0, 'f1_m': 0}\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.history['acc'].append(logs.get('val_acc'))\n",
    "        self.history['precision_m'].append(logs.get('val_precision_m'))\n",
    "        self.history['recall_m'].append(logs.get('val_recall_m'))\n",
    "        self.history['f1_m'].append(logs.get('val_f1_m'))\n",
    "        \n",
    "        # Update best metrics\n",
    "        if logs.get('val_acc') > self.best_metrics['acc']:\n",
    "            self.best_metrics['acc'] = logs.get('val_acc')\n",
    "            self.best_metrics['precision_m'] = logs.get('val_precision_m')\n",
    "            self.best_metrics['recall_m'] = logs.get('val_recall_m')\n",
    "            self.best_metrics['f1_m'] = logs.get('val_f1_m')\n",
    "            print(\"----------------------------------------------------------------------------\")\n",
    "            print(\"NAJBOLJA METRIKA\")\n",
    "            print(\"----------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 19:16:49.804158: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-11 19:16:49.944289: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-11 19:16:49.944527: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-11 19:16:49.945725: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-11 19:16:49.945967: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-11 19:16:49.946173: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-11 19:16:50.023202: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-11 19:16:50.023363: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-11 19:16:50.023494: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-11 19:16:50.023616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6918 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 19:16:51.415663: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-11 19:16:52.924509: I external/local_xla/xla/service/service.cc:168] XLA service 0x7734a856aac0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-11 19:16:52.924531: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1070, Compute Capability 6.1\n",
      "2024-06-11 19:16:52.935623: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1718126213.030171    4233 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292/292 [==============================] - ETA: 0s - loss: 0.1432 - acc: 0.9626 - precision_m: 0.1760 - recall_m: 0.0395 - f1_m: 0.0607\n",
      "Epoch 1: val_acc improved from -inf to 0.96286, saving model to models/best_model_1_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 5s 6ms/step - loss: 0.1432 - acc: 0.9626 - precision_m: 0.1760 - recall_m: 0.0395 - f1_m: 0.0607 - val_loss: 0.1065 - val_acc: 0.9629 - val_precision_m: 0.3548 - val_recall_m: 0.1124 - val_f1_m: 0.1568\n",
      "Epoch 2/30\n",
      " 42/292 [===>..........................] - ETA: 0s - loss: 0.0977 - acc: 0.9661 - precision_m: 0.6045 - recall_m: 0.1984 - f1_m: 0.2811          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pmedur/strojnoUcenje/env/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290/292 [============================>.] - ETA: 0s - loss: 0.0960 - acc: 0.9677 - precision_m: 0.6398 - recall_m: 0.2632 - f1_m: 0.3500\n",
      "Epoch 2: val_acc improved from 0.96286 to 0.96477, saving model to models/best_model_1_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0959 - acc: 0.9678 - precision_m: 0.6388 - recall_m: 0.2621 - f1_m: 0.3487 - val_loss: 0.1103 - val_acc: 0.9648 - val_precision_m: 0.5220 - val_recall_m: 0.1515 - val_f1_m: 0.2197\n",
      "Epoch 3/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0854 - acc: 0.9711 - precision_m: 0.7324 - recall_m: 0.3759 - f1_m: 0.4600\n",
      "Epoch 3: val_acc improved from 0.96477 to 0.96990, saving model to models/best_model_1_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0854 - acc: 0.9712 - precision_m: 0.7331 - recall_m: 0.3789 - f1_m: 0.4623 - val_loss: 0.0982 - val_acc: 0.9699 - val_precision_m: 0.7797 - val_recall_m: 0.2791 - val_f1_m: 0.3782\n",
      "Epoch 4/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0763 - acc: 0.9742 - precision_m: 0.7630 - recall_m: 0.4665 - f1_m: 0.5556\n",
      "Epoch 4: val_acc did not improve from 0.96990\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0763 - acc: 0.9742 - precision_m: 0.7604 - recall_m: 0.4672 - f1_m: 0.5553 - val_loss: 0.1056 - val_acc: 0.9689 - val_precision_m: 0.7386 - val_recall_m: 0.2456 - val_f1_m: 0.3420\n",
      "Epoch 5/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0740 - acc: 0.9750 - precision_m: 0.7811 - recall_m: 0.4822 - f1_m: 0.5667\n",
      "Epoch 5: val_acc did not improve from 0.96990\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0738 - acc: 0.9750 - precision_m: 0.7794 - recall_m: 0.4805 - f1_m: 0.5649 - val_loss: 0.0913 - val_acc: 0.9680 - val_precision_m: 0.5666 - val_recall_m: 0.6266 - val_f1_m: 0.5760\n",
      "Epoch 6/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0690 - acc: 0.9758 - precision_m: 0.7790 - recall_m: 0.5102 - f1_m: 0.5910\n",
      "Epoch 6: val_acc improved from 0.96990 to 0.97146, saving model to models/best_model_1_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0690 - acc: 0.9759 - precision_m: 0.7791 - recall_m: 0.5112 - f1_m: 0.5918 - val_loss: 0.0861 - val_acc: 0.9715 - val_precision_m: 0.7691 - val_recall_m: 0.3678 - val_f1_m: 0.4686\n",
      "Epoch 7/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0660 - acc: 0.9772 - precision_m: 0.7877 - recall_m: 0.5419 - f1_m: 0.6184\n",
      "Epoch 7: val_acc improved from 0.97146 to 0.97456, saving model to models/best_model_1_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0660 - acc: 0.9773 - precision_m: 0.7875 - recall_m: 0.5401 - f1_m: 0.6172 - val_loss: 0.0781 - val_acc: 0.9746 - val_precision_m: 0.7380 - val_recall_m: 0.4977 - val_f1_m: 0.5703\n",
      "Epoch 8/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0618 - acc: 0.9780 - precision_m: 0.7887 - recall_m: 0.5644 - f1_m: 0.6339\n",
      "Epoch 8: val_acc improved from 0.97456 to 0.97599, saving model to models/best_model_1_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0622 - acc: 0.9780 - precision_m: 0.7888 - recall_m: 0.5662 - f1_m: 0.6355 - val_loss: 0.0778 - val_acc: 0.9760 - val_precision_m: 0.7847 - val_recall_m: 0.4948 - val_f1_m: 0.5866\n",
      "Epoch 9/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0603 - acc: 0.9792 - precision_m: 0.8099 - recall_m: 0.5872 - f1_m: 0.6570\n",
      "Epoch 9: val_acc did not improve from 0.97599\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0602 - acc: 0.9793 - precision_m: 0.8077 - recall_m: 0.5851 - f1_m: 0.6552 - val_loss: 0.0834 - val_acc: 0.9748 - val_precision_m: 0.8185 - val_recall_m: 0.4262 - val_f1_m: 0.5403\n",
      "Epoch 10/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.0571 - acc: 0.9806 - precision_m: 0.8317 - recall_m: 0.6178 - f1_m: 0.6854\n",
      "Epoch 10: val_acc improved from 0.97599 to 0.97719, saving model to models/best_model_1_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0571 - acc: 0.9806 - precision_m: 0.8317 - recall_m: 0.6178 - f1_m: 0.6854 - val_loss: 0.0755 - val_acc: 0.9772 - val_precision_m: 0.7634 - val_recall_m: 0.5243 - val_f1_m: 0.6055\n",
      "Epoch 11/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0529 - acc: 0.9814 - precision_m: 0.8352 - recall_m: 0.6392 - f1_m: 0.7036\n",
      "Epoch 11: val_acc did not improve from 0.97719\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0533 - acc: 0.9812 - precision_m: 0.8339 - recall_m: 0.6353 - f1_m: 0.7004 - val_loss: 0.0782 - val_acc: 0.9747 - val_precision_m: 0.6525 - val_recall_m: 0.6747 - val_f1_m: 0.6465\n",
      "Epoch 12/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0503 - acc: 0.9827 - precision_m: 0.8453 - recall_m: 0.6682 - f1_m: 0.7262\n",
      "Epoch 12: val_acc did not improve from 0.97719\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0506 - acc: 0.9826 - precision_m: 0.8430 - recall_m: 0.6684 - f1_m: 0.7256 - val_loss: 0.0780 - val_acc: 0.9759 - val_precision_m: 0.7109 - val_recall_m: 0.5866 - val_f1_m: 0.6222\n",
      "Epoch 13/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0484 - acc: 0.9830 - precision_m: 0.8488 - recall_m: 0.6769 - f1_m: 0.7358\n",
      "Epoch 13: val_acc did not improve from 0.97719\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0483 - acc: 0.9830 - precision_m: 0.8479 - recall_m: 0.6761 - f1_m: 0.7352 - val_loss: 0.0746 - val_acc: 0.9756 - val_precision_m: 0.6825 - val_recall_m: 0.6207 - val_f1_m: 0.6317\n",
      "Epoch 14/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0483 - acc: 0.9827 - precision_m: 0.8432 - recall_m: 0.6784 - f1_m: 0.7284\n",
      "Epoch 14: val_acc did not improve from 0.97719\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0481 - acc: 0.9828 - precision_m: 0.8437 - recall_m: 0.6795 - f1_m: 0.7298 - val_loss: 0.0751 - val_acc: 0.9771 - val_precision_m: 0.7287 - val_recall_m: 0.5884 - val_f1_m: 0.6267\n",
      "Epoch 15/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0471 - acc: 0.9831 - precision_m: 0.8476 - recall_m: 0.6843 - f1_m: 0.7340\n",
      "Epoch 15: val_acc improved from 0.97719 to 0.97755, saving model to models/best_model_1_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0472 - acc: 0.9831 - precision_m: 0.8471 - recall_m: 0.6861 - f1_m: 0.7350 - val_loss: 0.0741 - val_acc: 0.9775 - val_precision_m: 0.7801 - val_recall_m: 0.5381 - val_f1_m: 0.6105\n",
      "Epoch 16/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9844 - precision_m: 0.8590 - recall_m: 0.7110 - f1_m: 0.7608\n",
      "Epoch 16: val_acc improved from 0.97755 to 0.97934, saving model to models/best_model_1_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0433 - acc: 0.9845 - precision_m: 0.8577 - recall_m: 0.7132 - f1_m: 0.7617 - val_loss: 0.0787 - val_acc: 0.9793 - val_precision_m: 0.8058 - val_recall_m: 0.5691 - val_f1_m: 0.6414\n",
      "Epoch 17/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9846 - precision_m: 0.8621 - recall_m: 0.7100 - f1_m: 0.7625\n",
      "Epoch 17: val_acc did not improve from 0.97934\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0426 - acc: 0.9846 - precision_m: 0.8626 - recall_m: 0.7101 - f1_m: 0.7629 - val_loss: 0.0762 - val_acc: 0.9753 - val_precision_m: 0.6461 - val_recall_m: 0.6610 - val_f1_m: 0.6330\n",
      "Epoch 18/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0404 - acc: 0.9853 - precision_m: 0.8611 - recall_m: 0.7358 - f1_m: 0.7758\n",
      "Epoch 18: val_acc did not improve from 0.97934\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0403 - acc: 0.9853 - precision_m: 0.8593 - recall_m: 0.7358 - f1_m: 0.7753 - val_loss: 0.1030 - val_acc: 0.9759 - val_precision_m: 0.8181 - val_recall_m: 0.4318 - val_f1_m: 0.5427\n",
      "Epoch 19/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9858 - precision_m: 0.8686 - recall_m: 0.7344 - f1_m: 0.7803\n",
      "Epoch 19: val_acc did not improve from 0.97934\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0383 - acc: 0.9858 - precision_m: 0.8699 - recall_m: 0.7340 - f1_m: 0.7806 - val_loss: 0.0838 - val_acc: 0.9787 - val_precision_m: 0.8526 - val_recall_m: 0.5210 - val_f1_m: 0.6275\n",
      "Epoch 20/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0399 - acc: 0.9861 - precision_m: 0.8734 - recall_m: 0.7527 - f1_m: 0.7919\n",
      "Epoch 20: val_acc did not improve from 0.97934\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0400 - acc: 0.9861 - precision_m: 0.8713 - recall_m: 0.7515 - f1_m: 0.7896 - val_loss: 0.0747 - val_acc: 0.9786 - val_precision_m: 0.7377 - val_recall_m: 0.6374 - val_f1_m: 0.6634\n",
      "Epoch 21/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0347 - acc: 0.9873 - precision_m: 0.8859 - recall_m: 0.7658 - f1_m: 0.8082\n",
      "Epoch 21: val_acc did not improve from 0.97934\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0346 - acc: 0.9874 - precision_m: 0.8868 - recall_m: 0.7654 - f1_m: 0.8086 - val_loss: 0.0877 - val_acc: 0.9774 - val_precision_m: 0.7483 - val_recall_m: 0.5645 - val_f1_m: 0.6180\n",
      "Epoch 22/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0355 - acc: 0.9872 - precision_m: 0.8810 - recall_m: 0.7738 - f1_m: 0.8082\n",
      "Epoch 22: val_acc did not improve from 0.97934\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0354 - acc: 0.9873 - precision_m: 0.8821 - recall_m: 0.7732 - f1_m: 0.8085 - val_loss: 0.0857 - val_acc: 0.9787 - val_precision_m: 0.7612 - val_recall_m: 0.5932 - val_f1_m: 0.6476\n",
      "Epoch 23/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9874 - precision_m: 0.8798 - recall_m: 0.7741 - f1_m: 0.8092\n",
      "Epoch 23: val_acc did not improve from 0.97934\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0338 - acc: 0.9874 - precision_m: 0.8784 - recall_m: 0.7753 - f1_m: 0.8092 - val_loss: 0.0892 - val_acc: 0.9781 - val_precision_m: 0.7670 - val_recall_m: 0.5734 - val_f1_m: 0.6296\n",
      "Epoch 24/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0312 - acc: 0.9883 - precision_m: 0.8874 - recall_m: 0.7878 - f1_m: 0.8223\n",
      "Epoch 24: val_acc did not improve from 0.97934\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0313 - acc: 0.9883 - precision_m: 0.8869 - recall_m: 0.7876 - f1_m: 0.8217 - val_loss: 0.0877 - val_acc: 0.9786 - val_precision_m: 0.7379 - val_recall_m: 0.6406 - val_f1_m: 0.6662\n",
      "Epoch 25/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9885 - precision_m: 0.8858 - recall_m: 0.8000 - f1_m: 0.8275\n",
      "Epoch 25: val_acc did not improve from 0.97934\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0314 - acc: 0.9885 - precision_m: 0.8862 - recall_m: 0.7972 - f1_m: 0.8258 - val_loss: 0.0863 - val_acc: 0.9781 - val_precision_m: 0.7907 - val_recall_m: 0.5770 - val_f1_m: 0.6425\n",
      "Epoch 26/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9895 - precision_m: 0.9087 - recall_m: 0.8045 - f1_m: 0.8410\n",
      "Epoch 26: val_acc did not improve from 0.97934\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0301 - acc: 0.9894 - precision_m: 0.9093 - recall_m: 0.8013 - f1_m: 0.8385 - val_loss: 0.0868 - val_acc: 0.9792 - val_precision_m: 0.7972 - val_recall_m: 0.6075 - val_f1_m: 0.6626\n",
      "Epoch 27/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.0290 - acc: 0.9891 - precision_m: 0.8972 - recall_m: 0.8036 - f1_m: 0.8350\n",
      "Epoch 27: val_acc did not improve from 0.97934\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0290 - acc: 0.9891 - precision_m: 0.8972 - recall_m: 0.8036 - f1_m: 0.8350 - val_loss: 0.0948 - val_acc: 0.9775 - val_precision_m: 0.7140 - val_recall_m: 0.6043 - val_f1_m: 0.6297\n",
      "Epoch 28/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0278 - acc: 0.9897 - precision_m: 0.9049 - recall_m: 0.8157 - f1_m: 0.8455\n",
      "Epoch 28: val_acc did not improve from 0.97934\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0278 - acc: 0.9897 - precision_m: 0.9059 - recall_m: 0.8147 - f1_m: 0.8454 - val_loss: 0.1043 - val_acc: 0.9789 - val_precision_m: 0.7977 - val_recall_m: 0.5724 - val_f1_m: 0.6483\n",
      "Epoch 29/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9899 - precision_m: 0.9083 - recall_m: 0.8242 - f1_m: 0.8511\n",
      "Epoch 29: val_acc did not improve from 0.97934\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0270 - acc: 0.9900 - precision_m: 0.9085 - recall_m: 0.8262 - f1_m: 0.8525 - val_loss: 0.1016 - val_acc: 0.9787 - val_precision_m: 0.7637 - val_recall_m: 0.6108 - val_f1_m: 0.6625\n",
      "Epoch 30/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9900 - precision_m: 0.9110 - recall_m: 0.8162 - f1_m: 0.8447\n",
      "Epoch 30: val_acc did not improve from 0.97934\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0275 - acc: 0.9900 - precision_m: 0.9102 - recall_m: 0.8159 - f1_m: 0.8441 - val_loss: 0.0914 - val_acc: 0.9779 - val_precision_m: 0.7093 - val_recall_m: 0.6311 - val_f1_m: 0.6479\n",
      "Score for fold 1: loss of 0.07865358144044876; acc of 97.93383479118347%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.051237430423498154; acc of 98.26105833053589%\n",
      "Test Precision: precision_m of 24.260564148426056%\n",
      "Test Recall: recall_m of 18.379302322864532%\n",
      "Test F1: f1_m of 19.992582499980927%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.1513 - acc: 0.9630 - precision_m: 0.0370 - recall_m: 0.0103 - f1_m: 0.0127\n",
      "Epoch 1: val_acc improved from -inf to 0.96336, saving model to models/best_model_1_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 3s 6ms/step - loss: 0.1513 - acc: 0.9630 - precision_m: 0.0370 - recall_m: 0.0103 - f1_m: 0.0127 - val_loss: 0.1248 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.0989 - acc: 0.9682 - precision_m: 0.5704 - recall_m: 0.1887 - f1_m: 0.2627\n",
      "Epoch 2: val_acc improved from 0.96336 to 0.96839, saving model to models/best_model_1_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0991 - acc: 0.9681 - precision_m: 0.5759 - recall_m: 0.1901 - f1_m: 0.2650 - val_loss: 0.0931 - val_acc: 0.9684 - val_precision_m: 0.4712 - val_recall_m: 0.1241 - val_f1_m: 0.1852\n",
      "Epoch 3/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0858 - acc: 0.9714 - precision_m: 0.6935 - recall_m: 0.3362 - f1_m: 0.4224\n",
      "Epoch 3: val_acc improved from 0.96839 to 0.97186, saving model to models/best_model_1_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0854 - acc: 0.9715 - precision_m: 0.6955 - recall_m: 0.3377 - f1_m: 0.4245 - val_loss: 0.0847 - val_acc: 0.9719 - val_precision_m: 0.7094 - val_recall_m: 0.3499 - val_f1_m: 0.4354\n",
      "Epoch 4/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0760 - acc: 0.9746 - precision_m: 0.7627 - recall_m: 0.4386 - f1_m: 0.5288\n",
      "Epoch 4: val_acc improved from 0.97186 to 0.97198, saving model to models/best_model_1_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0761 - acc: 0.9745 - precision_m: 0.7607 - recall_m: 0.4382 - f1_m: 0.5272 - val_loss: 0.0895 - val_acc: 0.9720 - val_precision_m: 0.8363 - val_recall_m: 0.2832 - val_f1_m: 0.3904\n",
      "Epoch 5/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.0719 - acc: 0.9753 - precision_m: 0.7703 - recall_m: 0.4669 - f1_m: 0.5508\n",
      "Epoch 5: val_acc improved from 0.97198 to 0.97485, saving model to models/best_model_1_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0719 - acc: 0.9753 - precision_m: 0.7703 - recall_m: 0.4669 - f1_m: 0.5508 - val_loss: 0.0773 - val_acc: 0.9749 - val_precision_m: 0.7782 - val_recall_m: 0.4425 - val_f1_m: 0.5258\n",
      "Epoch 6/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 0.9770 - precision_m: 0.7823 - recall_m: 0.5009 - f1_m: 0.5795\n",
      "Epoch 6: val_acc improved from 0.97485 to 0.97509, saving model to models/best_model_1_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0680 - acc: 0.9770 - precision_m: 0.7824 - recall_m: 0.5001 - f1_m: 0.5787 - val_loss: 0.0752 - val_acc: 0.9751 - val_precision_m: 0.7646 - val_recall_m: 0.4662 - val_f1_m: 0.5450\n",
      "Epoch 7/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9782 - precision_m: 0.8083 - recall_m: 0.5395 - f1_m: 0.6201\n",
      "Epoch 7: val_acc did not improve from 0.97509\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0638 - acc: 0.9782 - precision_m: 0.8095 - recall_m: 0.5406 - f1_m: 0.6214 - val_loss: 0.0753 - val_acc: 0.9750 - val_precision_m: 0.7310 - val_recall_m: 0.4615 - val_f1_m: 0.5322\n",
      "Epoch 8/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9793 - precision_m: 0.8092 - recall_m: 0.5667 - f1_m: 0.6421\n",
      "Epoch 8: val_acc improved from 0.97509 to 0.97557, saving model to models/best_model_1_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0605 - acc: 0.9792 - precision_m: 0.8079 - recall_m: 0.5663 - f1_m: 0.6413 - val_loss: 0.0788 - val_acc: 0.9756 - val_precision_m: 0.8297 - val_recall_m: 0.3705 - val_f1_m: 0.4771\n",
      "Epoch 9/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0574 - acc: 0.9797 - precision_m: 0.8098 - recall_m: 0.5753 - f1_m: 0.6492\n",
      "Epoch 9: val_acc did not improve from 0.97557\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0569 - acc: 0.9799 - precision_m: 0.8123 - recall_m: 0.5740 - f1_m: 0.6495 - val_loss: 0.0719 - val_acc: 0.9755 - val_precision_m: 0.6703 - val_recall_m: 0.6091 - val_f1_m: 0.6122\n",
      "Epoch 10/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0544 - acc: 0.9811 - precision_m: 0.8206 - recall_m: 0.6113 - f1_m: 0.6795\n",
      "Epoch 10: val_acc did not improve from 0.97557\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0545 - acc: 0.9812 - precision_m: 0.8199 - recall_m: 0.6153 - f1_m: 0.6817 - val_loss: 0.0849 - val_acc: 0.9747 - val_precision_m: 0.8590 - val_recall_m: 0.3378 - val_f1_m: 0.4588\n",
      "Epoch 11/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0537 - acc: 0.9809 - precision_m: 0.8232 - recall_m: 0.6106 - f1_m: 0.6758\n",
      "Epoch 11: val_acc improved from 0.97557 to 0.97677, saving model to models/best_model_1_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0537 - acc: 0.9809 - precision_m: 0.8243 - recall_m: 0.6112 - f1_m: 0.6767 - val_loss: 0.0740 - val_acc: 0.9768 - val_precision_m: 0.8624 - val_recall_m: 0.4211 - val_f1_m: 0.5367\n",
      "Epoch 12/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.0505 - acc: 0.9826 - precision_m: 0.8432 - recall_m: 0.6447 - f1_m: 0.7100\n",
      "Epoch 12: val_acc did not improve from 0.97677\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0504 - acc: 0.9826 - precision_m: 0.8433 - recall_m: 0.6459 - f1_m: 0.7108 - val_loss: 0.0766 - val_acc: 0.9763 - val_precision_m: 0.7917 - val_recall_m: 0.4530 - val_f1_m: 0.5391\n",
      "Epoch 13/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.0476 - acc: 0.9835 - precision_m: 0.8486 - recall_m: 0.6666 - f1_m: 0.7264\n",
      "Epoch 13: val_acc did not improve from 0.97677\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0476 - acc: 0.9835 - precision_m: 0.8486 - recall_m: 0.6666 - f1_m: 0.7264 - val_loss: 0.0706 - val_acc: 0.9766 - val_precision_m: 0.7073 - val_recall_m: 0.6005 - val_f1_m: 0.6238\n",
      "Epoch 14/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.0467 - acc: 0.9840 - precision_m: 0.8540 - recall_m: 0.6768 - f1_m: 0.7353\n",
      "Epoch 14: val_acc improved from 0.97677 to 0.97809, saving model to models/best_model_1_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0468 - acc: 0.9840 - precision_m: 0.8539 - recall_m: 0.6775 - f1_m: 0.7357 - val_loss: 0.0724 - val_acc: 0.9781 - val_precision_m: 0.7937 - val_recall_m: 0.5386 - val_f1_m: 0.6076\n",
      "Epoch 15/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9846 - precision_m: 0.8603 - recall_m: 0.6857 - f1_m: 0.7462\n",
      "Epoch 15: val_acc did not improve from 0.97809\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0453 - acc: 0.9845 - precision_m: 0.8581 - recall_m: 0.6829 - f1_m: 0.7437 - val_loss: 0.0736 - val_acc: 0.9766 - val_precision_m: 0.6743 - val_recall_m: 0.6086 - val_f1_m: 0.6151\n",
      "Epoch 16/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.0425 - acc: 0.9852 - precision_m: 0.8671 - recall_m: 0.7024 - f1_m: 0.7600\n",
      "Epoch 16: val_acc did not improve from 0.97809\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0425 - acc: 0.9852 - precision_m: 0.8671 - recall_m: 0.7024 - f1_m: 0.7600 - val_loss: 0.0758 - val_acc: 0.9772 - val_precision_m: 0.8133 - val_recall_m: 0.5052 - val_f1_m: 0.5848\n",
      "Epoch 17/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0411 - acc: 0.9858 - precision_m: 0.8674 - recall_m: 0.7242 - f1_m: 0.7748\n",
      "Epoch 17: val_acc did not improve from 0.97809\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0411 - acc: 0.9858 - precision_m: 0.8675 - recall_m: 0.7229 - f1_m: 0.7734 - val_loss: 0.0716 - val_acc: 0.9778 - val_precision_m: 0.7433 - val_recall_m: 0.5487 - val_f1_m: 0.6004\n",
      "Epoch 18/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9861 - precision_m: 0.8738 - recall_m: 0.7207 - f1_m: 0.7730\n",
      "Epoch 18: val_acc did not improve from 0.97809\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0398 - acc: 0.9861 - precision_m: 0.8734 - recall_m: 0.7212 - f1_m: 0.7732 - val_loss: 0.0794 - val_acc: 0.9780 - val_precision_m: 0.8161 - val_recall_m: 0.5174 - val_f1_m: 0.6029\n",
      "Epoch 19/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9866 - precision_m: 0.8765 - recall_m: 0.7331 - f1_m: 0.7816\n",
      "Epoch 19: val_acc improved from 0.97809 to 0.97857, saving model to models/best_model_1_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0388 - acc: 0.9867 - precision_m: 0.8774 - recall_m: 0.7332 - f1_m: 0.7821 - val_loss: 0.0742 - val_acc: 0.9786 - val_precision_m: 0.7802 - val_recall_m: 0.5795 - val_f1_m: 0.6356\n",
      "Epoch 20/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0378 - acc: 0.9871 - precision_m: 0.8834 - recall_m: 0.7501 - f1_m: 0.7930\n",
      "Epoch 20: val_acc improved from 0.97857 to 0.97869, saving model to models/best_model_1_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0378 - acc: 0.9871 - precision_m: 0.8817 - recall_m: 0.7513 - f1_m: 0.7934 - val_loss: 0.0750 - val_acc: 0.9787 - val_precision_m: 0.7596 - val_recall_m: 0.5991 - val_f1_m: 0.6500\n",
      "Epoch 21/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.0368 - acc: 0.9872 - precision_m: 0.8911 - recall_m: 0.7375 - f1_m: 0.7893\n",
      "Epoch 21: val_acc did not improve from 0.97869\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0368 - acc: 0.9872 - precision_m: 0.8911 - recall_m: 0.7375 - f1_m: 0.7893 - val_loss: 0.0733 - val_acc: 0.9761 - val_precision_m: 0.6551 - val_recall_m: 0.6260 - val_f1_m: 0.6163\n",
      "Epoch 22/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.0352 - acc: 0.9879 - precision_m: 0.8921 - recall_m: 0.7618 - f1_m: 0.8061\n",
      "Epoch 22: val_acc did not improve from 0.97869\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0353 - acc: 0.9878 - precision_m: 0.8915 - recall_m: 0.7623 - f1_m: 0.8061 - val_loss: 0.0790 - val_acc: 0.9749 - val_precision_m: 0.6160 - val_recall_m: 0.6625 - val_f1_m: 0.6145\n",
      "Epoch 23/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9881 - precision_m: 0.8878 - recall_m: 0.7693 - f1_m: 0.8098\n",
      "Epoch 23: val_acc did not improve from 0.97869\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0329 - acc: 0.9881 - precision_m: 0.8886 - recall_m: 0.7688 - f1_m: 0.8099 - val_loss: 0.0960 - val_acc: 0.9772 - val_precision_m: 0.8360 - val_recall_m: 0.4360 - val_f1_m: 0.5478\n",
      "Epoch 24/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9888 - precision_m: 0.9053 - recall_m: 0.7737 - f1_m: 0.8205\n",
      "Epoch 24: val_acc did not improve from 0.97869\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0327 - acc: 0.9888 - precision_m: 0.9059 - recall_m: 0.7737 - f1_m: 0.8209 - val_loss: 0.1032 - val_acc: 0.9776 - val_precision_m: 0.8361 - val_recall_m: 0.4626 - val_f1_m: 0.5694\n",
      "Epoch 25/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.0319 - acc: 0.9883 - precision_m: 0.8919 - recall_m: 0.7651 - f1_m: 0.8107\n",
      "Epoch 25: val_acc improved from 0.97869 to 0.97916, saving model to models/best_model_1_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0319 - acc: 0.9882 - precision_m: 0.8916 - recall_m: 0.7636 - f1_m: 0.8087 - val_loss: 0.0764 - val_acc: 0.9792 - val_precision_m: 0.7866 - val_recall_m: 0.5545 - val_f1_m: 0.6278\n",
      "Epoch 26/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.0311 - acc: 0.9889 - precision_m: 0.9059 - recall_m: 0.7813 - f1_m: 0.8253\n",
      "Epoch 26: val_acc did not improve from 0.97916\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0311 - acc: 0.9889 - precision_m: 0.9059 - recall_m: 0.7813 - f1_m: 0.8253 - val_loss: 0.0887 - val_acc: 0.9790 - val_precision_m: 0.8145 - val_recall_m: 0.5161 - val_f1_m: 0.6107\n",
      "Epoch 27/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0291 - acc: 0.9899 - precision_m: 0.9172 - recall_m: 0.8006 - f1_m: 0.8431\n",
      "Epoch 27: val_acc did not improve from 0.97916\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0291 - acc: 0.9900 - precision_m: 0.9178 - recall_m: 0.8012 - f1_m: 0.8439 - val_loss: 0.1069 - val_acc: 0.9786 - val_precision_m: 0.8248 - val_recall_m: 0.4935 - val_f1_m: 0.5938\n",
      "Epoch 28/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0277 - acc: 0.9898 - precision_m: 0.9038 - recall_m: 0.7968 - f1_m: 0.8334\n",
      "Epoch 28: val_acc did not improve from 0.97916\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0277 - acc: 0.9898 - precision_m: 0.9028 - recall_m: 0.7979 - f1_m: 0.8338 - val_loss: 0.0855 - val_acc: 0.9778 - val_precision_m: 0.7021 - val_recall_m: 0.6255 - val_f1_m: 0.6388\n",
      "Epoch 29/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9904 - precision_m: 0.9167 - recall_m: 0.8131 - f1_m: 0.8489\n",
      "Epoch 29: val_acc did not improve from 0.97916\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0272 - acc: 0.9904 - precision_m: 0.9172 - recall_m: 0.8126 - f1_m: 0.8489 - val_loss: 0.0923 - val_acc: 0.9789 - val_precision_m: 0.7765 - val_recall_m: 0.5541 - val_f1_m: 0.6233\n",
      "Epoch 30/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9905 - precision_m: 0.9174 - recall_m: 0.8226 - f1_m: 0.8551\n",
      "Epoch 30: val_acc did not improve from 0.97916\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0266 - acc: 0.9905 - precision_m: 0.9189 - recall_m: 0.8210 - f1_m: 0.8545 - val_loss: 0.0992 - val_acc: 0.9776 - val_precision_m: 0.8283 - val_recall_m: 0.4730 - val_f1_m: 0.5762\n",
      "Score for fold 2: loss of 0.07635778188705444; acc of 97.9164183139801%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.07432913780212402; acc of 97.71533012390137%\n",
      "Test Precision: precision_m of 29.585370421409607%\n",
      "Test Recall: recall_m of 22.675712406635284%\n",
      "Test F1: f1_m of 24.570707976818085%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.1450 - acc: 0.9636 - precision_m: 0.1133 - recall_m: 0.0217 - f1_m: 0.0344\n",
      "Epoch 1: val_acc improved from -inf to 0.96394, saving model to models/best_model_1_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 3s 5ms/step - loss: 0.1450 - acc: 0.9636 - precision_m: 0.1133 - recall_m: 0.0217 - f1_m: 0.0344 - val_loss: 0.1100 - val_acc: 0.9639 - val_precision_m: 0.1212 - val_recall_m: 0.0132 - val_f1_m: 0.0235\n",
      "Epoch 2/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.0977 - acc: 0.9685 - precision_m: 0.6455 - recall_m: 0.2565 - f1_m: 0.3366\n",
      "Epoch 2: val_acc improved from 0.96394 to 0.96730, saving model to models/best_model_1_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0977 - acc: 0.9685 - precision_m: 0.6455 - recall_m: 0.2565 - f1_m: 0.3366 - val_loss: 0.1009 - val_acc: 0.9673 - val_precision_m: 0.4394 - val_recall_m: 0.0964 - val_f1_m: 0.1513\n",
      "Epoch 3/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0825 - acc: 0.9724 - precision_m: 0.7442 - recall_m: 0.3836 - f1_m: 0.4748\n",
      "Epoch 3: val_acc improved from 0.96730 to 0.97233, saving model to models/best_model_1_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0825 - acc: 0.9724 - precision_m: 0.7442 - recall_m: 0.3837 - f1_m: 0.4753 - val_loss: 0.0812 - val_acc: 0.9723 - val_precision_m: 0.6717 - val_recall_m: 0.4298 - val_f1_m: 0.4982\n",
      "Epoch 4/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.0745 - acc: 0.9746 - precision_m: 0.7618 - recall_m: 0.4600 - f1_m: 0.5436\n",
      "Epoch 4: val_acc improved from 0.97233 to 0.97556, saving model to models/best_model_1_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0745 - acc: 0.9746 - precision_m: 0.7618 - recall_m: 0.4600 - f1_m: 0.5436 - val_loss: 0.0757 - val_acc: 0.9756 - val_precision_m: 0.7267 - val_recall_m: 0.4357 - val_f1_m: 0.5209\n",
      "Epoch 5/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0677 - acc: 0.9767 - precision_m: 0.7845 - recall_m: 0.5046 - f1_m: 0.5840\n",
      "Epoch 5: val_acc did not improve from 0.97556\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0682 - acc: 0.9766 - precision_m: 0.7864 - recall_m: 0.5041 - f1_m: 0.5849 - val_loss: 0.0735 - val_acc: 0.9753 - val_precision_m: 0.7453 - val_recall_m: 0.3823 - val_f1_m: 0.4872\n",
      "Epoch 6/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0639 - acc: 0.9783 - precision_m: 0.7965 - recall_m: 0.5496 - f1_m: 0.6243\n",
      "Epoch 6: val_acc did not improve from 0.97556\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0641 - acc: 0.9782 - precision_m: 0.7974 - recall_m: 0.5492 - f1_m: 0.6246 - val_loss: 0.0759 - val_acc: 0.9751 - val_precision_m: 0.6998 - val_recall_m: 0.3497 - val_f1_m: 0.4520\n",
      "Epoch 7/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9786 - precision_m: 0.8148 - recall_m: 0.5562 - f1_m: 0.6308\n",
      "Epoch 7: val_acc did not improve from 0.97556\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0605 - acc: 0.9786 - precision_m: 0.8137 - recall_m: 0.5569 - f1_m: 0.6307 - val_loss: 0.0695 - val_acc: 0.9752 - val_precision_m: 0.6437 - val_recall_m: 0.5463 - val_f1_m: 0.5739\n",
      "Epoch 8/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.0558 - acc: 0.9802 - precision_m: 0.8212 - recall_m: 0.5996 - f1_m: 0.6724\n",
      "Epoch 8: val_acc improved from 0.97556 to 0.97724, saving model to models/best_model_1_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0556 - acc: 0.9803 - precision_m: 0.8213 - recall_m: 0.6011 - f1_m: 0.6730 - val_loss: 0.0668 - val_acc: 0.9772 - val_precision_m: 0.7202 - val_recall_m: 0.5599 - val_f1_m: 0.6163\n",
      "Epoch 9/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0534 - acc: 0.9811 - precision_m: 0.8284 - recall_m: 0.6259 - f1_m: 0.6912\n",
      "Epoch 9: val_acc did not improve from 0.97724\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0534 - acc: 0.9811 - precision_m: 0.8288 - recall_m: 0.6251 - f1_m: 0.6911 - val_loss: 0.0666 - val_acc: 0.9771 - val_precision_m: 0.6952 - val_recall_m: 0.5519 - val_f1_m: 0.5985\n",
      "Epoch 10/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9823 - precision_m: 0.8394 - recall_m: 0.6509 - f1_m: 0.7128\n",
      "Epoch 10: val_acc did not improve from 0.97724\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0505 - acc: 0.9822 - precision_m: 0.8385 - recall_m: 0.6518 - f1_m: 0.7129 - val_loss: 0.0723 - val_acc: 0.9769 - val_precision_m: 0.7823 - val_recall_m: 0.4807 - val_f1_m: 0.5777\n",
      "Epoch 11/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0479 - acc: 0.9828 - precision_m: 0.8494 - recall_m: 0.6523 - f1_m: 0.7195\n",
      "Epoch 11: val_acc did not improve from 0.97724\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0483 - acc: 0.9827 - precision_m: 0.8500 - recall_m: 0.6522 - f1_m: 0.7186 - val_loss: 0.0738 - val_acc: 0.9769 - val_precision_m: 0.8142 - val_recall_m: 0.4394 - val_f1_m: 0.5520\n",
      "Epoch 12/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.0456 - acc: 0.9840 - precision_m: 0.8494 - recall_m: 0.6894 - f1_m: 0.7454\n",
      "Epoch 12: val_acc did not improve from 0.97724\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0457 - acc: 0.9839 - precision_m: 0.8486 - recall_m: 0.6865 - f1_m: 0.7427 - val_loss: 0.0673 - val_acc: 0.9772 - val_precision_m: 0.7868 - val_recall_m: 0.5029 - val_f1_m: 0.5864\n",
      "Epoch 13/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9840 - precision_m: 0.8550 - recall_m: 0.6938 - f1_m: 0.7450\n",
      "Epoch 13: val_acc improved from 0.97724 to 0.97772, saving model to models/best_model_1_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0442 - acc: 0.9840 - precision_m: 0.8560 - recall_m: 0.6944 - f1_m: 0.7458 - val_loss: 0.0737 - val_acc: 0.9777 - val_precision_m: 0.7333 - val_recall_m: 0.5578 - val_f1_m: 0.6169\n",
      "Epoch 14/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0422 - acc: 0.9846 - precision_m: 0.8510 - recall_m: 0.7184 - f1_m: 0.7603\n",
      "Epoch 14: val_acc improved from 0.97772 to 0.97844, saving model to models/best_model_1_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0421 - acc: 0.9846 - precision_m: 0.8516 - recall_m: 0.7200 - f1_m: 0.7615 - val_loss: 0.0851 - val_acc: 0.9784 - val_precision_m: 0.8250 - val_recall_m: 0.4417 - val_f1_m: 0.5518\n",
      "Epoch 15/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.0394 - acc: 0.9858 - precision_m: 0.8687 - recall_m: 0.7379 - f1_m: 0.7813\n",
      "Epoch 15: val_acc improved from 0.97844 to 0.97868, saving model to models/best_model_1_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0397 - acc: 0.9858 - precision_m: 0.8660 - recall_m: 0.7349 - f1_m: 0.7784 - val_loss: 0.0708 - val_acc: 0.9787 - val_precision_m: 0.7228 - val_recall_m: 0.6203 - val_f1_m: 0.6481\n",
      "Epoch 16/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0387 - acc: 0.9859 - precision_m: 0.8735 - recall_m: 0.7347 - f1_m: 0.7795\n",
      "Epoch 16: val_acc improved from 0.97868 to 0.97880, saving model to models/best_model_1_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0388 - acc: 0.9859 - precision_m: 0.8719 - recall_m: 0.7334 - f1_m: 0.7783 - val_loss: 0.0663 - val_acc: 0.9788 - val_precision_m: 0.7240 - val_recall_m: 0.6145 - val_f1_m: 0.6495\n",
      "Epoch 17/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0357 - acc: 0.9869 - precision_m: 0.8817 - recall_m: 0.7580 - f1_m: 0.8004\n",
      "Epoch 17: val_acc improved from 0.97880 to 0.98131, saving model to models/best_model_1_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0355 - acc: 0.9870 - precision_m: 0.8820 - recall_m: 0.7576 - f1_m: 0.8004 - val_loss: 0.0724 - val_acc: 0.9813 - val_precision_m: 0.8090 - val_recall_m: 0.6001 - val_f1_m: 0.6729\n",
      "Epoch 18/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0355 - acc: 0.9874 - precision_m: 0.8813 - recall_m: 0.7689 - f1_m: 0.8048\n",
      "Epoch 18: val_acc did not improve from 0.98131\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0356 - acc: 0.9874 - precision_m: 0.8812 - recall_m: 0.7695 - f1_m: 0.8051 - val_loss: 0.0682 - val_acc: 0.9789 - val_precision_m: 0.7069 - val_recall_m: 0.6322 - val_f1_m: 0.6459\n",
      "Epoch 19/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9879 - precision_m: 0.8851 - recall_m: 0.7792 - f1_m: 0.8155\n",
      "Epoch 19: val_acc did not improve from 0.98131\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0330 - acc: 0.9880 - precision_m: 0.8862 - recall_m: 0.7797 - f1_m: 0.8164 - val_loss: 0.0734 - val_acc: 0.9793 - val_precision_m: 0.7323 - val_recall_m: 0.5962 - val_f1_m: 0.6431\n",
      "Epoch 20/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.0311 - acc: 0.9886 - precision_m: 0.8842 - recall_m: 0.7970 - f1_m: 0.8254\n",
      "Epoch 20: val_acc did not improve from 0.98131\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0311 - acc: 0.9886 - precision_m: 0.8842 - recall_m: 0.7970 - f1_m: 0.8254 - val_loss: 0.0725 - val_acc: 0.9801 - val_precision_m: 0.7952 - val_recall_m: 0.5806 - val_f1_m: 0.6546\n",
      "Epoch 21/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0312 - acc: 0.9886 - precision_m: 0.8886 - recall_m: 0.7943 - f1_m: 0.8256\n",
      "Epoch 21: val_acc did not improve from 0.98131\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0314 - acc: 0.9886 - precision_m: 0.8888 - recall_m: 0.7950 - f1_m: 0.8261 - val_loss: 0.0728 - val_acc: 0.9781 - val_precision_m: 0.6908 - val_recall_m: 0.6862 - val_f1_m: 0.6786\n",
      "Epoch 22/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0285 - acc: 0.9892 - precision_m: 0.8992 - recall_m: 0.8057 - f1_m: 0.8372\n",
      "Epoch 22: val_acc did not improve from 0.98131\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0285 - acc: 0.9893 - precision_m: 0.9008 - recall_m: 0.8084 - f1_m: 0.8396 - val_loss: 0.0795 - val_acc: 0.9790 - val_precision_m: 0.7484 - val_recall_m: 0.5833 - val_f1_m: 0.6316\n",
      "Epoch 23/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9905 - precision_m: 0.9171 - recall_m: 0.8206 - f1_m: 0.8554\n",
      "Epoch 23: val_acc did not improve from 0.98131\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0270 - acc: 0.9905 - precision_m: 0.9168 - recall_m: 0.8227 - f1_m: 0.8564 - val_loss: 0.0873 - val_acc: 0.9789 - val_precision_m: 0.7584 - val_recall_m: 0.5852 - val_f1_m: 0.6342\n",
      "Epoch 24/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9903 - precision_m: 0.8960 - recall_m: 0.8230 - f1_m: 0.8486\n",
      "Epoch 24: val_acc did not improve from 0.98131\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0255 - acc: 0.9903 - precision_m: 0.8961 - recall_m: 0.8224 - f1_m: 0.8482 - val_loss: 0.0907 - val_acc: 0.9787 - val_precision_m: 0.7648 - val_recall_m: 0.5538 - val_f1_m: 0.6115\n",
      "Epoch 25/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0263 - acc: 0.9902 - precision_m: 0.9010 - recall_m: 0.8305 - f1_m: 0.8509\n",
      "Epoch 25: val_acc did not improve from 0.98131\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0262 - acc: 0.9902 - precision_m: 0.9001 - recall_m: 0.8305 - f1_m: 0.8506 - val_loss: 0.0800 - val_acc: 0.9787 - val_precision_m: 0.7551 - val_recall_m: 0.5799 - val_f1_m: 0.6406\n",
      "Epoch 26/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.0245 - acc: 0.9906 - precision_m: 0.9119 - recall_m: 0.8382 - f1_m: 0.8602\n",
      "Epoch 26: val_acc did not improve from 0.98131\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0244 - acc: 0.9907 - precision_m: 0.9118 - recall_m: 0.8401 - f1_m: 0.8613 - val_loss: 0.0849 - val_acc: 0.9807 - val_precision_m: 0.7441 - val_recall_m: 0.6440 - val_f1_m: 0.6811\n",
      "Epoch 27/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9921 - precision_m: 0.9182 - recall_m: 0.8644 - f1_m: 0.8824\n",
      "Epoch 27: val_acc did not improve from 0.98131\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0220 - acc: 0.9920 - precision_m: 0.9159 - recall_m: 0.8642 - f1_m: 0.8812 - val_loss: 0.0790 - val_acc: 0.9800 - val_precision_m: 0.7295 - val_recall_m: 0.6716 - val_f1_m: 0.6829\n",
      "Epoch 28/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9917 - precision_m: 0.9139 - recall_m: 0.8515 - f1_m: 0.8729\n",
      "Epoch 28: val_acc did not improve from 0.98131\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0212 - acc: 0.9917 - precision_m: 0.9148 - recall_m: 0.8516 - f1_m: 0.8734 - val_loss: 0.0788 - val_acc: 0.9796 - val_precision_m: 0.7296 - val_recall_m: 0.6568 - val_f1_m: 0.6756\n",
      "Epoch 29/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9923 - precision_m: 0.9265 - recall_m: 0.8611 - f1_m: 0.8830\n",
      "Epoch 29: val_acc did not improve from 0.98131\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0202 - acc: 0.9922 - precision_m: 0.9251 - recall_m: 0.8617 - f1_m: 0.8824 - val_loss: 0.0909 - val_acc: 0.9768 - val_precision_m: 0.6359 - val_recall_m: 0.7030 - val_f1_m: 0.6550\n",
      "Epoch 30/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9926 - precision_m: 0.9245 - recall_m: 0.8724 - f1_m: 0.8895\n",
      "Epoch 30: val_acc did not improve from 0.98131\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0202 - acc: 0.9925 - precision_m: 0.9253 - recall_m: 0.8694 - f1_m: 0.8879 - val_loss: 0.1090 - val_acc: 0.9802 - val_precision_m: 0.7745 - val_recall_m: 0.5606 - val_f1_m: 0.6321\n",
      "Score for fold 3: loss of 0.0724339634180069; acc of 98.13128709793091%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.06933111697435379; acc of 98.03774952888489%\n",
      "Test Precision: precision_m of 28.061223030090332%\n",
      "Test Recall: recall_m of 21.725380420684814%\n",
      "Test F1: f1_m of 23.5274538397789%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1403 - acc: 0.9639 - precision_m: 0.0632 - recall_m: 0.0107 - f1_m: 0.0169    \n",
      "Epoch 1: val_acc improved from -inf to 0.96179, saving model to models/best_model_1_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 3s 5ms/step - loss: 0.1403 - acc: 0.9639 - precision_m: 0.0632 - recall_m: 0.0107 - f1_m: 0.0169 - val_loss: 0.1143 - val_acc: 0.9618 - val_precision_m: 0.1111 - val_recall_m: 0.0145 - val_f1_m: 0.0248\n",
      "Epoch 2/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0947 - acc: 0.9687 - precision_m: 0.6102 - recall_m: 0.2080 - f1_m: 0.2884\n",
      "Epoch 2: val_acc improved from 0.96179 to 0.96525, saving model to models/best_model_1_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0945 - acc: 0.9688 - precision_m: 0.6074 - recall_m: 0.2097 - f1_m: 0.2894 - val_loss: 0.1124 - val_acc: 0.9653 - val_precision_m: 0.4828 - val_recall_m: 0.1160 - val_f1_m: 0.1741\n",
      "Epoch 3/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0816 - acc: 0.9731 - precision_m: 0.7380 - recall_m: 0.3917 - f1_m: 0.4840\n",
      "Epoch 3: val_acc improved from 0.96525 to 0.96848, saving model to models/best_model_1_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0814 - acc: 0.9731 - precision_m: 0.7355 - recall_m: 0.3922 - f1_m: 0.4837 - val_loss: 0.0954 - val_acc: 0.9685 - val_precision_m: 0.5609 - val_recall_m: 0.5419 - val_f1_m: 0.5273\n",
      "Epoch 4/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0732 - acc: 0.9745 - precision_m: 0.7269 - recall_m: 0.4495 - f1_m: 0.5254\n",
      "Epoch 4: val_acc improved from 0.96848 to 0.97266, saving model to models/best_model_1_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0732 - acc: 0.9746 - precision_m: 0.7253 - recall_m: 0.4479 - f1_m: 0.5241 - val_loss: 0.0872 - val_acc: 0.9727 - val_precision_m: 0.7873 - val_recall_m: 0.3526 - val_f1_m: 0.4503\n",
      "Epoch 5/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0691 - acc: 0.9766 - precision_m: 0.7635 - recall_m: 0.4981 - f1_m: 0.5765\n",
      "Epoch 5: val_acc improved from 0.97266 to 0.97325, saving model to models/best_model_1_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0691 - acc: 0.9766 - precision_m: 0.7610 - recall_m: 0.4966 - f1_m: 0.5748 - val_loss: 0.0803 - val_acc: 0.9733 - val_precision_m: 0.6490 - val_recall_m: 0.5634 - val_f1_m: 0.5786\n",
      "Epoch 6/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0647 - acc: 0.9776 - precision_m: 0.7740 - recall_m: 0.5287 - f1_m: 0.6025\n",
      "Epoch 6: val_acc did not improve from 0.97325\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0647 - acc: 0.9777 - precision_m: 0.7731 - recall_m: 0.5269 - f1_m: 0.6011 - val_loss: 0.1632 - val_acc: 0.9305 - val_precision_m: 0.3230 - val_recall_m: 0.7754 - val_f1_m: 0.4362\n",
      "Epoch 7/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0688 - acc: 0.9763 - precision_m: 0.7842 - recall_m: 0.5050 - f1_m: 0.5814\n",
      "Epoch 7: val_acc did not improve from 0.97325\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0687 - acc: 0.9763 - precision_m: 0.7825 - recall_m: 0.5033 - f1_m: 0.5797 - val_loss: 0.1107 - val_acc: 0.9713 - val_precision_m: 0.7532 - val_recall_m: 0.2697 - val_f1_m: 0.3718\n",
      "Epoch 8/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9789 - precision_m: 0.7998 - recall_m: 0.5575 - f1_m: 0.6290\n",
      "Epoch 8: val_acc improved from 0.97325 to 0.97660, saving model to models/best_model_1_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0603 - acc: 0.9789 - precision_m: 0.7947 - recall_m: 0.5546 - f1_m: 0.6256 - val_loss: 0.0739 - val_acc: 0.9766 - val_precision_m: 0.7867 - val_recall_m: 0.4918 - val_f1_m: 0.5729\n",
      "Epoch 9/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0548 - acc: 0.9809 - precision_m: 0.8129 - recall_m: 0.6100 - f1_m: 0.6753\n",
      "Epoch 9: val_acc did not improve from 0.97660\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0548 - acc: 0.9809 - precision_m: 0.8096 - recall_m: 0.6072 - f1_m: 0.6724 - val_loss: 0.0793 - val_acc: 0.9727 - val_precision_m: 0.6299 - val_recall_m: 0.6482 - val_f1_m: 0.6204\n",
      "Epoch 10/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0523 - acc: 0.9820 - precision_m: 0.8282 - recall_m: 0.6432 - f1_m: 0.7023\n",
      "Epoch 10: val_acc improved from 0.97660 to 0.97707, saving model to models/best_model_1_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0522 - acc: 0.9820 - precision_m: 0.8257 - recall_m: 0.6426 - f1_m: 0.7011 - val_loss: 0.0736 - val_acc: 0.9771 - val_precision_m: 0.7324 - val_recall_m: 0.5813 - val_f1_m: 0.6190\n",
      "Epoch 11/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0495 - acc: 0.9828 - precision_m: 0.8352 - recall_m: 0.6427 - f1_m: 0.7078\n",
      "Epoch 11: val_acc improved from 0.97707 to 0.97719, saving model to models/best_model_1_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0497 - acc: 0.9827 - precision_m: 0.8308 - recall_m: 0.6388 - f1_m: 0.7037 - val_loss: 0.0717 - val_acc: 0.9772 - val_precision_m: 0.7587 - val_recall_m: 0.5304 - val_f1_m: 0.5974\n",
      "Epoch 12/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0484 - acc: 0.9832 - precision_m: 0.8457 - recall_m: 0.6608 - f1_m: 0.7194\n",
      "Epoch 12: val_acc improved from 0.97719 to 0.97755, saving model to models/best_model_1_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0485 - acc: 0.9831 - precision_m: 0.8437 - recall_m: 0.6620 - f1_m: 0.7192 - val_loss: 0.0702 - val_acc: 0.9776 - val_precision_m: 0.7200 - val_recall_m: 0.6385 - val_f1_m: 0.6551\n",
      "Epoch 13/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0470 - acc: 0.9839 - precision_m: 0.8631 - recall_m: 0.6751 - f1_m: 0.7373\n",
      "Epoch 13: val_acc improved from 0.97755 to 0.97922, saving model to models/best_model_1_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0467 - acc: 0.9839 - precision_m: 0.8612 - recall_m: 0.6711 - f1_m: 0.7344 - val_loss: 0.0718 - val_acc: 0.9792 - val_precision_m: 0.7841 - val_recall_m: 0.5524 - val_f1_m: 0.6173\n",
      "Epoch 14/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9842 - precision_m: 0.8493 - recall_m: 0.6976 - f1_m: 0.7461\n",
      "Epoch 14: val_acc did not improve from 0.97922\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0449 - acc: 0.9843 - precision_m: 0.8477 - recall_m: 0.6983 - f1_m: 0.7459 - val_loss: 0.0907 - val_acc: 0.9768 - val_precision_m: 0.8422 - val_recall_m: 0.4540 - val_f1_m: 0.5510\n",
      "Epoch 15/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0433 - acc: 0.9846 - precision_m: 0.8452 - recall_m: 0.7002 - f1_m: 0.7460\n",
      "Epoch 15: val_acc did not improve from 0.97922\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0433 - acc: 0.9845 - precision_m: 0.8409 - recall_m: 0.6974 - f1_m: 0.7428 - val_loss: 0.0940 - val_acc: 0.9774 - val_precision_m: 0.8328 - val_recall_m: 0.4721 - val_f1_m: 0.5669\n",
      "Epoch 16/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9857 - precision_m: 0.8733 - recall_m: 0.7136 - f1_m: 0.7666\n",
      "Epoch 16: val_acc improved from 0.97922 to 0.97934, saving model to models/best_model_1_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0416 - acc: 0.9856 - precision_m: 0.8678 - recall_m: 0.7092 - f1_m: 0.7621 - val_loss: 0.0740 - val_acc: 0.9793 - val_precision_m: 0.7628 - val_recall_m: 0.6052 - val_f1_m: 0.6489\n",
      "Epoch 17/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9865 - precision_m: 0.8782 - recall_m: 0.7299 - f1_m: 0.7800\n",
      "Epoch 17: val_acc did not improve from 0.97934\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0390 - acc: 0.9865 - precision_m: 0.8756 - recall_m: 0.7279 - f1_m: 0.7779 - val_loss: 0.0839 - val_acc: 0.9765 - val_precision_m: 0.8156 - val_recall_m: 0.4507 - val_f1_m: 0.5471\n",
      "Epoch 18/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0372 - acc: 0.9870 - precision_m: 0.8793 - recall_m: 0.7457 - f1_m: 0.7913\n",
      "Epoch 18: val_acc did not improve from 0.97934\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0374 - acc: 0.9869 - precision_m: 0.8775 - recall_m: 0.7490 - f1_m: 0.7925 - val_loss: 0.0786 - val_acc: 0.9789 - val_precision_m: 0.7132 - val_recall_m: 0.6736 - val_f1_m: 0.6715\n",
      "Epoch 19/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9864 - precision_m: 0.8654 - recall_m: 0.7409 - f1_m: 0.7824\n",
      "Epoch 19: val_acc did not improve from 0.97934\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0383 - acc: 0.9865 - precision_m: 0.8624 - recall_m: 0.7405 - f1_m: 0.7811 - val_loss: 0.0950 - val_acc: 0.9767 - val_precision_m: 0.8216 - val_recall_m: 0.4706 - val_f1_m: 0.5624\n",
      "Epoch 20/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0346 - acc: 0.9875 - precision_m: 0.8806 - recall_m: 0.7515 - f1_m: 0.7963\n",
      "Epoch 20: val_acc did not improve from 0.97934\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0347 - acc: 0.9875 - precision_m: 0.8785 - recall_m: 0.7486 - f1_m: 0.7939 - val_loss: 0.0801 - val_acc: 0.9748 - val_precision_m: 0.6431 - val_recall_m: 0.6780 - val_f1_m: 0.6377\n",
      "Epoch 21/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0332 - acc: 0.9880 - precision_m: 0.8869 - recall_m: 0.7686 - f1_m: 0.8072\n",
      "Epoch 21: val_acc improved from 0.97934 to 0.98030, saving model to models/best_model_1_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0331 - acc: 0.9880 - precision_m: 0.8836 - recall_m: 0.7647 - f1_m: 0.8037 - val_loss: 0.0756 - val_acc: 0.9803 - val_precision_m: 0.7396 - val_recall_m: 0.6646 - val_f1_m: 0.6809\n",
      "Epoch 22/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0342 - acc: 0.9876 - precision_m: 0.8799 - recall_m: 0.7660 - f1_m: 0.8042\n",
      "Epoch 22: val_acc did not improve from 0.98030\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0343 - acc: 0.9877 - precision_m: 0.8770 - recall_m: 0.7652 - f1_m: 0.8028 - val_loss: 0.0748 - val_acc: 0.9790 - val_precision_m: 0.7185 - val_recall_m: 0.6527 - val_f1_m: 0.6654\n",
      "Epoch 23/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9883 - precision_m: 0.8765 - recall_m: 0.7654 - f1_m: 0.8045\n",
      "Epoch 23: val_acc did not improve from 0.98030\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0311 - acc: 0.9883 - precision_m: 0.8746 - recall_m: 0.7640 - f1_m: 0.8030 - val_loss: 0.1159 - val_acc: 0.9563 - val_precision_m: 0.4416 - val_recall_m: 0.7868 - val_f1_m: 0.5415\n",
      "Epoch 24/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0577 - acc: 0.9803 - precision_m: 0.8147 - recall_m: 0.5693 - f1_m: 0.6369\n",
      "Epoch 24: val_acc did not improve from 0.98030\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0573 - acc: 0.9804 - precision_m: 0.8132 - recall_m: 0.5697 - f1_m: 0.6370 - val_loss: 0.0743 - val_acc: 0.9802 - val_precision_m: 0.7379 - val_recall_m: 0.6195 - val_f1_m: 0.6481\n",
      "Epoch 25/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 0.9880 - precision_m: 0.8877 - recall_m: 0.7640 - f1_m: 0.8061\n",
      "Epoch 25: val_acc did not improve from 0.98030\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0333 - acc: 0.9881 - precision_m: 0.8854 - recall_m: 0.7621 - f1_m: 0.8042 - val_loss: 0.0827 - val_acc: 0.9798 - val_precision_m: 0.7513 - val_recall_m: 0.5924 - val_f1_m: 0.6324\n",
      "Epoch 26/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9890 - precision_m: 0.9025 - recall_m: 0.7836 - f1_m: 0.8232\n",
      "Epoch 26: val_acc did not improve from 0.98030\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0302 - acc: 0.9890 - precision_m: 0.9001 - recall_m: 0.7816 - f1_m: 0.8211 - val_loss: 0.0928 - val_acc: 0.9796 - val_precision_m: 0.7813 - val_recall_m: 0.5874 - val_f1_m: 0.6433\n",
      "Epoch 27/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9903 - precision_m: 0.9048 - recall_m: 0.8154 - f1_m: 0.8455\n",
      "Epoch 27: val_acc improved from 0.98030 to 0.98101, saving model to models/best_model_1_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0273 - acc: 0.9903 - precision_m: 0.9059 - recall_m: 0.8173 - f1_m: 0.8472 - val_loss: 0.0970 - val_acc: 0.9810 - val_precision_m: 0.7920 - val_recall_m: 0.6212 - val_f1_m: 0.6699\n",
      "Epoch 28/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0265 - acc: 0.9902 - precision_m: 0.9114 - recall_m: 0.8129 - f1_m: 0.8454\n",
      "Epoch 28: val_acc did not improve from 0.98101\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0269 - acc: 0.9900 - precision_m: 0.9056 - recall_m: 0.8118 - f1_m: 0.8418 - val_loss: 0.1028 - val_acc: 0.9778 - val_precision_m: 0.8283 - val_recall_m: 0.5230 - val_f1_m: 0.6050\n",
      "Epoch 29/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9911 - precision_m: 0.9208 - recall_m: 0.8201 - f1_m: 0.8565\n",
      "Epoch 29: val_acc did not improve from 0.98101\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0247 - acc: 0.9911 - precision_m: 0.9175 - recall_m: 0.8174 - f1_m: 0.8535 - val_loss: 0.0917 - val_acc: 0.9793 - val_precision_m: 0.7499 - val_recall_m: 0.6218 - val_f1_m: 0.6506\n",
      "Epoch 30/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9913 - precision_m: 0.9174 - recall_m: 0.8359 - f1_m: 0.8639\n",
      "Epoch 30: val_acc did not improve from 0.98101\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0237 - acc: 0.9913 - precision_m: 0.9143 - recall_m: 0.8333 - f1_m: 0.8612 - val_loss: 0.0865 - val_acc: 0.9780 - val_precision_m: 0.7429 - val_recall_m: 0.6174 - val_f1_m: 0.6490\n",
      "Score for fold 4: loss of 0.09699736535549164; acc of 98.10149073600769%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.105609230697155; acc of 97.53326773643494%\n",
      "Test Precision: precision_m of 31.135687232017517%\n",
      "Test Recall: recall_m of 25.165820121765137%\n",
      "Test F1: f1_m of 26.554447412490845%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.1759 - acc: 0.9566 - precision_m: 0.0182 - recall_m: 0.0112 - f1_m: 0.0057\n",
      "Epoch 1: val_acc improved from -inf to 0.96259, saving model to models/best_model_1_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 3s 5ms/step - loss: 0.1759 - acc: 0.9566 - precision_m: 0.0182 - recall_m: 0.0112 - f1_m: 0.0057 - val_loss: 0.1287 - val_acc: 0.9626 - val_precision_m: 0.1035 - val_recall_m: 0.0160 - val_f1_m: 0.0269\n",
      "Epoch 2/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.1110 - acc: 0.9659 - precision_m: 0.4788 - recall_m: 0.1466 - f1_m: 0.2064\n",
      "Epoch 2: val_acc improved from 0.96259 to 0.96773, saving model to models/best_model_1_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.1111 - acc: 0.9659 - precision_m: 0.4788 - recall_m: 0.1474 - f1_m: 0.2076 - val_loss: 0.0974 - val_acc: 0.9677 - val_precision_m: 0.6819 - val_recall_m: 0.2451 - val_f1_m: 0.3347\n",
      "Epoch 3/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0913 - acc: 0.9703 - precision_m: 0.6821 - recall_m: 0.3145 - f1_m: 0.4034\n",
      "Epoch 3: val_acc improved from 0.96773 to 0.97191, saving model to models/best_model_1_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0912 - acc: 0.9704 - precision_m: 0.6861 - recall_m: 0.3163 - f1_m: 0.4054 - val_loss: 0.0894 - val_acc: 0.9719 - val_precision_m: 0.7325 - val_recall_m: 0.4175 - val_f1_m: 0.4985\n",
      "Epoch 4/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0821 - acc: 0.9722 - precision_m: 0.7160 - recall_m: 0.3914 - f1_m: 0.4776\n",
      "Epoch 4: val_acc did not improve from 0.97191\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0819 - acc: 0.9724 - precision_m: 0.7173 - recall_m: 0.3963 - f1_m: 0.4818 - val_loss: 0.0921 - val_acc: 0.9713 - val_precision_m: 0.7509 - val_recall_m: 0.3060 - val_f1_m: 0.4075\n",
      "Epoch 5/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0771 - acc: 0.9742 - precision_m: 0.7600 - recall_m: 0.4520 - f1_m: 0.5338\n",
      "Epoch 5: val_acc did not improve from 0.97191\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0767 - acc: 0.9743 - precision_m: 0.7633 - recall_m: 0.4509 - f1_m: 0.5337 - val_loss: 0.0954 - val_acc: 0.9706 - val_precision_m: 0.8153 - val_recall_m: 0.2632 - val_f1_m: 0.3680\n",
      "Epoch 6/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0710 - acc: 0.9760 - precision_m: 0.7842 - recall_m: 0.4931 - f1_m: 0.5763\n",
      "Epoch 6: val_acc improved from 0.97191 to 0.97299, saving model to models/best_model_1_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0708 - acc: 0.9760 - precision_m: 0.7847 - recall_m: 0.4953 - f1_m: 0.5780 - val_loss: 0.0844 - val_acc: 0.9730 - val_precision_m: 0.7654 - val_recall_m: 0.3963 - val_f1_m: 0.4898\n",
      "Epoch 7/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0666 - acc: 0.9771 - precision_m: 0.7845 - recall_m: 0.5289 - f1_m: 0.6038\n",
      "Epoch 7: val_acc did not improve from 0.97299\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0667 - acc: 0.9771 - precision_m: 0.7860 - recall_m: 0.5304 - f1_m: 0.6057 - val_loss: 0.0816 - val_acc: 0.9728 - val_precision_m: 0.6789 - val_recall_m: 0.5379 - val_f1_m: 0.5744\n",
      "Epoch 8/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0631 - acc: 0.9787 - precision_m: 0.8086 - recall_m: 0.5642 - f1_m: 0.6395\n",
      "Epoch 8: val_acc improved from 0.97299 to 0.97490, saving model to models/best_model_1_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0631 - acc: 0.9787 - precision_m: 0.8060 - recall_m: 0.5626 - f1_m: 0.6369 - val_loss: 0.0760 - val_acc: 0.9749 - val_precision_m: 0.7151 - val_recall_m: 0.5295 - val_f1_m: 0.5776\n",
      "Epoch 9/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0614 - acc: 0.9791 - precision_m: 0.7982 - recall_m: 0.5728 - f1_m: 0.6467\n",
      "Epoch 9: val_acc improved from 0.97490 to 0.97634, saving model to models/best_model_1_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0611 - acc: 0.9791 - precision_m: 0.7969 - recall_m: 0.5734 - f1_m: 0.6463 - val_loss: 0.0789 - val_acc: 0.9763 - val_precision_m: 0.8095 - val_recall_m: 0.4939 - val_f1_m: 0.5822\n",
      "Epoch 10/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0567 - acc: 0.9808 - precision_m: 0.8236 - recall_m: 0.6102 - f1_m: 0.6807\n",
      "Epoch 10: val_acc did not improve from 0.97634\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0565 - acc: 0.9808 - precision_m: 0.8244 - recall_m: 0.6106 - f1_m: 0.6816 - val_loss: 0.0792 - val_acc: 0.9754 - val_precision_m: 0.7273 - val_recall_m: 0.5500 - val_f1_m: 0.6031\n",
      "Epoch 11/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0535 - acc: 0.9823 - precision_m: 0.8386 - recall_m: 0.6451 - f1_m: 0.7090\n",
      "Epoch 11: val_acc did not improve from 0.97634\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0534 - acc: 0.9823 - precision_m: 0.8383 - recall_m: 0.6447 - f1_m: 0.7088 - val_loss: 0.0739 - val_acc: 0.9751 - val_precision_m: 0.7650 - val_recall_m: 0.5083 - val_f1_m: 0.5841\n",
      "Epoch 12/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9826 - precision_m: 0.8452 - recall_m: 0.6480 - f1_m: 0.7098\n",
      "Epoch 12: val_acc did not improve from 0.97634\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0506 - acc: 0.9826 - precision_m: 0.8444 - recall_m: 0.6475 - f1_m: 0.7090 - val_loss: 0.0783 - val_acc: 0.9763 - val_precision_m: 0.7765 - val_recall_m: 0.5061 - val_f1_m: 0.5848\n",
      "Epoch 13/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0493 - acc: 0.9830 - precision_m: 0.8409 - recall_m: 0.6647 - f1_m: 0.7248\n",
      "Epoch 13: val_acc improved from 0.97634 to 0.97849, saving model to models/best_model_1_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0492 - acc: 0.9831 - precision_m: 0.8432 - recall_m: 0.6674 - f1_m: 0.7274 - val_loss: 0.0775 - val_acc: 0.9785 - val_precision_m: 0.8034 - val_recall_m: 0.5363 - val_f1_m: 0.6224\n",
      "Epoch 14/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9844 - precision_m: 0.8614 - recall_m: 0.6947 - f1_m: 0.7538\n",
      "Epoch 14: val_acc improved from 0.97849 to 0.97861, saving model to models/best_model_1_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0460 - acc: 0.9844 - precision_m: 0.8600 - recall_m: 0.6978 - f1_m: 0.7543 - val_loss: 0.0726 - val_acc: 0.9786 - val_precision_m: 0.7527 - val_recall_m: 0.6083 - val_f1_m: 0.6453\n",
      "Epoch 15/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9842 - precision_m: 0.8575 - recall_m: 0.6874 - f1_m: 0.7445\n",
      "Epoch 15: val_acc did not improve from 0.97861\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0445 - acc: 0.9842 - precision_m: 0.8561 - recall_m: 0.6912 - f1_m: 0.7460 - val_loss: 0.0841 - val_acc: 0.9784 - val_precision_m: 0.8789 - val_recall_m: 0.5140 - val_f1_m: 0.6147\n",
      "Epoch 16/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9848 - precision_m: 0.8624 - recall_m: 0.6984 - f1_m: 0.7548\n",
      "Epoch 16: val_acc did not improve from 0.97861\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0438 - acc: 0.9847 - precision_m: 0.8612 - recall_m: 0.6959 - f1_m: 0.7522 - val_loss: 0.0762 - val_acc: 0.9754 - val_precision_m: 0.6608 - val_recall_m: 0.6973 - val_f1_m: 0.6545\n",
      "Epoch 17/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9858 - precision_m: 0.8723 - recall_m: 0.7314 - f1_m: 0.7799\n",
      "Epoch 17: val_acc did not improve from 0.97861\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0396 - acc: 0.9859 - precision_m: 0.8734 - recall_m: 0.7330 - f1_m: 0.7812 - val_loss: 0.0784 - val_acc: 0.9748 - val_precision_m: 0.6726 - val_recall_m: 0.6290 - val_f1_m: 0.6245\n",
      "Epoch 18/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0385 - acc: 0.9867 - precision_m: 0.8901 - recall_m: 0.7381 - f1_m: 0.7904\n",
      "Epoch 18: val_acc did not improve from 0.97861\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0386 - acc: 0.9867 - precision_m: 0.8890 - recall_m: 0.7380 - f1_m: 0.7897 - val_loss: 0.0805 - val_acc: 0.9759 - val_precision_m: 0.7262 - val_recall_m: 0.5814 - val_f1_m: 0.6180\n",
      "Epoch 19/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0385 - acc: 0.9862 - precision_m: 0.8699 - recall_m: 0.7322 - f1_m: 0.7777\n",
      "Epoch 19: val_acc did not improve from 0.97861\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0382 - acc: 0.9863 - precision_m: 0.8720 - recall_m: 0.7303 - f1_m: 0.7773 - val_loss: 0.0792 - val_acc: 0.9781 - val_precision_m: 0.8346 - val_recall_m: 0.5630 - val_f1_m: 0.6401\n",
      "Epoch 20/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.9872 - precision_m: 0.8840 - recall_m: 0.7661 - f1_m: 0.8076\n",
      "Epoch 20: val_acc did not improve from 0.97861\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0356 - acc: 0.9872 - precision_m: 0.8834 - recall_m: 0.7656 - f1_m: 0.8073 - val_loss: 0.0791 - val_acc: 0.9775 - val_precision_m: 0.7136 - val_recall_m: 0.6599 - val_f1_m: 0.6546\n",
      "Epoch 21/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 0.9870 - precision_m: 0.8784 - recall_m: 0.7593 - f1_m: 0.7961\n",
      "Epoch 21: val_acc did not improve from 0.97861\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0361 - acc: 0.9869 - precision_m: 0.8795 - recall_m: 0.7565 - f1_m: 0.7949 - val_loss: 0.0792 - val_acc: 0.9786 - val_precision_m: 0.8133 - val_recall_m: 0.5830 - val_f1_m: 0.6460\n",
      "Epoch 22/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9883 - precision_m: 0.8971 - recall_m: 0.7725 - f1_m: 0.8187\n",
      "Epoch 22: val_acc improved from 0.97861 to 0.97885, saving model to models/best_model_1_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0328 - acc: 0.9884 - precision_m: 0.8986 - recall_m: 0.7706 - f1_m: 0.8178 - val_loss: 0.0898 - val_acc: 0.9788 - val_precision_m: 0.8579 - val_recall_m: 0.5605 - val_f1_m: 0.6449\n",
      "Epoch 23/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9889 - precision_m: 0.9016 - recall_m: 0.7849 - f1_m: 0.8268\n",
      "Epoch 23: val_acc improved from 0.97885 to 0.97932, saving model to models/best_model_1_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0308 - acc: 0.9890 - precision_m: 0.9015 - recall_m: 0.7884 - f1_m: 0.8290 - val_loss: 0.0969 - val_acc: 0.9793 - val_precision_m: 0.7986 - val_recall_m: 0.6025 - val_f1_m: 0.6645\n",
      "Epoch 24/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9895 - precision_m: 0.9057 - recall_m: 0.8015 - f1_m: 0.8398\n",
      "Epoch 24: val_acc did not improve from 0.97932\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0297 - acc: 0.9895 - precision_m: 0.9054 - recall_m: 0.7999 - f1_m: 0.8389 - val_loss: 0.0962 - val_acc: 0.9773 - val_precision_m: 0.7724 - val_recall_m: 0.5477 - val_f1_m: 0.6207\n",
      "Epoch 25/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0286 - acc: 0.9897 - precision_m: 0.9007 - recall_m: 0.8133 - f1_m: 0.8425\n",
      "Epoch 25: val_acc did not improve from 0.97932\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0285 - acc: 0.9898 - precision_m: 0.9015 - recall_m: 0.8131 - f1_m: 0.8428 - val_loss: 0.0970 - val_acc: 0.9781 - val_precision_m: 0.7988 - val_recall_m: 0.5531 - val_f1_m: 0.6310\n",
      "Epoch 26/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9901 - precision_m: 0.9082 - recall_m: 0.8139 - f1_m: 0.8480\n",
      "Epoch 26: val_acc did not improve from 0.97932\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0273 - acc: 0.9901 - precision_m: 0.9085 - recall_m: 0.8134 - f1_m: 0.8479 - val_loss: 0.0959 - val_acc: 0.9782 - val_precision_m: 0.7539 - val_recall_m: 0.5674 - val_f1_m: 0.6200\n",
      "Epoch 27/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9906 - precision_m: 0.9136 - recall_m: 0.8228 - f1_m: 0.8539\n",
      "Epoch 27: val_acc did not improve from 0.97932\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0270 - acc: 0.9907 - precision_m: 0.9142 - recall_m: 0.8234 - f1_m: 0.8546 - val_loss: 0.1064 - val_acc: 0.9786 - val_precision_m: 0.8077 - val_recall_m: 0.5734 - val_f1_m: 0.6395\n",
      "Epoch 28/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.9908 - precision_m: 0.9201 - recall_m: 0.8201 - f1_m: 0.8560\n",
      "Epoch 28: val_acc did not improve from 0.97932\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0260 - acc: 0.9908 - precision_m: 0.9204 - recall_m: 0.8221 - f1_m: 0.8572 - val_loss: 0.1319 - val_acc: 0.9781 - val_precision_m: 0.8376 - val_recall_m: 0.5238 - val_f1_m: 0.6206\n",
      "Epoch 29/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9910 - precision_m: 0.9162 - recall_m: 0.8399 - f1_m: 0.8624\n",
      "Epoch 29: val_acc did not improve from 0.97932\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0259 - acc: 0.9909 - precision_m: 0.9150 - recall_m: 0.8396 - f1_m: 0.8615 - val_loss: 0.1136 - val_acc: 0.9787 - val_precision_m: 0.8529 - val_recall_m: 0.5413 - val_f1_m: 0.6278\n",
      "Epoch 30/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.0249 - acc: 0.9912 - precision_m: 0.9080 - recall_m: 0.8441 - f1_m: 0.8628\n",
      "Epoch 30: val_acc did not improve from 0.97932\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0248 - acc: 0.9912 - precision_m: 0.9083 - recall_m: 0.8437 - f1_m: 0.8630 - val_loss: 0.1062 - val_acc: 0.9780 - val_precision_m: 0.7588 - val_recall_m: 0.6112 - val_f1_m: 0.6447\n",
      "Score for fold 5: loss of 0.09691799432039261; acc of 97.93235063552856%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.08372467756271362; acc of 97.77920246124268%\n",
      "Test Precision: precision_m of 28.250446915626526%\n",
      "Test Recall: recall_m of 24.305254220962524%\n",
      "Test F1: f1_m of 24.782028794288635%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1780 - acc: 0.9562 - precision_m: 0.0052 - recall_m: 0.0076 - f1_m: 0.0026\n",
      "Epoch 1: val_acc improved from -inf to 0.96059, saving model to models/best_model_1_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 3s 5ms/step - loss: 0.1780 - acc: 0.9562 - precision_m: 0.0052 - recall_m: 0.0076 - f1_m: 0.0026 - val_loss: 0.1311 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.1100 - acc: 0.9655 - precision_m: 0.4212 - recall_m: 0.1109 - f1_m: 0.1603\n",
      "Epoch 2: val_acc improved from 0.96059 to 0.96637, saving model to models/best_model_1_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1100 - acc: 0.9656 - precision_m: 0.4231 - recall_m: 0.1132 - f1_m: 0.1631 - val_loss: 0.0982 - val_acc: 0.9664 - val_precision_m: 0.5856 - val_recall_m: 0.1917 - val_f1_m: 0.2777\n",
      "Epoch 3/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0885 - acc: 0.9700 - precision_m: 0.6932 - recall_m: 0.3080 - f1_m: 0.3981\n",
      "Epoch 3: val_acc improved from 0.96637 to 0.96854, saving model to models/best_model_1_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0885 - acc: 0.9700 - precision_m: 0.6953 - recall_m: 0.3099 - f1_m: 0.3998 - val_loss: 0.0870 - val_acc: 0.9685 - val_precision_m: 0.6694 - val_recall_m: 0.3571 - val_f1_m: 0.4446\n",
      "Epoch 4/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0834 - acc: 0.9716 - precision_m: 0.7177 - recall_m: 0.3775 - f1_m: 0.4604\n",
      "Epoch 4: val_acc did not improve from 0.96854\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0834 - acc: 0.9716 - precision_m: 0.7175 - recall_m: 0.3776 - f1_m: 0.4598 - val_loss: 0.0904 - val_acc: 0.9676 - val_precision_m: 0.6786 - val_recall_m: 0.2069 - val_f1_m: 0.2994\n",
      "Epoch 5/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0771 - acc: 0.9732 - precision_m: 0.7243 - recall_m: 0.4272 - f1_m: 0.5022\n",
      "Epoch 5: val_acc improved from 0.96854 to 0.97119, saving model to models/best_model_1_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0771 - acc: 0.9732 - precision_m: 0.7241 - recall_m: 0.4303 - f1_m: 0.5044 - val_loss: 0.0817 - val_acc: 0.9712 - val_precision_m: 0.7367 - val_recall_m: 0.4173 - val_f1_m: 0.4962\n",
      "Epoch 6/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0727 - acc: 0.9755 - precision_m: 0.7759 - recall_m: 0.4728 - f1_m: 0.5577\n",
      "Epoch 6: val_acc did not improve from 0.97119\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0724 - acc: 0.9757 - precision_m: 0.7782 - recall_m: 0.4755 - f1_m: 0.5606 - val_loss: 0.0834 - val_acc: 0.9693 - val_precision_m: 0.5934 - val_recall_m: 0.6304 - val_f1_m: 0.5771\n",
      "Epoch 7/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0698 - acc: 0.9758 - precision_m: 0.7660 - recall_m: 0.5005 - f1_m: 0.5750\n",
      "Epoch 7: val_acc improved from 0.97119 to 0.97228, saving model to models/best_model_1_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0698 - acc: 0.9758 - precision_m: 0.7598 - recall_m: 0.4981 - f1_m: 0.5715 - val_loss: 0.0815 - val_acc: 0.9723 - val_precision_m: 0.7840 - val_recall_m: 0.3568 - val_f1_m: 0.4654\n",
      "Epoch 8/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0655 - acc: 0.9773 - precision_m: 0.7895 - recall_m: 0.5263 - f1_m: 0.6059\n",
      "Epoch 8: val_acc did not improve from 0.97228\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0653 - acc: 0.9773 - precision_m: 0.7911 - recall_m: 0.5286 - f1_m: 0.6079 - val_loss: 0.0805 - val_acc: 0.9713 - val_precision_m: 0.7367 - val_recall_m: 0.3504 - val_f1_m: 0.4475\n",
      "Epoch 9/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0633 - acc: 0.9785 - precision_m: 0.8109 - recall_m: 0.5406 - f1_m: 0.6247\n",
      "Epoch 9: val_acc improved from 0.97228 to 0.97276, saving model to models/best_model_1_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0631 - acc: 0.9786 - precision_m: 0.8127 - recall_m: 0.5446 - f1_m: 0.6287 - val_loss: 0.0804 - val_acc: 0.9728 - val_precision_m: 0.6832 - val_recall_m: 0.5481 - val_f1_m: 0.5665\n",
      "Epoch 10/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0615 - acc: 0.9782 - precision_m: 0.8063 - recall_m: 0.5638 - f1_m: 0.6358\n",
      "Epoch 10: val_acc did not improve from 0.97276\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0618 - acc: 0.9783 - precision_m: 0.8045 - recall_m: 0.5650 - f1_m: 0.6367 - val_loss: 0.0751 - val_acc: 0.9728 - val_precision_m: 0.6652 - val_recall_m: 0.6171 - val_f1_m: 0.6038\n",
      "Epoch 11/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0579 - acc: 0.9800 - precision_m: 0.8148 - recall_m: 0.5857 - f1_m: 0.6553\n",
      "Epoch 11: val_acc improved from 0.97276 to 0.97445, saving model to models/best_model_1_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0579 - acc: 0.9799 - precision_m: 0.8143 - recall_m: 0.5876 - f1_m: 0.6560 - val_loss: 0.0765 - val_acc: 0.9744 - val_precision_m: 0.7785 - val_recall_m: 0.4011 - val_f1_m: 0.5106\n",
      "Epoch 12/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0566 - acc: 0.9801 - precision_m: 0.8167 - recall_m: 0.5918 - f1_m: 0.6607\n",
      "Epoch 12: val_acc improved from 0.97445 to 0.97469, saving model to models/best_model_1_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0564 - acc: 0.9803 - precision_m: 0.8147 - recall_m: 0.5912 - f1_m: 0.6595 - val_loss: 0.0849 - val_acc: 0.9747 - val_precision_m: 0.8122 - val_recall_m: 0.3965 - val_f1_m: 0.5118\n",
      "Epoch 13/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0539 - acc: 0.9811 - precision_m: 0.8351 - recall_m: 0.6164 - f1_m: 0.6857\n",
      "Epoch 13: val_acc did not improve from 0.97469\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0541 - acc: 0.9810 - precision_m: 0.8322 - recall_m: 0.6143 - f1_m: 0.6835 - val_loss: 0.0734 - val_acc: 0.9744 - val_precision_m: 0.7034 - val_recall_m: 0.5367 - val_f1_m: 0.5767\n",
      "Epoch 14/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0516 - acc: 0.9823 - precision_m: 0.8324 - recall_m: 0.6464 - f1_m: 0.7089\n",
      "Epoch 14: val_acc did not improve from 0.97469\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0516 - acc: 0.9822 - precision_m: 0.8325 - recall_m: 0.6430 - f1_m: 0.7063 - val_loss: 0.0725 - val_acc: 0.9735 - val_precision_m: 0.6578 - val_recall_m: 0.6727 - val_f1_m: 0.6292\n",
      "Epoch 15/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0515 - acc: 0.9817 - precision_m: 0.8293 - recall_m: 0.6442 - f1_m: 0.6979\n",
      "Epoch 15: val_acc did not improve from 0.97469\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0516 - acc: 0.9817 - precision_m: 0.8287 - recall_m: 0.6408 - f1_m: 0.6955 - val_loss: 0.0830 - val_acc: 0.9736 - val_precision_m: 0.7717 - val_recall_m: 0.3441 - val_f1_m: 0.4621\n",
      "Epoch 16/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0490 - acc: 0.9827 - precision_m: 0.8395 - recall_m: 0.6596 - f1_m: 0.7155\n",
      "Epoch 16: val_acc improved from 0.97469 to 0.97758, saving model to models/best_model_1_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0490 - acc: 0.9828 - precision_m: 0.8398 - recall_m: 0.6621 - f1_m: 0.7163 - val_loss: 0.0712 - val_acc: 0.9776 - val_precision_m: 0.8280 - val_recall_m: 0.5394 - val_f1_m: 0.6270\n",
      "Epoch 17/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9844 - precision_m: 0.8515 - recall_m: 0.7016 - f1_m: 0.7539\n",
      "Epoch 17: val_acc did not improve from 0.97758\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0445 - acc: 0.9845 - precision_m: 0.8535 - recall_m: 0.7000 - f1_m: 0.7535 - val_loss: 0.0799 - val_acc: 0.9749 - val_precision_m: 0.8123 - val_recall_m: 0.4155 - val_f1_m: 0.5237\n",
      "Epoch 18/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0446 - acc: 0.9841 - precision_m: 0.8555 - recall_m: 0.6866 - f1_m: 0.7404\n",
      "Epoch 18: val_acc did not improve from 0.97758\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0448 - acc: 0.9840 - precision_m: 0.8561 - recall_m: 0.6873 - f1_m: 0.7413 - val_loss: 0.0756 - val_acc: 0.9752 - val_precision_m: 0.7956 - val_recall_m: 0.4440 - val_f1_m: 0.5477\n",
      "Epoch 19/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9851 - precision_m: 0.8670 - recall_m: 0.7102 - f1_m: 0.7642\n",
      "Epoch 19: val_acc did not improve from 0.97758\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0424 - acc: 0.9852 - precision_m: 0.8679 - recall_m: 0.7113 - f1_m: 0.7654 - val_loss: 0.0789 - val_acc: 0.9763 - val_precision_m: 0.7705 - val_recall_m: 0.4948 - val_f1_m: 0.5702\n",
      "Epoch 20/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9855 - precision_m: 0.8691 - recall_m: 0.7156 - f1_m: 0.7697\n",
      "Epoch 20: val_acc did not improve from 0.97758\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0406 - acc: 0.9856 - precision_m: 0.8696 - recall_m: 0.7185 - f1_m: 0.7717 - val_loss: 0.0739 - val_acc: 0.9771 - val_precision_m: 0.7293 - val_recall_m: 0.6057 - val_f1_m: 0.6273\n",
      "Epoch 21/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9861 - precision_m: 0.8718 - recall_m: 0.7331 - f1_m: 0.7794\n",
      "Epoch 21: val_acc did not improve from 0.97758\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0390 - acc: 0.9860 - precision_m: 0.8697 - recall_m: 0.7275 - f1_m: 0.7747 - val_loss: 0.0778 - val_acc: 0.9728 - val_precision_m: 0.6304 - val_recall_m: 0.6949 - val_f1_m: 0.6258\n",
      "Epoch 22/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9866 - precision_m: 0.8758 - recall_m: 0.7469 - f1_m: 0.7913\n",
      "Epoch 22: val_acc did not improve from 0.97758\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0370 - acc: 0.9866 - precision_m: 0.8758 - recall_m: 0.7458 - f1_m: 0.7906 - val_loss: 0.0870 - val_acc: 0.9765 - val_precision_m: 0.8033 - val_recall_m: 0.4755 - val_f1_m: 0.5684\n",
      "Epoch 23/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9868 - precision_m: 0.8806 - recall_m: 0.7480 - f1_m: 0.7919\n",
      "Epoch 23: val_acc did not improve from 0.97758\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0359 - acc: 0.9869 - precision_m: 0.8827 - recall_m: 0.7491 - f1_m: 0.7936 - val_loss: 0.0736 - val_acc: 0.9754 - val_precision_m: 0.7120 - val_recall_m: 0.6430 - val_f1_m: 0.6357\n",
      "Epoch 24/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0351 - acc: 0.9869 - precision_m: 0.8790 - recall_m: 0.7628 - f1_m: 0.7990\n",
      "Epoch 24: val_acc did not improve from 0.97758\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0359 - acc: 0.9868 - precision_m: 0.8779 - recall_m: 0.7583 - f1_m: 0.7941 - val_loss: 0.0734 - val_acc: 0.9764 - val_precision_m: 0.8113 - val_recall_m: 0.5245 - val_f1_m: 0.5961\n",
      "Epoch 25/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0320 - acc: 0.9880 - precision_m: 0.8956 - recall_m: 0.7670 - f1_m: 0.8105\n",
      "Epoch 25: val_acc did not improve from 0.97758\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0320 - acc: 0.9881 - precision_m: 0.8950 - recall_m: 0.7689 - f1_m: 0.8114 - val_loss: 0.0939 - val_acc: 0.9771 - val_precision_m: 0.7713 - val_recall_m: 0.5613 - val_f1_m: 0.6146\n",
      "Epoch 26/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.0325 - acc: 0.9881 - precision_m: 0.8908 - recall_m: 0.7763 - f1_m: 0.8137\n",
      "Epoch 26: val_acc did not improve from 0.97758\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0325 - acc: 0.9881 - precision_m: 0.8908 - recall_m: 0.7763 - f1_m: 0.8137 - val_loss: 0.0834 - val_acc: 0.9763 - val_precision_m: 0.7346 - val_recall_m: 0.5671 - val_f1_m: 0.6091\n",
      "Epoch 27/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0293 - acc: 0.9891 - precision_m: 0.8878 - recall_m: 0.7936 - f1_m: 0.8275\n",
      "Epoch 27: val_acc did not improve from 0.97758\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0295 - acc: 0.9891 - precision_m: 0.8879 - recall_m: 0.7944 - f1_m: 0.8276 - val_loss: 0.0821 - val_acc: 0.9751 - val_precision_m: 0.7114 - val_recall_m: 0.6472 - val_f1_m: 0.6325\n",
      "Epoch 28/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.9886 - precision_m: 0.8883 - recall_m: 0.7896 - f1_m: 0.8236\n",
      "Epoch 28: val_acc did not improve from 0.97758\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0299 - acc: 0.9887 - precision_m: 0.8907 - recall_m: 0.7900 - f1_m: 0.8250 - val_loss: 0.0880 - val_acc: 0.9748 - val_precision_m: 0.6603 - val_recall_m: 0.6642 - val_f1_m: 0.6285\n",
      "Epoch 29/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0291 - acc: 0.9893 - precision_m: 0.8963 - recall_m: 0.8046 - f1_m: 0.8321\n",
      "Epoch 29: val_acc did not improve from 0.97758\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0292 - acc: 0.9892 - precision_m: 0.8952 - recall_m: 0.8052 - f1_m: 0.8319 - val_loss: 0.0858 - val_acc: 0.9765 - val_precision_m: 0.7567 - val_recall_m: 0.5426 - val_f1_m: 0.6045\n",
      "Epoch 30/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9904 - precision_m: 0.9026 - recall_m: 0.8242 - f1_m: 0.8506\n",
      "Epoch 30: val_acc did not improve from 0.97758\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0265 - acc: 0.9904 - precision_m: 0.9041 - recall_m: 0.8229 - f1_m: 0.8505 - val_loss: 0.0861 - val_acc: 0.9743 - val_precision_m: 0.6569 - val_recall_m: 0.6695 - val_f1_m: 0.6285\n",
      "Score for fold 6: loss of 0.07121623307466507; acc of 97.75822758674622%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.06736349314451218; acc of 97.87789583206177%\n",
      "Test Precision: precision_m of 28.255996108055115%\n",
      "Test Recall: recall_m of 23.23192209005356%\n",
      "Test F1: f1_m of 24.64188188314438%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1455 - acc: 0.9625 - precision_m: 0.1336 - recall_m: 0.0343 - f1_m: 0.0491     \n",
      "Epoch 1: val_acc improved from -inf to 0.96260, saving model to models/best_model_1_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 3s 5ms/step - loss: 0.1455 - acc: 0.9625 - precision_m: 0.1336 - recall_m: 0.0343 - f1_m: 0.0491 - val_loss: 0.1117 - val_acc: 0.9626 - val_precision_m: 0.0303 - val_recall_m: 0.0025 - val_f1_m: 0.0047\n",
      "Epoch 2/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0960 - acc: 0.9678 - precision_m: 0.6309 - recall_m: 0.2492 - f1_m: 0.3297\n",
      "Epoch 2: val_acc improved from 0.96260 to 0.96822, saving model to models/best_model_1_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0954 - acc: 0.9681 - precision_m: 0.6329 - recall_m: 0.2547 - f1_m: 0.3350 - val_loss: 0.0883 - val_acc: 0.9682 - val_precision_m: 0.6409 - val_recall_m: 0.2772 - val_f1_m: 0.3510\n",
      "Epoch 3/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0839 - acc: 0.9716 - precision_m: 0.7342 - recall_m: 0.3801 - f1_m: 0.4703\n",
      "Epoch 3: val_acc improved from 0.96822 to 0.96965, saving model to models/best_model_1_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0845 - acc: 0.9713 - precision_m: 0.7301 - recall_m: 0.3814 - f1_m: 0.4703 - val_loss: 0.0885 - val_acc: 0.9697 - val_precision_m: 0.6755 - val_recall_m: 0.2675 - val_f1_m: 0.3511\n",
      "Epoch 4/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0765 - acc: 0.9732 - precision_m: 0.7491 - recall_m: 0.4360 - f1_m: 0.5225\n",
      "Epoch 4: val_acc improved from 0.96965 to 0.97407, saving model to models/best_model_1_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0766 - acc: 0.9731 - precision_m: 0.7485 - recall_m: 0.4390 - f1_m: 0.5247 - val_loss: 0.0788 - val_acc: 0.9741 - val_precision_m: 0.7581 - val_recall_m: 0.4333 - val_f1_m: 0.5142\n",
      "Epoch 5/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0712 - acc: 0.9750 - precision_m: 0.7551 - recall_m: 0.4909 - f1_m: 0.5691\n",
      "Epoch 5: val_acc improved from 0.97407 to 0.97539, saving model to models/best_model_1_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0710 - acc: 0.9750 - precision_m: 0.7556 - recall_m: 0.4904 - f1_m: 0.5691 - val_loss: 0.0769 - val_acc: 0.9754 - val_precision_m: 0.8338 - val_recall_m: 0.4086 - val_f1_m: 0.5151\n",
      "Epoch 6/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0684 - acc: 0.9767 - precision_m: 0.7900 - recall_m: 0.5262 - f1_m: 0.6016\n",
      "Epoch 6: val_acc improved from 0.97539 to 0.97611, saving model to models/best_model_1_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0681 - acc: 0.9767 - precision_m: 0.7916 - recall_m: 0.5249 - f1_m: 0.6014 - val_loss: 0.0735 - val_acc: 0.9761 - val_precision_m: 0.7702 - val_recall_m: 0.4800 - val_f1_m: 0.5498\n",
      "Epoch 7/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0630 - acc: 0.9775 - precision_m: 0.7900 - recall_m: 0.5558 - f1_m: 0.6248\n",
      "Epoch 7: val_acc improved from 0.97611 to 0.97646, saving model to models/best_model_1_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0632 - acc: 0.9775 - precision_m: 0.7881 - recall_m: 0.5566 - f1_m: 0.6253 - val_loss: 0.0701 - val_acc: 0.9765 - val_precision_m: 0.7357 - val_recall_m: 0.5203 - val_f1_m: 0.5790\n",
      "Epoch 8/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0597 - acc: 0.9795 - precision_m: 0.8174 - recall_m: 0.5862 - f1_m: 0.6580\n",
      "Epoch 8: val_acc did not improve from 0.97646\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0600 - acc: 0.9793 - precision_m: 0.8147 - recall_m: 0.5850 - f1_m: 0.6564 - val_loss: 0.0783 - val_acc: 0.9717 - val_precision_m: 0.5967 - val_recall_m: 0.6436 - val_f1_m: 0.5992\n",
      "Epoch 9/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9800 - precision_m: 0.8333 - recall_m: 0.6132 - f1_m: 0.6752\n",
      "Epoch 9: val_acc improved from 0.97646 to 0.97706, saving model to models/best_model_1_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0582 - acc: 0.9799 - precision_m: 0.8329 - recall_m: 0.6107 - f1_m: 0.6735 - val_loss: 0.0713 - val_acc: 0.9771 - val_precision_m: 0.7735 - val_recall_m: 0.5417 - val_f1_m: 0.5963\n",
      "Epoch 10/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0543 - acc: 0.9809 - precision_m: 0.8322 - recall_m: 0.6223 - f1_m: 0.6893\n",
      "Epoch 10: val_acc improved from 0.97706 to 0.97766, saving model to models/best_model_1_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0542 - acc: 0.9810 - precision_m: 0.8327 - recall_m: 0.6249 - f1_m: 0.6912 - val_loss: 0.0777 - val_acc: 0.9777 - val_precision_m: 0.8352 - val_recall_m: 0.4848 - val_f1_m: 0.5833\n",
      "Epoch 11/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9820 - precision_m: 0.8252 - recall_m: 0.6582 - f1_m: 0.7147\n",
      "Epoch 11: val_acc did not improve from 0.97766\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0508 - acc: 0.9820 - precision_m: 0.8281 - recall_m: 0.6585 - f1_m: 0.7160 - val_loss: 0.0727 - val_acc: 0.9749 - val_precision_m: 0.6392 - val_recall_m: 0.6537 - val_f1_m: 0.6224\n",
      "Epoch 12/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9827 - precision_m: 0.8483 - recall_m: 0.6703 - f1_m: 0.7240\n",
      "Epoch 12: val_acc did not improve from 0.97766\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0499 - acc: 0.9826 - precision_m: 0.8461 - recall_m: 0.6718 - f1_m: 0.7242 - val_loss: 0.0732 - val_acc: 0.9773 - val_precision_m: 0.8109 - val_recall_m: 0.4633 - val_f1_m: 0.5508\n",
      "Epoch 13/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0484 - acc: 0.9834 - precision_m: 0.8570 - recall_m: 0.6836 - f1_m: 0.7406\n",
      "Epoch 13: val_acc improved from 0.97766 to 0.97933, saving model to models/best_model_1_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0483 - acc: 0.9834 - precision_m: 0.8577 - recall_m: 0.6848 - f1_m: 0.7418 - val_loss: 0.0708 - val_acc: 0.9793 - val_precision_m: 0.8380 - val_recall_m: 0.5206 - val_f1_m: 0.6136\n",
      "Epoch 14/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0455 - acc: 0.9841 - precision_m: 0.8637 - recall_m: 0.6917 - f1_m: 0.7469\n",
      "Epoch 14: val_acc did not improve from 0.97933\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0456 - acc: 0.9840 - precision_m: 0.8616 - recall_m: 0.6923 - f1_m: 0.7466 - val_loss: 0.0760 - val_acc: 0.9768 - val_precision_m: 0.8347 - val_recall_m: 0.4587 - val_f1_m: 0.5558\n",
      "Epoch 15/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9843 - precision_m: 0.8613 - recall_m: 0.6996 - f1_m: 0.7531\n",
      "Epoch 15: val_acc did not improve from 0.97933\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0441 - acc: 0.9844 - precision_m: 0.8622 - recall_m: 0.7016 - f1_m: 0.7547 - val_loss: 0.0930 - val_acc: 0.9756 - val_precision_m: 0.8801 - val_recall_m: 0.3622 - val_f1_m: 0.4781\n",
      "Epoch 16/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9855 - precision_m: 0.8722 - recall_m: 0.7287 - f1_m: 0.7760\n",
      "Epoch 16: val_acc did not improve from 0.97933\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0411 - acc: 0.9855 - precision_m: 0.8728 - recall_m: 0.7277 - f1_m: 0.7757 - val_loss: 0.0783 - val_acc: 0.9793 - val_precision_m: 0.8120 - val_recall_m: 0.5101 - val_f1_m: 0.5997\n",
      "Epoch 17/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9865 - precision_m: 0.8765 - recall_m: 0.7386 - f1_m: 0.7867\n",
      "Epoch 17: val_acc improved from 0.97933 to 0.98017, saving model to models/best_model_1_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0388 - acc: 0.9865 - precision_m: 0.8749 - recall_m: 0.7400 - f1_m: 0.7869 - val_loss: 0.0705 - val_acc: 0.9802 - val_precision_m: 0.8175 - val_recall_m: 0.5707 - val_f1_m: 0.6434\n",
      "Epoch 18/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0384 - acc: 0.9863 - precision_m: 0.8690 - recall_m: 0.7463 - f1_m: 0.7868\n",
      "Epoch 18: val_acc did not improve from 0.98017\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0385 - acc: 0.9862 - precision_m: 0.8703 - recall_m: 0.7462 - f1_m: 0.7876 - val_loss: 0.0763 - val_acc: 0.9750 - val_precision_m: 0.6239 - val_recall_m: 0.7094 - val_f1_m: 0.6431\n",
      "Epoch 19/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9866 - precision_m: 0.8808 - recall_m: 0.7556 - f1_m: 0.7977\n",
      "Epoch 19: val_acc did not improve from 0.98017\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0374 - acc: 0.9866 - precision_m: 0.8790 - recall_m: 0.7525 - f1_m: 0.7953 - val_loss: 0.0650 - val_acc: 0.9796 - val_precision_m: 0.7450 - val_recall_m: 0.6227 - val_f1_m: 0.6516\n",
      "Epoch 20/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0346 - acc: 0.9873 - precision_m: 0.8791 - recall_m: 0.7682 - f1_m: 0.8056\n",
      "Epoch 20: val_acc did not improve from 0.98017\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0349 - acc: 0.9873 - precision_m: 0.8795 - recall_m: 0.7692 - f1_m: 0.8063 - val_loss: 0.0707 - val_acc: 0.9796 - val_precision_m: 0.7687 - val_recall_m: 0.6135 - val_f1_m: 0.6542\n",
      "Epoch 21/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0332 - acc: 0.9883 - precision_m: 0.8897 - recall_m: 0.7875 - f1_m: 0.8216\n",
      "Epoch 21: val_acc did not improve from 0.98017\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0329 - acc: 0.9884 - precision_m: 0.8924 - recall_m: 0.7871 - f1_m: 0.8228 - val_loss: 0.0729 - val_acc: 0.9787 - val_precision_m: 0.7550 - val_recall_m: 0.6215 - val_f1_m: 0.6520\n",
      "Epoch 22/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9885 - precision_m: 0.8961 - recall_m: 0.7829 - f1_m: 0.8223\n",
      "Epoch 22: val_acc did not improve from 0.98017\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0320 - acc: 0.9885 - precision_m: 0.8936 - recall_m: 0.7803 - f1_m: 0.8198 - val_loss: 0.0734 - val_acc: 0.9774 - val_precision_m: 0.6830 - val_recall_m: 0.6896 - val_f1_m: 0.6690\n",
      "Epoch 23/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0318 - acc: 0.9880 - precision_m: 0.8985 - recall_m: 0.7782 - f1_m: 0.8172\n",
      "Epoch 23: val_acc did not improve from 0.98017\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0315 - acc: 0.9881 - precision_m: 0.9000 - recall_m: 0.7817 - f1_m: 0.8203 - val_loss: 0.0775 - val_acc: 0.9792 - val_precision_m: 0.7598 - val_recall_m: 0.6060 - val_f1_m: 0.6479\n",
      "Epoch 24/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9893 - precision_m: 0.9008 - recall_m: 0.8025 - f1_m: 0.8362\n",
      "Epoch 24: val_acc did not improve from 0.98017\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0294 - acc: 0.9893 - precision_m: 0.8997 - recall_m: 0.8046 - f1_m: 0.8368 - val_loss: 0.0984 - val_acc: 0.9779 - val_precision_m: 0.8411 - val_recall_m: 0.4829 - val_f1_m: 0.5831\n",
      "Epoch 25/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0282 - acc: 0.9895 - precision_m: 0.9040 - recall_m: 0.8118 - f1_m: 0.8424\n",
      "Epoch 25: val_acc did not improve from 0.98017\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0283 - acc: 0.9896 - precision_m: 0.9059 - recall_m: 0.8134 - f1_m: 0.8441 - val_loss: 0.0879 - val_acc: 0.9791 - val_precision_m: 0.7908 - val_recall_m: 0.5596 - val_f1_m: 0.6285\n",
      "Epoch 26/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0263 - acc: 0.9901 - precision_m: 0.9070 - recall_m: 0.8238 - f1_m: 0.8515\n",
      "Epoch 26: val_acc did not improve from 0.98017\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0262 - acc: 0.9902 - precision_m: 0.9084 - recall_m: 0.8246 - f1_m: 0.8527 - val_loss: 0.0872 - val_acc: 0.9792 - val_precision_m: 0.7845 - val_recall_m: 0.5717 - val_f1_m: 0.6405\n",
      "Epoch 27/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9906 - precision_m: 0.9152 - recall_m: 0.8323 - f1_m: 0.8623\n",
      "Epoch 27: val_acc did not improve from 0.98017\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0255 - acc: 0.9906 - precision_m: 0.9132 - recall_m: 0.8311 - f1_m: 0.8609 - val_loss: 0.0803 - val_acc: 0.9792 - val_precision_m: 0.7304 - val_recall_m: 0.6448 - val_f1_m: 0.6665\n",
      "Epoch 28/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9910 - precision_m: 0.9150 - recall_m: 0.8443 - f1_m: 0.8684\n",
      "Epoch 28: val_acc did not improve from 0.98017\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0234 - acc: 0.9911 - precision_m: 0.9148 - recall_m: 0.8445 - f1_m: 0.8684 - val_loss: 0.0950 - val_acc: 0.9793 - val_precision_m: 0.7781 - val_recall_m: 0.5482 - val_f1_m: 0.6226\n",
      "Epoch 29/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0255 - acc: 0.9901 - precision_m: 0.9010 - recall_m: 0.8333 - f1_m: 0.8534\n",
      "Epoch 29: val_acc did not improve from 0.98017\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0256 - acc: 0.9901 - precision_m: 0.9009 - recall_m: 0.8329 - f1_m: 0.8532 - val_loss: 0.0911 - val_acc: 0.9786 - val_precision_m: 0.7609 - val_recall_m: 0.5914 - val_f1_m: 0.6394\n",
      "Epoch 30/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9919 - precision_m: 0.9213 - recall_m: 0.8581 - f1_m: 0.8804\n",
      "Epoch 30: val_acc did not improve from 0.98017\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0230 - acc: 0.9919 - precision_m: 0.9198 - recall_m: 0.8576 - f1_m: 0.8795 - val_loss: 0.0906 - val_acc: 0.9778 - val_precision_m: 0.6973 - val_recall_m: 0.6529 - val_f1_m: 0.6569\n",
      "Score for fold 7: loss of 0.0705006867647171; acc of 98.01672697067261%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.060885239392519; acc of 98.2195496559143%\n",
      "Test Precision: precision_m of 23.426246643066406%\n",
      "Test Recall: recall_m of 18.6100035905838%\n",
      "Test F1: f1_m of 19.845329225063324%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1473 - acc: 0.9630 - precision_m: 0.1208 - recall_m: 0.0233 - f1_m: 0.0366     \n",
      "Epoch 1: val_acc improved from -inf to 0.96322, saving model to models/best_model_1_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 3s 5ms/step - loss: 0.1473 - acc: 0.9630 - precision_m: 0.1208 - recall_m: 0.0233 - f1_m: 0.0366 - val_loss: 0.1167 - val_acc: 0.9632 - val_precision_m: 0.0606 - val_recall_m: 0.0043 - val_f1_m: 0.0079\n",
      "Epoch 2/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0943 - acc: 0.9686 - precision_m: 0.6413 - recall_m: 0.2689 - f1_m: 0.3504\n",
      "Epoch 2: val_acc improved from 0.96322 to 0.97089, saving model to models/best_model_1_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0943 - acc: 0.9685 - precision_m: 0.6414 - recall_m: 0.2681 - f1_m: 0.3495 - val_loss: 0.0851 - val_acc: 0.9709 - val_precision_m: 0.6638 - val_recall_m: 0.2864 - val_f1_m: 0.3642\n",
      "Epoch 3/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0806 - acc: 0.9724 - precision_m: 0.7261 - recall_m: 0.3984 - f1_m: 0.4859\n",
      "Epoch 3: val_acc improved from 0.97089 to 0.97197, saving model to models/best_model_1_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0803 - acc: 0.9724 - precision_m: 0.7252 - recall_m: 0.3996 - f1_m: 0.4866 - val_loss: 0.0786 - val_acc: 0.9720 - val_precision_m: 0.6352 - val_recall_m: 0.4082 - val_f1_m: 0.4652\n",
      "Epoch 4/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0742 - acc: 0.9746 - precision_m: 0.7630 - recall_m: 0.4567 - f1_m: 0.5436\n",
      "Epoch 4: val_acc improved from 0.97197 to 0.97413, saving model to models/best_model_1_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0740 - acc: 0.9747 - precision_m: 0.7631 - recall_m: 0.4582 - f1_m: 0.5449 - val_loss: 0.0782 - val_acc: 0.9741 - val_precision_m: 0.7332 - val_recall_m: 0.3842 - val_f1_m: 0.4621\n",
      "Epoch 5/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0691 - acc: 0.9762 - precision_m: 0.7714 - recall_m: 0.5029 - f1_m: 0.5839\n",
      "Epoch 5: val_acc improved from 0.97413 to 0.97568, saving model to models/best_model_1_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0688 - acc: 0.9762 - precision_m: 0.7703 - recall_m: 0.5034 - f1_m: 0.5839 - val_loss: 0.0752 - val_acc: 0.9757 - val_precision_m: 0.7291 - val_recall_m: 0.3826 - val_f1_m: 0.4720\n",
      "Epoch 6/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0646 - acc: 0.9769 - precision_m: 0.7884 - recall_m: 0.5352 - f1_m: 0.6093\n",
      "Epoch 6: val_acc did not improve from 0.97568\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0646 - acc: 0.9770 - precision_m: 0.7888 - recall_m: 0.5374 - f1_m: 0.6111 - val_loss: 0.0717 - val_acc: 0.9741 - val_precision_m: 0.6389 - val_recall_m: 0.5098 - val_f1_m: 0.5363\n",
      "Epoch 7/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9785 - precision_m: 0.7976 - recall_m: 0.5724 - f1_m: 0.6415\n",
      "Epoch 7: val_acc did not improve from 0.97568\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0613 - acc: 0.9785 - precision_m: 0.7933 - recall_m: 0.5722 - f1_m: 0.6399 - val_loss: 0.0830 - val_acc: 0.9750 - val_precision_m: 0.7689 - val_recall_m: 0.3578 - val_f1_m: 0.4503\n",
      "Epoch 8/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0586 - acc: 0.9797 - precision_m: 0.8070 - recall_m: 0.5911 - f1_m: 0.6592\n",
      "Epoch 8: val_acc improved from 0.97568 to 0.97724, saving model to models/best_model_1_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0586 - acc: 0.9797 - precision_m: 0.8098 - recall_m: 0.5897 - f1_m: 0.6586 - val_loss: 0.0698 - val_acc: 0.9772 - val_precision_m: 0.7714 - val_recall_m: 0.4580 - val_f1_m: 0.5392\n",
      "Epoch 9/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9801 - precision_m: 0.8283 - recall_m: 0.6094 - f1_m: 0.6729\n",
      "Epoch 9: val_acc improved from 0.97724 to 0.97736, saving model to models/best_model_1_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0579 - acc: 0.9801 - precision_m: 0.8282 - recall_m: 0.6109 - f1_m: 0.6741 - val_loss: 0.0702 - val_acc: 0.9774 - val_precision_m: 0.7659 - val_recall_m: 0.4800 - val_f1_m: 0.5575\n",
      "Epoch 10/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0533 - acc: 0.9807 - precision_m: 0.8192 - recall_m: 0.6398 - f1_m: 0.6966\n",
      "Epoch 10: val_acc did not improve from 0.97736\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0536 - acc: 0.9806 - precision_m: 0.8167 - recall_m: 0.6386 - f1_m: 0.6942 - val_loss: 0.0791 - val_acc: 0.9766 - val_precision_m: 0.7871 - val_recall_m: 0.3790 - val_f1_m: 0.4834\n",
      "Epoch 11/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0513 - acc: 0.9820 - precision_m: 0.8366 - recall_m: 0.6461 - f1_m: 0.7079\n",
      "Epoch 11: val_acc improved from 0.97736 to 0.97808, saving model to models/best_model_1_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0511 - acc: 0.9820 - precision_m: 0.8360 - recall_m: 0.6446 - f1_m: 0.7068 - val_loss: 0.0688 - val_acc: 0.9781 - val_precision_m: 0.7996 - val_recall_m: 0.4783 - val_f1_m: 0.5611\n",
      "Epoch 12/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0490 - acc: 0.9829 - precision_m: 0.8347 - recall_m: 0.6746 - f1_m: 0.7271\n",
      "Epoch 12: val_acc improved from 0.97808 to 0.97892, saving model to models/best_model_1_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0487 - acc: 0.9830 - precision_m: 0.8377 - recall_m: 0.6750 - f1_m: 0.7288 - val_loss: 0.0668 - val_acc: 0.9789 - val_precision_m: 0.7497 - val_recall_m: 0.5452 - val_f1_m: 0.6050\n",
      "Epoch 13/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9834 - precision_m: 0.8498 - recall_m: 0.6806 - f1_m: 0.7361\n",
      "Epoch 13: val_acc did not improve from 0.97892\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0476 - acc: 0.9835 - precision_m: 0.8498 - recall_m: 0.6821 - f1_m: 0.7372 - val_loss: 0.0743 - val_acc: 0.9787 - val_precision_m: 0.7606 - val_recall_m: 0.4594 - val_f1_m: 0.5463\n",
      "Epoch 14/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0462 - acc: 0.9841 - precision_m: 0.8547 - recall_m: 0.6960 - f1_m: 0.7482\n",
      "Epoch 14: val_acc did not improve from 0.97892\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0460 - acc: 0.9841 - precision_m: 0.8567 - recall_m: 0.6932 - f1_m: 0.7467 - val_loss: 0.0913 - val_acc: 0.9747 - val_precision_m: 0.7227 - val_recall_m: 0.3361 - val_f1_m: 0.4327\n",
      "Epoch 15/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9844 - precision_m: 0.8551 - recall_m: 0.7051 - f1_m: 0.7559\n",
      "Epoch 15: val_acc improved from 0.97892 to 0.97940, saving model to models/best_model_1_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0437 - acc: 0.9844 - precision_m: 0.8554 - recall_m: 0.7056 - f1_m: 0.7564 - val_loss: 0.0709 - val_acc: 0.9794 - val_precision_m: 0.7498 - val_recall_m: 0.5334 - val_f1_m: 0.5957\n",
      "Epoch 16/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9853 - precision_m: 0.8582 - recall_m: 0.7209 - f1_m: 0.7685\n",
      "Epoch 16: val_acc improved from 0.97940 to 0.97952, saving model to models/best_model_1_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0421 - acc: 0.9852 - precision_m: 0.8582 - recall_m: 0.7187 - f1_m: 0.7669 - val_loss: 0.0647 - val_acc: 0.9795 - val_precision_m: 0.7396 - val_recall_m: 0.5240 - val_f1_m: 0.5935\n",
      "Epoch 17/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9859 - precision_m: 0.8651 - recall_m: 0.7333 - f1_m: 0.7769\n",
      "Epoch 17: val_acc did not improve from 0.97952\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0401 - acc: 0.9859 - precision_m: 0.8659 - recall_m: 0.7325 - f1_m: 0.7767 - val_loss: 0.0754 - val_acc: 0.9774 - val_precision_m: 0.7889 - val_recall_m: 0.3889 - val_f1_m: 0.4897\n",
      "Epoch 18/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9854 - precision_m: 0.8756 - recall_m: 0.7171 - f1_m: 0.7672\n",
      "Epoch 18: val_acc did not improve from 0.97952\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0404 - acc: 0.9855 - precision_m: 0.8768 - recall_m: 0.7184 - f1_m: 0.7686 - val_loss: 0.0700 - val_acc: 0.9768 - val_precision_m: 0.6681 - val_recall_m: 0.6316 - val_f1_m: 0.6188\n",
      "Epoch 19/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9870 - precision_m: 0.8749 - recall_m: 0.7507 - f1_m: 0.7932\n",
      "Epoch 19: val_acc did not improve from 0.97952\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0368 - acc: 0.9869 - precision_m: 0.8761 - recall_m: 0.7501 - f1_m: 0.7933 - val_loss: 0.0734 - val_acc: 0.9758 - val_precision_m: 0.6464 - val_recall_m: 0.6303 - val_f1_m: 0.6020\n",
      "Epoch 20/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0370 - acc: 0.9872 - precision_m: 0.8850 - recall_m: 0.7598 - f1_m: 0.8009\n",
      "Epoch 20: val_acc did not improve from 0.97952\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0371 - acc: 0.9871 - precision_m: 0.8835 - recall_m: 0.7588 - f1_m: 0.7996 - val_loss: 0.0717 - val_acc: 0.9740 - val_precision_m: 0.5934 - val_recall_m: 0.6626 - val_f1_m: 0.6057\n",
      "Epoch 21/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0355 - acc: 0.9871 - precision_m: 0.8746 - recall_m: 0.7681 - f1_m: 0.8038\n",
      "Epoch 21: val_acc did not improve from 0.97952\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0355 - acc: 0.9871 - precision_m: 0.8744 - recall_m: 0.7680 - f1_m: 0.8038 - val_loss: 0.0723 - val_acc: 0.9765 - val_precision_m: 0.6486 - val_recall_m: 0.6409 - val_f1_m: 0.6193\n",
      "Epoch 22/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9883 - precision_m: 0.8871 - recall_m: 0.7941 - f1_m: 0.8265\n",
      "Epoch 22: val_acc did not improve from 0.97952\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0330 - acc: 0.9884 - precision_m: 0.8867 - recall_m: 0.7940 - f1_m: 0.8260 - val_loss: 0.0856 - val_acc: 0.9781 - val_precision_m: 0.7720 - val_recall_m: 0.5042 - val_f1_m: 0.5778\n",
      "Epoch 23/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9886 - precision_m: 0.8925 - recall_m: 0.7873 - f1_m: 0.8223\n",
      "Epoch 23: val_acc did not improve from 0.97952\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0332 - acc: 0.9887 - precision_m: 0.8933 - recall_m: 0.7883 - f1_m: 0.8233 - val_loss: 0.0783 - val_acc: 0.9792 - val_precision_m: 0.7375 - val_recall_m: 0.5536 - val_f1_m: 0.6039\n",
      "Epoch 24/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0316 - acc: 0.9887 - precision_m: 0.8932 - recall_m: 0.7967 - f1_m: 0.8279\n",
      "Epoch 24: val_acc did not improve from 0.97952\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0316 - acc: 0.9887 - precision_m: 0.8939 - recall_m: 0.7964 - f1_m: 0.8282 - val_loss: 0.0707 - val_acc: 0.9789 - val_precision_m: 0.7429 - val_recall_m: 0.5510 - val_f1_m: 0.6043\n",
      "Epoch 25/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9891 - precision_m: 0.9026 - recall_m: 0.8013 - f1_m: 0.8361\n",
      "Epoch 25: val_acc improved from 0.97952 to 0.98035, saving model to models/best_model_1_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0305 - acc: 0.9891 - precision_m: 0.9016 - recall_m: 0.8009 - f1_m: 0.8356 - val_loss: 0.0744 - val_acc: 0.9804 - val_precision_m: 0.7443 - val_recall_m: 0.6017 - val_f1_m: 0.6417\n",
      "Epoch 26/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9894 - precision_m: 0.9006 - recall_m: 0.8043 - f1_m: 0.8379\n",
      "Epoch 26: val_acc did not improve from 0.98035\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0295 - acc: 0.9894 - precision_m: 0.8997 - recall_m: 0.8054 - f1_m: 0.8381 - val_loss: 0.0839 - val_acc: 0.9736 - val_precision_m: 0.5870 - val_recall_m: 0.6693 - val_f1_m: 0.6062\n",
      "Epoch 27/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0284 - acc: 0.9897 - precision_m: 0.8982 - recall_m: 0.8169 - f1_m: 0.8443\n",
      "Epoch 27: val_acc did not improve from 0.98035\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0286 - acc: 0.9896 - precision_m: 0.8978 - recall_m: 0.8171 - f1_m: 0.8440 - val_loss: 0.0733 - val_acc: 0.9801 - val_precision_m: 0.7396 - val_recall_m: 0.6043 - val_f1_m: 0.6364\n",
      "Epoch 28/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0281 - acc: 0.9895 - precision_m: 0.9085 - recall_m: 0.8072 - f1_m: 0.8411\n",
      "Epoch 28: val_acc did not improve from 0.98035\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0282 - acc: 0.9896 - precision_m: 0.9100 - recall_m: 0.8065 - f1_m: 0.8415 - val_loss: 0.0840 - val_acc: 0.9790 - val_precision_m: 0.7161 - val_recall_m: 0.5777 - val_f1_m: 0.6146\n",
      "Epoch 29/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0268 - acc: 0.9905 - precision_m: 0.9093 - recall_m: 0.8287 - f1_m: 0.8566\n",
      "Epoch 29: val_acc did not improve from 0.98035\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0268 - acc: 0.9906 - precision_m: 0.9099 - recall_m: 0.8294 - f1_m: 0.8572 - val_loss: 0.0837 - val_acc: 0.9782 - val_precision_m: 0.6835 - val_recall_m: 0.6118 - val_f1_m: 0.6195\n",
      "Epoch 30/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9903 - precision_m: 0.9077 - recall_m: 0.8216 - f1_m: 0.8501\n",
      "Epoch 30: val_acc did not improve from 0.98035\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0263 - acc: 0.9903 - precision_m: 0.9080 - recall_m: 0.8218 - f1_m: 0.8504 - val_loss: 0.0808 - val_acc: 0.9738 - val_precision_m: 0.5915 - val_recall_m: 0.6593 - val_f1_m: 0.6017\n",
      "Score for fold 8: loss of 0.07435198128223419; acc of 98.03545475006104%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.0704757496714592; acc of 97.99756407737732%\n",
      "Test Precision: precision_m of 26.321163773536682%\n",
      "Test Recall: recall_m of 22.40196019411087%\n",
      "Test F1: f1_m of 23.255880177021027%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "Epoch 1/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.1709 - acc: 0.9559 - precision_m: 0.0039 - recall_m: 0.0083 - f1_m: 0.0014       \n",
      "Epoch 1: val_acc improved from -inf to 0.96151, saving model to models/best_model_1_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 3s 5ms/step - loss: 0.1709 - acc: 0.9559 - precision_m: 0.0039 - recall_m: 0.0083 - f1_m: 0.0014 - val_loss: 0.1321 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.1126 - acc: 0.9652 - precision_m: 0.3719 - recall_m: 0.1016 - f1_m: 0.1477\n",
      "Epoch 2: val_acc improved from 0.96151 to 0.96473, saving model to models/best_model_1_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.1129 - acc: 0.9652 - precision_m: 0.3809 - recall_m: 0.1057 - f1_m: 0.1529 - val_loss: 0.0955 - val_acc: 0.9647 - val_precision_m: 0.4525 - val_recall_m: 0.1194 - val_f1_m: 0.1738\n",
      "Epoch 3/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0947 - acc: 0.9686 - precision_m: 0.6442 - recall_m: 0.2537 - f1_m: 0.3337\n",
      "Epoch 3: val_acc improved from 0.96473 to 0.96663, saving model to models/best_model_1_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0940 - acc: 0.9688 - precision_m: 0.6478 - recall_m: 0.2544 - f1_m: 0.3352 - val_loss: 0.1051 - val_acc: 0.9666 - val_precision_m: 0.4928 - val_recall_m: 0.1440 - val_f1_m: 0.2075\n",
      "Epoch 4/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0830 - acc: 0.9718 - precision_m: 0.7096 - recall_m: 0.3666 - f1_m: 0.4561\n",
      "Epoch 4: val_acc improved from 0.96663 to 0.97176, saving model to models/best_model_1_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0830 - acc: 0.9719 - precision_m: 0.7116 - recall_m: 0.3673 - f1_m: 0.4572 - val_loss: 0.0820 - val_acc: 0.9718 - val_precision_m: 0.7393 - val_recall_m: 0.4299 - val_f1_m: 0.5032\n",
      "Epoch 5/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.0776 - acc: 0.9733 - precision_m: 0.7310 - recall_m: 0.4275 - f1_m: 0.5106\n",
      "Epoch 5: val_acc did not improve from 0.97176\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0772 - acc: 0.9735 - precision_m: 0.7316 - recall_m: 0.4289 - f1_m: 0.5121 - val_loss: 0.0938 - val_acc: 0.9702 - val_precision_m: 0.6897 - val_recall_m: 0.2718 - val_f1_m: 0.3622\n",
      "Epoch 6/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0738 - acc: 0.9745 - precision_m: 0.7622 - recall_m: 0.4453 - f1_m: 0.5298\n",
      "Epoch 6: val_acc improved from 0.97176 to 0.97224, saving model to models/best_model_1_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0739 - acc: 0.9745 - precision_m: 0.7618 - recall_m: 0.4479 - f1_m: 0.5315 - val_loss: 0.0815 - val_acc: 0.9722 - val_precision_m: 0.8126 - val_recall_m: 0.3345 - val_f1_m: 0.4432\n",
      "Epoch 7/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0693 - acc: 0.9766 - precision_m: 0.7802 - recall_m: 0.4865 - f1_m: 0.5719\n",
      "Epoch 7: val_acc improved from 0.97224 to 0.97438, saving model to models/best_model_1_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0698 - acc: 0.9763 - precision_m: 0.7749 - recall_m: 0.4806 - f1_m: 0.5661 - val_loss: 0.0761 - val_acc: 0.9744 - val_precision_m: 0.7902 - val_recall_m: 0.4643 - val_f1_m: 0.5545\n",
      "Epoch 8/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0673 - acc: 0.9773 - precision_m: 0.7991 - recall_m: 0.5129 - f1_m: 0.5943\n",
      "Epoch 8: val_acc did not improve from 0.97438\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0676 - acc: 0.9772 - precision_m: 0.7954 - recall_m: 0.5146 - f1_m: 0.5941 - val_loss: 0.0975 - val_acc: 0.9712 - val_precision_m: 0.7590 - val_recall_m: 0.2867 - val_f1_m: 0.3892\n",
      "Epoch 9/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0643 - acc: 0.9784 - precision_m: 0.8118 - recall_m: 0.5434 - f1_m: 0.6245\n",
      "Epoch 9: val_acc did not improve from 0.97438\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0642 - acc: 0.9784 - precision_m: 0.8138 - recall_m: 0.5409 - f1_m: 0.6227 - val_loss: 0.0856 - val_acc: 0.9732 - val_precision_m: 0.8445 - val_recall_m: 0.3495 - val_f1_m: 0.4664\n",
      "Epoch 10/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0598 - acc: 0.9797 - precision_m: 0.8119 - recall_m: 0.5804 - f1_m: 0.6527\n",
      "Epoch 10: val_acc improved from 0.97438 to 0.97617, saving model to models/best_model_1_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0599 - acc: 0.9797 - precision_m: 0.8142 - recall_m: 0.5776 - f1_m: 0.6513 - val_loss: 0.0746 - val_acc: 0.9762 - val_precision_m: 0.7698 - val_recall_m: 0.4960 - val_f1_m: 0.5737\n",
      "Epoch 11/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0581 - acc: 0.9802 - precision_m: 0.8242 - recall_m: 0.5818 - f1_m: 0.6602\n",
      "Epoch 11: val_acc did not improve from 0.97617\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0582 - acc: 0.9803 - precision_m: 0.8276 - recall_m: 0.5811 - f1_m: 0.6609 - val_loss: 0.0719 - val_acc: 0.9750 - val_precision_m: 0.7372 - val_recall_m: 0.5120 - val_f1_m: 0.5707\n",
      "Epoch 12/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0557 - acc: 0.9806 - precision_m: 0.8098 - recall_m: 0.6031 - f1_m: 0.6673\n",
      "Epoch 12: val_acc did not improve from 0.97617\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0560 - acc: 0.9804 - precision_m: 0.8111 - recall_m: 0.5977 - f1_m: 0.6636 - val_loss: 0.0804 - val_acc: 0.9735 - val_precision_m: 0.6394 - val_recall_m: 0.6251 - val_f1_m: 0.6070\n",
      "Epoch 13/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.0552 - acc: 0.9810 - precision_m: 0.8247 - recall_m: 0.6125 - f1_m: 0.6804\n",
      "Epoch 13: val_acc did not improve from 0.97617\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0553 - acc: 0.9810 - precision_m: 0.8296 - recall_m: 0.6074 - f1_m: 0.6775 - val_loss: 0.0771 - val_acc: 0.9738 - val_precision_m: 0.6530 - val_recall_m: 0.6324 - val_f1_m: 0.6164\n",
      "Epoch 14/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0519 - acc: 0.9815 - precision_m: 0.8152 - recall_m: 0.6227 - f1_m: 0.6865\n",
      "Epoch 14: val_acc did not improve from 0.97617\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0520 - acc: 0.9815 - precision_m: 0.8155 - recall_m: 0.6226 - f1_m: 0.6854 - val_loss: 0.0901 - val_acc: 0.9731 - val_precision_m: 0.8308 - val_recall_m: 0.3318 - val_f1_m: 0.4366\n",
      "Epoch 15/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.0510 - acc: 0.9823 - precision_m: 0.8401 - recall_m: 0.6321 - f1_m: 0.6980\n",
      "Epoch 15: val_acc did not improve from 0.97617\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0508 - acc: 0.9824 - precision_m: 0.8421 - recall_m: 0.6348 - f1_m: 0.7012 - val_loss: 0.0772 - val_acc: 0.9739 - val_precision_m: 0.6216 - val_recall_m: 0.6368 - val_f1_m: 0.6098\n",
      "Epoch 16/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9831 - precision_m: 0.8391 - recall_m: 0.6552 - f1_m: 0.7137\n",
      "Epoch 16: val_acc improved from 0.97617 to 0.97688, saving model to models/best_model_1_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0484 - acc: 0.9831 - precision_m: 0.8387 - recall_m: 0.6556 - f1_m: 0.7139 - val_loss: 0.0726 - val_acc: 0.9769 - val_precision_m: 0.7670 - val_recall_m: 0.5135 - val_f1_m: 0.5827\n",
      "Epoch 17/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0455 - acc: 0.9836 - precision_m: 0.8547 - recall_m: 0.6686 - f1_m: 0.7344\n",
      "Epoch 17: val_acc improved from 0.97688 to 0.97700, saving model to models/best_model_1_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0458 - acc: 0.9836 - precision_m: 0.8547 - recall_m: 0.6683 - f1_m: 0.7342 - val_loss: 0.0818 - val_acc: 0.9770 - val_precision_m: 0.8417 - val_recall_m: 0.4570 - val_f1_m: 0.5639\n",
      "Epoch 18/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9845 - precision_m: 0.8604 - recall_m: 0.6892 - f1_m: 0.7444\n",
      "Epoch 18: val_acc improved from 0.97700 to 0.97736, saving model to models/best_model_1_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0444 - acc: 0.9846 - precision_m: 0.8612 - recall_m: 0.6907 - f1_m: 0.7457 - val_loss: 0.0753 - val_acc: 0.9774 - val_precision_m: 0.7536 - val_recall_m: 0.5789 - val_f1_m: 0.6223\n",
      "Epoch 19/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.0437 - acc: 0.9841 - precision_m: 0.8552 - recall_m: 0.6766 - f1_m: 0.7344\n",
      "Epoch 19: val_acc did not improve from 0.97736\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0438 - acc: 0.9842 - precision_m: 0.8557 - recall_m: 0.6801 - f1_m: 0.7373 - val_loss: 0.0879 - val_acc: 0.9764 - val_precision_m: 0.7913 - val_recall_m: 0.4592 - val_f1_m: 0.5470\n",
      "Epoch 20/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9851 - precision_m: 0.8646 - recall_m: 0.7074 - f1_m: 0.7564\n",
      "Epoch 20: val_acc improved from 0.97736 to 0.97939, saving model to models/best_model_1_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0417 - acc: 0.9850 - precision_m: 0.8641 - recall_m: 0.7079 - f1_m: 0.7569 - val_loss: 0.0786 - val_acc: 0.9794 - val_precision_m: 0.8286 - val_recall_m: 0.5274 - val_f1_m: 0.6105\n",
      "Epoch 21/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.0406 - acc: 0.9853 - precision_m: 0.8717 - recall_m: 0.7114 - f1_m: 0.7602\n",
      "Epoch 21: val_acc did not improve from 0.97939\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0407 - acc: 0.9853 - precision_m: 0.8723 - recall_m: 0.7105 - f1_m: 0.7606 - val_loss: 0.0728 - val_acc: 0.9778 - val_precision_m: 0.7233 - val_recall_m: 0.6029 - val_f1_m: 0.6378\n",
      "Epoch 22/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9871 - precision_m: 0.8799 - recall_m: 0.7410 - f1_m: 0.7897\n",
      "Epoch 22: val_acc did not improve from 0.97939\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0376 - acc: 0.9870 - precision_m: 0.8804 - recall_m: 0.7377 - f1_m: 0.7871 - val_loss: 0.0772 - val_acc: 0.9758 - val_precision_m: 0.6800 - val_recall_m: 0.6389 - val_f1_m: 0.6314\n",
      "Epoch 23/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9863 - precision_m: 0.8753 - recall_m: 0.7348 - f1_m: 0.7800\n",
      "Epoch 23: val_acc did not improve from 0.97939\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0378 - acc: 0.9864 - precision_m: 0.8756 - recall_m: 0.7363 - f1_m: 0.7813 - val_loss: 0.0836 - val_acc: 0.9790 - val_precision_m: 0.7730 - val_recall_m: 0.5834 - val_f1_m: 0.6358\n",
      "Epoch 24/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9865 - precision_m: 0.8741 - recall_m: 0.7409 - f1_m: 0.7806\n",
      "Epoch 24: val_acc did not improve from 0.97939\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0374 - acc: 0.9865 - precision_m: 0.8748 - recall_m: 0.7400 - f1_m: 0.7804 - val_loss: 0.0741 - val_acc: 0.9790 - val_precision_m: 0.7632 - val_recall_m: 0.5793 - val_f1_m: 0.6383\n",
      "Epoch 25/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9880 - precision_m: 0.8897 - recall_m: 0.7671 - f1_m: 0.8117\n",
      "Epoch 25: val_acc did not improve from 0.97939\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0325 - acc: 0.9880 - precision_m: 0.8897 - recall_m: 0.7666 - f1_m: 0.8115 - val_loss: 0.0835 - val_acc: 0.9777 - val_precision_m: 0.7427 - val_recall_m: 0.5418 - val_f1_m: 0.6018\n",
      "Epoch 26/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0328 - acc: 0.9879 - precision_m: 0.8881 - recall_m: 0.7617 - f1_m: 0.8054\n",
      "Epoch 26: val_acc did not improve from 0.97939\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0327 - acc: 0.9879 - precision_m: 0.8883 - recall_m: 0.7617 - f1_m: 0.8053 - val_loss: 0.0904 - val_acc: 0.9789 - val_precision_m: 0.7509 - val_recall_m: 0.5626 - val_f1_m: 0.6155\n",
      "Epoch 27/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0303 - acc: 0.9888 - precision_m: 0.8908 - recall_m: 0.7840 - f1_m: 0.8225\n",
      "Epoch 27: val_acc did not improve from 0.97939\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0303 - acc: 0.9888 - precision_m: 0.8917 - recall_m: 0.7849 - f1_m: 0.8235 - val_loss: 0.0833 - val_acc: 0.9794 - val_precision_m: 0.7264 - val_recall_m: 0.6272 - val_f1_m: 0.6556\n",
      "Epoch 28/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9882 - precision_m: 0.8931 - recall_m: 0.7749 - f1_m: 0.8152\n",
      "Epoch 28: val_acc did not improve from 0.97939\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0318 - acc: 0.9882 - precision_m: 0.8934 - recall_m: 0.7753 - f1_m: 0.8156 - val_loss: 0.0838 - val_acc: 0.9776 - val_precision_m: 0.6858 - val_recall_m: 0.6370 - val_f1_m: 0.6395\n",
      "Epoch 29/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9888 - precision_m: 0.8968 - recall_m: 0.7862 - f1_m: 0.8254\n",
      "Epoch 29: val_acc did not improve from 0.97939\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0292 - acc: 0.9888 - precision_m: 0.8958 - recall_m: 0.7886 - f1_m: 0.8263 - val_loss: 0.0903 - val_acc: 0.9765 - val_precision_m: 0.6929 - val_recall_m: 0.6107 - val_f1_m: 0.6232\n",
      "Epoch 30/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.0288 - acc: 0.9892 - precision_m: 0.9025 - recall_m: 0.7913 - f1_m: 0.8272\n",
      "Epoch 30: val_acc did not improve from 0.97939\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0288 - acc: 0.9893 - precision_m: 0.9010 - recall_m: 0.7905 - f1_m: 0.8264 - val_loss: 0.0984 - val_acc: 0.9791 - val_precision_m: 0.7379 - val_recall_m: 0.6497 - val_f1_m: 0.6697\n",
      "Score for fold 9: loss of 0.0786113291978836; acc of 97.93851375579834%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.06979600340127945; acc of 97.80184030532837%\n",
      "Test Precision: precision_m of 27.583622932434082%\n",
      "Test Recall: recall_m of 19.763275980949402%\n",
      "Test F1: f1_m of 22.053177654743195%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1747 - acc: 0.9566 - precision_m: 0.0538 - recall_m: 0.0178 - f1_m: 0.0168\n",
      "Epoch 1: val_acc improved from -inf to 0.96034, saving model to models/best_model_1_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 3s 5ms/step - loss: 0.1747 - acc: 0.9566 - precision_m: 0.0538 - recall_m: 0.0178 - f1_m: 0.0168 - val_loss: 0.1314 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.1069 - acc: 0.9671 - precision_m: 0.5531 - recall_m: 0.1667 - f1_m: 0.2373\n",
      "Epoch 2: val_acc improved from 0.96034 to 0.96575, saving model to models/best_model_1_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1064 - acc: 0.9673 - precision_m: 0.5574 - recall_m: 0.1671 - f1_m: 0.2380 - val_loss: 0.1015 - val_acc: 0.9657 - val_precision_m: 0.6748 - val_recall_m: 0.2143 - val_f1_m: 0.3062\n",
      "Epoch 3/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0915 - acc: 0.9693 - precision_m: 0.6676 - recall_m: 0.2749 - f1_m: 0.3611\n",
      "Epoch 3: val_acc did not improve from 0.96575\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0914 - acc: 0.9694 - precision_m: 0.6692 - recall_m: 0.2801 - f1_m: 0.3653 - val_loss: 0.1140 - val_acc: 0.9641 - val_precision_m: 0.4545 - val_recall_m: 0.1067 - val_f1_m: 0.1643\n",
      "Epoch 4/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0833 - acc: 0.9719 - precision_m: 0.7266 - recall_m: 0.3653 - f1_m: 0.4575\n",
      "Epoch 4: val_acc improved from 0.96575 to 0.97163, saving model to models/best_model_1_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0833 - acc: 0.9718 - precision_m: 0.7277 - recall_m: 0.3640 - f1_m: 0.4564 - val_loss: 0.0903 - val_acc: 0.9716 - val_precision_m: 0.7532 - val_recall_m: 0.5095 - val_f1_m: 0.5770\n",
      "Epoch 5/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0786 - acc: 0.9730 - precision_m: 0.7248 - recall_m: 0.4069 - f1_m: 0.4909\n",
      "Epoch 5: val_acc did not improve from 0.97163\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0787 - acc: 0.9730 - precision_m: 0.7268 - recall_m: 0.4059 - f1_m: 0.4904 - val_loss: 0.0966 - val_acc: 0.9704 - val_precision_m: 0.7613 - val_recall_m: 0.3040 - val_f1_m: 0.4117\n",
      "Epoch 6/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0745 - acc: 0.9749 - precision_m: 0.7578 - recall_m: 0.4781 - f1_m: 0.5527\n",
      "Epoch 6: val_acc improved from 0.97163 to 0.97284, saving model to models/best_model_1_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0742 - acc: 0.9751 - precision_m: 0.7584 - recall_m: 0.4785 - f1_m: 0.5538 - val_loss: 0.0873 - val_acc: 0.9728 - val_precision_m: 0.8379 - val_recall_m: 0.4523 - val_f1_m: 0.5529\n",
      "Epoch 7/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0724 - acc: 0.9756 - precision_m: 0.7594 - recall_m: 0.4822 - f1_m: 0.5575\n",
      "Epoch 7: val_acc did not improve from 0.97284\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0722 - acc: 0.9757 - precision_m: 0.7591 - recall_m: 0.4844 - f1_m: 0.5594 - val_loss: 0.0883 - val_acc: 0.9719 - val_precision_m: 0.8161 - val_recall_m: 0.4131 - val_f1_m: 0.5140\n",
      "Epoch 8/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0677 - acc: 0.9769 - precision_m: 0.7767 - recall_m: 0.5172 - f1_m: 0.5930\n",
      "Epoch 8: val_acc improved from 0.97284 to 0.97296, saving model to models/best_model_1_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0676 - acc: 0.9769 - precision_m: 0.7781 - recall_m: 0.5192 - f1_m: 0.5944 - val_loss: 0.0912 - val_acc: 0.9730 - val_precision_m: 0.8520 - val_recall_m: 0.3935 - val_f1_m: 0.5076\n",
      "Epoch 9/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0641 - acc: 0.9783 - precision_m: 0.7937 - recall_m: 0.5531 - f1_m: 0.6304\n",
      "Epoch 9: val_acc did not improve from 0.97296\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0641 - acc: 0.9783 - precision_m: 0.7913 - recall_m: 0.5493 - f1_m: 0.6266 - val_loss: 0.0901 - val_acc: 0.9712 - val_precision_m: 0.8226 - val_recall_m: 0.3108 - val_f1_m: 0.4311\n",
      "Epoch 10/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0624 - acc: 0.9789 - precision_m: 0.8127 - recall_m: 0.5722 - f1_m: 0.6431\n",
      "Epoch 10: val_acc improved from 0.97296 to 0.97500, saving model to models/best_model_1_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0626 - acc: 0.9789 - precision_m: 0.8131 - recall_m: 0.5706 - f1_m: 0.6420 - val_loss: 0.0805 - val_acc: 0.9750 - val_precision_m: 0.8317 - val_recall_m: 0.4954 - val_f1_m: 0.5894\n",
      "Epoch 11/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0581 - acc: 0.9800 - precision_m: 0.8001 - recall_m: 0.5859 - f1_m: 0.6520\n",
      "Epoch 11: val_acc improved from 0.97500 to 0.97512, saving model to models/best_model_1_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0581 - acc: 0.9800 - precision_m: 0.8037 - recall_m: 0.5881 - f1_m: 0.6546 - val_loss: 0.0829 - val_acc: 0.9751 - val_precision_m: 0.8236 - val_recall_m: 0.4599 - val_f1_m: 0.5616\n",
      "Epoch 12/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0568 - acc: 0.9804 - precision_m: 0.8262 - recall_m: 0.6043 - f1_m: 0.6710\n",
      "Epoch 12: val_acc did not improve from 0.97512\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0575 - acc: 0.9802 - precision_m: 0.8267 - recall_m: 0.6030 - f1_m: 0.6692 - val_loss: 0.1214 - val_acc: 0.9692 - val_precision_m: 0.8030 - val_recall_m: 0.2345 - val_f1_m: 0.3504\n",
      "Epoch 13/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.0561 - acc: 0.9806 - precision_m: 0.8177 - recall_m: 0.6091 - f1_m: 0.6672\n",
      "Epoch 13: val_acc did not improve from 0.97512\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0561 - acc: 0.9806 - precision_m: 0.8177 - recall_m: 0.6091 - f1_m: 0.6672 - val_loss: 0.0953 - val_acc: 0.9743 - val_precision_m: 0.8761 - val_recall_m: 0.4220 - val_f1_m: 0.5503\n",
      "Epoch 14/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9821 - precision_m: 0.8295 - recall_m: 0.6389 - f1_m: 0.6996\n",
      "Epoch 14: val_acc did not improve from 0.97512\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0522 - acc: 0.9821 - precision_m: 0.8302 - recall_m: 0.6376 - f1_m: 0.6995 - val_loss: 0.0795 - val_acc: 0.9743 - val_precision_m: 0.7873 - val_recall_m: 0.4986 - val_f1_m: 0.5811\n",
      "Epoch 15/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0514 - acc: 0.9823 - precision_m: 0.8329 - recall_m: 0.6515 - f1_m: 0.7103\n",
      "Epoch 15: val_acc improved from 0.97512 to 0.97692, saving model to models/best_model_1_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0513 - acc: 0.9824 - precision_m: 0.8332 - recall_m: 0.6514 - f1_m: 0.7099 - val_loss: 0.0845 - val_acc: 0.9769 - val_precision_m: 0.8864 - val_recall_m: 0.5059 - val_f1_m: 0.6163\n",
      "Epoch 16/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9837 - precision_m: 0.8447 - recall_m: 0.6775 - f1_m: 0.7319\n",
      "Epoch 16: val_acc did not improve from 0.97692\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0488 - acc: 0.9837 - precision_m: 0.8438 - recall_m: 0.6758 - f1_m: 0.7305 - val_loss: 0.0831 - val_acc: 0.9762 - val_precision_m: 0.8982 - val_recall_m: 0.4884 - val_f1_m: 0.6050\n",
      "Epoch 17/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0491 - acc: 0.9829 - precision_m: 0.8418 - recall_m: 0.6507 - f1_m: 0.7112\n",
      "Epoch 17: val_acc did not improve from 0.97692\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0491 - acc: 0.9829 - precision_m: 0.8424 - recall_m: 0.6504 - f1_m: 0.7112 - val_loss: 0.0780 - val_acc: 0.9760 - val_precision_m: 0.8035 - val_recall_m: 0.5335 - val_f1_m: 0.6160\n",
      "Epoch 18/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0459 - acc: 0.9845 - precision_m: 0.8589 - recall_m: 0.6884 - f1_m: 0.7456\n",
      "Epoch 18: val_acc did not improve from 0.97692\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0459 - acc: 0.9845 - precision_m: 0.8588 - recall_m: 0.6876 - f1_m: 0.7449 - val_loss: 0.0774 - val_acc: 0.9763 - val_precision_m: 0.7501 - val_recall_m: 0.6240 - val_f1_m: 0.6581\n",
      "Epoch 19/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9851 - precision_m: 0.8569 - recall_m: 0.7064 - f1_m: 0.7601\n",
      "Epoch 19: val_acc did not improve from 0.97692\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0429 - acc: 0.9850 - precision_m: 0.8563 - recall_m: 0.7064 - f1_m: 0.7601 - val_loss: 0.0843 - val_acc: 0.9754 - val_precision_m: 0.7569 - val_recall_m: 0.5410 - val_f1_m: 0.6041\n",
      "Epoch 20/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0433 - acc: 0.9852 - precision_m: 0.8645 - recall_m: 0.7174 - f1_m: 0.7642\n",
      "Epoch 20: val_acc improved from 0.97692 to 0.97728, saving model to models/best_model_1_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0433 - acc: 0.9852 - precision_m: 0.8659 - recall_m: 0.7170 - f1_m: 0.7646 - val_loss: 0.0833 - val_acc: 0.9773 - val_precision_m: 0.8039 - val_recall_m: 0.5716 - val_f1_m: 0.6454\n",
      "Epoch 21/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9854 - precision_m: 0.8584 - recall_m: 0.7106 - f1_m: 0.7593\n",
      "Epoch 21: val_acc did not improve from 0.97728\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0419 - acc: 0.9854 - precision_m: 0.8585 - recall_m: 0.7105 - f1_m: 0.7597 - val_loss: 0.0794 - val_acc: 0.9768 - val_precision_m: 0.7880 - val_recall_m: 0.6163 - val_f1_m: 0.6656\n",
      "Epoch 22/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0396 - acc: 0.9863 - precision_m: 0.8736 - recall_m: 0.7289 - f1_m: 0.7808\n",
      "Epoch 22: val_acc did not improve from 0.97728\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0396 - acc: 0.9863 - precision_m: 0.8732 - recall_m: 0.7295 - f1_m: 0.7804 - val_loss: 0.0870 - val_acc: 0.9695 - val_precision_m: 0.5937 - val_recall_m: 0.6992 - val_f1_m: 0.6216\n",
      "Epoch 23/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0396 - acc: 0.9863 - precision_m: 0.8706 - recall_m: 0.7300 - f1_m: 0.7787\n",
      "Epoch 23: val_acc improved from 0.97728 to 0.97788, saving model to models/best_model_1_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0394 - acc: 0.9863 - precision_m: 0.8715 - recall_m: 0.7312 - f1_m: 0.7798 - val_loss: 0.0849 - val_acc: 0.9779 - val_precision_m: 0.7888 - val_recall_m: 0.6446 - val_f1_m: 0.6857\n",
      "Epoch 24/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9871 - precision_m: 0.8883 - recall_m: 0.7417 - f1_m: 0.7942\n",
      "Epoch 24: val_acc did not improve from 0.97788\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0370 - acc: 0.9871 - precision_m: 0.8887 - recall_m: 0.7426 - f1_m: 0.7949 - val_loss: 0.0881 - val_acc: 0.9764 - val_precision_m: 0.7432 - val_recall_m: 0.6349 - val_f1_m: 0.6653\n",
      "Epoch 25/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0351 - acc: 0.9880 - precision_m: 0.8920 - recall_m: 0.7615 - f1_m: 0.8085\n",
      "Epoch 25: val_acc did not improve from 0.97788\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0351 - acc: 0.9879 - precision_m: 0.8919 - recall_m: 0.7604 - f1_m: 0.8080 - val_loss: 0.0837 - val_acc: 0.9756 - val_precision_m: 0.7160 - val_recall_m: 0.6489 - val_f1_m: 0.6586\n",
      "Epoch 26/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.0353 - acc: 0.9874 - precision_m: 0.8784 - recall_m: 0.7588 - f1_m: 0.7997\n",
      "Epoch 26: val_acc did not improve from 0.97788\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0353 - acc: 0.9874 - precision_m: 0.8784 - recall_m: 0.7588 - f1_m: 0.7997 - val_loss: 0.0993 - val_acc: 0.9762 - val_precision_m: 0.8394 - val_recall_m: 0.5307 - val_f1_m: 0.6232\n",
      "Epoch 27/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0339 - acc: 0.9878 - precision_m: 0.8944 - recall_m: 0.7593 - f1_m: 0.8074\n",
      "Epoch 27: val_acc did not improve from 0.97788\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0336 - acc: 0.9879 - precision_m: 0.8943 - recall_m: 0.7610 - f1_m: 0.8087 - val_loss: 0.0979 - val_acc: 0.9775 - val_precision_m: 0.8018 - val_recall_m: 0.5832 - val_f1_m: 0.6536\n",
      "Epoch 28/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0324 - acc: 0.9887 - precision_m: 0.8937 - recall_m: 0.7714 - f1_m: 0.8140\n",
      "Epoch 28: val_acc did not improve from 0.97788\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0323 - acc: 0.9887 - precision_m: 0.8945 - recall_m: 0.7731 - f1_m: 0.8159 - val_loss: 0.0896 - val_acc: 0.9773 - val_precision_m: 0.7330 - val_recall_m: 0.6365 - val_f1_m: 0.6617\n",
      "Epoch 29/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0304 - acc: 0.9891 - precision_m: 0.8940 - recall_m: 0.8001 - f1_m: 0.8319\n",
      "Epoch 29: val_acc did not improve from 0.97788\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0307 - acc: 0.9891 - precision_m: 0.8935 - recall_m: 0.7985 - f1_m: 0.8304 - val_loss: 0.0836 - val_acc: 0.9744 - val_precision_m: 0.7219 - val_recall_m: 0.6593 - val_f1_m: 0.6645\n",
      "Epoch 30/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9892 - precision_m: 0.8913 - recall_m: 0.8006 - f1_m: 0.8320\n",
      "Epoch 30: val_acc did not improve from 0.97788\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0292 - acc: 0.9892 - precision_m: 0.8917 - recall_m: 0.8004 - f1_m: 0.8321 - val_loss: 0.1087 - val_acc: 0.9770 - val_precision_m: 0.8124 - val_recall_m: 0.5183 - val_f1_m: 0.6141\n",
      "Score for fold 10: loss of 0.08487985283136368; acc of 97.7884590625763%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.06430767476558685; acc of 97.83682823181152%\n",
      "Test Precision: precision_m of 32.976606488227844%\n",
      "Test Recall: recall_m of 27.79545783996582%\n",
      "Test F1: f1_m of 28.960898518562317%\n",
      "------------------------------------------------------------------------\n",
      "Validation score per fold\n",
      "> Fold 1 - Loss: 0.07865358144044876 - Accuracy: 97.93383479118347%\n",
      "> Fold 2 - Loss: 0.07635778188705444 - Accuracy: 97.9164183139801%\n",
      "> Fold 3 - Loss: 0.0724339634180069 - Accuracy: 98.13128709793091%\n",
      "> Fold 4 - Loss: 0.09699736535549164 - Accuracy: 98.10149073600769%\n",
      "> Fold 5 - Loss: 0.09691799432039261 - Accuracy: 97.93235063552856%\n",
      "> Fold 6 - Loss: 0.07121623307466507 - Accuracy: 97.75822758674622%\n",
      "> Fold 7 - Loss: 0.0705006867647171 - Accuracy: 98.01672697067261%\n",
      "> Fold 8 - Loss: 0.07435198128223419 - Accuracy: 98.03545475006104%\n",
      "> Fold 9 - Loss: 0.0786113291978836 - Accuracy: 97.93851375579834%\n",
      "> Fold 10 - Loss: 0.08487985283136368 - Accuracy: 97.7884590625763%\n",
      "------------------------------------------------------------------------\n",
      "Testing score per fold\n",
      "> Fold 1 - Accuracy: 98.26105833053589 - Precision: 24.260564148426056 - Recall: 18.379302322864532 - F1: 19.992582499980927%\n",
      "> Fold 2 - Accuracy: 97.71533012390137 - Precision: 29.585370421409607 - Recall: 22.675712406635284 - F1: 24.570707976818085%\n",
      "> Fold 3 - Accuracy: 98.03774952888489 - Precision: 28.061223030090332 - Recall: 21.725380420684814 - F1: 23.5274538397789%\n",
      "> Fold 4 - Accuracy: 97.53326773643494 - Precision: 31.135687232017517 - Recall: 25.165820121765137 - F1: 26.554447412490845%\n",
      "> Fold 5 - Accuracy: 97.77920246124268 - Precision: 28.250446915626526 - Recall: 24.305254220962524 - F1: 24.782028794288635%\n",
      "> Fold 6 - Accuracy: 97.87789583206177 - Precision: 28.255996108055115 - Recall: 23.23192209005356 - F1: 24.64188188314438%\n",
      "> Fold 7 - Accuracy: 98.2195496559143 - Precision: 23.426246643066406 - Recall: 18.6100035905838 - F1: 19.845329225063324%\n",
      "> Fold 8 - Accuracy: 97.99756407737732 - Precision: 26.321163773536682 - Recall: 22.40196019411087 - F1: 23.255880177021027%\n",
      "> Fold 9 - Accuracy: 97.80184030532837 - Precision: 27.583622932434082 - Recall: 19.763275980949402 - F1: 22.053177654743195%\n",
      "> Fold 10 - Accuracy: 97.83682823181152 - Precision: 32.976606488227844 - Recall: 27.79545783996582 - F1: 28.960898518562317%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Validation Accuracy: 97.95527637004852 (+- 0.11488936744522817)\n",
      "> Validation Loss: 0.0800920769572258\n",
      "> Testing Accuracy: 97.9060286283493 (+- 0.21398773160886242)\n",
      "> Testing Precision: 27.985692769289017\n",
      "> Testing Recall: 22.405408918857574\n",
      "> Testing F1: 23.818438798189163\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Lists to hold cross-validation results\n",
    "acc_1_per_fold = []\n",
    "loss_1_per_fold = []\n",
    "precision_1_per_fold = []\n",
    "recall_1_per_fold = []\n",
    "f1_1_per_fold = []\n",
    "\n",
    "testing_acc_1_per_fold = []\n",
    "testing_precision_1_per_fold = []\n",
    "testing_recall_1_per_fold = []\n",
    "testing_f1_1_per_fold = []\n",
    "\n",
    "# Load data from .npz files\n",
    "for fold_no in range(1, 11):\n",
    "    with np.load(f'fold_{fold_no}.npz') as data:\n",
    "        x_train = data['x_train_fold.npy']\n",
    "        y_train = data['y_train_fold.npy']\n",
    "        x_val = data['x_val_fold.npy']\n",
    "        y_val = data['y_val_fold.npy']\n",
    "        x_test = data['x_test_fold.npy']\n",
    "        y_test = data['y_test_fold.npy']\n",
    "        \n",
    "        # Converting ground truth arrays to one wake word (1) and 'other' (0)\n",
    "        wake_word_index = all_targets.index(wake_word)\n",
    "        y_train = np.equal(y_train, wake_word_index).astype('float64')\n",
    "        y_val = np.equal(y_val, wake_word_index).astype('float64')\n",
    "        y_test = np.equal(y_test, wake_word_index).astype('float64')\n",
    "        \n",
    "        # CNN for TF expects (batch, height, width, channels)\n",
    "        x_train = x_train.reshape(x_train.shape[0], \n",
    "                          x_train.shape[1], \n",
    "                          x_train.shape[2], \n",
    "                          1)\n",
    "        x_val = x_val.reshape(x_val.shape[0], \n",
    "                          x_val.shape[1], \n",
    "                          x_val.shape[2], \n",
    "                          1)\n",
    "        x_test = x_test.reshape(x_test.shape[0], \n",
    "                          x_test.shape[1], \n",
    "                          x_test.shape[2], \n",
    "                          1)\n",
    "        sample_shape = x_test.shape[1:]\n",
    "\n",
    "    # CNN model\n",
    "    model_1 = models.Sequential()\n",
    "    model_1.add(layers.Conv2D(32, \n",
    "                            (2, 2), \n",
    "                            activation='relu',\n",
    "                            input_shape=sample_shape))\n",
    "    model_1.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model_1.add(layers.Conv2D(32, (2, 2), activation='relu'))\n",
    "    model_1.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model_1.add(layers.Conv2D(64, (2, 2), activation='relu'))\n",
    "    model_1.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Classifier\n",
    "    model_1.add(layers.Flatten())\n",
    "    model_1.add(layers.Dense(64, activation='relu'))\n",
    "    model_1.add(layers.Dropout(0.5))\n",
    "    model_1.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "\n",
    "    model_1.compile(loss='binary_crossentropy', \n",
    "              optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "              metrics=['acc', precision_m, recall_m, f1_m])\n",
    "\n",
    "    checkpoint_filepath = f'models/best_model_1_fold_{fold_no}.h5'\n",
    "    model_checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=False,\n",
    "        monitor='val_acc',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "        save_freq='epoch'\n",
    "    )\n",
    "\n",
    "    # Instantiate the custom callback\n",
    "    metrics_history = MetricsHistory()\n",
    "    \n",
    "    # Print fold number\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Train\n",
    "    history_1 = model_1.fit(x_train, \n",
    "                    y_train, \n",
    "                    epochs=30, \n",
    "                    batch_size=256, \n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[model_checkpoint_callback, metrics_history])\n",
    "\n",
    "    model_1.load_weights(checkpoint_filepath)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    scores = model_1.evaluate(x_val, y_val, verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model_1.metrics_names[0]} of {scores[0]}; {model_1.metrics_names[1]} of {scores[1] * 100}%')\n",
    "    acc_1_per_fold.append(scores[1] * 100)\n",
    "    loss_1_per_fold.append(scores[0])\n",
    "    precision_1_per_fold.append(metrics_history.best_metrics['precision_m'] * 100)\n",
    "    recall_1_per_fold.append(metrics_history.best_metrics['recall_m'] * 100)\n",
    "    f1_1_per_fold.append(metrics_history.best_metrics['f1_m'] * 100)\n",
    "\n",
    "    # Final evaluation on test set\n",
    "    final_scores = model_1.evaluate(x_test, y_test, verbose=0)\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Final test score: {model_1.metrics_names[0]} of {final_scores[0]}; {model_1.metrics_names[1]} of {final_scores[1] * 100}%')\n",
    "    print(f'Test Precision: {model_1.metrics_names[2]} of {final_scores[2] * 100}%')\n",
    "    print(f'Test Recall: {model_1.metrics_names[3]} of {final_scores[3] * 100}%')\n",
    "    print(f'Test F1: {model_1.metrics_names[4]} of {final_scores[4] * 100}%')\n",
    "\n",
    "    # Append test metrics to lists\n",
    "    testing_acc_1_per_fold.append(final_scores[1] * 100)\n",
    "    testing_precision_1_per_fold.append(final_scores[2] * 100)\n",
    "    testing_recall_1_per_fold.append(final_scores[3] * 100)\n",
    "    testing_f1_1_per_fold.append(final_scores[4] * 100)\n",
    "\n",
    "# Print the results\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Validation score per fold')\n",
    "for i in range(0, len(acc_1_per_fold)):\n",
    "    print(f'> Fold {i+1} - Loss: {loss_1_per_fold[i]} - Accuracy: {acc_1_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Testing score per fold')\n",
    "for i in range(0, len(testing_acc_1_per_fold)):\n",
    "    print(f'> Fold {i+1} - Accuracy: {testing_acc_1_per_fold[i]} - Precision: {testing_precision_1_per_fold[i]} - Recall: {testing_recall_1_per_fold[i]} - F1: {testing_f1_1_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Validation Accuracy: {np.mean(acc_1_per_fold)} (+- {np.std(acc_1_per_fold)})')\n",
    "print(f'> Validation Loss: {np.mean(loss_1_per_fold)}')\n",
    "print(f'> Testing Accuracy: {np.mean(testing_acc_1_per_fold)} (+- {np.std(testing_acc_1_per_fold)})')\n",
    "print(f'> Testing Precision: {np.mean(testing_precision_1_per_fold)}')\n",
    "print(f'> Testing Recall: {np.mean(testing_recall_1_per_fold)}')\n",
    "print(f'> Testing F1: {np.mean(testing_f1_1_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9583833813667297, 0.9662671685218811, 0.9701004028320312, 0.9732053875923157, 0.9744064807891846, 0.9765658974647522, 0.9774219989776611, 0.9790575504302979, 0.9796197414398193, 0.9802841544151306, 0.9816257953643799, 0.9820346832275391, 0.9823285937309265, 0.9832485914230347, 0.9838491082191467, 0.9840535521507263, 0.9843857884407043, 0.9847818613052368, 0.9859574437141418, 0.9861490726470947, 0.9871202111244202, 0.9874396324157715, 0.9876951575279236, 0.9889729619026184, 0.9884235262870789, 0.9887429475784302, 0.9895351529121399, 0.9899057149887085, 0.990135669708252, 0.9907873272895813]\n",
      "[98.13594222068787, 97.99796342849731, 98.19346070289612, 98.1485664844513, 98.329758644104, 98.12265038490295, 98.11171293258667, 98.08063507080078, 98.14374446868896, 98.20086359977722]\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(history_1.history['acc'])\n",
    "print(acc_1_per_fold)\n",
    "print(len(testing_acc_1_per_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1775 - acc: 0.9569 - precision_m: 0.0638 - recall_m: 0.0129 - f1_m: 0.0149\n",
      "Epoch 1: val_acc improved from -inf to 0.96023, saving model to models/best_model_2_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 3s 5ms/step - loss: 0.1775 - acc: 0.9569 - precision_m: 0.0638 - recall_m: 0.0129 - f1_m: 0.0149 - val_loss: 0.1233 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.1168 - acc: 0.9636 - precision_m: 0.3713 - recall_m: 0.0800 - f1_m: 0.1237\n",
      "Epoch 2: val_acc improved from 0.96023 to 0.96298, saving model to models/best_model_2_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1157 - acc: 0.9638 - precision_m: 0.3800 - recall_m: 0.0818 - f1_m: 0.1266 - val_loss: 0.1031 - val_acc: 0.9630 - val_precision_m: 0.4596 - val_recall_m: 0.1026 - val_f1_m: 0.1598\n",
      "Epoch 3/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0991 - acc: 0.9666 - precision_m: 0.6367 - recall_m: 0.2067 - f1_m: 0.2933\n",
      "Epoch 3: val_acc improved from 0.96298 to 0.96859, saving model to models/best_model_2_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0994 - acc: 0.9666 - precision_m: 0.6392 - recall_m: 0.2066 - f1_m: 0.2937 - val_loss: 0.0983 - val_acc: 0.9686 - val_precision_m: 0.6248 - val_recall_m: 0.4102 - val_f1_m: 0.4740\n",
      "Epoch 4/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0920 - acc: 0.9684 - precision_m: 0.6649 - recall_m: 0.2788 - f1_m: 0.3692\n",
      "Epoch 4: val_acc did not improve from 0.96859\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0919 - acc: 0.9684 - precision_m: 0.6624 - recall_m: 0.2780 - f1_m: 0.3683 - val_loss: 0.0951 - val_acc: 0.9674 - val_precision_m: 0.7323 - val_recall_m: 0.1862 - val_f1_m: 0.2776\n",
      "Epoch 5/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.0848 - acc: 0.9703 - precision_m: 0.6892 - recall_m: 0.3372 - f1_m: 0.4324\n",
      "Epoch 5: val_acc improved from 0.96859 to 0.97014, saving model to models/best_model_2_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0854 - acc: 0.9702 - precision_m: 0.6931 - recall_m: 0.3397 - f1_m: 0.4350 - val_loss: 0.0950 - val_acc: 0.9701 - val_precision_m: 0.8184 - val_recall_m: 0.2725 - val_f1_m: 0.3876\n",
      "Epoch 6/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.0806 - acc: 0.9715 - precision_m: 0.7239 - recall_m: 0.3905 - f1_m: 0.4835\n",
      "Epoch 6: val_acc improved from 0.97014 to 0.97193, saving model to models/best_model_2_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0806 - acc: 0.9715 - precision_m: 0.7239 - recall_m: 0.3905 - f1_m: 0.4835 - val_loss: 0.0837 - val_acc: 0.9719 - val_precision_m: 0.7295 - val_recall_m: 0.4099 - val_f1_m: 0.4970\n",
      "Epoch 7/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0777 - acc: 0.9727 - precision_m: 0.7388 - recall_m: 0.4129 - f1_m: 0.5045\n",
      "Epoch 7: val_acc did not improve from 0.97193\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0777 - acc: 0.9727 - precision_m: 0.7379 - recall_m: 0.4122 - f1_m: 0.5039 - val_loss: 0.0847 - val_acc: 0.9700 - val_precision_m: 0.6667 - val_recall_m: 0.4168 - val_f1_m: 0.4801\n",
      "Epoch 8/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0737 - acc: 0.9741 - precision_m: 0.7616 - recall_m: 0.4538 - f1_m: 0.5459\n",
      "Epoch 8: val_acc improved from 0.97193 to 0.97313, saving model to models/best_model_2_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0741 - acc: 0.9740 - precision_m: 0.7606 - recall_m: 0.4538 - f1_m: 0.5455 - val_loss: 0.0796 - val_acc: 0.9731 - val_precision_m: 0.6853 - val_recall_m: 0.4791 - val_f1_m: 0.5442\n",
      "Epoch 9/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.0719 - acc: 0.9748 - precision_m: 0.7707 - recall_m: 0.4680 - f1_m: 0.5577\n",
      "Epoch 9: val_acc did not improve from 0.97313\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0720 - acc: 0.9748 - precision_m: 0.7714 - recall_m: 0.4679 - f1_m: 0.5579 - val_loss: 0.0823 - val_acc: 0.9719 - val_precision_m: 0.7092 - val_recall_m: 0.4266 - val_f1_m: 0.5081\n",
      "Epoch 10/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.0694 - acc: 0.9752 - precision_m: 0.7682 - recall_m: 0.4959 - f1_m: 0.5798\n",
      "Epoch 10: val_acc improved from 0.97313 to 0.97349, saving model to models/best_model_2_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0692 - acc: 0.9752 - precision_m: 0.7681 - recall_m: 0.4927 - f1_m: 0.5764 - val_loss: 0.0775 - val_acc: 0.9735 - val_precision_m: 0.6885 - val_recall_m: 0.5175 - val_f1_m: 0.5562\n",
      "Epoch 11/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.0662 - acc: 0.9764 - precision_m: 0.7827 - recall_m: 0.5002 - f1_m: 0.5876\n",
      "Epoch 11: val_acc did not improve from 0.97349\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0665 - acc: 0.9762 - precision_m: 0.7776 - recall_m: 0.5027 - f1_m: 0.5876 - val_loss: 0.0796 - val_acc: 0.9730 - val_precision_m: 0.6941 - val_recall_m: 0.4837 - val_f1_m: 0.5451\n",
      "Epoch 12/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.0635 - acc: 0.9772 - precision_m: 0.7969 - recall_m: 0.5244 - f1_m: 0.6116\n",
      "Epoch 12: val_acc improved from 0.97349 to 0.97396, saving model to models/best_model_2_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0635 - acc: 0.9772 - precision_m: 0.7969 - recall_m: 0.5244 - f1_m: 0.6116 - val_loss: 0.0773 - val_acc: 0.9740 - val_precision_m: 0.6962 - val_recall_m: 0.5128 - val_f1_m: 0.5589\n",
      "Epoch 13/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0624 - acc: 0.9778 - precision_m: 0.8014 - recall_m: 0.5432 - f1_m: 0.6276\n",
      "Epoch 13: val_acc improved from 0.97396 to 0.97468, saving model to models/best_model_2_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0626 - acc: 0.9778 - precision_m: 0.8004 - recall_m: 0.5454 - f1_m: 0.6292 - val_loss: 0.0801 - val_acc: 0.9747 - val_precision_m: 0.7056 - val_recall_m: 0.5196 - val_f1_m: 0.5760\n",
      "Epoch 14/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9783 - precision_m: 0.8005 - recall_m: 0.5596 - f1_m: 0.6394\n",
      "Epoch 14: val_acc improved from 0.97468 to 0.97480, saving model to models/best_model_2_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0603 - acc: 0.9783 - precision_m: 0.8005 - recall_m: 0.5596 - f1_m: 0.6395 - val_loss: 0.0765 - val_acc: 0.9748 - val_precision_m: 0.6879 - val_recall_m: 0.5193 - val_f1_m: 0.5712\n",
      "Epoch 15/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.0604 - acc: 0.9782 - precision_m: 0.8011 - recall_m: 0.5494 - f1_m: 0.6288\n",
      "Epoch 15: val_acc did not improve from 0.97480\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0604 - acc: 0.9782 - precision_m: 0.8075 - recall_m: 0.5494 - f1_m: 0.6308 - val_loss: 0.0740 - val_acc: 0.9744 - val_precision_m: 0.6930 - val_recall_m: 0.5215 - val_f1_m: 0.5705\n",
      "Epoch 16/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.0580 - acc: 0.9788 - precision_m: 0.8025 - recall_m: 0.5713 - f1_m: 0.6424\n",
      "Epoch 16: val_acc improved from 0.97480 to 0.97516, saving model to models/best_model_2_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0580 - acc: 0.9788 - precision_m: 0.8025 - recall_m: 0.5713 - f1_m: 0.6424 - val_loss: 0.0934 - val_acc: 0.9752 - val_precision_m: 0.8085 - val_recall_m: 0.4484 - val_f1_m: 0.5473\n",
      "Epoch 17/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.0557 - acc: 0.9802 - precision_m: 0.8280 - recall_m: 0.5880 - f1_m: 0.6713\n",
      "Epoch 17: val_acc improved from 0.97516 to 0.97611, saving model to models/best_model_2_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0560 - acc: 0.9801 - precision_m: 0.8266 - recall_m: 0.5869 - f1_m: 0.6703 - val_loss: 0.0763 - val_acc: 0.9761 - val_precision_m: 0.7838 - val_recall_m: 0.4816 - val_f1_m: 0.5703\n",
      "Epoch 18/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.0549 - acc: 0.9796 - precision_m: 0.8248 - recall_m: 0.5842 - f1_m: 0.6596\n",
      "Epoch 18: val_acc improved from 0.97611 to 0.97635, saving model to models/best_model_2_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0549 - acc: 0.9796 - precision_m: 0.8248 - recall_m: 0.5842 - f1_m: 0.6596 - val_loss: 0.0797 - val_acc: 0.9764 - val_precision_m: 0.7685 - val_recall_m: 0.5255 - val_f1_m: 0.5992\n",
      "Epoch 19/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0542 - acc: 0.9805 - precision_m: 0.8239 - recall_m: 0.5973 - f1_m: 0.6772\n",
      "Epoch 19: val_acc improved from 0.97635 to 0.97647, saving model to models/best_model_2_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0542 - acc: 0.9803 - precision_m: 0.8240 - recall_m: 0.5923 - f1_m: 0.6730 - val_loss: 0.0774 - val_acc: 0.9765 - val_precision_m: 0.7755 - val_recall_m: 0.5046 - val_f1_m: 0.5845\n",
      "Epoch 20/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0521 - acc: 0.9809 - precision_m: 0.8379 - recall_m: 0.6181 - f1_m: 0.6927\n",
      "Epoch 20: val_acc did not improve from 0.97647\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0523 - acc: 0.9810 - precision_m: 0.8389 - recall_m: 0.6204 - f1_m: 0.6944 - val_loss: 0.0779 - val_acc: 0.9756 - val_precision_m: 0.7748 - val_recall_m: 0.4931 - val_f1_m: 0.5761\n",
      "Epoch 21/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.0516 - acc: 0.9812 - precision_m: 0.8446 - recall_m: 0.6216 - f1_m: 0.6964\n",
      "Epoch 21: val_acc did not improve from 0.97647\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0519 - acc: 0.9811 - precision_m: 0.8421 - recall_m: 0.6201 - f1_m: 0.6944 - val_loss: 0.0720 - val_acc: 0.9760 - val_precision_m: 0.7066 - val_recall_m: 0.6035 - val_f1_m: 0.6212\n",
      "Epoch 22/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.0509 - acc: 0.9814 - precision_m: 0.8475 - recall_m: 0.6280 - f1_m: 0.7011\n",
      "Epoch 22: val_acc improved from 0.97647 to 0.97731, saving model to models/best_model_2_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0510 - acc: 0.9814 - precision_m: 0.8472 - recall_m: 0.6280 - f1_m: 0.7011 - val_loss: 0.0735 - val_acc: 0.9773 - val_precision_m: 0.7595 - val_recall_m: 0.5684 - val_f1_m: 0.6186\n",
      "Epoch 23/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0491 - acc: 0.9817 - precision_m: 0.8431 - recall_m: 0.6336 - f1_m: 0.7058\n",
      "Epoch 23: val_acc did not improve from 0.97731\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0491 - acc: 0.9818 - precision_m: 0.8437 - recall_m: 0.6346 - f1_m: 0.7067 - val_loss: 0.0745 - val_acc: 0.9756 - val_precision_m: 0.6983 - val_recall_m: 0.5835 - val_f1_m: 0.6060\n",
      "Epoch 24/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.0494 - acc: 0.9819 - precision_m: 0.8463 - recall_m: 0.6409 - f1_m: 0.7119\n",
      "Epoch 24: val_acc did not improve from 0.97731\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0491 - acc: 0.9819 - precision_m: 0.8463 - recall_m: 0.6393 - f1_m: 0.7101 - val_loss: 0.0764 - val_acc: 0.9773 - val_precision_m: 0.7712 - val_recall_m: 0.5491 - val_f1_m: 0.6124\n",
      "Epoch 25/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.0494 - acc: 0.9820 - precision_m: 0.8574 - recall_m: 0.6348 - f1_m: 0.7070\n",
      "Epoch 25: val_acc did not improve from 0.97731\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0492 - acc: 0.9820 - precision_m: 0.8544 - recall_m: 0.6358 - f1_m: 0.7059 - val_loss: 0.0886 - val_acc: 0.9748 - val_precision_m: 0.8134 - val_recall_m: 0.4110 - val_f1_m: 0.5206\n",
      "Epoch 26/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.0474 - acc: 0.9824 - precision_m: 0.8578 - recall_m: 0.6418 - f1_m: 0.7141\n",
      "Epoch 26: val_acc did not improve from 0.97731\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0473 - acc: 0.9824 - precision_m: 0.8575 - recall_m: 0.6379 - f1_m: 0.7115 - val_loss: 0.0761 - val_acc: 0.9759 - val_precision_m: 0.6898 - val_recall_m: 0.6416 - val_f1_m: 0.6348\n",
      "Epoch 27/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.0458 - acc: 0.9829 - precision_m: 0.8538 - recall_m: 0.6521 - f1_m: 0.7243\n",
      "Epoch 27: val_acc improved from 0.97731 to 0.97779, saving model to models/best_model_2_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0458 - acc: 0.9829 - precision_m: 0.8585 - recall_m: 0.6520 - f1_m: 0.7260 - val_loss: 0.0728 - val_acc: 0.9778 - val_precision_m: 0.7461 - val_recall_m: 0.5848 - val_f1_m: 0.6242\n",
      "Epoch 28/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.0454 - acc: 0.9834 - precision_m: 0.8634 - recall_m: 0.6708 - f1_m: 0.7403\n",
      "Epoch 28: val_acc did not improve from 0.97779\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0454 - acc: 0.9834 - precision_m: 0.8634 - recall_m: 0.6708 - f1_m: 0.7403 - val_loss: 0.0779 - val_acc: 0.9773 - val_precision_m: 0.7215 - val_recall_m: 0.5913 - val_f1_m: 0.6278\n",
      "Epoch 29/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.0451 - acc: 0.9834 - precision_m: 0.8595 - recall_m: 0.6686 - f1_m: 0.7369\n",
      "Epoch 29: val_acc improved from 0.97779 to 0.97791, saving model to models/best_model_2_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0452 - acc: 0.9834 - precision_m: 0.8586 - recall_m: 0.6690 - f1_m: 0.7370 - val_loss: 0.0778 - val_acc: 0.9779 - val_precision_m: 0.7881 - val_recall_m: 0.5502 - val_f1_m: 0.6233\n",
      "Epoch 30/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.0433 - acc: 0.9841 - precision_m: 0.8711 - recall_m: 0.6796 - f1_m: 0.7475\n",
      "Epoch 30: val_acc improved from 0.97791 to 0.97862, saving model to models/best_model_2_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0433 - acc: 0.9841 - precision_m: 0.8711 - recall_m: 0.6796 - f1_m: 0.7475 - val_loss: 0.0822 - val_acc: 0.9786 - val_precision_m: 0.7943 - val_recall_m: 0.5620 - val_f1_m: 0.6300\n",
      "Score for fold 1: loss of 0.0822378620505333; acc of 97.8621780872345%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.0579567551612854; acc of 98.45916628837585%\n",
      "Test Precision: precision_m of 24.853287637233734%\n",
      "Test Recall: recall_m of 19.732002913951874%\n",
      "Test F1: f1_m of 21.165457367897034%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.1543 - acc: 0.9629 - precision_m: 0.1024 - recall_m: 0.0238 - f1_m: 0.0339\n",
      "Epoch 1: val_acc improved from -inf to 0.96420, saving model to models/best_model_2_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 2s 5ms/step - loss: 0.1543 - acc: 0.9629 - precision_m: 0.1024 - recall_m: 0.0238 - f1_m: 0.0339 - val_loss: 0.1083 - val_acc: 0.9642 - val_precision_m: 0.1818 - val_recall_m: 0.0308 - val_f1_m: 0.0502\n",
      "Epoch 2/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.1047 - acc: 0.9659 - precision_m: 0.4810 - recall_m: 0.1082 - f1_m: 0.1665\n",
      "Epoch 2: val_acc improved from 0.96420 to 0.96839, saving model to models/best_model_2_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1045 - acc: 0.9660 - precision_m: 0.4852 - recall_m: 0.1109 - f1_m: 0.1699 - val_loss: 0.0931 - val_acc: 0.9684 - val_precision_m: 0.5470 - val_recall_m: 0.2041 - val_f1_m: 0.2783\n",
      "Epoch 3/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.0937 - acc: 0.9680 - precision_m: 0.5761 - recall_m: 0.1941 - f1_m: 0.2715\n",
      "Epoch 3: val_acc did not improve from 0.96839\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0938 - acc: 0.9679 - precision_m: 0.5784 - recall_m: 0.1953 - f1_m: 0.2723 - val_loss: 0.0920 - val_acc: 0.9679 - val_precision_m: 0.5859 - val_recall_m: 0.1295 - val_f1_m: 0.2010\n",
      "Epoch 4/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.0860 - acc: 0.9698 - precision_m: 0.6838 - recall_m: 0.2659 - f1_m: 0.3628\n",
      "Epoch 4: val_acc improved from 0.96839 to 0.97042, saving model to models/best_model_2_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0860 - acc: 0.9698 - precision_m: 0.6879 - recall_m: 0.2676 - f1_m: 0.3652 - val_loss: 0.0883 - val_acc: 0.9704 - val_precision_m: 0.6031 - val_recall_m: 0.4470 - val_f1_m: 0.4922\n",
      "Epoch 5/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.0821 - acc: 0.9714 - precision_m: 0.7256 - recall_m: 0.3254 - f1_m: 0.4246\n",
      "Epoch 5: val_acc improved from 0.97042 to 0.97270, saving model to models/best_model_2_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0815 - acc: 0.9716 - precision_m: 0.7265 - recall_m: 0.3279 - f1_m: 0.4275 - val_loss: 0.0820 - val_acc: 0.9727 - val_precision_m: 0.6998 - val_recall_m: 0.3667 - val_f1_m: 0.4544\n",
      "Epoch 6/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.0764 - acc: 0.9728 - precision_m: 0.7178 - recall_m: 0.3676 - f1_m: 0.4646\n",
      "Epoch 6: val_acc did not improve from 0.97270\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0765 - acc: 0.9728 - precision_m: 0.7158 - recall_m: 0.3667 - f1_m: 0.4635 - val_loss: 0.0948 - val_acc: 0.9705 - val_precision_m: 0.7260 - val_recall_m: 0.2288 - val_f1_m: 0.3274\n",
      "Epoch 7/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.0737 - acc: 0.9734 - precision_m: 0.7412 - recall_m: 0.3957 - f1_m: 0.4913\n",
      "Epoch 7: val_acc improved from 0.97270 to 0.97497, saving model to models/best_model_2_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0740 - acc: 0.9733 - precision_m: 0.7388 - recall_m: 0.3969 - f1_m: 0.4918 - val_loss: 0.0752 - val_acc: 0.9750 - val_precision_m: 0.7374 - val_recall_m: 0.4734 - val_f1_m: 0.5396\n",
      "Epoch 8/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.0702 - acc: 0.9748 - precision_m: 0.7540 - recall_m: 0.4350 - f1_m: 0.5249\n",
      "Epoch 8: val_acc improved from 0.97497 to 0.97509, saving model to models/best_model_2_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0704 - acc: 0.9748 - precision_m: 0.7544 - recall_m: 0.4375 - f1_m: 0.5276 - val_loss: 0.0750 - val_acc: 0.9751 - val_precision_m: 0.7521 - val_recall_m: 0.4697 - val_f1_m: 0.5470\n",
      "Epoch 9/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0678 - acc: 0.9757 - precision_m: 0.7584 - recall_m: 0.4546 - f1_m: 0.5447\n",
      "Epoch 9: val_acc did not improve from 0.97509\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0680 - acc: 0.9757 - precision_m: 0.7576 - recall_m: 0.4549 - f1_m: 0.5448 - val_loss: 0.0769 - val_acc: 0.9751 - val_precision_m: 0.7746 - val_recall_m: 0.4271 - val_f1_m: 0.5189\n",
      "Epoch 10/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0654 - acc: 0.9770 - precision_m: 0.7794 - recall_m: 0.4883 - f1_m: 0.5768\n",
      "Epoch 10: val_acc improved from 0.97509 to 0.97521, saving model to models/best_model_2_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0650 - acc: 0.9772 - precision_m: 0.7826 - recall_m: 0.4921 - f1_m: 0.5810 - val_loss: 0.0717 - val_acc: 0.9752 - val_precision_m: 0.7253 - val_recall_m: 0.4614 - val_f1_m: 0.5289\n",
      "Epoch 11/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.0616 - acc: 0.9776 - precision_m: 0.7896 - recall_m: 0.4987 - f1_m: 0.5917\n",
      "Epoch 11: val_acc improved from 0.97521 to 0.97569, saving model to models/best_model_2_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0615 - acc: 0.9776 - precision_m: 0.7871 - recall_m: 0.4978 - f1_m: 0.5906 - val_loss: 0.0702 - val_acc: 0.9757 - val_precision_m: 0.7183 - val_recall_m: 0.5589 - val_f1_m: 0.6033\n",
      "Epoch 12/30\n",
      "276/291 [===========================>..] - ETA: 0s - loss: 0.0603 - acc: 0.9787 - precision_m: 0.8003 - recall_m: 0.5405 - f1_m: 0.6241\n",
      "Epoch 12: val_acc improved from 0.97569 to 0.97773, saving model to models/best_model_2_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0603 - acc: 0.9786 - precision_m: 0.8012 - recall_m: 0.5369 - f1_m: 0.6206 - val_loss: 0.0701 - val_acc: 0.9777 - val_precision_m: 0.7436 - val_recall_m: 0.6014 - val_f1_m: 0.6405\n",
      "Epoch 13/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.0615 - acc: 0.9779 - precision_m: 0.8020 - recall_m: 0.5233 - f1_m: 0.6040\n",
      "Epoch 13: val_acc did not improve from 0.97773\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0610 - acc: 0.9781 - precision_m: 0.8056 - recall_m: 0.5291 - f1_m: 0.6100 - val_loss: 0.0725 - val_acc: 0.9762 - val_precision_m: 0.8140 - val_recall_m: 0.4812 - val_f1_m: 0.5661\n",
      "Epoch 14/30\n",
      "276/291 [===========================>..] - ETA: 0s - loss: 0.0572 - acc: 0.9794 - precision_m: 0.8177 - recall_m: 0.5490 - f1_m: 0.6367\n",
      "Epoch 14: val_acc did not improve from 0.97773\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0576 - acc: 0.9793 - precision_m: 0.8123 - recall_m: 0.5468 - f1_m: 0.6337 - val_loss: 0.0673 - val_acc: 0.9768 - val_precision_m: 0.7444 - val_recall_m: 0.5444 - val_f1_m: 0.5958\n",
      "Epoch 15/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0549 - acc: 0.9799 - precision_m: 0.8300 - recall_m: 0.5595 - f1_m: 0.6478\n",
      "Epoch 15: val_acc did not improve from 0.97773\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0548 - acc: 0.9801 - precision_m: 0.8321 - recall_m: 0.5612 - f1_m: 0.6503 - val_loss: 0.0698 - val_acc: 0.9761 - val_precision_m: 0.7905 - val_recall_m: 0.4809 - val_f1_m: 0.5611\n",
      "Epoch 16/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0527 - acc: 0.9814 - precision_m: 0.8337 - recall_m: 0.5990 - f1_m: 0.6766\n",
      "Epoch 16: val_acc did not improve from 0.97773\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0534 - acc: 0.9813 - precision_m: 0.8326 - recall_m: 0.5965 - f1_m: 0.6746 - val_loss: 0.0666 - val_acc: 0.9772 - val_precision_m: 0.7388 - val_recall_m: 0.5537 - val_f1_m: 0.5992\n",
      "Epoch 17/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0520 - acc: 0.9812 - precision_m: 0.8462 - recall_m: 0.5887 - f1_m: 0.6767\n",
      "Epoch 17: val_acc improved from 0.97773 to 0.97845, saving model to models/best_model_2_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0518 - acc: 0.9813 - precision_m: 0.8480 - recall_m: 0.5879 - f1_m: 0.6767 - val_loss: 0.0712 - val_acc: 0.9784 - val_precision_m: 0.8081 - val_recall_m: 0.5150 - val_f1_m: 0.5964\n",
      "Epoch 18/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.0523 - acc: 0.9818 - precision_m: 0.8483 - recall_m: 0.6068 - f1_m: 0.6845\n",
      "Epoch 18: val_acc did not improve from 0.97845\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0525 - acc: 0.9817 - precision_m: 0.8473 - recall_m: 0.6073 - f1_m: 0.6844 - val_loss: 0.0660 - val_acc: 0.9782 - val_precision_m: 0.7445 - val_recall_m: 0.5782 - val_f1_m: 0.6254\n",
      "Epoch 19/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.0501 - acc: 0.9820 - precision_m: 0.8404 - recall_m: 0.6174 - f1_m: 0.6910\n",
      "Epoch 19: val_acc improved from 0.97845 to 0.97880, saving model to models/best_model_2_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0501 - acc: 0.9820 - precision_m: 0.8395 - recall_m: 0.6187 - f1_m: 0.6912 - val_loss: 0.0724 - val_acc: 0.9788 - val_precision_m: 0.8151 - val_recall_m: 0.5321 - val_f1_m: 0.6069\n",
      "Epoch 20/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9823 - precision_m: 0.8517 - recall_m: 0.6330 - f1_m: 0.7065\n",
      "Epoch 20: val_acc improved from 0.97880 to 0.97892, saving model to models/best_model_2_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0484 - acc: 0.9822 - precision_m: 0.8470 - recall_m: 0.6318 - f1_m: 0.7041 - val_loss: 0.0691 - val_acc: 0.9789 - val_precision_m: 0.8610 - val_recall_m: 0.5099 - val_f1_m: 0.6090\n",
      "Epoch 21/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9830 - precision_m: 0.8592 - recall_m: 0.6276 - f1_m: 0.7060\n",
      "Epoch 21: val_acc did not improve from 0.97892\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0477 - acc: 0.9830 - precision_m: 0.8585 - recall_m: 0.6280 - f1_m: 0.7061 - val_loss: 0.0661 - val_acc: 0.9778 - val_precision_m: 0.7171 - val_recall_m: 0.5970 - val_f1_m: 0.6306\n",
      "Epoch 22/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.0455 - acc: 0.9838 - precision_m: 0.8599 - recall_m: 0.6531 - f1_m: 0.7244\n",
      "Epoch 22: val_acc did not improve from 0.97892\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0456 - acc: 0.9836 - precision_m: 0.8526 - recall_m: 0.6489 - f1_m: 0.7193 - val_loss: 0.0738 - val_acc: 0.9778 - val_precision_m: 0.8559 - val_recall_m: 0.4778 - val_f1_m: 0.5824\n",
      "Epoch 23/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.0455 - acc: 0.9835 - precision_m: 0.8649 - recall_m: 0.6418 - f1_m: 0.7202\n",
      "Epoch 23: val_acc improved from 0.97892 to 0.97952, saving model to models/best_model_2_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0453 - acc: 0.9836 - precision_m: 0.8655 - recall_m: 0.6418 - f1_m: 0.7208 - val_loss: 0.0701 - val_acc: 0.9795 - val_precision_m: 0.8151 - val_recall_m: 0.5452 - val_f1_m: 0.6205\n",
      "Epoch 24/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.0446 - acc: 0.9837 - precision_m: 0.8614 - recall_m: 0.6479 - f1_m: 0.7228\n",
      "Epoch 24: val_acc did not improve from 0.97952\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0446 - acc: 0.9837 - precision_m: 0.8614 - recall_m: 0.6479 - f1_m: 0.7228 - val_loss: 0.0665 - val_acc: 0.9780 - val_precision_m: 0.7705 - val_recall_m: 0.5442 - val_f1_m: 0.6111\n",
      "Epoch 25/30\n",
      "275/291 [===========================>..] - ETA: 0s - loss: 0.0445 - acc: 0.9835 - precision_m: 0.8640 - recall_m: 0.6503 - f1_m: 0.7206\n",
      "Epoch 25: val_acc did not improve from 0.97952\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0445 - acc: 0.9835 - precision_m: 0.8668 - recall_m: 0.6501 - f1_m: 0.7222 - val_loss: 0.0641 - val_acc: 0.9787 - val_precision_m: 0.7409 - val_recall_m: 0.5893 - val_f1_m: 0.6247\n",
      "Epoch 26/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9844 - precision_m: 0.8647 - recall_m: 0.6709 - f1_m: 0.7408\n",
      "Epoch 26: val_acc did not improve from 0.97952\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0423 - acc: 0.9844 - precision_m: 0.8650 - recall_m: 0.6720 - f1_m: 0.7417 - val_loss: 0.0704 - val_acc: 0.9784 - val_precision_m: 0.7722 - val_recall_m: 0.5735 - val_f1_m: 0.6285\n",
      "Epoch 27/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0411 - acc: 0.9847 - precision_m: 0.8660 - recall_m: 0.6755 - f1_m: 0.7434\n",
      "Epoch 27: val_acc did not improve from 0.97952\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0416 - acc: 0.9845 - precision_m: 0.8665 - recall_m: 0.6748 - f1_m: 0.7430 - val_loss: 0.0712 - val_acc: 0.9750 - val_precision_m: 0.6130 - val_recall_m: 0.6831 - val_f1_m: 0.6294\n",
      "Epoch 28/30\n",
      "276/291 [===========================>..] - ETA: 0s - loss: 0.0408 - acc: 0.9853 - precision_m: 0.8794 - recall_m: 0.6760 - f1_m: 0.7483\n",
      "Epoch 28: val_acc did not improve from 0.97952\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0413 - acc: 0.9852 - precision_m: 0.8792 - recall_m: 0.6735 - f1_m: 0.7468 - val_loss: 0.0676 - val_acc: 0.9794 - val_precision_m: 0.7865 - val_recall_m: 0.5559 - val_f1_m: 0.6246\n",
      "Epoch 29/30\n",
      "275/291 [===========================>..] - ETA: 0s - loss: 0.0397 - acc: 0.9855 - precision_m: 0.8869 - recall_m: 0.6941 - f1_m: 0.7630\n",
      "Epoch 29: val_acc improved from 0.97952 to 0.97988, saving model to models/best_model_2_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0396 - acc: 0.9855 - precision_m: 0.8871 - recall_m: 0.6907 - f1_m: 0.7612 - val_loss: 0.0747 - val_acc: 0.9799 - val_precision_m: 0.7792 - val_recall_m: 0.5840 - val_f1_m: 0.6387\n",
      "Epoch 30/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9856 - precision_m: 0.8729 - recall_m: 0.7010 - f1_m: 0.7627\n",
      "Epoch 30: val_acc did not improve from 0.97988\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0394 - acc: 0.9857 - precision_m: 0.8727 - recall_m: 0.7021 - f1_m: 0.7632 - val_loss: 0.0710 - val_acc: 0.9799 - val_precision_m: 0.7699 - val_recall_m: 0.6191 - val_f1_m: 0.6571\n",
      "Score for fold 2: loss of 0.07468299567699432; acc of 97.98826575279236%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.07655681669712067; acc of 97.84404039382935%\n",
      "Test Precision: precision_m of 30.71591556072235%\n",
      "Test Recall: recall_m of 22.560203075408936%\n",
      "Test F1: f1_m of 24.90968108177185%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.1794 - acc: 0.9547 - precision_m: 0.0707 - recall_m: 0.0180 - f1_m: 0.0176\n",
      "Epoch 1: val_acc improved from -inf to 0.96299, saving model to models/best_model_2_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 2s 5ms/step - loss: 0.1794 - acc: 0.9547 - precision_m: 0.0707 - recall_m: 0.0180 - f1_m: 0.0176 - val_loss: 0.1208 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.1175 - acc: 0.9641 - precision_m: 0.4031 - recall_m: 0.0821 - f1_m: 0.1291\n",
      "Epoch 2: val_acc improved from 0.96299 to 0.96682, saving model to models/best_model_2_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1169 - acc: 0.9642 - precision_m: 0.4115 - recall_m: 0.0843 - f1_m: 0.1322 - val_loss: 0.0968 - val_acc: 0.9668 - val_precision_m: 0.5399 - val_recall_m: 0.1307 - val_f1_m: 0.1966\n",
      "Epoch 3/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.1012 - acc: 0.9659 - precision_m: 0.5873 - recall_m: 0.1798 - f1_m: 0.2572\n",
      "Epoch 3: val_acc improved from 0.96682 to 0.97041, saving model to models/best_model_2_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1005 - acc: 0.9660 - precision_m: 0.5914 - recall_m: 0.1814 - f1_m: 0.2594 - val_loss: 0.0896 - val_acc: 0.9704 - val_precision_m: 0.6268 - val_recall_m: 0.2410 - val_f1_m: 0.3275\n",
      "Epoch 4/30\n",
      "275/291 [===========================>..] - ETA: 0s - loss: 0.0901 - acc: 0.9676 - precision_m: 0.6350 - recall_m: 0.2311 - f1_m: 0.3193\n",
      "Epoch 4: val_acc improved from 0.97041 to 0.97077, saving model to models/best_model_2_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0895 - acc: 0.9678 - precision_m: 0.6419 - recall_m: 0.2345 - f1_m: 0.3235 - val_loss: 0.0909 - val_acc: 0.9708 - val_precision_m: 0.6553 - val_recall_m: 0.2286 - val_f1_m: 0.3182\n",
      "Epoch 5/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0831 - acc: 0.9708 - precision_m: 0.7154 - recall_m: 0.3527 - f1_m: 0.4432\n",
      "Epoch 5: val_acc improved from 0.97077 to 0.97137, saving model to models/best_model_2_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0830 - acc: 0.9706 - precision_m: 0.7122 - recall_m: 0.3483 - f1_m: 0.4391 - val_loss: 0.0814 - val_acc: 0.9714 - val_precision_m: 0.6477 - val_recall_m: 0.3448 - val_f1_m: 0.4175\n",
      "Epoch 6/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.0764 - acc: 0.9734 - precision_m: 0.7362 - recall_m: 0.4348 - f1_m: 0.5236\n",
      "Epoch 6: val_acc improved from 0.97137 to 0.97209, saving model to models/best_model_2_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0770 - acc: 0.9732 - precision_m: 0.7346 - recall_m: 0.4319 - f1_m: 0.5214 - val_loss: 0.0833 - val_acc: 0.9721 - val_precision_m: 0.6317 - val_recall_m: 0.5326 - val_f1_m: 0.5500\n",
      "Epoch 7/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0734 - acc: 0.9747 - precision_m: 0.7552 - recall_m: 0.4691 - f1_m: 0.5571\n",
      "Epoch 7: val_acc improved from 0.97209 to 0.97269, saving model to models/best_model_2_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0733 - acc: 0.9748 - precision_m: 0.7519 - recall_m: 0.4701 - f1_m: 0.5573 - val_loss: 0.0772 - val_acc: 0.9727 - val_precision_m: 0.5907 - val_recall_m: 0.5449 - val_f1_m: 0.5471\n",
      "Epoch 8/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.0696 - acc: 0.9764 - precision_m: 0.7707 - recall_m: 0.5283 - f1_m: 0.6027\n",
      "Epoch 8: val_acc improved from 0.97269 to 0.97556, saving model to models/best_model_2_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0699 - acc: 0.9762 - precision_m: 0.7651 - recall_m: 0.5266 - f1_m: 0.5999 - val_loss: 0.0745 - val_acc: 0.9756 - val_precision_m: 0.6941 - val_recall_m: 0.4625 - val_f1_m: 0.5295\n",
      "Epoch 9/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0678 - acc: 0.9773 - precision_m: 0.7843 - recall_m: 0.5396 - f1_m: 0.6149\n",
      "Epoch 9: val_acc improved from 0.97556 to 0.97712, saving model to models/best_model_2_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0679 - acc: 0.9773 - precision_m: 0.7848 - recall_m: 0.5394 - f1_m: 0.6150 - val_loss: 0.0703 - val_acc: 0.9771 - val_precision_m: 0.7183 - val_recall_m: 0.4634 - val_f1_m: 0.5404\n",
      "Epoch 10/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.0637 - acc: 0.9779 - precision_m: 0.7794 - recall_m: 0.5561 - f1_m: 0.6277\n",
      "Epoch 10: val_acc did not improve from 0.97712\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0641 - acc: 0.9779 - precision_m: 0.7807 - recall_m: 0.5563 - f1_m: 0.6287 - val_loss: 0.0702 - val_acc: 0.9752 - val_precision_m: 0.6636 - val_recall_m: 0.5113 - val_f1_m: 0.5580\n",
      "Epoch 11/30\n",
      "276/291 [===========================>..] - ETA: 0s - loss: 0.0631 - acc: 0.9783 - precision_m: 0.7958 - recall_m: 0.5622 - f1_m: 0.6390\n",
      "Epoch 11: val_acc did not improve from 0.97712\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0631 - acc: 0.9784 - precision_m: 0.8011 - recall_m: 0.5632 - f1_m: 0.6414 - val_loss: 0.0694 - val_acc: 0.9754 - val_precision_m: 0.6566 - val_recall_m: 0.5516 - val_f1_m: 0.5798\n",
      "Epoch 12/30\n",
      "275/291 [===========================>..] - ETA: 0s - loss: 0.0600 - acc: 0.9793 - precision_m: 0.7993 - recall_m: 0.5760 - f1_m: 0.6511\n",
      "Epoch 12: val_acc did not improve from 0.97712\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0600 - acc: 0.9793 - precision_m: 0.8008 - recall_m: 0.5778 - f1_m: 0.6530 - val_loss: 0.0687 - val_acc: 0.9762 - val_precision_m: 0.7068 - val_recall_m: 0.5019 - val_f1_m: 0.5628\n",
      "Epoch 13/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0567 - acc: 0.9806 - precision_m: 0.8323 - recall_m: 0.5996 - f1_m: 0.6799\n",
      "Epoch 13: val_acc did not improve from 0.97712\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0569 - acc: 0.9805 - precision_m: 0.8304 - recall_m: 0.5945 - f1_m: 0.6758 - val_loss: 0.0755 - val_acc: 0.9753 - val_precision_m: 0.7838 - val_recall_m: 0.3791 - val_f1_m: 0.4864\n",
      "Epoch 14/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0577 - acc: 0.9804 - precision_m: 0.8199 - recall_m: 0.6163 - f1_m: 0.6811\n",
      "Epoch 14: val_acc did not improve from 0.97712\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0575 - acc: 0.9804 - precision_m: 0.8199 - recall_m: 0.6155 - f1_m: 0.6810 - val_loss: 0.0733 - val_acc: 0.9770 - val_precision_m: 0.7653 - val_recall_m: 0.4516 - val_f1_m: 0.5416\n",
      "Epoch 15/30\n",
      "275/291 [===========================>..] - ETA: 0s - loss: 0.0537 - acc: 0.9812 - precision_m: 0.8183 - recall_m: 0.6195 - f1_m: 0.6882\n",
      "Epoch 15: val_acc improved from 0.97712 to 0.97796, saving model to models/best_model_2_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0540 - acc: 0.9810 - precision_m: 0.8150 - recall_m: 0.6183 - f1_m: 0.6866 - val_loss: 0.0670 - val_acc: 0.9780 - val_precision_m: 0.7496 - val_recall_m: 0.5177 - val_f1_m: 0.5889\n",
      "Epoch 16/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.0530 - acc: 0.9814 - precision_m: 0.8251 - recall_m: 0.6289 - f1_m: 0.6939\n",
      "Epoch 16: val_acc did not improve from 0.97796\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0531 - acc: 0.9814 - precision_m: 0.8269 - recall_m: 0.6254 - f1_m: 0.6918 - val_loss: 0.0681 - val_acc: 0.9768 - val_precision_m: 0.6902 - val_recall_m: 0.5477 - val_f1_m: 0.5869\n",
      "Epoch 17/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9818 - precision_m: 0.8266 - recall_m: 0.6359 - f1_m: 0.7002\n",
      "Epoch 17: val_acc improved from 0.97796 to 0.97928, saving model to models/best_model_2_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0504 - acc: 0.9818 - precision_m: 0.8265 - recall_m: 0.6371 - f1_m: 0.7009 - val_loss: 0.0649 - val_acc: 0.9793 - val_precision_m: 0.7899 - val_recall_m: 0.5540 - val_f1_m: 0.6211\n",
      "Epoch 18/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0497 - acc: 0.9823 - precision_m: 0.8443 - recall_m: 0.6399 - f1_m: 0.7129\n",
      "Epoch 18: val_acc did not improve from 0.97928\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0496 - acc: 0.9823 - precision_m: 0.8438 - recall_m: 0.6399 - f1_m: 0.7128 - val_loss: 0.0723 - val_acc: 0.9765 - val_precision_m: 0.7052 - val_recall_m: 0.5589 - val_f1_m: 0.5937\n",
      "Epoch 19/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0494 - acc: 0.9824 - precision_m: 0.8470 - recall_m: 0.6431 - f1_m: 0.7123\n",
      "Epoch 19: val_acc did not improve from 0.97928\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0492 - acc: 0.9825 - precision_m: 0.8477 - recall_m: 0.6447 - f1_m: 0.7137 - val_loss: 0.0764 - val_acc: 0.9768 - val_precision_m: 0.7675 - val_recall_m: 0.4131 - val_f1_m: 0.5154\n",
      "Epoch 20/30\n",
      "275/291 [===========================>..] - ETA: 0s - loss: 0.0475 - acc: 0.9836 - precision_m: 0.8637 - recall_m: 0.6634 - f1_m: 0.7330\n",
      "Epoch 20: val_acc did not improve from 0.97928\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0473 - acc: 0.9838 - precision_m: 0.8644 - recall_m: 0.6646 - f1_m: 0.7341 - val_loss: 0.0687 - val_acc: 0.9775 - val_precision_m: 0.7509 - val_recall_m: 0.5405 - val_f1_m: 0.5956\n",
      "Epoch 21/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.0481 - acc: 0.9832 - precision_m: 0.8630 - recall_m: 0.6606 - f1_m: 0.7266\n",
      "Epoch 21: val_acc did not improve from 0.97928\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0477 - acc: 0.9834 - precision_m: 0.8657 - recall_m: 0.6635 - f1_m: 0.7298 - val_loss: 0.0662 - val_acc: 0.9772 - val_precision_m: 0.6809 - val_recall_m: 0.6526 - val_f1_m: 0.6428\n",
      "Epoch 22/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0465 - acc: 0.9839 - precision_m: 0.8705 - recall_m: 0.6763 - f1_m: 0.7425\n",
      "Epoch 22: val_acc did not improve from 0.97928\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0467 - acc: 0.9838 - precision_m: 0.8711 - recall_m: 0.6725 - f1_m: 0.7402 - val_loss: 0.0643 - val_acc: 0.9772 - val_precision_m: 0.7475 - val_recall_m: 0.5042 - val_f1_m: 0.5741\n",
      "Epoch 23/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9840 - precision_m: 0.8571 - recall_m: 0.6839 - f1_m: 0.7437\n",
      "Epoch 23: val_acc did not improve from 0.97928\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0445 - acc: 0.9840 - precision_m: 0.8576 - recall_m: 0.6835 - f1_m: 0.7436 - val_loss: 0.0660 - val_acc: 0.9784 - val_precision_m: 0.8062 - val_recall_m: 0.4990 - val_f1_m: 0.5926\n",
      "Epoch 24/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0423 - acc: 0.9853 - precision_m: 0.8710 - recall_m: 0.7035 - f1_m: 0.7642\n",
      "Epoch 24: val_acc did not improve from 0.97928\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0426 - acc: 0.9852 - precision_m: 0.8710 - recall_m: 0.6998 - f1_m: 0.7607 - val_loss: 0.0682 - val_acc: 0.9778 - val_precision_m: 0.7705 - val_recall_m: 0.5367 - val_f1_m: 0.6002\n",
      "Epoch 25/30\n",
      "276/291 [===========================>..] - ETA: 0s - loss: 0.0420 - acc: 0.9850 - precision_m: 0.8737 - recall_m: 0.6985 - f1_m: 0.7599\n",
      "Epoch 25: val_acc did not improve from 0.97928\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0420 - acc: 0.9849 - precision_m: 0.8733 - recall_m: 0.6964 - f1_m: 0.7583 - val_loss: 0.0752 - val_acc: 0.9736 - val_precision_m: 0.6126 - val_recall_m: 0.7590 - val_f1_m: 0.6548\n",
      "Epoch 26/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9847 - precision_m: 0.8764 - recall_m: 0.6925 - f1_m: 0.7583\n",
      "Epoch 26: val_acc did not improve from 0.97928\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0427 - acc: 0.9847 - precision_m: 0.8751 - recall_m: 0.6936 - f1_m: 0.7580 - val_loss: 0.0651 - val_acc: 0.9782 - val_precision_m: 0.7406 - val_recall_m: 0.5782 - val_f1_m: 0.6176\n",
      "Epoch 27/30\n",
      "274/291 [===========================>..] - ETA: 0s - loss: 0.0408 - acc: 0.9851 - precision_m: 0.8791 - recall_m: 0.7017 - f1_m: 0.7651\n",
      "Epoch 27: val_acc did not improve from 0.97928\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0410 - acc: 0.9852 - precision_m: 0.8795 - recall_m: 0.7033 - f1_m: 0.7667 - val_loss: 0.0707 - val_acc: 0.9772 - val_precision_m: 0.7088 - val_recall_m: 0.5040 - val_f1_m: 0.5677\n",
      "Epoch 28/30\n",
      "276/291 [===========================>..] - ETA: 0s - loss: 0.0400 - acc: 0.9853 - precision_m: 0.8733 - recall_m: 0.7099 - f1_m: 0.7695\n",
      "Epoch 28: val_acc did not improve from 0.97928\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0401 - acc: 0.9854 - precision_m: 0.8750 - recall_m: 0.7089 - f1_m: 0.7695 - val_loss: 0.0824 - val_acc: 0.9763 - val_precision_m: 0.7807 - val_recall_m: 0.4079 - val_f1_m: 0.5086\n",
      "Epoch 29/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.0395 - acc: 0.9858 - precision_m: 0.8824 - recall_m: 0.7121 - f1_m: 0.7726\n",
      "Epoch 29: val_acc did not improve from 0.97928\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0395 - acc: 0.9857 - precision_m: 0.8819 - recall_m: 0.7113 - f1_m: 0.7718 - val_loss: 0.0724 - val_acc: 0.9776 - val_precision_m: 0.7159 - val_recall_m: 0.5415 - val_f1_m: 0.5968\n",
      "Epoch 30/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0371 - acc: 0.9869 - precision_m: 0.8930 - recall_m: 0.7412 - f1_m: 0.7958\n",
      "Epoch 30: val_acc did not improve from 0.97928\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0372 - acc: 0.9869 - precision_m: 0.8926 - recall_m: 0.7392 - f1_m: 0.7945 - val_loss: 0.0764 - val_acc: 0.9781 - val_precision_m: 0.7381 - val_recall_m: 0.5359 - val_f1_m: 0.6005\n",
      "Score for fold 3: loss of 0.06490476429462433; acc of 97.92764782905579%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.07266781479120255; acc of 97.84579277038574%\n",
      "Test Precision: precision_m of 26.643988490104675%\n",
      "Test Recall: recall_m of 20.972225069999695%\n",
      "Test F1: f1_m of 22.23331928253174%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1613 - acc: 0.9603 - precision_m: 0.0038 - recall_m: 0.0034 - f1_m: 0.0013     \n",
      "Epoch 1: val_acc improved from -inf to 0.96143, saving model to models/best_model_2_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 2s 4ms/step - loss: 0.1613 - acc: 0.9603 - precision_m: 0.0038 - recall_m: 0.0034 - f1_m: 0.0013 - val_loss: 0.1195 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1103 - acc: 0.9655 - precision_m: 0.3041 - recall_m: 0.0529 - f1_m: 0.0863\n",
      "Epoch 2: val_acc improved from 0.96143 to 0.96155, saving model to models/best_model_2_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1102 - acc: 0.9656 - precision_m: 0.3078 - recall_m: 0.0537 - f1_m: 0.0877 - val_loss: 0.1188 - val_acc: 0.9616 - val_precision_m: 0.0303 - val_recall_m: 0.0016 - val_f1_m: 0.0030\n",
      "Epoch 3/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0941 - acc: 0.9678 - precision_m: 0.5626 - recall_m: 0.1450 - f1_m: 0.2190\n",
      "Epoch 3: val_acc improved from 0.96155 to 0.97146, saving model to models/best_model_2_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0942 - acc: 0.9677 - precision_m: 0.5597 - recall_m: 0.1450 - f1_m: 0.2185 - val_loss: 0.1041 - val_acc: 0.9715 - val_precision_m: 0.6358 - val_recall_m: 0.4532 - val_f1_m: 0.4914\n",
      "Epoch 4/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0844 - acc: 0.9706 - precision_m: 0.6830 - recall_m: 0.2648 - f1_m: 0.3612\n",
      "Epoch 4: val_acc did not improve from 0.97146\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0844 - acc: 0.9706 - precision_m: 0.6828 - recall_m: 0.2639 - f1_m: 0.3604 - val_loss: 0.0866 - val_acc: 0.9711 - val_precision_m: 0.7479 - val_recall_m: 0.3390 - val_f1_m: 0.4308\n",
      "Epoch 5/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0811 - acc: 0.9716 - precision_m: 0.7053 - recall_m: 0.3362 - f1_m: 0.4295\n",
      "Epoch 5: val_acc improved from 0.97146 to 0.97301, saving model to models/best_model_2_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0810 - acc: 0.9716 - precision_m: 0.7030 - recall_m: 0.3365 - f1_m: 0.4297 - val_loss: 0.0851 - val_acc: 0.9730 - val_precision_m: 0.7332 - val_recall_m: 0.3699 - val_f1_m: 0.4554\n",
      "Epoch 6/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0758 - acc: 0.9730 - precision_m: 0.7205 - recall_m: 0.3765 - f1_m: 0.4689\n",
      "Epoch 6: val_acc did not improve from 0.97301\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0759 - acc: 0.9729 - precision_m: 0.7179 - recall_m: 0.3741 - f1_m: 0.4663 - val_loss: 0.0917 - val_acc: 0.9718 - val_precision_m: 0.7659 - val_recall_m: 0.3061 - val_f1_m: 0.4028\n",
      "Epoch 7/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0710 - acc: 0.9743 - precision_m: 0.7461 - recall_m: 0.4239 - f1_m: 0.5150\n",
      "Epoch 7: val_acc improved from 0.97301 to 0.97504, saving model to models/best_model_2_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0711 - acc: 0.9743 - precision_m: 0.7432 - recall_m: 0.4245 - f1_m: 0.5142 - val_loss: 0.0811 - val_acc: 0.9750 - val_precision_m: 0.7850 - val_recall_m: 0.4378 - val_f1_m: 0.5277\n",
      "Epoch 8/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0676 - acc: 0.9763 - precision_m: 0.7751 - recall_m: 0.4721 - f1_m: 0.5609\n",
      "Epoch 8: val_acc did not improve from 0.97504\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0676 - acc: 0.9763 - precision_m: 0.7723 - recall_m: 0.4708 - f1_m: 0.5594 - val_loss: 0.0828 - val_acc: 0.9750 - val_precision_m: 0.7838 - val_recall_m: 0.4067 - val_f1_m: 0.4990\n",
      "Epoch 9/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0661 - acc: 0.9765 - precision_m: 0.7677 - recall_m: 0.4850 - f1_m: 0.5655\n",
      "Epoch 9: val_acc did not improve from 0.97504\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0666 - acc: 0.9764 - precision_m: 0.7671 - recall_m: 0.4807 - f1_m: 0.5620 - val_loss: 0.0835 - val_acc: 0.9749 - val_precision_m: 0.6530 - val_recall_m: 0.5915 - val_f1_m: 0.5880\n",
      "Epoch 10/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9775 - precision_m: 0.7978 - recall_m: 0.5162 - f1_m: 0.6017\n",
      "Epoch 10: val_acc improved from 0.97504 to 0.97707, saving model to models/best_model_2_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0618 - acc: 0.9774 - precision_m: 0.7955 - recall_m: 0.5172 - f1_m: 0.6018 - val_loss: 0.0752 - val_acc: 0.9771 - val_precision_m: 0.8376 - val_recall_m: 0.4749 - val_f1_m: 0.5705\n",
      "Epoch 11/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9789 - precision_m: 0.8102 - recall_m: 0.5395 - f1_m: 0.6275\n",
      "Epoch 11: val_acc improved from 0.97707 to 0.97779, saving model to models/best_model_2_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0592 - acc: 0.9790 - precision_m: 0.8088 - recall_m: 0.5387 - f1_m: 0.6267 - val_loss: 0.0753 - val_acc: 0.9778 - val_precision_m: 0.7971 - val_recall_m: 0.5130 - val_f1_m: 0.5916\n",
      "Epoch 12/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0583 - acc: 0.9793 - precision_m: 0.8105 - recall_m: 0.5531 - f1_m: 0.6352\n",
      "Epoch 12: val_acc did not improve from 0.97779\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0582 - acc: 0.9793 - precision_m: 0.8079 - recall_m: 0.5520 - f1_m: 0.6339 - val_loss: 0.0898 - val_acc: 0.9747 - val_precision_m: 0.8387 - val_recall_m: 0.4014 - val_f1_m: 0.5092\n",
      "Epoch 13/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0554 - acc: 0.9807 - precision_m: 0.8267 - recall_m: 0.5857 - f1_m: 0.6636\n",
      "Epoch 13: val_acc improved from 0.97779 to 0.97851, saving model to models/best_model_2_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0554 - acc: 0.9807 - precision_m: 0.8237 - recall_m: 0.5834 - f1_m: 0.6612 - val_loss: 0.0745 - val_acc: 0.9785 - val_precision_m: 0.8154 - val_recall_m: 0.5495 - val_f1_m: 0.6222\n",
      "Epoch 14/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0543 - acc: 0.9805 - precision_m: 0.8122 - recall_m: 0.5903 - f1_m: 0.6650\n",
      "Epoch 14: val_acc did not improve from 0.97851\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0541 - acc: 0.9807 - precision_m: 0.8117 - recall_m: 0.5892 - f1_m: 0.6638 - val_loss: 0.0757 - val_acc: 0.9768 - val_precision_m: 0.7456 - val_recall_m: 0.5585 - val_f1_m: 0.6128\n",
      "Epoch 15/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0515 - acc: 0.9812 - precision_m: 0.8284 - recall_m: 0.6016 - f1_m: 0.6778\n",
      "Epoch 15: val_acc did not improve from 0.97851\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0514 - acc: 0.9812 - precision_m: 0.8252 - recall_m: 0.6001 - f1_m: 0.6756 - val_loss: 0.0796 - val_acc: 0.9780 - val_precision_m: 0.7915 - val_recall_m: 0.5396 - val_f1_m: 0.6068\n",
      "Epoch 16/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9813 - precision_m: 0.8286 - recall_m: 0.5985 - f1_m: 0.6733\n",
      "Epoch 16: val_acc improved from 0.97851 to 0.97899, saving model to models/best_model_2_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0516 - acc: 0.9813 - precision_m: 0.8258 - recall_m: 0.5965 - f1_m: 0.6710 - val_loss: 0.0773 - val_acc: 0.9790 - val_precision_m: 0.7840 - val_recall_m: 0.6006 - val_f1_m: 0.6484\n",
      "Epoch 17/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9820 - precision_m: 0.8325 - recall_m: 0.6316 - f1_m: 0.7006\n",
      "Epoch 17: val_acc did not improve from 0.97899\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0500 - acc: 0.9820 - precision_m: 0.8304 - recall_m: 0.6294 - f1_m: 0.6987 - val_loss: 0.0891 - val_acc: 0.9774 - val_precision_m: 0.8515 - val_recall_m: 0.4818 - val_f1_m: 0.5793\n",
      "Epoch 18/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0481 - acc: 0.9823 - precision_m: 0.8324 - recall_m: 0.6221 - f1_m: 0.6918\n",
      "Epoch 18: val_acc improved from 0.97899 to 0.97934, saving model to models/best_model_2_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0481 - acc: 0.9823 - precision_m: 0.8280 - recall_m: 0.6226 - f1_m: 0.6905 - val_loss: 0.0880 - val_acc: 0.9793 - val_precision_m: 0.8008 - val_recall_m: 0.5566 - val_f1_m: 0.6323\n",
      "Epoch 19/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9832 - precision_m: 0.8486 - recall_m: 0.6575 - f1_m: 0.7220\n",
      "Epoch 19: val_acc did not improve from 0.97934\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0470 - acc: 0.9832 - precision_m: 0.8457 - recall_m: 0.6552 - f1_m: 0.7196 - val_loss: 0.0872 - val_acc: 0.9777 - val_precision_m: 0.8188 - val_recall_m: 0.4918 - val_f1_m: 0.5757\n",
      "Epoch 20/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9833 - precision_m: 0.8410 - recall_m: 0.6524 - f1_m: 0.7163\n",
      "Epoch 20: val_acc did not improve from 0.97934\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0461 - acc: 0.9833 - precision_m: 0.8386 - recall_m: 0.6485 - f1_m: 0.7129 - val_loss: 0.0753 - val_acc: 0.9758 - val_precision_m: 0.6422 - val_recall_m: 0.6326 - val_f1_m: 0.6130\n",
      "Epoch 21/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0518 - acc: 0.9813 - precision_m: 0.8345 - recall_m: 0.6212 - f1_m: 0.6890\n",
      "Epoch 21: val_acc did not improve from 0.97934\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0518 - acc: 0.9813 - precision_m: 0.8313 - recall_m: 0.6198 - f1_m: 0.6873 - val_loss: 0.0799 - val_acc: 0.9784 - val_precision_m: 0.7622 - val_recall_m: 0.5712 - val_f1_m: 0.6338\n",
      "Epoch 22/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9840 - precision_m: 0.8467 - recall_m: 0.6741 - f1_m: 0.7339\n",
      "Epoch 22: val_acc did not improve from 0.97934\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0429 - acc: 0.9840 - precision_m: 0.8438 - recall_m: 0.6718 - f1_m: 0.7314 - val_loss: 0.0869 - val_acc: 0.9789 - val_precision_m: 0.8400 - val_recall_m: 0.5337 - val_f1_m: 0.6237\n",
      "Epoch 23/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9840 - precision_m: 0.8490 - recall_m: 0.6684 - f1_m: 0.7298\n",
      "Epoch 23: val_acc did not improve from 0.97934\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0424 - acc: 0.9840 - precision_m: 0.8458 - recall_m: 0.6670 - f1_m: 0.7278 - val_loss: 0.0969 - val_acc: 0.9789 - val_precision_m: 0.8233 - val_recall_m: 0.5286 - val_f1_m: 0.6180\n",
      "Epoch 24/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9844 - precision_m: 0.8581 - recall_m: 0.6797 - f1_m: 0.7412\n",
      "Epoch 24: val_acc did not improve from 0.97934\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0424 - acc: 0.9843 - precision_m: 0.8561 - recall_m: 0.6756 - f1_m: 0.7378 - val_loss: 0.1038 - val_acc: 0.9772 - val_precision_m: 0.8257 - val_recall_m: 0.4739 - val_f1_m: 0.5700\n",
      "Epoch 25/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0396 - acc: 0.9854 - precision_m: 0.8682 - recall_m: 0.6990 - f1_m: 0.7602\n",
      "Epoch 25: val_acc did not improve from 0.97934\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0399 - acc: 0.9853 - precision_m: 0.8651 - recall_m: 0.6960 - f1_m: 0.7572 - val_loss: 0.1010 - val_acc: 0.9624 - val_precision_m: 0.4844 - val_recall_m: 0.7570 - val_f1_m: 0.5678\n",
      "Epoch 26/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9823 - precision_m: 0.8533 - recall_m: 0.6384 - f1_m: 0.7024\n",
      "Epoch 26: val_acc did not improve from 0.97934\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0503 - acc: 0.9823 - precision_m: 0.8505 - recall_m: 0.6368 - f1_m: 0.7006 - val_loss: 0.0934 - val_acc: 0.9781 - val_precision_m: 0.7936 - val_recall_m: 0.5141 - val_f1_m: 0.5936\n",
      "Epoch 27/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.0387 - acc: 0.9858 - precision_m: 0.8683 - recall_m: 0.7028 - f1_m: 0.7643\n",
      "Epoch 27: val_acc did not improve from 0.97934\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0394 - acc: 0.9856 - precision_m: 0.8631 - recall_m: 0.7012 - f1_m: 0.7610 - val_loss: 0.0807 - val_acc: 0.9781 - val_precision_m: 0.7445 - val_recall_m: 0.5746 - val_f1_m: 0.6246\n",
      "Epoch 28/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0385 - acc: 0.9857 - precision_m: 0.8732 - recall_m: 0.7068 - f1_m: 0.7636\n",
      "Epoch 28: val_acc did not improve from 0.97934\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0387 - acc: 0.9857 - precision_m: 0.8703 - recall_m: 0.7042 - f1_m: 0.7611 - val_loss: 0.0798 - val_acc: 0.9774 - val_precision_m: 0.6863 - val_recall_m: 0.6472 - val_f1_m: 0.6502\n",
      "Epoch 29/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9860 - precision_m: 0.8686 - recall_m: 0.7139 - f1_m: 0.7704\n",
      "Epoch 29: val_acc did not improve from 0.97934\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0377 - acc: 0.9860 - precision_m: 0.8665 - recall_m: 0.7107 - f1_m: 0.7673 - val_loss: 0.0797 - val_acc: 0.9783 - val_precision_m: 0.6938 - val_recall_m: 0.6737 - val_f1_m: 0.6642\n",
      "Epoch 30/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9861 - precision_m: 0.8672 - recall_m: 0.7167 - f1_m: 0.7688\n",
      "Epoch 30: val_acc did not improve from 0.97934\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0371 - acc: 0.9861 - precision_m: 0.8650 - recall_m: 0.7121 - f1_m: 0.7649 - val_loss: 0.1011 - val_acc: 0.9789 - val_precision_m: 0.7914 - val_recall_m: 0.5178 - val_f1_m: 0.6061\n",
      "Score for fold 4: loss of 0.08796519041061401; acc of 97.93432950973511%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.08931726962327957; acc of 97.57654666900635%\n",
      "Test Precision: precision_m of 30.294117331504822%\n",
      "Test Recall: recall_m of 22.18320071697235%\n",
      "Test F1: f1_m of 24.4797945022583%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.1746 - acc: 0.9587 - precision_m: 5.2690e-04 - recall_m: 0.0059 - f1_m: 9.2993e-04\n",
      "Epoch 1: val_acc improved from -inf to 0.96211, saving model to models/best_model_2_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 2s 5ms/step - loss: 0.1746 - acc: 0.9587 - precision_m: 5.2690e-04 - recall_m: 0.0059 - f1_m: 9.2993e-04 - val_loss: 0.1390 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.1203 - acc: 0.9640 - precision_m: 0.0632 - recall_m: 0.0077 - f1_m: 0.0137  \n",
      "Epoch 2: val_acc improved from 0.96211 to 0.96247, saving model to models/best_model_2_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1199 - acc: 0.9640 - precision_m: 0.0676 - recall_m: 0.0096 - f1_m: 0.0162 - val_loss: 0.1086 - val_acc: 0.9625 - val_precision_m: 0.0455 - val_recall_m: 0.0068 - val_f1_m: 0.0118\n",
      "Epoch 3/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.1007 - acc: 0.9656 - precision_m: 0.4279 - recall_m: 0.0904 - f1_m: 0.1424\n",
      "Epoch 3: val_acc improved from 0.96247 to 0.96689, saving model to models/best_model_2_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1008 - acc: 0.9656 - precision_m: 0.4264 - recall_m: 0.0901 - f1_m: 0.1419 - val_loss: 0.0978 - val_acc: 0.9669 - val_precision_m: 0.6113 - val_recall_m: 0.1785 - val_f1_m: 0.2602\n",
      "Epoch 4/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0899 - acc: 0.9681 - precision_m: 0.6464 - recall_m: 0.2089 - f1_m: 0.2976\n",
      "Epoch 4: val_acc improved from 0.96689 to 0.97060, saving model to models/best_model_2_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0896 - acc: 0.9681 - precision_m: 0.6484 - recall_m: 0.2108 - f1_m: 0.3000 - val_loss: 0.0898 - val_acc: 0.9706 - val_precision_m: 0.7920 - val_recall_m: 0.3026 - val_f1_m: 0.4116\n",
      "Epoch 5/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.0827 - acc: 0.9712 - precision_m: 0.7042 - recall_m: 0.3329 - f1_m: 0.4284\n",
      "Epoch 5: val_acc improved from 0.97060 to 0.97227, saving model to models/best_model_2_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0827 - acc: 0.9711 - precision_m: 0.7093 - recall_m: 0.3321 - f1_m: 0.4290 - val_loss: 0.0840 - val_acc: 0.9723 - val_precision_m: 0.7772 - val_recall_m: 0.3745 - val_f1_m: 0.4695\n",
      "Epoch 6/30\n",
      "274/291 [===========================>..] - ETA: 0s - loss: 0.0780 - acc: 0.9729 - precision_m: 0.7368 - recall_m: 0.3813 - f1_m: 0.4798\n",
      "Epoch 6: val_acc did not improve from 0.97227\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0777 - acc: 0.9729 - precision_m: 0.7412 - recall_m: 0.3853 - f1_m: 0.4836 - val_loss: 0.0963 - val_acc: 0.9698 - val_precision_m: 0.6815 - val_recall_m: 0.2241 - val_f1_m: 0.3179\n",
      "Epoch 7/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0743 - acc: 0.9740 - precision_m: 0.7560 - recall_m: 0.4274 - f1_m: 0.5185\n",
      "Epoch 7: val_acc improved from 0.97227 to 0.97466, saving model to models/best_model_2_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0744 - acc: 0.9739 - precision_m: 0.7548 - recall_m: 0.4285 - f1_m: 0.5186 - val_loss: 0.0785 - val_acc: 0.9747 - val_precision_m: 0.8533 - val_recall_m: 0.4359 - val_f1_m: 0.5332\n",
      "Epoch 8/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0693 - acc: 0.9759 - precision_m: 0.7648 - recall_m: 0.4770 - f1_m: 0.5662\n",
      "Epoch 8: val_acc did not improve from 0.97466\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0694 - acc: 0.9758 - precision_m: 0.7641 - recall_m: 0.4761 - f1_m: 0.5653 - val_loss: 0.0788 - val_acc: 0.9741 - val_precision_m: 0.8838 - val_recall_m: 0.4049 - val_f1_m: 0.5090\n",
      "Epoch 9/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0668 - acc: 0.9772 - precision_m: 0.7765 - recall_m: 0.5130 - f1_m: 0.5937\n",
      "Epoch 9: val_acc improved from 0.97466 to 0.97753, saving model to models/best_model_2_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0667 - acc: 0.9773 - precision_m: 0.7796 - recall_m: 0.5144 - f1_m: 0.5959 - val_loss: 0.0708 - val_acc: 0.9775 - val_precision_m: 0.7677 - val_recall_m: 0.5852 - val_f1_m: 0.6352\n",
      "Epoch 10/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0627 - acc: 0.9782 - precision_m: 0.8064 - recall_m: 0.5466 - f1_m: 0.6299\n",
      "Epoch 10: val_acc did not improve from 0.97753\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0624 - acc: 0.9783 - precision_m: 0.8075 - recall_m: 0.5485 - f1_m: 0.6316 - val_loss: 0.0777 - val_acc: 0.9760 - val_precision_m: 0.8102 - val_recall_m: 0.4675 - val_f1_m: 0.5511\n",
      "Epoch 11/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.0596 - acc: 0.9796 - precision_m: 0.8111 - recall_m: 0.5814 - f1_m: 0.6610\n",
      "Epoch 11: val_acc improved from 0.97753 to 0.97861, saving model to models/best_model_2_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0596 - acc: 0.9796 - precision_m: 0.8100 - recall_m: 0.5801 - f1_m: 0.6597 - val_loss: 0.0675 - val_acc: 0.9786 - val_precision_m: 0.8354 - val_recall_m: 0.5696 - val_f1_m: 0.6465\n",
      "Epoch 12/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0579 - acc: 0.9799 - precision_m: 0.8088 - recall_m: 0.5860 - f1_m: 0.6589\n",
      "Epoch 12: val_acc did not improve from 0.97861\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0580 - acc: 0.9799 - precision_m: 0.8084 - recall_m: 0.5853 - f1_m: 0.6583 - val_loss: 0.0648 - val_acc: 0.9780 - val_precision_m: 0.7773 - val_recall_m: 0.6133 - val_f1_m: 0.6503\n",
      "Epoch 13/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0553 - acc: 0.9805 - precision_m: 0.8211 - recall_m: 0.5943 - f1_m: 0.6690\n",
      "Epoch 13: val_acc did not improve from 0.97861\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0551 - acc: 0.9805 - precision_m: 0.8210 - recall_m: 0.5945 - f1_m: 0.6689 - val_loss: 0.0707 - val_acc: 0.9771 - val_precision_m: 0.8590 - val_recall_m: 0.4842 - val_f1_m: 0.5690\n",
      "Epoch 14/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.0528 - acc: 0.9815 - precision_m: 0.8286 - recall_m: 0.6135 - f1_m: 0.6829\n",
      "Epoch 14: val_acc improved from 0.97861 to 0.97944, saving model to models/best_model_2_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0528 - acc: 0.9815 - precision_m: 0.8286 - recall_m: 0.6135 - f1_m: 0.6829 - val_loss: 0.0676 - val_acc: 0.9794 - val_precision_m: 0.8115 - val_recall_m: 0.6063 - val_f1_m: 0.6677\n",
      "Epoch 15/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0513 - acc: 0.9828 - precision_m: 0.8551 - recall_m: 0.6311 - f1_m: 0.7057\n",
      "Epoch 15: val_acc did not improve from 0.97944\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0514 - acc: 0.9827 - precision_m: 0.8542 - recall_m: 0.6313 - f1_m: 0.7057 - val_loss: 0.0650 - val_acc: 0.9790 - val_precision_m: 0.8570 - val_recall_m: 0.5722 - val_f1_m: 0.6451\n",
      "Epoch 16/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0493 - acc: 0.9827 - precision_m: 0.8423 - recall_m: 0.6501 - f1_m: 0.7182\n",
      "Epoch 16: val_acc did not improve from 0.97944\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0492 - acc: 0.9827 - precision_m: 0.8405 - recall_m: 0.6525 - f1_m: 0.7183 - val_loss: 0.0714 - val_acc: 0.9790 - val_precision_m: 0.8357 - val_recall_m: 0.5950 - val_f1_m: 0.6611\n",
      "Epoch 17/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9828 - precision_m: 0.8496 - recall_m: 0.6552 - f1_m: 0.7181\n",
      "Epoch 17: val_acc did not improve from 0.97944\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0484 - acc: 0.9828 - precision_m: 0.8482 - recall_m: 0.6572 - f1_m: 0.7191 - val_loss: 0.0618 - val_acc: 0.9791 - val_precision_m: 0.7507 - val_recall_m: 0.6840 - val_f1_m: 0.6881\n",
      "Epoch 18/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9841 - precision_m: 0.8608 - recall_m: 0.6697 - f1_m: 0.7375\n",
      "Epoch 18: val_acc did not improve from 0.97944\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0467 - acc: 0.9841 - precision_m: 0.8580 - recall_m: 0.6699 - f1_m: 0.7364 - val_loss: 0.0771 - val_acc: 0.9785 - val_precision_m: 0.8293 - val_recall_m: 0.5374 - val_f1_m: 0.6192\n",
      "Epoch 19/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.9841 - precision_m: 0.8628 - recall_m: 0.6733 - f1_m: 0.7413\n",
      "Epoch 19: val_acc did not improve from 0.97944\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0459 - acc: 0.9840 - precision_m: 0.8618 - recall_m: 0.6719 - f1_m: 0.7401 - val_loss: 0.0703 - val_acc: 0.9768 - val_precision_m: 0.6648 - val_recall_m: 0.7632 - val_f1_m: 0.6925\n",
      "Epoch 20/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9837 - precision_m: 0.8578 - recall_m: 0.6714 - f1_m: 0.7330\n",
      "Epoch 20: val_acc improved from 0.97944 to 0.98100, saving model to models/best_model_2_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0458 - acc: 0.9837 - precision_m: 0.8556 - recall_m: 0.6714 - f1_m: 0.7323 - val_loss: 0.0657 - val_acc: 0.9810 - val_precision_m: 0.8335 - val_recall_m: 0.5944 - val_f1_m: 0.6662\n",
      "Epoch 21/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9847 - precision_m: 0.8656 - recall_m: 0.6828 - f1_m: 0.7473\n",
      "Epoch 21: val_acc did not improve from 0.98100\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0430 - acc: 0.9847 - precision_m: 0.8635 - recall_m: 0.6796 - f1_m: 0.7445 - val_loss: 0.0622 - val_acc: 0.9810 - val_precision_m: 0.8000 - val_recall_m: 0.6889 - val_f1_m: 0.7150\n",
      "Epoch 22/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9851 - precision_m: 0.8714 - recall_m: 0.6880 - f1_m: 0.7541\n",
      "Epoch 22: val_acc did not improve from 0.98100\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0422 - acc: 0.9851 - precision_m: 0.8717 - recall_m: 0.6885 - f1_m: 0.7547 - val_loss: 0.0627 - val_acc: 0.9809 - val_precision_m: 0.8305 - val_recall_m: 0.6544 - val_f1_m: 0.6960\n",
      "Epoch 23/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9855 - precision_m: 0.8818 - recall_m: 0.7068 - f1_m: 0.7673\n",
      "Epoch 23: val_acc did not improve from 0.98100\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0420 - acc: 0.9854 - precision_m: 0.8781 - recall_m: 0.7074 - f1_m: 0.7654 - val_loss: 0.0640 - val_acc: 0.9805 - val_precision_m: 0.7608 - val_recall_m: 0.7258 - val_f1_m: 0.7173\n",
      "Epoch 24/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9852 - precision_m: 0.8759 - recall_m: 0.6894 - f1_m: 0.7545\n",
      "Epoch 24: val_acc improved from 0.98100 to 0.98124, saving model to models/best_model_2_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0412 - acc: 0.9853 - precision_m: 0.8778 - recall_m: 0.6910 - f1_m: 0.7565 - val_loss: 0.0623 - val_acc: 0.9812 - val_precision_m: 0.7819 - val_recall_m: 0.6961 - val_f1_m: 0.7104\n",
      "Epoch 25/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0388 - acc: 0.9860 - precision_m: 0.8852 - recall_m: 0.7097 - f1_m: 0.7737\n",
      "Epoch 25: val_acc did not improve from 0.98124\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0387 - acc: 0.9860 - precision_m: 0.8829 - recall_m: 0.7140 - f1_m: 0.7748 - val_loss: 0.0654 - val_acc: 0.9810 - val_precision_m: 0.8200 - val_recall_m: 0.6609 - val_f1_m: 0.7049\n",
      "Epoch 26/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0391 - acc: 0.9859 - precision_m: 0.8803 - recall_m: 0.7218 - f1_m: 0.7767\n",
      "Epoch 26: val_acc did not improve from 0.98124\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0389 - acc: 0.9859 - precision_m: 0.8796 - recall_m: 0.7239 - f1_m: 0.7779 - val_loss: 0.0802 - val_acc: 0.9798 - val_precision_m: 0.8459 - val_recall_m: 0.5528 - val_f1_m: 0.6411\n",
      "Epoch 27/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0363 - acc: 0.9865 - precision_m: 0.8828 - recall_m: 0.7323 - f1_m: 0.7871\n",
      "Epoch 27: val_acc did not improve from 0.98124\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0367 - acc: 0.9864 - precision_m: 0.8822 - recall_m: 0.7321 - f1_m: 0.7863 - val_loss: 0.0763 - val_acc: 0.9797 - val_precision_m: 0.8160 - val_recall_m: 0.5833 - val_f1_m: 0.6464\n",
      "Epoch 28/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0360 - acc: 0.9868 - precision_m: 0.8879 - recall_m: 0.7388 - f1_m: 0.7918\n",
      "Epoch 28: val_acc did not improve from 0.98124\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0360 - acc: 0.9868 - precision_m: 0.8892 - recall_m: 0.7372 - f1_m: 0.7912 - val_loss: 0.0716 - val_acc: 0.9804 - val_precision_m: 0.7803 - val_recall_m: 0.6355 - val_f1_m: 0.6786\n",
      "Epoch 29/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0355 - acc: 0.9869 - precision_m: 0.8909 - recall_m: 0.7331 - f1_m: 0.7898\n",
      "Epoch 29: val_acc did not improve from 0.98124\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0355 - acc: 0.9868 - precision_m: 0.8878 - recall_m: 0.7325 - f1_m: 0.7874 - val_loss: 0.0706 - val_acc: 0.9800 - val_precision_m: 0.7931 - val_recall_m: 0.6462 - val_f1_m: 0.6843\n",
      "Epoch 30/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0343 - acc: 0.9877 - precision_m: 0.8995 - recall_m: 0.7529 - f1_m: 0.8073\n",
      "Epoch 30: val_acc improved from 0.98124 to 0.98136, saving model to models/best_model_2_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0343 - acc: 0.9877 - precision_m: 0.8999 - recall_m: 0.7517 - f1_m: 0.8067 - val_loss: 0.0684 - val_acc: 0.9814 - val_precision_m: 0.7993 - val_recall_m: 0.6902 - val_f1_m: 0.7192\n",
      "Score for fold 5: loss of 0.0683632344007492; acc of 98.13553094863892%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.07527348399162292; acc of 97.84326553344727%\n",
      "Test Precision: precision_m of 31.348121166229248%\n",
      "Test Recall: recall_m of 26.19428038597107%\n",
      "Test F1: f1_m of 27.2617369890213%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1643 - acc: 0.9615 - precision_m: 0.0247 - recall_m: 0.0055 - f1_m: 0.0055\n",
      "Epoch 1: val_acc improved from -inf to 0.96252, saving model to models/best_model_2_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 2s 5ms/step - loss: 0.1643 - acc: 0.9615 - precision_m: 0.0247 - recall_m: 0.0055 - f1_m: 0.0055 - val_loss: 0.1259 - val_acc: 0.9625 - val_precision_m: 0.3232 - val_recall_m: 0.0438 - val_f1_m: 0.0751\n",
      "Epoch 2/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.1096 - acc: 0.9661 - precision_m: 0.5117 - recall_m: 0.1415 - f1_m: 0.2063\n",
      "Epoch 2: val_acc improved from 0.96252 to 0.96661, saving model to models/best_model_2_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1096 - acc: 0.9659 - precision_m: 0.5127 - recall_m: 0.1419 - f1_m: 0.2072 - val_loss: 0.0959 - val_acc: 0.9666 - val_precision_m: 0.5958 - val_recall_m: 0.2466 - val_f1_m: 0.3256\n",
      "Epoch 3/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0930 - acc: 0.9686 - precision_m: 0.6367 - recall_m: 0.2711 - f1_m: 0.3578\n",
      "Epoch 3: val_acc improved from 0.96661 to 0.96878, saving model to models/best_model_2_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0930 - acc: 0.9686 - precision_m: 0.6448 - recall_m: 0.2719 - f1_m: 0.3594 - val_loss: 0.0899 - val_acc: 0.9688 - val_precision_m: 0.7229 - val_recall_m: 0.2655 - val_f1_m: 0.3670\n",
      "Epoch 4/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0839 - acc: 0.9710 - precision_m: 0.6797 - recall_m: 0.3348 - f1_m: 0.4243\n",
      "Epoch 4: val_acc improved from 0.96878 to 0.97023, saving model to models/best_model_2_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0840 - acc: 0.9709 - precision_m: 0.6774 - recall_m: 0.3341 - f1_m: 0.4232 - val_loss: 0.0864 - val_acc: 0.9702 - val_precision_m: 0.6544 - val_recall_m: 0.4378 - val_f1_m: 0.5018\n",
      "Epoch 5/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0807 - acc: 0.9718 - precision_m: 0.7128 - recall_m: 0.3499 - f1_m: 0.4459\n",
      "Epoch 5: val_acc improved from 0.97023 to 0.97059, saving model to models/best_model_2_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0806 - acc: 0.9718 - precision_m: 0.7131 - recall_m: 0.3490 - f1_m: 0.4452 - val_loss: 0.0851 - val_acc: 0.9706 - val_precision_m: 0.7305 - val_recall_m: 0.3195 - val_f1_m: 0.4203\n",
      "Epoch 6/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0757 - acc: 0.9732 - precision_m: 0.7470 - recall_m: 0.3982 - f1_m: 0.4979\n",
      "Epoch 6: val_acc did not improve from 0.97059\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0753 - acc: 0.9734 - precision_m: 0.7493 - recall_m: 0.4004 - f1_m: 0.5006 - val_loss: 0.0911 - val_acc: 0.9700 - val_precision_m: 0.6953 - val_recall_m: 0.2989 - val_f1_m: 0.3938\n",
      "Epoch 7/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.0712 - acc: 0.9746 - precision_m: 0.7582 - recall_m: 0.4404 - f1_m: 0.5362\n",
      "Epoch 7: val_acc improved from 0.97059 to 0.97156, saving model to models/best_model_2_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0712 - acc: 0.9746 - precision_m: 0.7582 - recall_m: 0.4404 - f1_m: 0.5362 - val_loss: 0.0941 - val_acc: 0.9716 - val_precision_m: 0.7774 - val_recall_m: 0.3278 - val_f1_m: 0.4399\n",
      "Epoch 8/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0688 - acc: 0.9749 - precision_m: 0.7638 - recall_m: 0.4397 - f1_m: 0.5373\n",
      "Epoch 8: val_acc improved from 0.97156 to 0.97348, saving model to models/best_model_2_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0688 - acc: 0.9748 - precision_m: 0.7624 - recall_m: 0.4397 - f1_m: 0.5373 - val_loss: 0.0795 - val_acc: 0.9735 - val_precision_m: 0.7730 - val_recall_m: 0.4709 - val_f1_m: 0.5466\n",
      "Epoch 9/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0677 - acc: 0.9759 - precision_m: 0.7896 - recall_m: 0.4853 - f1_m: 0.5709\n",
      "Epoch 9: val_acc improved from 0.97348 to 0.97360, saving model to models/best_model_2_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0678 - acc: 0.9759 - precision_m: 0.7876 - recall_m: 0.4837 - f1_m: 0.5695 - val_loss: 0.0765 - val_acc: 0.9736 - val_precision_m: 0.7582 - val_recall_m: 0.4844 - val_f1_m: 0.5520\n",
      "Epoch 10/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0651 - acc: 0.9763 - precision_m: 0.7946 - recall_m: 0.4904 - f1_m: 0.5802\n",
      "Epoch 10: val_acc did not improve from 0.97360\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0651 - acc: 0.9764 - precision_m: 0.7941 - recall_m: 0.4898 - f1_m: 0.5798 - val_loss: 0.0865 - val_acc: 0.9732 - val_precision_m: 0.8179 - val_recall_m: 0.4165 - val_f1_m: 0.5117\n",
      "Epoch 11/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.0622 - acc: 0.9772 - precision_m: 0.7939 - recall_m: 0.4990 - f1_m: 0.5905\n",
      "Epoch 11: val_acc improved from 0.97360 to 0.97565, saving model to models/best_model_2_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0622 - acc: 0.9772 - precision_m: 0.7939 - recall_m: 0.4990 - f1_m: 0.5905 - val_loss: 0.0772 - val_acc: 0.9757 - val_precision_m: 0.8313 - val_recall_m: 0.4968 - val_f1_m: 0.5776\n",
      "Epoch 12/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9771 - precision_m: 0.7828 - recall_m: 0.5181 - f1_m: 0.6017\n",
      "Epoch 12: val_acc improved from 0.97565 to 0.97674, saving model to models/best_model_2_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0620 - acc: 0.9771 - precision_m: 0.7806 - recall_m: 0.5180 - f1_m: 0.6009 - val_loss: 0.0721 - val_acc: 0.9767 - val_precision_m: 0.7922 - val_recall_m: 0.5510 - val_f1_m: 0.6118\n",
      "Epoch 13/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0600 - acc: 0.9782 - precision_m: 0.7972 - recall_m: 0.5323 - f1_m: 0.6156\n",
      "Epoch 13: val_acc improved from 0.97674 to 0.97722, saving model to models/best_model_2_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0598 - acc: 0.9783 - precision_m: 0.7977 - recall_m: 0.5346 - f1_m: 0.6173 - val_loss: 0.0714 - val_acc: 0.9772 - val_precision_m: 0.7567 - val_recall_m: 0.6168 - val_f1_m: 0.6419\n",
      "Epoch 14/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0568 - acc: 0.9793 - precision_m: 0.8104 - recall_m: 0.5638 - f1_m: 0.6452\n",
      "Epoch 14: val_acc improved from 0.97722 to 0.97734, saving model to models/best_model_2_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0568 - acc: 0.9793 - precision_m: 0.8094 - recall_m: 0.5650 - f1_m: 0.6459 - val_loss: 0.0746 - val_acc: 0.9773 - val_precision_m: 0.7679 - val_recall_m: 0.5989 - val_f1_m: 0.6370\n",
      "Epoch 15/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0562 - acc: 0.9801 - precision_m: 0.8235 - recall_m: 0.5887 - f1_m: 0.6636\n",
      "Epoch 15: val_acc did not improve from 0.97734\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0564 - acc: 0.9799 - precision_m: 0.8211 - recall_m: 0.5845 - f1_m: 0.6600 - val_loss: 0.0721 - val_acc: 0.9760 - val_precision_m: 0.7130 - val_recall_m: 0.6505 - val_f1_m: 0.6448\n",
      "Epoch 16/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0549 - acc: 0.9803 - precision_m: 0.8237 - recall_m: 0.5916 - f1_m: 0.6674\n",
      "Epoch 16: val_acc improved from 0.97734 to 0.97855, saving model to models/best_model_2_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0548 - acc: 0.9803 - precision_m: 0.8235 - recall_m: 0.5915 - f1_m: 0.6677 - val_loss: 0.0716 - val_acc: 0.9785 - val_precision_m: 0.8258 - val_recall_m: 0.5837 - val_f1_m: 0.6481\n",
      "Epoch 17/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0534 - acc: 0.9809 - precision_m: 0.8269 - recall_m: 0.5879 - f1_m: 0.6658\n",
      "Epoch 17: val_acc did not improve from 0.97855\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0537 - acc: 0.9808 - precision_m: 0.8251 - recall_m: 0.5902 - f1_m: 0.6665 - val_loss: 0.0760 - val_acc: 0.9772 - val_precision_m: 0.8308 - val_recall_m: 0.5472 - val_f1_m: 0.6253\n",
      "Epoch 18/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0523 - acc: 0.9811 - precision_m: 0.8450 - recall_m: 0.6013 - f1_m: 0.6797\n",
      "Epoch 18: val_acc did not improve from 0.97855\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0522 - acc: 0.9811 - precision_m: 0.8437 - recall_m: 0.6024 - f1_m: 0.6801 - val_loss: 0.0817 - val_acc: 0.9753 - val_precision_m: 0.8578 - val_recall_m: 0.4877 - val_f1_m: 0.5859\n",
      "Epoch 19/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9818 - precision_m: 0.8434 - recall_m: 0.6101 - f1_m: 0.6898\n",
      "Epoch 19: val_acc did not improve from 0.97855\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0501 - acc: 0.9817 - precision_m: 0.8438 - recall_m: 0.6117 - f1_m: 0.6909 - val_loss: 0.0752 - val_acc: 0.9779 - val_precision_m: 0.8346 - val_recall_m: 0.5718 - val_f1_m: 0.6476\n",
      "Epoch 20/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0486 - acc: 0.9824 - precision_m: 0.8401 - recall_m: 0.6345 - f1_m: 0.7046\n",
      "Epoch 20: val_acc did not improve from 0.97855\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0489 - acc: 0.9824 - precision_m: 0.8388 - recall_m: 0.6359 - f1_m: 0.7048 - val_loss: 0.0782 - val_acc: 0.9702 - val_precision_m: 0.6148 - val_recall_m: 0.7824 - val_f1_m: 0.6485\n",
      "Epoch 21/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9820 - precision_m: 0.8348 - recall_m: 0.6358 - f1_m: 0.7028\n",
      "Epoch 21: val_acc did not improve from 0.97855\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0487 - acc: 0.9820 - precision_m: 0.8345 - recall_m: 0.6353 - f1_m: 0.7024 - val_loss: 0.0729 - val_acc: 0.9783 - val_precision_m: 0.7734 - val_recall_m: 0.6789 - val_f1_m: 0.6770\n",
      "Epoch 22/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9824 - precision_m: 0.8569 - recall_m: 0.6383 - f1_m: 0.7112\n",
      "Epoch 22: val_acc did not improve from 0.97855\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0476 - acc: 0.9824 - precision_m: 0.8567 - recall_m: 0.6391 - f1_m: 0.7116 - val_loss: 0.0699 - val_acc: 0.9781 - val_precision_m: 0.7570 - val_recall_m: 0.6550 - val_f1_m: 0.6687\n",
      "Epoch 23/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9827 - precision_m: 0.8517 - recall_m: 0.6511 - f1_m: 0.7163\n",
      "Epoch 23: val_acc did not improve from 0.97855\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0471 - acc: 0.9828 - precision_m: 0.8495 - recall_m: 0.6511 - f1_m: 0.7157 - val_loss: 0.0725 - val_acc: 0.9773 - val_precision_m: 0.7308 - val_recall_m: 0.6762 - val_f1_m: 0.6651\n",
      "Epoch 24/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0459 - acc: 0.9830 - precision_m: 0.8566 - recall_m: 0.6559 - f1_m: 0.7235\n",
      "Epoch 24: val_acc did not improve from 0.97855\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0457 - acc: 0.9831 - precision_m: 0.8564 - recall_m: 0.6525 - f1_m: 0.7205 - val_loss: 0.0713 - val_acc: 0.9773 - val_precision_m: 0.7377 - val_recall_m: 0.7105 - val_f1_m: 0.6798\n",
      "Epoch 25/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.0449 - acc: 0.9835 - precision_m: 0.8549 - recall_m: 0.6593 - f1_m: 0.7251\n",
      "Epoch 25: val_acc did not improve from 0.97855\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0449 - acc: 0.9835 - precision_m: 0.8543 - recall_m: 0.6600 - f1_m: 0.7252 - val_loss: 0.0740 - val_acc: 0.9728 - val_precision_m: 0.6544 - val_recall_m: 0.6916 - val_f1_m: 0.6369\n",
      "Epoch 26/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0444 - acc: 0.9837 - precision_m: 0.8499 - recall_m: 0.6712 - f1_m: 0.7307\n",
      "Epoch 26: val_acc did not improve from 0.97855\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0443 - acc: 0.9837 - precision_m: 0.8508 - recall_m: 0.6719 - f1_m: 0.7317 - val_loss: 0.0947 - val_acc: 0.9759 - val_precision_m: 0.8664 - val_recall_m: 0.4773 - val_f1_m: 0.5804\n",
      "Epoch 27/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9836 - precision_m: 0.8514 - recall_m: 0.6653 - f1_m: 0.7293\n",
      "Epoch 27: val_acc did not improve from 0.97855\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0434 - acc: 0.9836 - precision_m: 0.8529 - recall_m: 0.6639 - f1_m: 0.7288 - val_loss: 0.0792 - val_acc: 0.9784 - val_precision_m: 0.8496 - val_recall_m: 0.5733 - val_f1_m: 0.6532\n",
      "Epoch 28/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.0422 - acc: 0.9844 - precision_m: 0.8601 - recall_m: 0.6856 - f1_m: 0.7458\n",
      "Epoch 28: val_acc improved from 0.97855 to 0.97903, saving model to models/best_model_2_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0420 - acc: 0.9843 - precision_m: 0.8619 - recall_m: 0.6786 - f1_m: 0.7411 - val_loss: 0.0709 - val_acc: 0.9790 - val_precision_m: 0.7736 - val_recall_m: 0.6601 - val_f1_m: 0.6812\n",
      "Epoch 29/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.0410 - acc: 0.9848 - precision_m: 0.8704 - recall_m: 0.6926 - f1_m: 0.7558\n",
      "Epoch 29: val_acc did not improve from 0.97903\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0406 - acc: 0.9850 - precision_m: 0.8724 - recall_m: 0.6946 - f1_m: 0.7579 - val_loss: 0.0778 - val_acc: 0.9783 - val_precision_m: 0.7531 - val_recall_m: 0.6741 - val_f1_m: 0.6762\n",
      "Epoch 30/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9852 - precision_m: 0.8737 - recall_m: 0.7000 - f1_m: 0.7617\n",
      "Epoch 30: val_acc improved from 0.97903 to 0.97963, saving model to models/best_model_2_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0393 - acc: 0.9851 - precision_m: 0.8713 - recall_m: 0.6978 - f1_m: 0.7595 - val_loss: 0.0766 - val_acc: 0.9796 - val_precision_m: 0.8099 - val_recall_m: 0.6380 - val_f1_m: 0.6827\n",
      "Score for fold 6: loss of 0.07662399858236313; acc of 97.96311855316162%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.07863759994506836; acc of 97.79083728790283%\n",
      "Test Precision: precision_m of 26.860085129737854%\n",
      "Test Recall: recall_m of 23.24969470500946%\n",
      "Test F1: f1_m of 23.789387941360474%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1570 - acc: 0.9611 - precision_m: 0.0320 - recall_m: 0.0049 - f1_m: 0.0064\n",
      "Epoch 1: val_acc improved from -inf to 0.96320, saving model to models/best_model_2_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 2s 4ms/step - loss: 0.1570 - acc: 0.9611 - precision_m: 0.0320 - recall_m: 0.0049 - f1_m: 0.0064 - val_loss: 0.1195 - val_acc: 0.9632 - val_precision_m: 0.0909 - val_recall_m: 0.0122 - val_f1_m: 0.0212\n",
      "Epoch 2/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.1123 - acc: 0.9645 - precision_m: 0.4624 - recall_m: 0.1082 - f1_m: 0.1647\n",
      "Epoch 2: val_acc improved from 0.96320 to 0.96559, saving model to models/best_model_2_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1118 - acc: 0.9646 - precision_m: 0.4600 - recall_m: 0.1086 - f1_m: 0.1641 - val_loss: 0.0994 - val_acc: 0.9656 - val_precision_m: 0.3636 - val_recall_m: 0.0817 - val_f1_m: 0.1219\n",
      "Epoch 3/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0977 - acc: 0.9666 - precision_m: 0.6251 - recall_m: 0.2109 - f1_m: 0.2950\n",
      "Epoch 3: val_acc improved from 0.96559 to 0.97180, saving model to models/best_model_2_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0976 - acc: 0.9666 - precision_m: 0.6242 - recall_m: 0.2103 - f1_m: 0.2942 - val_loss: 0.0875 - val_acc: 0.9718 - val_precision_m: 0.7985 - val_recall_m: 0.3142 - val_f1_m: 0.4126\n",
      "Epoch 4/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.0873 - acc: 0.9691 - precision_m: 0.6714 - recall_m: 0.2934 - f1_m: 0.3880\n",
      "Epoch 4: val_acc improved from 0.97180 to 0.97204, saving model to models/best_model_2_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0868 - acc: 0.9692 - precision_m: 0.6699 - recall_m: 0.2983 - f1_m: 0.3919 - val_loss: 0.0869 - val_acc: 0.9720 - val_precision_m: 0.7903 - val_recall_m: 0.2960 - val_f1_m: 0.4019\n",
      "Epoch 5/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0809 - acc: 0.9713 - precision_m: 0.7258 - recall_m: 0.3693 - f1_m: 0.4632\n",
      "Epoch 5: val_acc improved from 0.97204 to 0.97407, saving model to models/best_model_2_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0810 - acc: 0.9713 - precision_m: 0.7234 - recall_m: 0.3723 - f1_m: 0.4639 - val_loss: 0.0786 - val_acc: 0.9741 - val_precision_m: 0.7638 - val_recall_m: 0.4352 - val_f1_m: 0.5164\n",
      "Epoch 6/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0744 - acc: 0.9732 - precision_m: 0.7277 - recall_m: 0.4296 - f1_m: 0.5172\n",
      "Epoch 6: val_acc improved from 0.97407 to 0.97539, saving model to models/best_model_2_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0743 - acc: 0.9732 - precision_m: 0.7283 - recall_m: 0.4324 - f1_m: 0.5186 - val_loss: 0.0756 - val_acc: 0.9754 - val_precision_m: 0.7790 - val_recall_m: 0.4655 - val_f1_m: 0.5478\n",
      "Epoch 7/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0737 - acc: 0.9740 - precision_m: 0.7526 - recall_m: 0.4483 - f1_m: 0.5386\n",
      "Epoch 7: val_acc did not improve from 0.97539\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0737 - acc: 0.9740 - precision_m: 0.7516 - recall_m: 0.4500 - f1_m: 0.5396 - val_loss: 0.0753 - val_acc: 0.9744 - val_precision_m: 0.7646 - val_recall_m: 0.4133 - val_f1_m: 0.5014\n",
      "Epoch 8/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0688 - acc: 0.9755 - precision_m: 0.7793 - recall_m: 0.4794 - f1_m: 0.5701\n",
      "Epoch 8: val_acc did not improve from 0.97539\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0688 - acc: 0.9756 - precision_m: 0.7819 - recall_m: 0.4814 - f1_m: 0.5726 - val_loss: 0.0723 - val_acc: 0.9750 - val_precision_m: 0.7292 - val_recall_m: 0.5285 - val_f1_m: 0.5798\n",
      "Epoch 9/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0677 - acc: 0.9756 - precision_m: 0.7721 - recall_m: 0.4956 - f1_m: 0.5767\n",
      "Epoch 9: val_acc did not improve from 0.97539\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0676 - acc: 0.9757 - precision_m: 0.7727 - recall_m: 0.4978 - f1_m: 0.5784 - val_loss: 0.0739 - val_acc: 0.9735 - val_precision_m: 0.6814 - val_recall_m: 0.5434 - val_f1_m: 0.5802\n",
      "Epoch 10/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0647 - acc: 0.9768 - precision_m: 0.7858 - recall_m: 0.5218 - f1_m: 0.6075\n",
      "Epoch 10: val_acc did not improve from 0.97539\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0649 - acc: 0.9768 - precision_m: 0.7879 - recall_m: 0.5198 - f1_m: 0.6066 - val_loss: 0.0721 - val_acc: 0.9746 - val_precision_m: 0.6757 - val_recall_m: 0.6263 - val_f1_m: 0.6260\n",
      "Epoch 11/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0621 - acc: 0.9781 - precision_m: 0.8067 - recall_m: 0.5401 - f1_m: 0.6267\n",
      "Epoch 11: val_acc improved from 0.97539 to 0.97802, saving model to models/best_model_2_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0623 - acc: 0.9781 - precision_m: 0.8072 - recall_m: 0.5428 - f1_m: 0.6285 - val_loss: 0.0675 - val_acc: 0.9780 - val_precision_m: 0.8324 - val_recall_m: 0.5169 - val_f1_m: 0.6029\n",
      "Epoch 12/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0600 - acc: 0.9783 - precision_m: 0.8071 - recall_m: 0.5532 - f1_m: 0.6335\n",
      "Epoch 12: val_acc did not improve from 0.97802\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0605 - acc: 0.9782 - precision_m: 0.8065 - recall_m: 0.5525 - f1_m: 0.6328 - val_loss: 0.0682 - val_acc: 0.9768 - val_precision_m: 0.7416 - val_recall_m: 0.5761 - val_f1_m: 0.6179\n",
      "Epoch 13/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9789 - precision_m: 0.8287 - recall_m: 0.5708 - f1_m: 0.6510\n",
      "Epoch 13: val_acc improved from 0.97802 to 0.97814, saving model to models/best_model_2_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0601 - acc: 0.9789 - precision_m: 0.8273 - recall_m: 0.5707 - f1_m: 0.6506 - val_loss: 0.0685 - val_acc: 0.9781 - val_precision_m: 0.8527 - val_recall_m: 0.5002 - val_f1_m: 0.5948\n",
      "Epoch 14/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0582 - acc: 0.9793 - precision_m: 0.8255 - recall_m: 0.5839 - f1_m: 0.6570\n",
      "Epoch 14: val_acc did not improve from 0.97814\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0583 - acc: 0.9792 - precision_m: 0.8230 - recall_m: 0.5845 - f1_m: 0.6568 - val_loss: 0.0696 - val_acc: 0.9780 - val_precision_m: 0.8698 - val_recall_m: 0.4911 - val_f1_m: 0.5868\n",
      "Epoch 15/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0560 - acc: 0.9800 - precision_m: 0.8157 - recall_m: 0.5920 - f1_m: 0.6661\n",
      "Epoch 15: val_acc did not improve from 0.97814\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0560 - acc: 0.9800 - precision_m: 0.8169 - recall_m: 0.5931 - f1_m: 0.6672 - val_loss: 0.0700 - val_acc: 0.9777 - val_precision_m: 0.7905 - val_recall_m: 0.5612 - val_f1_m: 0.6202\n",
      "Epoch 16/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0546 - acc: 0.9803 - precision_m: 0.8268 - recall_m: 0.6082 - f1_m: 0.6819\n",
      "Epoch 16: val_acc did not improve from 0.97814\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0548 - acc: 0.9802 - precision_m: 0.8278 - recall_m: 0.6057 - f1_m: 0.6804 - val_loss: 0.0718 - val_acc: 0.9736 - val_precision_m: 0.6424 - val_recall_m: 0.6578 - val_f1_m: 0.6255\n",
      "Epoch 17/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0544 - acc: 0.9809 - precision_m: 0.8452 - recall_m: 0.6114 - f1_m: 0.6893\n",
      "Epoch 17: val_acc did not improve from 0.97814\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0545 - acc: 0.9810 - precision_m: 0.8469 - recall_m: 0.6102 - f1_m: 0.6891 - val_loss: 0.0709 - val_acc: 0.9773 - val_precision_m: 0.8370 - val_recall_m: 0.4913 - val_f1_m: 0.5821\n",
      "Epoch 18/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0527 - acc: 0.9812 - precision_m: 0.8338 - recall_m: 0.6193 - f1_m: 0.6905\n",
      "Epoch 18: val_acc improved from 0.97814 to 0.97885, saving model to models/best_model_2_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0525 - acc: 0.9812 - precision_m: 0.8318 - recall_m: 0.6211 - f1_m: 0.6904 - val_loss: 0.0689 - val_acc: 0.9789 - val_precision_m: 0.8163 - val_recall_m: 0.5663 - val_f1_m: 0.6295\n",
      "Epoch 19/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0501 - acc: 0.9823 - precision_m: 0.8311 - recall_m: 0.6453 - f1_m: 0.7095\n",
      "Epoch 19: val_acc improved from 0.97885 to 0.97897, saving model to models/best_model_2_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0502 - acc: 0.9822 - precision_m: 0.8309 - recall_m: 0.6431 - f1_m: 0.7078 - val_loss: 0.0674 - val_acc: 0.9790 - val_precision_m: 0.8131 - val_recall_m: 0.5518 - val_f1_m: 0.6200\n",
      "Epoch 20/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0486 - acc: 0.9829 - precision_m: 0.8555 - recall_m: 0.6549 - f1_m: 0.7253\n",
      "Epoch 20: val_acc did not improve from 0.97897\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0486 - acc: 0.9829 - precision_m: 0.8553 - recall_m: 0.6537 - f1_m: 0.7245 - val_loss: 0.0726 - val_acc: 0.9743 - val_precision_m: 0.6521 - val_recall_m: 0.6399 - val_f1_m: 0.6222\n",
      "Epoch 21/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9826 - precision_m: 0.8434 - recall_m: 0.6494 - f1_m: 0.7140\n",
      "Epoch 21: val_acc did not improve from 0.97897\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0487 - acc: 0.9825 - precision_m: 0.8447 - recall_m: 0.6489 - f1_m: 0.7140 - val_loss: 0.0729 - val_acc: 0.9779 - val_precision_m: 0.8078 - val_recall_m: 0.5387 - val_f1_m: 0.6138\n",
      "Epoch 22/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9828 - precision_m: 0.8454 - recall_m: 0.6553 - f1_m: 0.7210\n",
      "Epoch 22: val_acc did not improve from 0.97897\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0481 - acc: 0.9827 - precision_m: 0.8461 - recall_m: 0.6536 - f1_m: 0.7199 - val_loss: 0.0687 - val_acc: 0.9769 - val_precision_m: 0.7147 - val_recall_m: 0.6382 - val_f1_m: 0.6477\n",
      "Epoch 23/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9834 - precision_m: 0.8534 - recall_m: 0.6646 - f1_m: 0.7310\n",
      "Epoch 23: val_acc did not improve from 0.97897\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0469 - acc: 0.9834 - precision_m: 0.8554 - recall_m: 0.6630 - f1_m: 0.7303 - val_loss: 0.1029 - val_acc: 0.9757 - val_precision_m: 0.8707 - val_recall_m: 0.3706 - val_f1_m: 0.4886\n",
      "Epoch 24/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9837 - precision_m: 0.8551 - recall_m: 0.6857 - f1_m: 0.7432\n",
      "Epoch 24: val_acc did not improve from 0.97897\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0456 - acc: 0.9837 - precision_m: 0.8566 - recall_m: 0.6861 - f1_m: 0.7442 - val_loss: 0.0700 - val_acc: 0.9768 - val_precision_m: 0.7013 - val_recall_m: 0.6416 - val_f1_m: 0.6429\n",
      "Epoch 25/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9837 - precision_m: 0.8629 - recall_m: 0.6755 - f1_m: 0.7421\n",
      "Epoch 25: val_acc did not improve from 0.97897\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0454 - acc: 0.9837 - precision_m: 0.8621 - recall_m: 0.6738 - f1_m: 0.7409 - val_loss: 0.0692 - val_acc: 0.9790 - val_precision_m: 0.8052 - val_recall_m: 0.5707 - val_f1_m: 0.6374\n",
      "Epoch 26/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9839 - precision_m: 0.8657 - recall_m: 0.6824 - f1_m: 0.7447\n",
      "Epoch 26: val_acc did not improve from 0.97897\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0444 - acc: 0.9840 - precision_m: 0.8666 - recall_m: 0.6837 - f1_m: 0.7459 - val_loss: 0.0691 - val_acc: 0.9780 - val_precision_m: 0.7225 - val_recall_m: 0.6568 - val_f1_m: 0.6593\n",
      "Epoch 27/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9845 - precision_m: 0.8674 - recall_m: 0.6854 - f1_m: 0.7483\n",
      "Epoch 27: val_acc did not improve from 0.97897\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0434 - acc: 0.9844 - precision_m: 0.8645 - recall_m: 0.6828 - f1_m: 0.7456 - val_loss: 0.0711 - val_acc: 0.9786 - val_precision_m: 0.7670 - val_recall_m: 0.6236 - val_f1_m: 0.6547\n",
      "Epoch 28/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9852 - precision_m: 0.8758 - recall_m: 0.7117 - f1_m: 0.7708\n",
      "Epoch 28: val_acc improved from 0.97897 to 0.98041, saving model to models/best_model_2_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0413 - acc: 0.9852 - precision_m: 0.8738 - recall_m: 0.7120 - f1_m: 0.7704 - val_loss: 0.0712 - val_acc: 0.9804 - val_precision_m: 0.8443 - val_recall_m: 0.5778 - val_f1_m: 0.6508\n",
      "Epoch 29/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9853 - precision_m: 0.8683 - recall_m: 0.7136 - f1_m: 0.7690\n",
      "Epoch 29: val_acc did not improve from 0.98041\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0415 - acc: 0.9853 - precision_m: 0.8676 - recall_m: 0.7152 - f1_m: 0.7696 - val_loss: 0.0796 - val_acc: 0.9753 - val_precision_m: 0.6764 - val_recall_m: 0.6675 - val_f1_m: 0.6453\n",
      "Epoch 30/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.0401 - acc: 0.9858 - precision_m: 0.8792 - recall_m: 0.7203 - f1_m: 0.7769\n",
      "Epoch 30: val_acc did not improve from 0.98041\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0401 - acc: 0.9858 - precision_m: 0.8792 - recall_m: 0.7203 - f1_m: 0.7769 - val_loss: 0.0689 - val_acc: 0.9790 - val_precision_m: 0.7989 - val_recall_m: 0.5822 - val_f1_m: 0.6433\n",
      "Score for fold 7: loss of 0.071187824010849; acc of 98.04062247276306%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.0577411986887455; acc of 98.14308881759644%\n",
      "Test Precision: precision_m of 21.416957676410675%\n",
      "Test Recall: recall_m of 16.747552156448364%\n",
      "Test F1: f1_m of 18.011321127414703%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1956 - acc: 0.9488 - precision_m: 0.0575 - recall_m: 0.0241 - f1_m: 0.0145\n",
      "Epoch 1: val_acc improved from -inf to 0.96299, saving model to models/best_model_2_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 2s 4ms/step - loss: 0.1956 - acc: 0.9488 - precision_m: 0.0575 - recall_m: 0.0241 - f1_m: 0.0145 - val_loss: 0.1273 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.1186 - acc: 0.9640 - precision_m: 0.3442 - recall_m: 0.0695 - f1_m: 0.1088\n",
      "Epoch 2: val_acc improved from 0.96299 to 0.96526, saving model to models/best_model_2_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1188 - acc: 0.9639 - precision_m: 0.3508 - recall_m: 0.0698 - f1_m: 0.1097 - val_loss: 0.1099 - val_acc: 0.9653 - val_precision_m: 0.5137 - val_recall_m: 0.1671 - val_f1_m: 0.2190\n",
      "Epoch 3/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.1065 - acc: 0.9659 - precision_m: 0.5507 - recall_m: 0.1457 - f1_m: 0.2162\n",
      "Epoch 3: val_acc improved from 0.96526 to 0.96706, saving model to models/best_model_2_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1066 - acc: 0.9658 - precision_m: 0.5499 - recall_m: 0.1457 - f1_m: 0.2161 - val_loss: 0.0976 - val_acc: 0.9671 - val_precision_m: 0.5387 - val_recall_m: 0.2480 - val_f1_m: 0.3052\n",
      "Epoch 4/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0972 - acc: 0.9671 - precision_m: 0.6170 - recall_m: 0.2259 - f1_m: 0.3095\n",
      "Epoch 4: val_acc improved from 0.96706 to 0.96742, saving model to models/best_model_2_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0968 - acc: 0.9672 - precision_m: 0.6171 - recall_m: 0.2244 - f1_m: 0.3079 - val_loss: 0.0964 - val_acc: 0.9674 - val_precision_m: 0.5375 - val_recall_m: 0.1529 - val_f1_m: 0.2214\n",
      "Epoch 5/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0927 - acc: 0.9685 - precision_m: 0.6587 - recall_m: 0.2617 - f1_m: 0.3497\n",
      "Epoch 5: val_acc improved from 0.96742 to 0.97041, saving model to models/best_model_2_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0928 - acc: 0.9684 - precision_m: 0.6580 - recall_m: 0.2642 - f1_m: 0.3520 - val_loss: 0.0882 - val_acc: 0.9704 - val_precision_m: 0.6579 - val_recall_m: 0.2616 - val_f1_m: 0.3505\n",
      "Epoch 6/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0873 - acc: 0.9698 - precision_m: 0.6841 - recall_m: 0.3101 - f1_m: 0.4029\n",
      "Epoch 6: val_acc improved from 0.97041 to 0.97185, saving model to models/best_model_2_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0871 - acc: 0.9698 - precision_m: 0.6841 - recall_m: 0.3104 - f1_m: 0.4032 - val_loss: 0.0853 - val_acc: 0.9718 - val_precision_m: 0.6700 - val_recall_m: 0.3153 - val_f1_m: 0.3999\n",
      "Epoch 7/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0823 - acc: 0.9716 - precision_m: 0.7199 - recall_m: 0.3660 - f1_m: 0.4613\n",
      "Epoch 7: val_acc did not improve from 0.97185\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0829 - acc: 0.9713 - precision_m: 0.7174 - recall_m: 0.3637 - f1_m: 0.4591 - val_loss: 0.0883 - val_acc: 0.9709 - val_precision_m: 0.5806 - val_recall_m: 0.4279 - val_f1_m: 0.4627\n",
      "Epoch 8/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0798 - acc: 0.9724 - precision_m: 0.7302 - recall_m: 0.3846 - f1_m: 0.4778\n",
      "Epoch 8: val_acc improved from 0.97185 to 0.97317, saving model to models/best_model_2_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0800 - acc: 0.9723 - precision_m: 0.7312 - recall_m: 0.3839 - f1_m: 0.4774 - val_loss: 0.0796 - val_acc: 0.9732 - val_precision_m: 0.6301 - val_recall_m: 0.3898 - val_f1_m: 0.4532\n",
      "Epoch 9/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0753 - acc: 0.9737 - precision_m: 0.7369 - recall_m: 0.4433 - f1_m: 0.5317\n",
      "Epoch 9: val_acc improved from 0.97317 to 0.97341, saving model to models/best_model_2_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0753 - acc: 0.9737 - precision_m: 0.7362 - recall_m: 0.4427 - f1_m: 0.5312 - val_loss: 0.0767 - val_acc: 0.9734 - val_precision_m: 0.6438 - val_recall_m: 0.4313 - val_f1_m: 0.4849\n",
      "Epoch 10/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.0732 - acc: 0.9744 - precision_m: 0.7588 - recall_m: 0.4529 - f1_m: 0.5426\n",
      "Epoch 10: val_acc improved from 0.97341 to 0.97365, saving model to models/best_model_2_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0732 - acc: 0.9744 - precision_m: 0.7588 - recall_m: 0.4529 - f1_m: 0.5426 - val_loss: 0.0761 - val_acc: 0.9736 - val_precision_m: 0.6543 - val_recall_m: 0.4808 - val_f1_m: 0.5188\n",
      "Epoch 11/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0700 - acc: 0.9754 - precision_m: 0.7619 - recall_m: 0.4926 - f1_m: 0.5778\n",
      "Epoch 11: val_acc improved from 0.97365 to 0.97568, saving model to models/best_model_2_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0699 - acc: 0.9755 - precision_m: 0.7656 - recall_m: 0.4919 - f1_m: 0.5786 - val_loss: 0.0754 - val_acc: 0.9757 - val_precision_m: 0.7006 - val_recall_m: 0.4116 - val_f1_m: 0.4845\n",
      "Epoch 12/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0678 - acc: 0.9765 - precision_m: 0.7916 - recall_m: 0.4996 - f1_m: 0.5877\n",
      "Epoch 12: val_acc did not improve from 0.97568\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0675 - acc: 0.9765 - precision_m: 0.7902 - recall_m: 0.5021 - f1_m: 0.5892 - val_loss: 0.0873 - val_acc: 0.9742 - val_precision_m: 0.7645 - val_recall_m: 0.3435 - val_f1_m: 0.4407\n",
      "Epoch 13/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0653 - acc: 0.9771 - precision_m: 0.7884 - recall_m: 0.5350 - f1_m: 0.6128\n",
      "Epoch 13: val_acc did not improve from 0.97568\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0655 - acc: 0.9771 - precision_m: 0.7895 - recall_m: 0.5318 - f1_m: 0.6102 - val_loss: 0.0792 - val_acc: 0.9756 - val_precision_m: 0.6761 - val_recall_m: 0.3980 - val_f1_m: 0.4741\n",
      "Epoch 14/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0636 - acc: 0.9773 - precision_m: 0.7896 - recall_m: 0.5394 - f1_m: 0.6142\n",
      "Epoch 14: val_acc improved from 0.97568 to 0.97628, saving model to models/best_model_2_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0635 - acc: 0.9773 - precision_m: 0.7900 - recall_m: 0.5393 - f1_m: 0.6146 - val_loss: 0.0749 - val_acc: 0.9763 - val_precision_m: 0.7267 - val_recall_m: 0.4733 - val_f1_m: 0.5371\n",
      "Epoch 15/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9783 - precision_m: 0.8041 - recall_m: 0.5551 - f1_m: 0.6356\n",
      "Epoch 15: val_acc improved from 0.97628 to 0.97688, saving model to models/best_model_2_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0612 - acc: 0.9784 - precision_m: 0.8046 - recall_m: 0.5579 - f1_m: 0.6377 - val_loss: 0.0716 - val_acc: 0.9769 - val_precision_m: 0.7131 - val_recall_m: 0.4774 - val_f1_m: 0.5360\n",
      "Epoch 16/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9790 - precision_m: 0.7985 - recall_m: 0.5644 - f1_m: 0.6415\n",
      "Epoch 16: val_acc improved from 0.97688 to 0.97760, saving model to models/best_model_2_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0587 - acc: 0.9791 - precision_m: 0.8017 - recall_m: 0.5655 - f1_m: 0.6429 - val_loss: 0.0751 - val_acc: 0.9776 - val_precision_m: 0.7326 - val_recall_m: 0.4846 - val_f1_m: 0.5529\n",
      "Epoch 17/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0561 - acc: 0.9800 - precision_m: 0.8147 - recall_m: 0.5892 - f1_m: 0.6639\n",
      "Epoch 17: val_acc did not improve from 0.97760\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0564 - acc: 0.9800 - precision_m: 0.8169 - recall_m: 0.5906 - f1_m: 0.6661 - val_loss: 0.0788 - val_acc: 0.9705 - val_precision_m: 0.5676 - val_recall_m: 0.6597 - val_f1_m: 0.5815\n",
      "Epoch 18/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0554 - acc: 0.9802 - precision_m: 0.8157 - recall_m: 0.5999 - f1_m: 0.6730\n",
      "Epoch 18: val_acc did not improve from 0.97760\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0553 - acc: 0.9803 - precision_m: 0.8175 - recall_m: 0.6027 - f1_m: 0.6757 - val_loss: 0.0703 - val_acc: 0.9774 - val_precision_m: 0.6852 - val_recall_m: 0.5085 - val_f1_m: 0.5532\n",
      "Epoch 19/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0546 - acc: 0.9806 - precision_m: 0.8267 - recall_m: 0.6097 - f1_m: 0.6794\n",
      "Epoch 19: val_acc did not improve from 0.97760\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0544 - acc: 0.9807 - precision_m: 0.8259 - recall_m: 0.6104 - f1_m: 0.6794 - val_loss: 0.0743 - val_acc: 0.9766 - val_precision_m: 0.6979 - val_recall_m: 0.4299 - val_f1_m: 0.4939\n",
      "Epoch 20/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.0511 - acc: 0.9819 - precision_m: 0.8367 - recall_m: 0.6375 - f1_m: 0.7054\n",
      "Epoch 20: val_acc did not improve from 0.97760\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0514 - acc: 0.9817 - precision_m: 0.8293 - recall_m: 0.6349 - f1_m: 0.7009 - val_loss: 0.0725 - val_acc: 0.9774 - val_precision_m: 0.7242 - val_recall_m: 0.4787 - val_f1_m: 0.5422\n",
      "Epoch 21/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9814 - precision_m: 0.8250 - recall_m: 0.6262 - f1_m: 0.6939\n",
      "Epoch 21: val_acc did not improve from 0.97760\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0507 - acc: 0.9814 - precision_m: 0.8248 - recall_m: 0.6253 - f1_m: 0.6933 - val_loss: 0.0710 - val_acc: 0.9757 - val_precision_m: 0.6747 - val_recall_m: 0.5161 - val_f1_m: 0.5545\n",
      "Epoch 22/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0496 - acc: 0.9822 - precision_m: 0.8429 - recall_m: 0.6440 - f1_m: 0.7108\n",
      "Epoch 22: val_acc improved from 0.97760 to 0.97820, saving model to models/best_model_2_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0496 - acc: 0.9823 - precision_m: 0.8427 - recall_m: 0.6465 - f1_m: 0.7127 - val_loss: 0.0690 - val_acc: 0.9782 - val_precision_m: 0.6990 - val_recall_m: 0.5543 - val_f1_m: 0.5806\n",
      "Epoch 23/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0491 - acc: 0.9826 - precision_m: 0.8493 - recall_m: 0.6514 - f1_m: 0.7171\n",
      "Epoch 23: val_acc improved from 0.97820 to 0.97856, saving model to models/best_model_2_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0493 - acc: 0.9825 - precision_m: 0.8491 - recall_m: 0.6496 - f1_m: 0.7161 - val_loss: 0.0744 - val_acc: 0.9786 - val_precision_m: 0.7479 - val_recall_m: 0.5039 - val_f1_m: 0.5642\n",
      "Epoch 24/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0467 - acc: 0.9830 - precision_m: 0.8395 - recall_m: 0.6642 - f1_m: 0.7240\n",
      "Epoch 24: val_acc did not improve from 0.97856\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0467 - acc: 0.9830 - precision_m: 0.8409 - recall_m: 0.6628 - f1_m: 0.7236 - val_loss: 0.0694 - val_acc: 0.9781 - val_precision_m: 0.6865 - val_recall_m: 0.5657 - val_f1_m: 0.5845\n",
      "Epoch 25/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0471 - acc: 0.9827 - precision_m: 0.8470 - recall_m: 0.6555 - f1_m: 0.7200\n",
      "Epoch 25: val_acc did not improve from 0.97856\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0472 - acc: 0.9826 - precision_m: 0.8466 - recall_m: 0.6517 - f1_m: 0.7173 - val_loss: 0.0680 - val_acc: 0.9778 - val_precision_m: 0.7096 - val_recall_m: 0.5062 - val_f1_m: 0.5613\n",
      "Epoch 26/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9835 - precision_m: 0.8505 - recall_m: 0.6566 - f1_m: 0.7255\n",
      "Epoch 26: val_acc did not improve from 0.97856\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0459 - acc: 0.9835 - precision_m: 0.8491 - recall_m: 0.6563 - f1_m: 0.7249 - val_loss: 0.0697 - val_acc: 0.9786 - val_precision_m: 0.6944 - val_recall_m: 0.5724 - val_f1_m: 0.5942\n",
      "Epoch 27/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9841 - precision_m: 0.8537 - recall_m: 0.6858 - f1_m: 0.7462\n",
      "Epoch 27: val_acc did not improve from 0.97856\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0438 - acc: 0.9840 - precision_m: 0.8550 - recall_m: 0.6831 - f1_m: 0.7441 - val_loss: 0.0710 - val_acc: 0.9768 - val_precision_m: 0.6388 - val_recall_m: 0.6135 - val_f1_m: 0.5940\n",
      "Epoch 28/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9843 - precision_m: 0.8533 - recall_m: 0.6774 - f1_m: 0.7391\n",
      "Epoch 28: val_acc did not improve from 0.97856\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0431 - acc: 0.9841 - precision_m: 0.8506 - recall_m: 0.6766 - f1_m: 0.7378 - val_loss: 0.0766 - val_acc: 0.9781 - val_precision_m: 0.7220 - val_recall_m: 0.5125 - val_f1_m: 0.5679\n",
      "Epoch 29/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0424 - acc: 0.9846 - precision_m: 0.8657 - recall_m: 0.6827 - f1_m: 0.7457\n",
      "Epoch 29: val_acc improved from 0.97856 to 0.97868, saving model to models/best_model_2_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0422 - acc: 0.9846 - precision_m: 0.8675 - recall_m: 0.6842 - f1_m: 0.7476 - val_loss: 0.0719 - val_acc: 0.9787 - val_precision_m: 0.6763 - val_recall_m: 0.5728 - val_f1_m: 0.5863\n",
      "Epoch 30/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0419 - acc: 0.9842 - precision_m: 0.8565 - recall_m: 0.6799 - f1_m: 0.7418\n",
      "Epoch 30: val_acc improved from 0.97868 to 0.98000, saving model to models/best_model_2_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0420 - acc: 0.9841 - precision_m: 0.8560 - recall_m: 0.6834 - f1_m: 0.7440 - val_loss: 0.0725 - val_acc: 0.9800 - val_precision_m: 0.7249 - val_recall_m: 0.5904 - val_f1_m: 0.6167\n",
      "Score for fold 8: loss of 0.07254233211278915; acc of 97.99951910972595%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.07395217567682266; acc of 97.93118834495544%\n",
      "Test Precision: precision_m of 26.37220323085785%\n",
      "Test Recall: recall_m of 22.433598339557648%\n",
      "Test F1: f1_m of 23.113684356212616%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "Epoch 1/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.1949 - acc: 0.9564 - precision_m: 0.0058 - recall_m: 0.0073 - f1_m: 0.0029\n",
      "Epoch 1: val_acc improved from -inf to 0.96151, saving model to models/best_model_2_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 2s 5ms/step - loss: 0.1949 - acc: 0.9564 - precision_m: 0.0058 - recall_m: 0.0073 - f1_m: 0.0029 - val_loss: 0.1296 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1203 - acc: 0.9643 - precision_m: 0.0796 - recall_m: 0.0083 - f1_m: 0.0149   \n",
      "Epoch 2: val_acc improved from 0.96151 to 0.96175, saving model to models/best_model_2_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1202 - acc: 0.9643 - precision_m: 0.0790 - recall_m: 0.0082 - f1_m: 0.0148 - val_loss: 0.1046 - val_acc: 0.9617 - val_precision_m: 0.0985 - val_recall_m: 0.0182 - val_f1_m: 0.0294\n",
      "Epoch 3/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.1046 - acc: 0.9655 - precision_m: 0.3960 - recall_m: 0.0792 - f1_m: 0.1251\n",
      "Epoch 3: val_acc improved from 0.96175 to 0.96211, saving model to models/best_model_2_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1046 - acc: 0.9655 - precision_m: 0.3960 - recall_m: 0.0792 - f1_m: 0.1251 - val_loss: 0.1056 - val_acc: 0.9621 - val_precision_m: 0.0909 - val_recall_m: 0.0185 - val_f1_m: 0.0293\n",
      "Epoch 4/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0953 - acc: 0.9680 - precision_m: 0.6276 - recall_m: 0.1787 - f1_m: 0.2626\n",
      "Epoch 4: val_acc improved from 0.96211 to 0.96949, saving model to models/best_model_2_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0952 - acc: 0.9682 - precision_m: 0.6301 - recall_m: 0.1786 - f1_m: 0.2626 - val_loss: 0.0918 - val_acc: 0.9695 - val_precision_m: 0.6401 - val_recall_m: 0.2172 - val_f1_m: 0.2986\n",
      "Epoch 5/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.0906 - acc: 0.9686 - precision_m: 0.6622 - recall_m: 0.2299 - f1_m: 0.3223\n",
      "Epoch 5: val_acc improved from 0.96949 to 0.97200, saving model to models/best_model_2_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0905 - acc: 0.9687 - precision_m: 0.6627 - recall_m: 0.2314 - f1_m: 0.3237 - val_loss: 0.0892 - val_acc: 0.9720 - val_precision_m: 0.7181 - val_recall_m: 0.3767 - val_f1_m: 0.4726\n",
      "Epoch 6/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0841 - acc: 0.9705 - precision_m: 0.6634 - recall_m: 0.2930 - f1_m: 0.3893\n",
      "Epoch 6: val_acc improved from 0.97200 to 0.97212, saving model to models/best_model_2_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0839 - acc: 0.9704 - precision_m: 0.6643 - recall_m: 0.2932 - f1_m: 0.3897 - val_loss: 0.0858 - val_acc: 0.9721 - val_precision_m: 0.7285 - val_recall_m: 0.4072 - val_f1_m: 0.4874\n",
      "Epoch 7/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0806 - acc: 0.9717 - precision_m: 0.7216 - recall_m: 0.3333 - f1_m: 0.4331\n",
      "Epoch 7: val_acc did not improve from 0.97212\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0807 - acc: 0.9717 - precision_m: 0.7233 - recall_m: 0.3324 - f1_m: 0.4325 - val_loss: 0.0854 - val_acc: 0.9719 - val_precision_m: 0.6903 - val_recall_m: 0.4344 - val_f1_m: 0.5074\n",
      "Epoch 8/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0763 - acc: 0.9728 - precision_m: 0.7460 - recall_m: 0.3864 - f1_m: 0.4814\n",
      "Epoch 8: val_acc did not improve from 0.97212\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0762 - acc: 0.9729 - precision_m: 0.7479 - recall_m: 0.3857 - f1_m: 0.4816 - val_loss: 0.0845 - val_acc: 0.9718 - val_precision_m: 0.6602 - val_recall_m: 0.3150 - val_f1_m: 0.4008\n",
      "Epoch 9/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0733 - acc: 0.9737 - precision_m: 0.7553 - recall_m: 0.3999 - f1_m: 0.4970\n",
      "Epoch 9: val_acc improved from 0.97212 to 0.97283, saving model to models/best_model_2_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0734 - acc: 0.9736 - precision_m: 0.7568 - recall_m: 0.3993 - f1_m: 0.4971 - val_loss: 0.0810 - val_acc: 0.9728 - val_precision_m: 0.6519 - val_recall_m: 0.3780 - val_f1_m: 0.4537\n",
      "Epoch 10/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.0701 - acc: 0.9751 - precision_m: 0.7726 - recall_m: 0.4295 - f1_m: 0.5282\n",
      "Epoch 10: val_acc improved from 0.97283 to 0.97414, saving model to models/best_model_2_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0701 - acc: 0.9751 - precision_m: 0.7726 - recall_m: 0.4295 - f1_m: 0.5282 - val_loss: 0.0833 - val_acc: 0.9741 - val_precision_m: 0.7197 - val_recall_m: 0.3971 - val_f1_m: 0.4826\n",
      "Epoch 11/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 0.9760 - precision_m: 0.7757 - recall_m: 0.4656 - f1_m: 0.5591\n",
      "Epoch 11: val_acc did not improve from 0.97414\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0679 - acc: 0.9761 - precision_m: 0.7749 - recall_m: 0.4654 - f1_m: 0.5587 - val_loss: 0.0849 - val_acc: 0.9740 - val_precision_m: 0.7639 - val_recall_m: 0.3689 - val_f1_m: 0.4597\n",
      "Epoch 12/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0646 - acc: 0.9770 - precision_m: 0.7888 - recall_m: 0.4929 - f1_m: 0.5840\n",
      "Epoch 12: val_acc improved from 0.97414 to 0.97557, saving model to models/best_model_2_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0650 - acc: 0.9768 - precision_m: 0.7864 - recall_m: 0.4918 - f1_m: 0.5826 - val_loss: 0.0751 - val_acc: 0.9756 - val_precision_m: 0.7711 - val_recall_m: 0.5296 - val_f1_m: 0.5893\n",
      "Epoch 13/30\n",
      "275/291 [===========================>..] - ETA: 0s - loss: 0.0652 - acc: 0.9766 - precision_m: 0.7948 - recall_m: 0.4876 - f1_m: 0.5783\n",
      "Epoch 13: val_acc did not improve from 0.97557\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0651 - acc: 0.9767 - precision_m: 0.7926 - recall_m: 0.4879 - f1_m: 0.5777 - val_loss: 0.0794 - val_acc: 0.9743 - val_precision_m: 0.7489 - val_recall_m: 0.4336 - val_f1_m: 0.5120\n",
      "Epoch 14/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.0619 - acc: 0.9776 - precision_m: 0.8049 - recall_m: 0.5000 - f1_m: 0.5973\n",
      "Epoch 14: val_acc did not improve from 0.97557\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0619 - acc: 0.9776 - precision_m: 0.8049 - recall_m: 0.5000 - f1_m: 0.5973 - val_loss: 0.0969 - val_acc: 0.9751 - val_precision_m: 0.7931 - val_recall_m: 0.3731 - val_f1_m: 0.4796\n",
      "Epoch 15/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.0596 - acc: 0.9783 - precision_m: 0.8100 - recall_m: 0.5297 - f1_m: 0.6172\n",
      "Epoch 15: val_acc did not improve from 0.97557\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0595 - acc: 0.9783 - precision_m: 0.8102 - recall_m: 0.5302 - f1_m: 0.6176 - val_loss: 0.0772 - val_acc: 0.9750 - val_precision_m: 0.7127 - val_recall_m: 0.4940 - val_f1_m: 0.5433\n",
      "Epoch 16/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0578 - acc: 0.9787 - precision_m: 0.8017 - recall_m: 0.5431 - f1_m: 0.6295\n",
      "Epoch 16: val_acc improved from 0.97557 to 0.97629, saving model to models/best_model_2_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0580 - acc: 0.9787 - precision_m: 0.8010 - recall_m: 0.5430 - f1_m: 0.6293 - val_loss: 0.0760 - val_acc: 0.9763 - val_precision_m: 0.7527 - val_recall_m: 0.5011 - val_f1_m: 0.5631\n",
      "Epoch 17/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0574 - acc: 0.9790 - precision_m: 0.8186 - recall_m: 0.5529 - f1_m: 0.6385\n",
      "Epoch 17: val_acc did not improve from 0.97629\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0579 - acc: 0.9789 - precision_m: 0.8170 - recall_m: 0.5493 - f1_m: 0.6350 - val_loss: 0.1060 - val_acc: 0.9743 - val_precision_m: 0.7596 - val_recall_m: 0.3666 - val_f1_m: 0.4655\n",
      "Epoch 18/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0558 - acc: 0.9802 - precision_m: 0.8182 - recall_m: 0.5700 - f1_m: 0.6568\n",
      "Epoch 18: val_acc improved from 0.97629 to 0.97700, saving model to models/best_model_2_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0557 - acc: 0.9802 - precision_m: 0.8151 - recall_m: 0.5693 - f1_m: 0.6548 - val_loss: 0.0780 - val_acc: 0.9770 - val_precision_m: 0.7802 - val_recall_m: 0.4951 - val_f1_m: 0.5681\n",
      "Epoch 19/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.0537 - acc: 0.9806 - precision_m: 0.8180 - recall_m: 0.5757 - f1_m: 0.6553\n",
      "Epoch 19: val_acc did not improve from 0.97700\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0537 - acc: 0.9806 - precision_m: 0.8209 - recall_m: 0.5720 - f1_m: 0.6534 - val_loss: 0.0748 - val_acc: 0.9768 - val_precision_m: 0.7885 - val_recall_m: 0.4808 - val_f1_m: 0.5655\n",
      "Epoch 20/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0536 - acc: 0.9809 - precision_m: 0.8332 - recall_m: 0.5853 - f1_m: 0.6697\n",
      "Epoch 20: val_acc improved from 0.97700 to 0.97784, saving model to models/best_model_2_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0534 - acc: 0.9810 - precision_m: 0.8344 - recall_m: 0.5870 - f1_m: 0.6715 - val_loss: 0.0731 - val_acc: 0.9778 - val_precision_m: 0.7291 - val_recall_m: 0.5759 - val_f1_m: 0.6160\n",
      "Epoch 21/30\n",
      "275/291 [===========================>..] - ETA: 0s - loss: 0.0505 - acc: 0.9823 - precision_m: 0.8344 - recall_m: 0.6223 - f1_m: 0.6957\n",
      "Epoch 21: val_acc did not improve from 0.97784\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0504 - acc: 0.9823 - precision_m: 0.8354 - recall_m: 0.6248 - f1_m: 0.6978 - val_loss: 0.0802 - val_acc: 0.9771 - val_precision_m: 0.7752 - val_recall_m: 0.5187 - val_f1_m: 0.5828\n",
      "Epoch 22/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0494 - acc: 0.9826 - precision_m: 0.8485 - recall_m: 0.6380 - f1_m: 0.7068\n",
      "Epoch 22: val_acc did not improve from 0.97784\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0498 - acc: 0.9826 - precision_m: 0.8474 - recall_m: 0.6385 - f1_m: 0.7068 - val_loss: 0.0753 - val_acc: 0.9764 - val_precision_m: 0.7140 - val_recall_m: 0.5702 - val_f1_m: 0.6061\n",
      "Epoch 23/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9823 - precision_m: 0.8508 - recall_m: 0.6141 - f1_m: 0.6948\n",
      "Epoch 23: val_acc did not improve from 0.97784\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0496 - acc: 0.9823 - precision_m: 0.8510 - recall_m: 0.6140 - f1_m: 0.6950 - val_loss: 0.0727 - val_acc: 0.9762 - val_precision_m: 0.7110 - val_recall_m: 0.5797 - val_f1_m: 0.6061\n",
      "Epoch 24/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0493 - acc: 0.9825 - precision_m: 0.8536 - recall_m: 0.6388 - f1_m: 0.7094\n",
      "Epoch 24: val_acc did not improve from 0.97784\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0493 - acc: 0.9825 - precision_m: 0.8510 - recall_m: 0.6392 - f1_m: 0.7086 - val_loss: 0.0841 - val_acc: 0.9774 - val_precision_m: 0.7778 - val_recall_m: 0.5343 - val_f1_m: 0.5976\n",
      "Epoch 25/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0475 - acc: 0.9829 - precision_m: 0.8505 - recall_m: 0.6314 - f1_m: 0.7035\n",
      "Epoch 25: val_acc did not improve from 0.97784\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0475 - acc: 0.9829 - precision_m: 0.8493 - recall_m: 0.6331 - f1_m: 0.7039 - val_loss: 0.0811 - val_acc: 0.9769 - val_precision_m: 0.7338 - val_recall_m: 0.5665 - val_f1_m: 0.6037\n",
      "Epoch 26/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0465 - acc: 0.9836 - precision_m: 0.8612 - recall_m: 0.6509 - f1_m: 0.7207\n",
      "Epoch 26: val_acc improved from 0.97784 to 0.97915, saving model to models/best_model_2_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0466 - acc: 0.9836 - precision_m: 0.8616 - recall_m: 0.6505 - f1_m: 0.7208 - val_loss: 0.0774 - val_acc: 0.9791 - val_precision_m: 0.7900 - val_recall_m: 0.5862 - val_f1_m: 0.6350\n",
      "Epoch 27/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9845 - precision_m: 0.8627 - recall_m: 0.6759 - f1_m: 0.7424\n",
      "Epoch 27: val_acc did not improve from 0.97915\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0436 - acc: 0.9844 - precision_m: 0.8642 - recall_m: 0.6737 - f1_m: 0.7417 - val_loss: 0.0788 - val_acc: 0.9778 - val_precision_m: 0.7582 - val_recall_m: 0.5415 - val_f1_m: 0.5958\n",
      "Epoch 28/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9843 - precision_m: 0.8583 - recall_m: 0.6737 - f1_m: 0.7365\n",
      "Epoch 28: val_acc did not improve from 0.97915\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0438 - acc: 0.9842 - precision_m: 0.8568 - recall_m: 0.6745 - f1_m: 0.7362 - val_loss: 0.0795 - val_acc: 0.9756 - val_precision_m: 0.6523 - val_recall_m: 0.6390 - val_f1_m: 0.6046\n",
      "Epoch 29/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.0420 - acc: 0.9846 - precision_m: 0.8618 - recall_m: 0.6762 - f1_m: 0.7405\n",
      "Epoch 29: val_acc did not improve from 0.97915\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0423 - acc: 0.9845 - precision_m: 0.8613 - recall_m: 0.6771 - f1_m: 0.7407 - val_loss: 0.1022 - val_acc: 0.9771 - val_precision_m: 0.8376 - val_recall_m: 0.4899 - val_f1_m: 0.5810\n",
      "Epoch 30/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0416 - acc: 0.9849 - precision_m: 0.8642 - recall_m: 0.6941 - f1_m: 0.7541\n",
      "Epoch 30: val_acc did not improve from 0.97915\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0415 - acc: 0.9850 - precision_m: 0.8629 - recall_m: 0.6962 - f1_m: 0.7545 - val_loss: 0.0969 - val_acc: 0.9776 - val_precision_m: 0.8471 - val_recall_m: 0.4707 - val_f1_m: 0.5705\n",
      "Score for fold 9: loss of 0.07737261801958084; acc of 97.91467785835266%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.05633339285850525; acc of 98.11586141586304%\n",
      "Test Precision: precision_m of 29.61360812187195%\n",
      "Test Recall: recall_m of 24.621711671352386%\n",
      "Test F1: f1_m of 26.042115688323975%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1907 - acc: 0.9542 - precision_m: 0.0030 - recall_m: 0.0111 - f1_m: 0.0029\n",
      "Epoch 1: val_acc improved from -inf to 0.96034, saving model to models/best_model_2_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 2s 5ms/step - loss: 0.1907 - acc: 0.9542 - precision_m: 0.0030 - recall_m: 0.0111 - f1_m: 0.0029 - val_loss: 0.1376 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.1195 - acc: 0.9644 - precision_m: 0.0851 - recall_m: 0.0143 - f1_m: 0.0239    \n",
      "Epoch 2: val_acc improved from 0.96034 to 0.96190, saving model to models/best_model_2_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1195 - acc: 0.9645 - precision_m: 0.1050 - recall_m: 0.0180 - f1_m: 0.0300 - val_loss: 0.1096 - val_acc: 0.9619 - val_precision_m: 0.3434 - val_recall_m: 0.0707 - val_f1_m: 0.1151\n",
      "Epoch 3/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.1052 - acc: 0.9650 - precision_m: 0.3018 - recall_m: 0.0587 - f1_m: 0.0945\n",
      "Epoch 3: val_acc did not improve from 0.96190\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1051 - acc: 0.9651 - precision_m: 0.3031 - recall_m: 0.0591 - f1_m: 0.0951 - val_loss: 0.1012 - val_acc: 0.9617 - val_precision_m: 0.3860 - val_recall_m: 0.0733 - val_f1_m: 0.1178\n",
      "Epoch 4/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0961 - acc: 0.9661 - precision_m: 0.5189 - recall_m: 0.1252 - f1_m: 0.1902\n",
      "Epoch 4: val_acc improved from 0.96190 to 0.96346, saving model to models/best_model_2_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0963 - acc: 0.9661 - precision_m: 0.5190 - recall_m: 0.1272 - f1_m: 0.1925 - val_loss: 0.1013 - val_acc: 0.9635 - val_precision_m: 0.4654 - val_recall_m: 0.0894 - val_f1_m: 0.1452\n",
      "Epoch 5/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0911 - acc: 0.9680 - precision_m: 0.6171 - recall_m: 0.2040 - f1_m: 0.2909\n",
      "Epoch 5: val_acc improved from 0.96346 to 0.96514, saving model to models/best_model_2_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0913 - acc: 0.9679 - precision_m: 0.6166 - recall_m: 0.2061 - f1_m: 0.2923 - val_loss: 0.0955 - val_acc: 0.9651 - val_precision_m: 0.6318 - val_recall_m: 0.2741 - val_f1_m: 0.3508\n",
      "Epoch 6/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0876 - acc: 0.9691 - precision_m: 0.6176 - recall_m: 0.2354 - f1_m: 0.3255\n",
      "Epoch 6: val_acc improved from 0.96514 to 0.96743, saving model to models/best_model_2_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0873 - acc: 0.9692 - precision_m: 0.6170 - recall_m: 0.2386 - f1_m: 0.3280 - val_loss: 0.0931 - val_acc: 0.9674 - val_precision_m: 0.7135 - val_recall_m: 0.2421 - val_f1_m: 0.3354\n",
      "Epoch 7/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.0841 - acc: 0.9708 - precision_m: 0.7210 - recall_m: 0.3079 - f1_m: 0.4049\n",
      "Epoch 7: val_acc improved from 0.96743 to 0.96767, saving model to models/best_model_2_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0841 - acc: 0.9706 - precision_m: 0.7184 - recall_m: 0.3066 - f1_m: 0.4038 - val_loss: 0.0900 - val_acc: 0.9677 - val_precision_m: 0.7000 - val_recall_m: 0.2616 - val_f1_m: 0.3551\n",
      "Epoch 8/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0786 - acc: 0.9722 - precision_m: 0.7142 - recall_m: 0.3492 - f1_m: 0.4433\n",
      "Epoch 8: val_acc improved from 0.96767 to 0.96959, saving model to models/best_model_2_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0786 - acc: 0.9722 - precision_m: 0.7130 - recall_m: 0.3505 - f1_m: 0.4443 - val_loss: 0.0848 - val_acc: 0.9696 - val_precision_m: 0.7179 - val_recall_m: 0.4456 - val_f1_m: 0.5171\n",
      "Epoch 9/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0782 - acc: 0.9723 - precision_m: 0.7252 - recall_m: 0.3851 - f1_m: 0.4760\n",
      "Epoch 9: val_acc did not improve from 0.96959\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0781 - acc: 0.9724 - precision_m: 0.7245 - recall_m: 0.3823 - f1_m: 0.4740 - val_loss: 0.0861 - val_acc: 0.9695 - val_precision_m: 0.7274 - val_recall_m: 0.3558 - val_f1_m: 0.4487\n",
      "Epoch 10/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0748 - acc: 0.9736 - precision_m: 0.7441 - recall_m: 0.4058 - f1_m: 0.4996\n",
      "Epoch 10: val_acc improved from 0.96959 to 0.97115, saving model to models/best_model_2_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0747 - acc: 0.9737 - precision_m: 0.7440 - recall_m: 0.4043 - f1_m: 0.4980 - val_loss: 0.0805 - val_acc: 0.9712 - val_precision_m: 0.7380 - val_recall_m: 0.4720 - val_f1_m: 0.5437\n",
      "Epoch 11/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0720 - acc: 0.9746 - precision_m: 0.7598 - recall_m: 0.4283 - f1_m: 0.5298\n",
      "Epoch 11: val_acc did not improve from 0.97115\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0720 - acc: 0.9746 - precision_m: 0.7613 - recall_m: 0.4295 - f1_m: 0.5311 - val_loss: 0.0813 - val_acc: 0.9704 - val_precision_m: 0.7553 - val_recall_m: 0.4595 - val_f1_m: 0.5346\n",
      "Epoch 12/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0709 - acc: 0.9745 - precision_m: 0.7589 - recall_m: 0.4344 - f1_m: 0.5294\n",
      "Epoch 12: val_acc improved from 0.97115 to 0.97284, saving model to models/best_model_2_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0710 - acc: 0.9746 - precision_m: 0.7611 - recall_m: 0.4353 - f1_m: 0.5307 - val_loss: 0.0789 - val_acc: 0.9728 - val_precision_m: 0.7568 - val_recall_m: 0.5403 - val_f1_m: 0.6050\n",
      "Epoch 13/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0678 - acc: 0.9763 - precision_m: 0.7791 - recall_m: 0.4851 - f1_m: 0.5722\n",
      "Epoch 13: val_acc did not improve from 0.97284\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0681 - acc: 0.9762 - precision_m: 0.7767 - recall_m: 0.4830 - f1_m: 0.5701 - val_loss: 0.0808 - val_acc: 0.9716 - val_precision_m: 0.7699 - val_recall_m: 0.4624 - val_f1_m: 0.5452\n",
      "Epoch 14/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0666 - acc: 0.9764 - precision_m: 0.7814 - recall_m: 0.4849 - f1_m: 0.5771\n",
      "Epoch 14: val_acc improved from 0.97284 to 0.97296, saving model to models/best_model_2_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0665 - acc: 0.9764 - precision_m: 0.7814 - recall_m: 0.4862 - f1_m: 0.5784 - val_loss: 0.0861 - val_acc: 0.9730 - val_precision_m: 0.8264 - val_recall_m: 0.4003 - val_f1_m: 0.5138\n",
      "Epoch 15/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.0643 - acc: 0.9772 - precision_m: 0.7829 - recall_m: 0.5168 - f1_m: 0.5994\n",
      "Epoch 15: val_acc improved from 0.97296 to 0.97440, saving model to models/best_model_2_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0642 - acc: 0.9772 - precision_m: 0.7835 - recall_m: 0.5179 - f1_m: 0.6002 - val_loss: 0.0801 - val_acc: 0.9744 - val_precision_m: 0.7535 - val_recall_m: 0.5550 - val_f1_m: 0.6124\n",
      "Epoch 16/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0625 - acc: 0.9779 - precision_m: 0.7871 - recall_m: 0.5188 - f1_m: 0.6008\n",
      "Epoch 16: val_acc improved from 0.97440 to 0.97464, saving model to models/best_model_2_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0627 - acc: 0.9778 - precision_m: 0.7868 - recall_m: 0.5190 - f1_m: 0.6012 - val_loss: 0.0764 - val_acc: 0.9746 - val_precision_m: 0.7711 - val_recall_m: 0.5302 - val_f1_m: 0.5931\n",
      "Epoch 17/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0612 - acc: 0.9785 - precision_m: 0.8007 - recall_m: 0.5356 - f1_m: 0.6197\n",
      "Epoch 17: val_acc improved from 0.97464 to 0.97500, saving model to models/best_model_2_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0607 - acc: 0.9787 - precision_m: 0.8019 - recall_m: 0.5380 - f1_m: 0.6219 - val_loss: 0.0752 - val_acc: 0.9750 - val_precision_m: 0.7853 - val_recall_m: 0.5682 - val_f1_m: 0.6315\n",
      "Epoch 18/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.0591 - acc: 0.9790 - precision_m: 0.8043 - recall_m: 0.5490 - f1_m: 0.6315\n",
      "Epoch 18: val_acc did not improve from 0.97500\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0598 - acc: 0.9786 - precision_m: 0.7997 - recall_m: 0.5459 - f1_m: 0.6273 - val_loss: 0.0725 - val_acc: 0.9744 - val_precision_m: 0.7180 - val_recall_m: 0.6429 - val_f1_m: 0.6506\n",
      "Epoch 19/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0582 - acc: 0.9793 - precision_m: 0.8150 - recall_m: 0.5580 - f1_m: 0.6447\n",
      "Epoch 19: val_acc improved from 0.97500 to 0.97632, saving model to models/best_model_2_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0581 - acc: 0.9795 - precision_m: 0.8163 - recall_m: 0.5611 - f1_m: 0.6476 - val_loss: 0.0742 - val_acc: 0.9763 - val_precision_m: 0.7449 - val_recall_m: 0.6684 - val_f1_m: 0.6809\n",
      "Epoch 20/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0573 - acc: 0.9800 - precision_m: 0.8235 - recall_m: 0.5768 - f1_m: 0.6574\n",
      "Epoch 20: val_acc did not improve from 0.97632\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0575 - acc: 0.9799 - precision_m: 0.8203 - recall_m: 0.5766 - f1_m: 0.6559 - val_loss: 0.0804 - val_acc: 0.9761 - val_precision_m: 0.8790 - val_recall_m: 0.5121 - val_f1_m: 0.6096\n",
      "Epoch 21/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0544 - acc: 0.9807 - precision_m: 0.8276 - recall_m: 0.5880 - f1_m: 0.6673\n",
      "Epoch 21: val_acc did not improve from 0.97632\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0543 - acc: 0.9807 - precision_m: 0.8287 - recall_m: 0.5901 - f1_m: 0.6694 - val_loss: 0.0856 - val_acc: 0.9750 - val_precision_m: 0.8656 - val_recall_m: 0.4595 - val_f1_m: 0.5674\n",
      "Epoch 22/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0531 - acc: 0.9810 - precision_m: 0.8278 - recall_m: 0.5922 - f1_m: 0.6741\n",
      "Epoch 22: val_acc did not improve from 0.97632\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0526 - acc: 0.9811 - precision_m: 0.8272 - recall_m: 0.5929 - f1_m: 0.6746 - val_loss: 0.0811 - val_acc: 0.9755 - val_precision_m: 0.8161 - val_recall_m: 0.5063 - val_f1_m: 0.5884\n",
      "Epoch 23/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0532 - acc: 0.9810 - precision_m: 0.8214 - recall_m: 0.6047 - f1_m: 0.6745\n",
      "Epoch 23: val_acc improved from 0.97632 to 0.97716, saving model to models/best_model_2_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0533 - acc: 0.9810 - precision_m: 0.8197 - recall_m: 0.6035 - f1_m: 0.6732 - val_loss: 0.0744 - val_acc: 0.9772 - val_precision_m: 0.7701 - val_recall_m: 0.6557 - val_f1_m: 0.6833\n",
      "Epoch 24/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9813 - precision_m: 0.8232 - recall_m: 0.6135 - f1_m: 0.6843\n",
      "Epoch 24: val_acc did not improve from 0.97716\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0515 - acc: 0.9814 - precision_m: 0.8237 - recall_m: 0.6140 - f1_m: 0.6849 - val_loss: 0.0810 - val_acc: 0.9762 - val_precision_m: 0.7832 - val_recall_m: 0.5228 - val_f1_m: 0.5971\n",
      "Epoch 25/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0488 - acc: 0.9827 - precision_m: 0.8555 - recall_m: 0.6242 - f1_m: 0.7028\n",
      "Epoch 25: val_acc did not improve from 0.97716\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0488 - acc: 0.9827 - precision_m: 0.8554 - recall_m: 0.6251 - f1_m: 0.7031 - val_loss: 0.0959 - val_acc: 0.9761 - val_precision_m: 0.8940 - val_recall_m: 0.4897 - val_f1_m: 0.5898\n",
      "Epoch 26/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9820 - precision_m: 0.8548 - recall_m: 0.6184 - f1_m: 0.6965\n",
      "Epoch 26: val_acc improved from 0.97716 to 0.97837, saving model to models/best_model_2_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0505 - acc: 0.9819 - precision_m: 0.8526 - recall_m: 0.6185 - f1_m: 0.6960 - val_loss: 0.0727 - val_acc: 0.9784 - val_precision_m: 0.7916 - val_recall_m: 0.6467 - val_f1_m: 0.6760\n",
      "Epoch 27/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9830 - precision_m: 0.8602 - recall_m: 0.6269 - f1_m: 0.7075\n",
      "Epoch 27: val_acc did not improve from 0.97837\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0484 - acc: 0.9828 - precision_m: 0.8580 - recall_m: 0.6271 - f1_m: 0.7071 - val_loss: 0.0741 - val_acc: 0.9773 - val_precision_m: 0.7579 - val_recall_m: 0.6875 - val_f1_m: 0.6934\n",
      "Epoch 28/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.0477 - acc: 0.9828 - precision_m: 0.8523 - recall_m: 0.6424 - f1_m: 0.7128\n",
      "Epoch 28: val_acc did not improve from 0.97837\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0479 - acc: 0.9827 - precision_m: 0.8523 - recall_m: 0.6386 - f1_m: 0.7103 - val_loss: 0.0734 - val_acc: 0.9770 - val_precision_m: 0.7593 - val_recall_m: 0.6491 - val_f1_m: 0.6708\n",
      "Epoch 29/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0471 - acc: 0.9829 - precision_m: 0.8491 - recall_m: 0.6345 - f1_m: 0.7063\n",
      "Epoch 29: val_acc did not improve from 0.97837\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0472 - acc: 0.9829 - precision_m: 0.8490 - recall_m: 0.6326 - f1_m: 0.7048 - val_loss: 0.0845 - val_acc: 0.9764 - val_precision_m: 0.8792 - val_recall_m: 0.5058 - val_f1_m: 0.5992\n",
      "Epoch 30/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0462 - acc: 0.9834 - precision_m: 0.8559 - recall_m: 0.6506 - f1_m: 0.7222\n",
      "Epoch 30: val_acc did not improve from 0.97837\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0462 - acc: 0.9834 - precision_m: 0.8570 - recall_m: 0.6530 - f1_m: 0.7244 - val_loss: 0.0830 - val_acc: 0.9768 - val_precision_m: 0.7995 - val_recall_m: 0.5709 - val_f1_m: 0.6307\n",
      "Score for fold 10: loss of 0.07266984134912491; acc of 97.83653616905212%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.06279979646205902; acc of 97.73800373077393%\n",
      "Test Precision: precision_m of 31.894737482070923%\n",
      "Test Recall: recall_m of 28.295600414276123%\n",
      "Test F1: f1_m of 28.6865234375%\n",
      "------------------------------------------------------------------------\n",
      "Validation score per fold\n",
      "> Fold 1 - Loss: 0.0822378620505333 - Accuracy: 97.8621780872345%\n",
      "> Fold 2 - Loss: 0.07468299567699432 - Accuracy: 97.98826575279236%\n",
      "> Fold 3 - Loss: 0.06490476429462433 - Accuracy: 97.92764782905579%\n",
      "> Fold 4 - Loss: 0.08796519041061401 - Accuracy: 97.93432950973511%\n",
      "> Fold 5 - Loss: 0.0683632344007492 - Accuracy: 98.13553094863892%\n",
      "> Fold 6 - Loss: 0.07662399858236313 - Accuracy: 97.96311855316162%\n",
      "> Fold 7 - Loss: 0.071187824010849 - Accuracy: 98.04062247276306%\n",
      "> Fold 8 - Loss: 0.07254233211278915 - Accuracy: 97.99951910972595%\n",
      "> Fold 9 - Loss: 0.07737261801958084 - Accuracy: 97.91467785835266%\n",
      "> Fold 10 - Loss: 0.07266984134912491 - Accuracy: 97.83653616905212%\n",
      "------------------------------------------------------------------------\n",
      "Testing score per fold\n",
      "> Fold 1 - Accuracy: 98.45916628837585 - Precision: 24.853287637233734 - Recall: 19.732002913951874 - F1: 21.165457367897034%\n",
      "> Fold 2 - Accuracy: 97.84404039382935 - Precision: 30.71591556072235 - Recall: 22.560203075408936 - F1: 24.90968108177185%\n",
      "> Fold 3 - Accuracy: 97.84579277038574 - Precision: 26.643988490104675 - Recall: 20.972225069999695 - F1: 22.23331928253174%\n",
      "> Fold 4 - Accuracy: 97.57654666900635 - Precision: 30.294117331504822 - Recall: 22.18320071697235 - F1: 24.4797945022583%\n",
      "> Fold 5 - Accuracy: 97.84326553344727 - Precision: 31.348121166229248 - Recall: 26.19428038597107 - F1: 27.2617369890213%\n",
      "> Fold 6 - Accuracy: 97.79083728790283 - Precision: 26.860085129737854 - Recall: 23.24969470500946 - F1: 23.789387941360474%\n",
      "> Fold 7 - Accuracy: 98.14308881759644 - Precision: 21.416957676410675 - Recall: 16.747552156448364 - F1: 18.011321127414703%\n",
      "> Fold 8 - Accuracy: 97.93118834495544 - Precision: 26.37220323085785 - Recall: 22.433598339557648 - F1: 23.113684356212616%\n",
      "> Fold 9 - Accuracy: 98.11586141586304 - Precision: 29.61360812187195 - Recall: 24.621711671352386 - F1: 26.042115688323975%\n",
      "> Fold 10 - Accuracy: 97.73800373077393 - Precision: 31.894737482070923 - Recall: 28.295600414276123 - F1: 28.6865234375%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Validation Accuracy: 97.96024262905121 (+- 0.08261544908332114)\n",
      "> Validation Loss: 0.07485506609082222\n",
      "> Testing Accuracy: 97.92877912521362 (+- 0.2373005777030514)\n",
      "> Testing Precision: 28.001302182674408\n",
      "> Testing Recall: 22.69900694489479\n",
      "> Testing F1: 23.9693021774292\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Lists to hold cross-validation results\n",
    "acc_2_per_fold = []\n",
    "loss_2_per_fold = []\n",
    "precision_2_per_fold = []\n",
    "recall_2_per_fold = []\n",
    "f1_2_per_fold = []\n",
    "\n",
    "testing_acc_2_per_fold = []\n",
    "testing_precision_2_per_fold = []\n",
    "testing_recall_2_per_fold = []\n",
    "testing_f1_2_per_fold = []\n",
    "\n",
    "\n",
    "# Load data from .npz files\n",
    "for fold_no in range(1, 11):\n",
    "    with np.load(f'fold_{fold_no}.npz') as data:\n",
    "        x_train = data['x_train_fold.npy']\n",
    "        y_train = data['y_train_fold.npy']\n",
    "        x_val = data['x_val_fold.npy']\n",
    "        y_val = data['y_val_fold.npy']\n",
    "        x_test = data['x_test_fold.npy']\n",
    "        y_test = data['y_test_fold.npy']\n",
    "        \n",
    "        # Converting ground truth arrays to one wake word (1) and 'other' (0)\n",
    "        wake_word_index = all_targets.index(wake_word)\n",
    "        y_train = np.equal(y_train, wake_word_index).astype('float64')\n",
    "        y_val = np.equal(y_val, wake_word_index).astype('float64')\n",
    "        y_test = np.equal(y_test, wake_word_index).astype('float64')\n",
    "        \n",
    "        # CNN for TF expects (batch, height, width, channels)\n",
    "        x_train = x_train.reshape(x_train.shape[0], \n",
    "                          x_train.shape[1], \n",
    "                          x_train.shape[2], \n",
    "                          1)\n",
    "        x_val = x_val.reshape(x_val.shape[0], \n",
    "                          x_val.shape[1], \n",
    "                          x_val.shape[2], \n",
    "                          1)\n",
    "        x_test = x_test.reshape(x_test.shape[0], \n",
    "                          x_test.shape[1], \n",
    "                          x_test.shape[2], \n",
    "                          1)\n",
    "        sample_shape = x_test.shape[1:]\n",
    "\n",
    "    # CNN model\n",
    "    model_2 = models.Sequential()\n",
    "    model_2.add(layers.Conv2D(16,\n",
    "                              (3,3),\n",
    "                              activation=\"relu\",\n",
    "                              input_shape=sample_shape))\n",
    "    model_2.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model_2.add(layers.Conv2D(32,\n",
    "                              (3,3),\n",
    "                              activation=\"relu\",\n",
    "                              ))\n",
    "    model_2.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model_2.add(layers.Flatten())\n",
    "    model_2.add(layers.Dense(32, activation='relu'))\n",
    "    model_2.add(layers.Dropout(0.5))\n",
    "    model_2.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "\n",
    "    model_2.compile(loss='binary_crossentropy', \n",
    "              optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "              metrics=['acc', precision_m, recall_m, f1_m])\n",
    "\n",
    "    checkpoint_filepath = f'models/best_model_2_fold_{fold_no}.h5'\n",
    "    model_checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=False,\n",
    "        monitor='val_acc',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "        save_freq='epoch'\n",
    "    )\n",
    "\n",
    "    # Instantiate the custom callback\n",
    "    metrics_history = MetricsHistory()\n",
    "\n",
    "    # Print fold number\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Train\n",
    "    history_2 = model_2.fit(x_train, \n",
    "                    y_train, \n",
    "                    epochs=30, \n",
    "                    batch_size=256, \n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[model_checkpoint_callback, metrics_history])\n",
    "\n",
    "    model_2.load_weights(checkpoint_filepath)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    scores = model_2.evaluate(x_val, y_val, verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model_2.metrics_names[0]} of {scores[0]}; {model_2.metrics_names[1]} of {scores[1] * 100}%')\n",
    "    acc_2_per_fold.append(scores[1] * 100)\n",
    "    loss_2_per_fold.append(scores[0])\n",
    "    precision_2_per_fold.append(metrics_history.best_metrics['precision_m'] * 100)\n",
    "    recall_2_per_fold.append(metrics_history.best_metrics['recall_m'] * 100)\n",
    "    f1_2_per_fold.append(metrics_history.best_metrics['f1_m'] * 100)\n",
    "\n",
    "    # Final evaluation on test set\n",
    "    final_scores = model_2.evaluate(x_test, y_test, verbose=0)\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Final test score: {model_2.metrics_names[0]} of {final_scores[0]}; {model_2.metrics_names[1]} of {final_scores[1] * 100}%')\n",
    "    print(f'Test Precision: {model_2.metrics_names[2]} of {final_scores[2] * 100}%')\n",
    "    print(f'Test Recall: {model_2.metrics_names[3]} of {final_scores[3] * 100}%')\n",
    "    print(f'Test F1: {model_2.metrics_names[4]} of {final_scores[4] * 100}%')\n",
    "\n",
    "    # Append test metrics to lists\n",
    "    testing_acc_2_per_fold.append(final_scores[1] * 100)\n",
    "    testing_precision_2_per_fold.append(final_scores[2] * 100)\n",
    "    testing_recall_2_per_fold.append(final_scores[3] * 100)\n",
    "    testing_f1_2_per_fold.append(final_scores[4] * 100)\n",
    "\n",
    "# Print the results\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Validation score per fold')\n",
    "for i in range(0, len(acc_2_per_fold)):\n",
    "    print(f'> Fold {i+1} - Loss: {loss_2_per_fold[i]} - Accuracy: {acc_2_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Testing score per fold')\n",
    "for i in range(0, len(testing_acc_2_per_fold)):\n",
    "    print(f'> Fold {i+1} - Accuracy: {testing_acc_2_per_fold[i]} - Precision: {testing_precision_2_per_fold[i]} - Recall: {testing_recall_2_per_fold[i]} - F1: {testing_f1_2_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Validation Accuracy: {np.mean(acc_2_per_fold)} (+- {np.std(acc_2_per_fold)})')\n",
    "print(f'> Validation Loss: {np.mean(loss_2_per_fold)}')\n",
    "print(f'> Testing Accuracy: {np.mean(testing_acc_2_per_fold)} (+- {np.std(testing_acc_2_per_fold)})')\n",
    "print(f'> Testing Precision: {np.mean(testing_precision_2_per_fold)}')\n",
    "print(f'> Testing Recall: {np.mean(testing_recall_2_per_fold)}')\n",
    "print(f'> Testing F1: {np.mean(testing_f1_2_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.2196 - acc: 0.9551 - precision_m: 0.0086 - recall_m: 0.0067 - f1_m: 0.0045\n",
      "Epoch 1: val_acc improved from -inf to 0.96023, saving model to models/best_model_3_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 2s 3ms/step - loss: 0.2195 - acc: 0.9551 - precision_m: 0.0085 - recall_m: 0.0066 - f1_m: 0.0045 - val_loss: 0.1741 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.1762 - acc: 0.9627 - precision_m: 0.0144 - recall_m: 0.0017 - f1_m: 0.0031       \n",
      "Epoch 2: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1760 - acc: 0.9627 - precision_m: 0.0137 - recall_m: 0.0016 - f1_m: 0.0029 - val_loss: 0.1650 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 3/30\n",
      "274/292 [===========================>..] - ETA: 0s - loss: 0.1637 - acc: 0.9630 - precision_m: 0.0164 - recall_m: 0.0021 - f1_m: 0.0037\n",
      "Epoch 3: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1640 - acc: 0.9628 - precision_m: 0.0188 - recall_m: 0.0025 - f1_m: 0.0043 - val_loss: 0.1610 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 4/30\n",
      "275/292 [===========================>..] - ETA: 0s - loss: 0.1562 - acc: 0.9630 - precision_m: 0.0073 - recall_m: 7.2727e-04 - f1_m: 0.0013 \n",
      "Epoch 4: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1570 - acc: 0.9627 - precision_m: 0.0068 - recall_m: 6.8493e-04 - f1_m: 0.0012 - val_loss: 0.1573 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 5/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.1516 - acc: 0.9626 - precision_m: 0.0326 - recall_m: 0.0037 - f1_m: 0.0067\n",
      "Epoch 5: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1515 - acc: 0.9627 - precision_m: 0.0325 - recall_m: 0.0037 - f1_m: 0.0066 - val_loss: 0.1572 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 6/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.1472 - acc: 0.9628 - precision_m: 0.0430 - recall_m: 0.0050 - f1_m: 0.0089\n",
      "Epoch 6: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1471 - acc: 0.9628 - precision_m: 0.0428 - recall_m: 0.0050 - f1_m: 0.0088 - val_loss: 0.1505 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 7/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.1447 - acc: 0.9628 - precision_m: 0.0584 - recall_m: 0.0077 - f1_m: 0.0133\n",
      "Epoch 7: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1447 - acc: 0.9628 - precision_m: 0.0582 - recall_m: 0.0076 - f1_m: 0.0132 - val_loss: 0.1470 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 8/30\n",
      "275/292 [===========================>..] - ETA: 0s - loss: 0.1422 - acc: 0.9626 - precision_m: 0.0315 - recall_m: 0.0036 - f1_m: 0.0061\n",
      "Epoch 8: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1416 - acc: 0.9627 - precision_m: 0.0297 - recall_m: 0.0034 - f1_m: 0.0057 - val_loss: 0.1458 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 9/30\n",
      "274/292 [===========================>..] - ETA: 0s - loss: 0.1412 - acc: 0.9628 - precision_m: 0.0274 - recall_m: 0.0034 - f1_m: 0.0060\n",
      "Epoch 9: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1409 - acc: 0.9627 - precision_m: 0.0257 - recall_m: 0.0032 - f1_m: 0.0056 - val_loss: 0.1442 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 10/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1382 - acc: 0.9628 - precision_m: 0.0479 - recall_m: 0.0054 - f1_m: 0.0096\n",
      "Epoch 10: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1382 - acc: 0.9628 - precision_m: 0.0479 - recall_m: 0.0054 - f1_m: 0.0096 - val_loss: 0.1446 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 11/30\n",
      "273/292 [===========================>..] - ETA: 0s - loss: 0.1368 - acc: 0.9628 - precision_m: 0.0458 - recall_m: 0.0058 - f1_m: 0.0101  \n",
      "Epoch 11: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1369 - acc: 0.9628 - precision_m: 0.0474 - recall_m: 0.0064 - f1_m: 0.0110 - val_loss: 0.1425 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 12/30\n",
      "274/292 [===========================>..] - ETA: 0s - loss: 0.1367 - acc: 0.9625 - precision_m: 0.0420 - recall_m: 0.0048 - f1_m: 0.0084 \n",
      "Epoch 12: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1364 - acc: 0.9627 - precision_m: 0.0394 - recall_m: 0.0045 - f1_m: 0.0079 - val_loss: 0.1440 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 13/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.1349 - acc: 0.9626 - precision_m: 0.0472 - recall_m: 0.0050 - f1_m: 0.0088\n",
      "Epoch 13: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1347 - acc: 0.9628 - precision_m: 0.0462 - recall_m: 0.0049 - f1_m: 0.0087 - val_loss: 0.1456 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 14/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.1345 - acc: 0.9628 - precision_m: 0.0693 - recall_m: 0.0091 - f1_m: 0.0157\n",
      "Epoch 14: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1345 - acc: 0.9628 - precision_m: 0.0691 - recall_m: 0.0091 - f1_m: 0.0157 - val_loss: 0.1417 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 15/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.1339 - acc: 0.9628 - precision_m: 0.0876 - recall_m: 0.0102 - f1_m: 0.0179\n",
      "Epoch 15: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1338 - acc: 0.9628 - precision_m: 0.0873 - recall_m: 0.0101 - f1_m: 0.0179 - val_loss: 0.1416 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 16/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1333 - acc: 0.9629 - precision_m: 0.0779 - recall_m: 0.0086 - f1_m: 0.0154\n",
      "Epoch 16: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1335 - acc: 0.9628 - precision_m: 0.0771 - recall_m: 0.0085 - f1_m: 0.0152 - val_loss: 0.1422 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 17/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.1329 - acc: 0.9627 - precision_m: 0.0941 - recall_m: 0.0126 - f1_m: 0.0219\n",
      "Epoch 17: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1328 - acc: 0.9628 - precision_m: 0.0925 - recall_m: 0.0124 - f1_m: 0.0215 - val_loss: 0.1414 - val_acc: 0.9601 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 18/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.1319 - acc: 0.9627 - precision_m: 0.0665 - recall_m: 0.0082 - f1_m: 0.0141\n",
      "Epoch 18: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1320 - acc: 0.9627 - precision_m: 0.0642 - recall_m: 0.0079 - f1_m: 0.0136 - val_loss: 0.1404 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 19/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.1311 - acc: 0.9627 - precision_m: 0.0645 - recall_m: 0.0080 - f1_m: 0.0135\n",
      "Epoch 19: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1310 - acc: 0.9627 - precision_m: 0.0634 - recall_m: 0.0078 - f1_m: 0.0133 - val_loss: 0.1404 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 20/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1301 - acc: 0.9627 - precision_m: 0.1090 - recall_m: 0.0127 - f1_m: 0.0225\n",
      "Epoch 20: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1301 - acc: 0.9627 - precision_m: 0.1090 - recall_m: 0.0127 - f1_m: 0.0225 - val_loss: 0.1377 - val_acc: 0.9601 - val_precision_m: 0.0303 - val_recall_m: 0.0023 - val_f1_m: 0.0043\n",
      "Epoch 21/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.1311 - acc: 0.9625 - precision_m: 0.0699 - recall_m: 0.0075 - f1_m: 0.0133\n",
      "Epoch 21: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1306 - acc: 0.9627 - precision_m: 0.0685 - recall_m: 0.0074 - f1_m: 0.0131 - val_loss: 0.1397 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 22/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.1300 - acc: 0.9627 - precision_m: 0.0684 - recall_m: 0.0089 - f1_m: 0.0153\n",
      "Epoch 22: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1301 - acc: 0.9626 - precision_m: 0.0675 - recall_m: 0.0088 - f1_m: 0.0150 - val_loss: 0.1398 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 23/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.1295 - acc: 0.9629 - precision_m: 0.0760 - recall_m: 0.0099 - f1_m: 0.0172\n",
      "Epoch 23: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1295 - acc: 0.9629 - precision_m: 0.0759 - recall_m: 0.0103 - f1_m: 0.0177 - val_loss: 0.1414 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 24/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.1298 - acc: 0.9628 - precision_m: 0.0876 - recall_m: 0.0107 - f1_m: 0.0188\n",
      "Epoch 24: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1298 - acc: 0.9628 - precision_m: 0.0873 - recall_m: 0.0107 - f1_m: 0.0187 - val_loss: 0.1400 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 25/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.1290 - acc: 0.9626 - precision_m: 0.0798 - recall_m: 0.0113 - f1_m: 0.0189\n",
      "Epoch 25: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1288 - acc: 0.9628 - precision_m: 0.0776 - recall_m: 0.0110 - f1_m: 0.0184 - val_loss: 0.1450 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 26/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1299 - acc: 0.9628 - precision_m: 0.1055 - recall_m: 0.0132 - f1_m: 0.0229\n",
      "Epoch 26: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1296 - acc: 0.9629 - precision_m: 0.1045 - recall_m: 0.0130 - f1_m: 0.0227 - val_loss: 0.1369 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 27/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.1287 - acc: 0.9627 - precision_m: 0.1127 - recall_m: 0.0148 - f1_m: 0.0256\n",
      "Epoch 27: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1282 - acc: 0.9629 - precision_m: 0.1130 - recall_m: 0.0149 - f1_m: 0.0259 - val_loss: 0.1421 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 28/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.1279 - acc: 0.9629 - precision_m: 0.1088 - recall_m: 0.0134 - f1_m: 0.0234\n",
      "Epoch 28: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1278 - acc: 0.9629 - precision_m: 0.1107 - recall_m: 0.0135 - f1_m: 0.0237 - val_loss: 0.1380 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 29/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.1276 - acc: 0.9629 - precision_m: 0.1385 - recall_m: 0.0169 - f1_m: 0.0296\n",
      "Epoch 29: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1277 - acc: 0.9629 - precision_m: 0.1416 - recall_m: 0.0172 - f1_m: 0.0301 - val_loss: 0.1386 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 30/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.1269 - acc: 0.9629 - precision_m: 0.1200 - recall_m: 0.0161 - f1_m: 0.0277\n",
      "Epoch 30: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1269 - acc: 0.9630 - precision_m: 0.1235 - recall_m: 0.0169 - f1_m: 0.0289 - val_loss: 0.1379 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Score for fold 1: loss of 0.1741141378879547; acc of 96.02293372154236%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.1292412281036377; acc of 97.27052450180054%\n",
      "Test Precision: precision_m of 0.0%\n",
      "Test Recall: recall_m of 0.0%\n",
      "Test F1: f1_m of 0.0%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1993 - acc: 0.9575 - precision_m: 0.0090 - recall_m: 0.0055 - f1_m: 0.0039\n",
      "Epoch 1: val_acc improved from -inf to 0.96336, saving model to models/best_model_3_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 2s 3ms/step - loss: 0.1991 - acc: 0.9575 - precision_m: 0.0089 - recall_m: 0.0055 - f1_m: 0.0039 - val_loss: 0.1580 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.1656 - acc: 0.9643 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 2: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1654 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1520 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 3/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.1549 - acc: 0.9643 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 3: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1546 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1485 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 4/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.1505 - acc: 0.9643 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 4: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1502 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1450 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 5/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.1452 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 5: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1454 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1417 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 6/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.1417 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 6: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1420 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1406 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 7/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.1392 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 7: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1391 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1386 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 8/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.1366 - acc: 0.9645 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 8: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1370 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1395 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 9/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.1345 - acc: 0.9643 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 9: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1342 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1387 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 10/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.1336 - acc: 0.9641 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 10: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1330 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1379 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 11/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.1340 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 11: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1334 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1401 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 12/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.1315 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 12: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1315 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1343 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 13/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.1313 - acc: 0.9643 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 13: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1312 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1343 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 14/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.1300 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 14: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1301 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1330 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 15/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.1302 - acc: 0.9641 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 15: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1297 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1331 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 16/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.1283 - acc: 0.9645 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 16: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1289 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1345 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 17/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.1299 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 17: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1293 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1404 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 18/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.1287 - acc: 0.9643 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 18: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1285 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1328 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 19/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.1280 - acc: 0.9645 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 19: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1285 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1348 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 20/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.1282 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 20: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1278 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1351 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 21/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.1275 - acc: 0.9645 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 21: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1278 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1358 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 22/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.1268 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 22: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1269 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1316 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 23/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.1264 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 23: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1264 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1313 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 24/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.1260 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 24: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1260 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1309 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 25/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.1261 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 25: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1263 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1311 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 26/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.1258 - acc: 0.9643 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 26: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1256 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1311 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 27/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.1247 - acc: 0.9645 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 27: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1248 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1305 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 28/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.1248 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 28: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1249 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1316 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 29/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.1256 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 29: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1250 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1328 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 30/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.1249 - acc: 0.9643 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 30: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1249 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1318 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Score for fold 2: loss of 0.15798361599445343; acc of 96.335768699646%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.1729929894208908; acc of 95.75244188308716%\n",
      "Test Precision: precision_m of 0.0%\n",
      "Test Recall: recall_m of 0.0%\n",
      "Test F1: f1_m of 0.0%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.4474 - acc: 0.9268 - precision_m: 0.0490 - recall_m: 0.0460 - f1_m: 0.0328\n",
      "Epoch 1: val_acc improved from -inf to 0.96299, saving model to models/best_model_3_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 2s 3ms/step - loss: 0.4445 - acc: 0.9273 - precision_m: 0.0494 - recall_m: 0.0458 - f1_m: 0.0330 - val_loss: 0.1732 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.1917 - acc: 0.9620 - precision_m: 0.0082 - recall_m: 0.0011 - f1_m: 0.0019\n",
      "Epoch 2: val_acc did not improve from 0.96299\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1914 - acc: 0.9621 - precision_m: 0.0080 - recall_m: 0.0011 - f1_m: 0.0019 - val_loss: 0.1627 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 3/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.1781 - acc: 0.9633 - precision_m: 0.0070 - recall_m: 4.9532e-04 - f1_m: 9.2320e-04\n",
      "Epoch 3: val_acc did not improve from 0.96299\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1784 - acc: 0.9632 - precision_m: 0.0069 - recall_m: 4.8851e-04 - f1_m: 9.1051e-04 - val_loss: 0.1567 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 4/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1680 - acc: 0.9630 - precision_m: 0.0035 - recall_m: 4.3253e-04 - f1_m: 7.6893e-04\n",
      "Epoch 4: val_acc did not improve from 0.96299\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1679 - acc: 0.9631 - precision_m: 0.0034 - recall_m: 4.2955e-04 - f1_m: 7.6365e-04 - val_loss: 0.1541 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 5/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.1614 - acc: 0.9632 - precision_m: 0.0035 - recall_m: 2.6896e-04 - f1_m: 4.9950e-04\n",
      "Epoch 5: val_acc did not improve from 0.96299\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1615 - acc: 0.9631 - precision_m: 0.0034 - recall_m: 2.6434e-04 - f1_m: 4.9092e-04 - val_loss: 0.1482 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 6/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.1557 - acc: 0.9633 - precision_m: 0.0404 - recall_m: 0.0047 - f1_m: 0.0083\n",
      "Epoch 6: val_acc did not improve from 0.96299\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1556 - acc: 0.9633 - precision_m: 0.0430 - recall_m: 0.0048 - f1_m: 0.0085 - val_loss: 0.1459 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 7/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.1510 - acc: 0.9635 - precision_m: 0.0371 - recall_m: 0.0040 - f1_m: 0.0072\n",
      "Epoch 7: val_acc did not improve from 0.96299\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1516 - acc: 0.9633 - precision_m: 0.0395 - recall_m: 0.0042 - f1_m: 0.0076 - val_loss: 0.1433 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 8/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.1501 - acc: 0.9634 - precision_m: 0.0592 - recall_m: 0.0060 - f1_m: 0.0108\n",
      "Epoch 8: val_acc did not improve from 0.96299\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1500 - acc: 0.9635 - precision_m: 0.0584 - recall_m: 0.0059 - f1_m: 0.0107 - val_loss: 0.1426 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 9/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.1465 - acc: 0.9634 - precision_m: 0.0452 - recall_m: 0.0059 - f1_m: 0.0097\n",
      "Epoch 9: val_acc did not improve from 0.96299\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1467 - acc: 0.9633 - precision_m: 0.0475 - recall_m: 0.0060 - f1_m: 0.0100 - val_loss: 0.1444 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 10/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.1435 - acc: 0.9634 - precision_m: 0.0678 - recall_m: 0.0089 - f1_m: 0.0154\n",
      "Epoch 10: val_acc did not improve from 0.96299\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1441 - acc: 0.9633 - precision_m: 0.0662 - recall_m: 0.0087 - f1_m: 0.0150 - val_loss: 0.1407 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 11/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.1426 - acc: 0.9633 - precision_m: 0.0618 - recall_m: 0.0077 - f1_m: 0.0135\n",
      "Epoch 11: val_acc did not improve from 0.96299\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1425 - acc: 0.9634 - precision_m: 0.0636 - recall_m: 0.0078 - f1_m: 0.0136 - val_loss: 0.1380 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 12/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.1406 - acc: 0.9633 - precision_m: 0.0542 - recall_m: 0.0067 - f1_m: 0.0118\n",
      "Epoch 12: val_acc did not improve from 0.96299\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1406 - acc: 0.9633 - precision_m: 0.0533 - recall_m: 0.0066 - f1_m: 0.0116 - val_loss: 0.1373 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 13/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.1384 - acc: 0.9633 - precision_m: 0.0559 - recall_m: 0.0066 - f1_m: 0.0114\n",
      "Epoch 13: val_acc did not improve from 0.96299\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1381 - acc: 0.9634 - precision_m: 0.0619 - recall_m: 0.0073 - f1_m: 0.0127 - val_loss: 0.1370 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 14/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.1375 - acc: 0.9634 - precision_m: 0.0700 - recall_m: 0.0081 - f1_m: 0.0142\n",
      "Epoch 14: val_acc did not improve from 0.96299\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1376 - acc: 0.9634 - precision_m: 0.0676 - recall_m: 0.0078 - f1_m: 0.0137 - val_loss: 0.1366 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 15/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.1365 - acc: 0.9633 - precision_m: 0.0418 - recall_m: 0.0054 - f1_m: 0.0095\n",
      "Epoch 15: val_acc did not improve from 0.96299\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1366 - acc: 0.9632 - precision_m: 0.0412 - recall_m: 0.0053 - f1_m: 0.0094 - val_loss: 0.1355 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 16/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.1364 - acc: 0.9634 - precision_m: 0.0912 - recall_m: 0.0123 - f1_m: 0.0213\n",
      "Epoch 16: val_acc did not improve from 0.96299\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1364 - acc: 0.9634 - precision_m: 0.0928 - recall_m: 0.0124 - f1_m: 0.0214 - val_loss: 0.1343 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 17/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.1347 - acc: 0.9632 - precision_m: 0.0642 - recall_m: 0.0087 - f1_m: 0.0145\n",
      "Epoch 17: val_acc did not improve from 0.96299\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1346 - acc: 0.9634 - precision_m: 0.0693 - recall_m: 0.0095 - f1_m: 0.0160 - val_loss: 0.1346 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 18/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.1338 - acc: 0.9635 - precision_m: 0.1079 - recall_m: 0.0142 - f1_m: 0.0244\n",
      "Epoch 18: val_acc did not improve from 0.96299\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1341 - acc: 0.9635 - precision_m: 0.1053 - recall_m: 0.0138 - f1_m: 0.0238 - val_loss: 0.1345 - val_acc: 0.9629 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 19/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.1332 - acc: 0.9635 - precision_m: 0.1166 - recall_m: 0.0153 - f1_m: 0.0261\n",
      "Epoch 19: val_acc did not improve from 0.96299\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1332 - acc: 0.9635 - precision_m: 0.1154 - recall_m: 0.0151 - f1_m: 0.0259 - val_loss: 0.1360 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 20/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.1328 - acc: 0.9634 - precision_m: 0.1127 - recall_m: 0.0136 - f1_m: 0.0240\n",
      "Epoch 20: val_acc did not improve from 0.96299\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1326 - acc: 0.9635 - precision_m: 0.1168 - recall_m: 0.0143 - f1_m: 0.0252 - val_loss: 0.1333 - val_acc: 0.9630 - val_precision_m: 0.0152 - val_recall_m: 0.0051 - val_f1_m: 0.0076\n",
      "Epoch 21/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.1330 - acc: 0.9634 - precision_m: 0.1190 - recall_m: 0.0128 - f1_m: 0.0228\n",
      "Epoch 21: val_acc did not improve from 0.96299\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1329 - acc: 0.9634 - precision_m: 0.1157 - recall_m: 0.0124 - f1_m: 0.0222 - val_loss: 0.1335 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 22/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.1316 - acc: 0.9635 - precision_m: 0.1305 - recall_m: 0.0159 - f1_m: 0.0278\n",
      "Epoch 22: val_acc did not improve from 0.96299\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1317 - acc: 0.9635 - precision_m: 0.1283 - recall_m: 0.0156 - f1_m: 0.0273 - val_loss: 0.1339 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 23/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.1307 - acc: 0.9636 - precision_m: 0.0848 - recall_m: 0.0113 - f1_m: 0.0194\n",
      "Epoch 23: val_acc improved from 0.96299 to 0.96370, saving model to models/best_model_3_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1313 - acc: 0.9633 - precision_m: 0.0922 - recall_m: 0.0120 - f1_m: 0.0208 - val_loss: 0.1376 - val_acc: 0.9637 - val_precision_m: 0.1061 - val_recall_m: 0.0201 - val_f1_m: 0.0326\n",
      "Epoch 24/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.1303 - acc: 0.9635 - precision_m: 0.1300 - recall_m: 0.0175 - f1_m: 0.0301\n",
      "Epoch 24: val_acc did not improve from 0.96370\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1304 - acc: 0.9635 - precision_m: 0.1312 - recall_m: 0.0175 - f1_m: 0.0301 - val_loss: 0.1325 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 25/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.1312 - acc: 0.9633 - precision_m: 0.1101 - recall_m: 0.0135 - f1_m: 0.0236\n",
      "Epoch 25: val_acc did not improve from 0.96370\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1308 - acc: 0.9634 - precision_m: 0.1082 - recall_m: 0.0132 - f1_m: 0.0232 - val_loss: 0.1378 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 26/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.1297 - acc: 0.9635 - precision_m: 0.1269 - recall_m: 0.0152 - f1_m: 0.0269\n",
      "Epoch 26: val_acc did not improve from 0.96370\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1299 - acc: 0.9636 - precision_m: 0.1294 - recall_m: 0.0158 - f1_m: 0.0280 - val_loss: 0.1334 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 27/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.1302 - acc: 0.9638 - precision_m: 0.1400 - recall_m: 0.0210 - f1_m: 0.0354\n",
      "Epoch 27: val_acc did not improve from 0.96370\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1301 - acc: 0.9638 - precision_m: 0.1380 - recall_m: 0.0207 - f1_m: 0.0349 - val_loss: 0.1370 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 28/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.1291 - acc: 0.9635 - precision_m: 0.1390 - recall_m: 0.0180 - f1_m: 0.0311\n",
      "Epoch 28: val_acc did not improve from 0.96370\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1292 - acc: 0.9635 - precision_m: 0.1415 - recall_m: 0.0187 - f1_m: 0.0323 - val_loss: 0.1319 - val_acc: 0.9637 - val_precision_m: 0.1364 - val_recall_m: 0.0211 - val_f1_m: 0.0358\n",
      "Epoch 29/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.1285 - acc: 0.9635 - precision_m: 0.1396 - recall_m: 0.0158 - f1_m: 0.0281\n",
      "Epoch 29: val_acc did not improve from 0.96370\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1286 - acc: 0.9634 - precision_m: 0.1392 - recall_m: 0.0161 - f1_m: 0.0285 - val_loss: 0.1309 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 30/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.1285 - acc: 0.9637 - precision_m: 0.1315 - recall_m: 0.0195 - f1_m: 0.0326\n",
      "Epoch 30: val_acc did not improve from 0.96370\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1284 - acc: 0.9637 - precision_m: 0.1343 - recall_m: 0.0198 - f1_m: 0.0331 - val_loss: 0.1299 - val_acc: 0.9633 - val_precision_m: 0.0303 - val_recall_m: 0.0029 - val_f1_m: 0.0053\n",
      "Score for fold 3: loss of 0.13756074011325836; acc of 96.37038707733154%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.1319393366575241; acc of 96.51274681091309%\n",
      "Test Precision: precision_m of 0.6802720483392477%\n",
      "Test Recall: recall_m of 0.29478457290679216%\n",
      "Test F1: f1_m of 0.38548747543245554%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.3863 - acc: 0.9244 - precision_m: 0.0346 - recall_m: 0.0504 - f1_m: 0.0255\n",
      "Epoch 1: val_acc improved from -inf to 0.96143, saving model to models/best_model_3_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 2s 4ms/step - loss: 0.3826 - acc: 0.9251 - precision_m: 0.0339 - recall_m: 0.0493 - f1_m: 0.0250 - val_loss: 0.1740 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.1788 - acc: 0.9641 - precision_m: 0.0054 - recall_m: 5.3861e-04 - f1_m: 9.5308e-04\n",
      "Epoch 2: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1780 - acc: 0.9643 - precision_m: 0.0051 - recall_m: 5.1278e-04 - f1_m: 9.0739e-04 - val_loss: 0.1649 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 3/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.1636 - acc: 0.9645 - precision_m: 0.0035 - recall_m: 4.4326e-04 - f1_m: 7.8802e-04\n",
      "Epoch 3: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1635 - acc: 0.9645 - precision_m: 0.0034 - recall_m: 4.2808e-04 - f1_m: 7.6103e-04 - val_loss: 0.1602 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 4/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.1627 - acc: 0.9643 - precision_m: 0.0036 - recall_m: 3.9683e-04 - f1_m: 7.1429e-04\n",
      "Epoch 4: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1624 - acc: 0.9643 - precision_m: 0.0086 - recall_m: 0.0010 - f1_m: 0.0018 - val_loss: 0.1557 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 5/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.1565 - acc: 0.9646 - precision_m: 0.0351 - recall_m: 0.0044 - f1_m: 0.0077\n",
      "Epoch 5: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1568 - acc: 0.9645 - precision_m: 0.0342 - recall_m: 0.0042 - f1_m: 0.0075 - val_loss: 0.1545 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 6/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.1525 - acc: 0.9644 - precision_m: 0.0246 - recall_m: 0.0031 - f1_m: 0.0054\n",
      "Epoch 6: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1523 - acc: 0.9645 - precision_m: 0.0240 - recall_m: 0.0030 - f1_m: 0.0053 - val_loss: 0.1519 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 7/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.1485 - acc: 0.9646 - precision_m: 0.0194 - recall_m: 0.0025 - f1_m: 0.0045\n",
      "Epoch 7: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1489 - acc: 0.9644 - precision_m: 0.0188 - recall_m: 0.0025 - f1_m: 0.0043 - val_loss: 0.1485 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 8/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.1439 - acc: 0.9647 - precision_m: 0.0674 - recall_m: 0.0085 - f1_m: 0.0149\n",
      "Epoch 8: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1443 - acc: 0.9646 - precision_m: 0.0651 - recall_m: 0.0082 - f1_m: 0.0144 - val_loss: 0.1471 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 9/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.1464 - acc: 0.9644 - precision_m: 0.0458 - recall_m: 0.0061 - f1_m: 0.0105\n",
      "Epoch 9: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1462 - acc: 0.9644 - precision_m: 0.0445 - recall_m: 0.0059 - f1_m: 0.0102 - val_loss: 0.1454 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 10/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.1402 - acc: 0.9644 - precision_m: 0.0693 - recall_m: 0.0097 - f1_m: 0.0163\n",
      "Epoch 10: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1402 - acc: 0.9644 - precision_m: 0.0696 - recall_m: 0.0097 - f1_m: 0.0164 - val_loss: 0.1460 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 11/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.1388 - acc: 0.9644 - precision_m: 0.0647 - recall_m: 0.0079 - f1_m: 0.0138\n",
      "Epoch 11: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1390 - acc: 0.9644 - precision_m: 0.0622 - recall_m: 0.0076 - f1_m: 0.0133 - val_loss: 0.1445 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 12/30\n",
      "275/292 [===========================>..] - ETA: 0s - loss: 0.1382 - acc: 0.9642 - precision_m: 0.0691 - recall_m: 0.0073 - f1_m: 0.0132\n",
      "Epoch 12: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1377 - acc: 0.9645 - precision_m: 0.0685 - recall_m: 0.0074 - f1_m: 0.0133 - val_loss: 0.1450 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 13/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.1355 - acc: 0.9643 - precision_m: 0.0936 - recall_m: 0.0119 - f1_m: 0.0208\n",
      "Epoch 13: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1352 - acc: 0.9644 - precision_m: 0.0908 - recall_m: 0.0116 - f1_m: 0.0201 - val_loss: 0.1433 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 14/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.1343 - acc: 0.9646 - precision_m: 0.1250 - recall_m: 0.0135 - f1_m: 0.0241\n",
      "Epoch 14: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1345 - acc: 0.9645 - precision_m: 0.1244 - recall_m: 0.0138 - f1_m: 0.0245 - val_loss: 0.1432 - val_acc: 0.9613 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 15/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.1351 - acc: 0.9644 - precision_m: 0.1220 - recall_m: 0.0170 - f1_m: 0.0293\n",
      "Epoch 15: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1345 - acc: 0.9646 - precision_m: 0.1170 - recall_m: 0.0163 - f1_m: 0.0281 - val_loss: 0.1415 - val_acc: 0.9611 - val_precision_m: 0.0606 - val_recall_m: 0.0144 - val_f1_m: 0.0220\n",
      "Epoch 16/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.1350 - acc: 0.9644 - precision_m: 0.0866 - recall_m: 0.0125 - f1_m: 0.0208\n",
      "Epoch 16: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1353 - acc: 0.9642 - precision_m: 0.0851 - recall_m: 0.0125 - f1_m: 0.0207 - val_loss: 0.1418 - val_acc: 0.9613 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 17/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.1315 - acc: 0.9645 - precision_m: 0.1078 - recall_m: 0.0156 - f1_m: 0.0266\n",
      "Epoch 17: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1318 - acc: 0.9645 - precision_m: 0.1090 - recall_m: 0.0156 - f1_m: 0.0266 - val_loss: 0.1425 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 18/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.1323 - acc: 0.9644 - precision_m: 0.1237 - recall_m: 0.0150 - f1_m: 0.0261\n",
      "Epoch 18: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1321 - acc: 0.9645 - precision_m: 0.1199 - recall_m: 0.0145 - f1_m: 0.0253 - val_loss: 0.1437 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 19/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.1303 - acc: 0.9646 - precision_m: 0.1111 - recall_m: 0.0159 - f1_m: 0.0271\n",
      "Epoch 19: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1309 - acc: 0.9644 - precision_m: 0.1142 - recall_m: 0.0160 - f1_m: 0.0273 - val_loss: 0.1433 - val_acc: 0.9598 - val_precision_m: 0.0909 - val_recall_m: 0.0225 - val_f1_m: 0.0340\n",
      "Epoch 20/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.1343 - acc: 0.9645 - precision_m: 0.1173 - recall_m: 0.0195 - f1_m: 0.0319\n",
      "Epoch 20: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1342 - acc: 0.9644 - precision_m: 0.1171 - recall_m: 0.0195 - f1_m: 0.0319 - val_loss: 0.1422 - val_acc: 0.9612 - val_precision_m: 0.0455 - val_recall_m: 0.0061 - val_f1_m: 0.0106\n",
      "Epoch 21/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.1319 - acc: 0.9646 - precision_m: 0.1480 - recall_m: 0.0202 - f1_m: 0.0351\n",
      "Epoch 21: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1318 - acc: 0.9645 - precision_m: 0.1507 - recall_m: 0.0210 - f1_m: 0.0362 - val_loss: 0.1409 - val_acc: 0.9611 - val_precision_m: 0.0808 - val_recall_m: 0.0129 - val_f1_m: 0.0216\n",
      "Epoch 22/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.1297 - acc: 0.9646 - precision_m: 0.1228 - recall_m: 0.0159 - f1_m: 0.0274\n",
      "Epoch 22: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1300 - acc: 0.9645 - precision_m: 0.1267 - recall_m: 0.0170 - f1_m: 0.0290 - val_loss: 0.1412 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 23/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.1309 - acc: 0.9644 - precision_m: 0.1027 - recall_m: 0.0136 - f1_m: 0.0232 \n",
      "Epoch 23: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1305 - acc: 0.9644 - precision_m: 0.1039 - recall_m: 0.0142 - f1_m: 0.0242 - val_loss: 0.1429 - val_acc: 0.9596 - val_precision_m: 0.2462 - val_recall_m: 0.0521 - val_f1_m: 0.0759\n",
      "Epoch 24/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.1318 - acc: 0.9642 - precision_m: 0.1158 - recall_m: 0.0211 - f1_m: 0.0325\n",
      "Epoch 24: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1318 - acc: 0.9642 - precision_m: 0.1235 - recall_m: 0.0217 - f1_m: 0.0338 - val_loss: 0.1405 - val_acc: 0.9613 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 25/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.1300 - acc: 0.9644 - precision_m: 0.1289 - recall_m: 0.0151 - f1_m: 0.0267\n",
      "Epoch 25: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1300 - acc: 0.9644 - precision_m: 0.1284 - recall_m: 0.0151 - f1_m: 0.0266 - val_loss: 0.1421 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 26/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.1283 - acc: 0.9645 - precision_m: 0.1361 - recall_m: 0.0183 - f1_m: 0.0310\n",
      "Epoch 26: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1284 - acc: 0.9645 - precision_m: 0.1367 - recall_m: 0.0184 - f1_m: 0.0312 - val_loss: 0.1439 - val_acc: 0.9612 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 27/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.1326 - acc: 0.9645 - precision_m: 0.1241 - recall_m: 0.0158 - f1_m: 0.0278\n",
      "Epoch 27: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1322 - acc: 0.9646 - precision_m: 0.1267 - recall_m: 0.0190 - f1_m: 0.0307 - val_loss: 0.1405 - val_acc: 0.9614 - val_precision_m: 0.0606 - val_recall_m: 0.0096 - val_f1_m: 0.0159\n",
      "Epoch 28/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.1294 - acc: 0.9645 - precision_m: 0.1530 - recall_m: 0.0233 - f1_m: 0.0384\n",
      "Epoch 28: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1294 - acc: 0.9645 - precision_m: 0.1517 - recall_m: 0.0237 - f1_m: 0.0389 - val_loss: 0.1403 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 29/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.1270 - acc: 0.9645 - precision_m: 0.1562 - recall_m: 0.0189 - f1_m: 0.0329\n",
      "Epoch 29: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1276 - acc: 0.9644 - precision_m: 0.1535 - recall_m: 0.0185 - f1_m: 0.0323 - val_loss: 0.1411 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 30/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.1277 - acc: 0.9645 - precision_m: 0.1320 - recall_m: 0.0212 - f1_m: 0.0350\n",
      "Epoch 30: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1278 - acc: 0.9645 - precision_m: 0.1284 - recall_m: 0.0206 - f1_m: 0.0341 - val_loss: 0.1450 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Score for fold 4: loss of 0.17402151226997375; acc of 96.14328145980835%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.19524995982646942; acc of 95.7481324672699%\n",
      "Test Precision: precision_m of 0.0%\n",
      "Test Recall: recall_m of 0.0%\n",
      "Test F1: f1_m of 0.0%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.1982 - acc: 0.9604 - precision_m: 0.0051 - recall_m: 0.0042 - f1_m: 0.0043\n",
      "Epoch 1: val_acc improved from -inf to 0.96211, saving model to models/best_model_3_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 2s 4ms/step - loss: 0.1982 - acc: 0.9604 - precision_m: 0.0050 - recall_m: 0.0041 - f1_m: 0.0042 - val_loss: 0.1593 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.1607 - acc: 0.9637 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 2: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1602 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1515 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 3/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.1516 - acc: 0.9637 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 3: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1509 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1490 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 4/30\n",
      "276/291 [===========================>..] - ETA: 0s - loss: 0.1454 - acc: 0.9640 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 4: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1456 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1445 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 5/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.1409 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 5: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1408 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1430 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 6/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.1387 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 6: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1385 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1422 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 7/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.1360 - acc: 0.9641 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 7: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1365 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1415 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 8/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.1334 - acc: 0.9637 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 8: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1332 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1411 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 9/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.1321 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 9: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1324 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1388 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 10/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.1310 - acc: 0.9640 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 10: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1313 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1411 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 11/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.1307 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 11: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1304 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1430 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 12/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.1298 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 12: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1300 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1394 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 13/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.1290 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 13: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1290 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1394 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 14/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.1278 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 14: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1279 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1385 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 15/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.1284 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 15: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1284 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1390 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 16/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.1280 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 16: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1280 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1401 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 17/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.1271 - acc: 0.9641 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 17: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1277 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1389 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 18/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.1267 - acc: 0.9640 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 18: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1273 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1374 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 19/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.1265 - acc: 0.9641 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 19: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1271 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1360 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 20/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.1270 - acc: 0.9636 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 20: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1265 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1376 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 21/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.1262 - acc: 0.9639 - precision_m: 0.0071 - recall_m: 7.9505e-04 - f1_m: 0.0014   \n",
      "Epoch 21: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1264 - acc: 0.9639 - precision_m: 0.0069 - recall_m: 7.7320e-04 - f1_m: 0.0014 - val_loss: 0.1358 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 22/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.1259 - acc: 0.9638 - precision_m: 0.0142 - recall_m: 0.0015 - f1_m: 0.0027  \n",
      "Epoch 22: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1255 - acc: 0.9639 - precision_m: 0.0137 - recall_m: 0.0014 - f1_m: 0.0026 - val_loss: 0.1374 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 23/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.1255 - acc: 0.9639 - precision_m: 0.0071 - recall_m: 0.0011 - f1_m: 0.0020   \n",
      "Epoch 23: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1260 - acc: 0.9638 - precision_m: 0.0069 - recall_m: 0.0011 - f1_m: 0.0019 - val_loss: 0.1369 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 24/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.1251 - acc: 0.9640 - precision_m: 0.0036 - recall_m: 2.7473e-04 - f1_m: 5.1020e-04\n",
      "Epoch 24: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1256 - acc: 0.9638 - precision_m: 0.0034 - recall_m: 2.6434e-04 - f1_m: 4.9092e-04 - val_loss: 0.1358 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 25/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.1259 - acc: 0.9637 - precision_m: 0.0108 - recall_m: 0.0012 - f1_m: 0.0021\n",
      "Epoch 25: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1255 - acc: 0.9639 - precision_m: 0.0137 - recall_m: 0.0016 - f1_m: 0.0028 - val_loss: 0.1361 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 26/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.1239 - acc: 0.9638 - precision_m: 0.0323 - recall_m: 0.0039 - f1_m: 0.0069\n",
      "Epoch 26: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1238 - acc: 0.9639 - precision_m: 0.0378 - recall_m: 0.0048 - f1_m: 0.0084 - val_loss: 0.1360 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 27/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.1248 - acc: 0.9641 - precision_m: 0.0776 - recall_m: 0.0087 - f1_m: 0.0154\n",
      "Epoch 27: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1248 - acc: 0.9641 - precision_m: 0.0739 - recall_m: 0.0083 - f1_m: 0.0146 - val_loss: 0.1337 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 28/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.1242 - acc: 0.9638 - precision_m: 0.0556 - recall_m: 0.0062 - f1_m: 0.0110\n",
      "Epoch 28: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1243 - acc: 0.9640 - precision_m: 0.0533 - recall_m: 0.0060 - f1_m: 0.0105 - val_loss: 0.1347 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 29/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.1243 - acc: 0.9639 - precision_m: 0.0448 - recall_m: 0.0049 - f1_m: 0.0087\n",
      "Epoch 29: val_acc improved from 0.96211 to 0.96247, saving model to models/best_model_3_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1240 - acc: 0.9639 - precision_m: 0.0515 - recall_m: 0.0058 - f1_m: 0.0102 - val_loss: 0.1340 - val_acc: 0.9625 - val_precision_m: 0.0303 - val_recall_m: 0.0043 - val_f1_m: 0.0076\n",
      "Epoch 30/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.1239 - acc: 0.9639 - precision_m: 0.0951 - recall_m: 0.0118 - f1_m: 0.0206\n",
      "Epoch 30: val_acc did not improve from 0.96247\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1238 - acc: 0.9640 - precision_m: 0.0962 - recall_m: 0.0119 - f1_m: 0.0207 - val_loss: 0.1348 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Score for fold 5: loss of 0.13400809466838837; acc of 96.2471604347229%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.12493212521076202; acc of 96.28443121910095%\n",
      "Test Precision: precision_m of 0.0%\n",
      "Test Recall: recall_m of 0.0%\n",
      "Test F1: f1_m of 0.0%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Epoch 1/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.2289 - acc: 0.9488 - precision_m: 0.0151 - recall_m: 0.0182 - f1_m: 0.0082\n",
      "Epoch 1: val_acc improved from -inf to 0.96059, saving model to models/best_model_3_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 2s 4ms/step - loss: 0.2276 - acc: 0.9492 - precision_m: 0.0146 - recall_m: 0.0177 - f1_m: 0.0079 - val_loss: 0.1715 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.1768 - acc: 0.9639 - precision_m: 0.0035 - recall_m: 3.8986e-04 - f1_m: 7.0175e-04\n",
      "Epoch 2: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1771 - acc: 0.9638 - precision_m: 0.0034 - recall_m: 3.8052e-04 - f1_m: 6.8493e-04 - val_loss: 0.1621 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 3/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.1674 - acc: 0.9641 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 3: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1674 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1572 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 4/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.1597 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 4: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1600 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1533 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 5/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.1532 - acc: 0.9641 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 5: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1542 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1507 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 6/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.1496 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 6: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1490 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1501 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 7/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.1452 - acc: 0.9640 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 7: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1458 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1444 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 8/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.1419 - acc: 0.9643 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 8: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1428 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1451 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 9/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.1393 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 9: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1388 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1432 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 10/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.1378 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 10: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1377 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1413 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 11/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.1351 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 11: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1351 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1402 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 12/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.1342 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 12: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1339 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1423 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 13/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.1325 - acc: 0.9637 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 13: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1321 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1390 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 14/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.1317 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 14: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1314 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1395 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 15/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.1300 - acc: 0.9640 - precision_m: 0.0036 - recall_m: 4.4484e-04 - f1_m: 7.9083e-04\n",
      "Epoch 15: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1305 - acc: 0.9639 - precision_m: 0.0034 - recall_m: 4.2808e-04 - f1_m: 7.6103e-04 - val_loss: 0.1392 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 16/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.1306 - acc: 0.9639 - precision_m: 0.0035 - recall_m: 3.2237e-04 - f1_m: 5.9102e-04  \n",
      "Epoch 16: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1305 - acc: 0.9639 - precision_m: 0.0034 - recall_m: 3.1133e-04 - f1_m: 5.7078e-04 - val_loss: 0.1394 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 17/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.1298 - acc: 0.9640 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 17: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1302 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1386 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 18/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.1284 - acc: 0.9640 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 18: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1286 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1377 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 19/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.1273 - acc: 0.9641 - precision_m: 0.0090 - recall_m: 0.0011 - f1_m: 0.0020\n",
      "Epoch 19: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1279 - acc: 0.9638 - precision_m: 0.0086 - recall_m: 0.0011 - f1_m: 0.0019 - val_loss: 0.1387 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 20/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.1287 - acc: 0.9637 - precision_m: 0.0035 - recall_m: 3.9262e-04 - f1_m: 7.0671e-04\n",
      "Epoch 20: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1284 - acc: 0.9639 - precision_m: 0.0034 - recall_m: 3.8052e-04 - f1_m: 6.8493e-04 - val_loss: 0.1389 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 21/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.1277 - acc: 0.9639 - precision_m: 0.0106 - recall_m: 8.6561e-04 - f1_m: 0.0016  \n",
      "Epoch 21: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1275 - acc: 0.9639 - precision_m: 0.0103 - recall_m: 8.4190e-04 - f1_m: 0.0016 - val_loss: 0.1387 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 22/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.1264 - acc: 0.9640 - precision_m: 0.0214 - recall_m: 0.0019 - f1_m: 0.0035 \n",
      "Epoch 22: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1270 - acc: 0.9639 - precision_m: 0.0205 - recall_m: 0.0018 - f1_m: 0.0033 - val_loss: 0.1386 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 23/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.1262 - acc: 0.9641 - precision_m: 0.0288 - recall_m: 0.0047 - f1_m: 0.0079\n",
      "Epoch 23: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1267 - acc: 0.9639 - precision_m: 0.0274 - recall_m: 0.0045 - f1_m: 0.0075 - val_loss: 0.1376 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 24/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.1263 - acc: 0.9638 - precision_m: 0.0338 - recall_m: 0.0040 - f1_m: 0.0071\n",
      "Epoch 24: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1266 - acc: 0.9638 - precision_m: 0.0360 - recall_m: 0.0041 - f1_m: 0.0073 - val_loss: 0.1392 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 25/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.1265 - acc: 0.9638 - precision_m: 0.0343 - recall_m: 0.0048 - f1_m: 0.0078\n",
      "Epoch 25: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1265 - acc: 0.9638 - precision_m: 0.0366 - recall_m: 0.0052 - f1_m: 0.0085 - val_loss: 0.1381 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 26/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.1260 - acc: 0.9640 - precision_m: 0.0338 - recall_m: 0.0044 - f1_m: 0.0076\n",
      "Epoch 26: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1260 - acc: 0.9638 - precision_m: 0.0325 - recall_m: 0.0042 - f1_m: 0.0073 - val_loss: 0.1385 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 27/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.1261 - acc: 0.9637 - precision_m: 0.0360 - recall_m: 0.0048 - f1_m: 0.0085\n",
      "Epoch 27: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1257 - acc: 0.9638 - precision_m: 0.0377 - recall_m: 0.0051 - f1_m: 0.0089 - val_loss: 0.1389 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 28/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.1258 - acc: 0.9638 - precision_m: 0.0504 - recall_m: 0.0053 - f1_m: 0.0095\n",
      "Epoch 28: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1256 - acc: 0.9639 - precision_m: 0.0479 - recall_m: 0.0050 - f1_m: 0.0090 - val_loss: 0.1394 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 29/30\n",
      "275/292 [===========================>..] - ETA: 0s - loss: 0.1252 - acc: 0.9638 - precision_m: 0.1018 - recall_m: 0.0124 - f1_m: 0.0219\n",
      "Epoch 29: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1249 - acc: 0.9640 - precision_m: 0.1010 - recall_m: 0.0126 - f1_m: 0.0220 - val_loss: 0.1392 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 30/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.1257 - acc: 0.9639 - precision_m: 0.0866 - recall_m: 0.0099 - f1_m: 0.0176\n",
      "Epoch 30: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1256 - acc: 0.9639 - precision_m: 0.0839 - recall_m: 0.0096 - f1_m: 0.0171 - val_loss: 0.1362 - val_acc: 0.9605 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Score for fold 6: loss of 0.17147700488567352; acc of 96.05881571769714%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.16715595126152039; acc of 96.38698697090149%\n",
      "Test Precision: precision_m of 0.0%\n",
      "Test Recall: recall_m of 0.0%\n",
      "Test F1: f1_m of 0.0%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Epoch 1/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.1956 - acc: 0.9565 - precision_m: 0.0048 - recall_m: 0.0062 - f1_m: 0.0044\n",
      "Epoch 1: val_acc improved from -inf to 0.96249, saving model to models/best_model_3_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 2s 4ms/step - loss: 0.1946 - acc: 0.9568 - precision_m: 0.0046 - recall_m: 0.0059 - f1_m: 0.0042 - val_loss: 0.1567 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.1629 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 2: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1626 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1488 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 3/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.1527 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 3: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1526 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1440 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 4/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.1474 - acc: 0.9628 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 4: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1467 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1407 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 5/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.1417 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 5: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1419 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1391 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 6/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.1397 - acc: 0.9632 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 6: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1404 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1380 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 7/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.1370 - acc: 0.9631 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 7: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1373 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1376 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 8/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.1363 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 8: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1362 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1377 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 9/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.1354 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 9: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1351 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1404 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 10/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.1329 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 10: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1331 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1359 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 11/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.1335 - acc: 0.9628 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 11: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1331 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1397 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 12/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.1329 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 12: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1331 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1349 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 13/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.1311 - acc: 0.9631 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 13: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1315 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1333 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 14/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.1317 - acc: 0.9629 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 14: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1313 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1330 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 15/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.1304 - acc: 0.9631 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 15: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1305 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1345 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 16/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.1304 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 16: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1305 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1340 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 17/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.1296 - acc: 0.9631 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 17: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1297 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1348 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 18/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.1303 - acc: 0.9628 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 18: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1299 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1344 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 19/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.1295 - acc: 0.9631 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 19: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1296 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1340 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 20/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.1276 - acc: 0.9631 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 20: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1280 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1350 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 21/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.1279 - acc: 0.9632 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 21: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1284 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1360 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 22/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.1286 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 22: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1290 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1343 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 23/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.1280 - acc: 0.9629 - precision_m: 0.0035 - recall_m: 2.9446e-04 - f1_m: 5.4363e-04    \n",
      "Epoch 23: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1276 - acc: 0.9630 - precision_m: 0.0034 - recall_m: 2.8539e-04 - f1_m: 5.2687e-04 - val_loss: 0.1356 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 24/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.1280 - acc: 0.9630 - precision_m: 0.0070 - recall_m: 7.2844e-04 - f1_m: 0.0013   \n",
      "Epoch 24: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1278 - acc: 0.9630 - precision_m: 0.0068 - recall_m: 7.1347e-04 - f1_m: 0.0013 - val_loss: 0.1333 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 25/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.1264 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 25: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1265 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1333 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 26/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.1271 - acc: 0.9629 - precision_m: 0.0144 - recall_m: 9.8921e-04 - f1_m: 0.0018\n",
      "Epoch 26: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1267 - acc: 0.9631 - precision_m: 0.0137 - recall_m: 9.4178e-04 - f1_m: 0.0018 - val_loss: 0.1328 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 27/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.1256 - acc: 0.9631 - precision_m: 0.0106 - recall_m: 0.0012 - f1_m: 0.0022  \n",
      "Epoch 27: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1258 - acc: 0.9630 - precision_m: 0.0103 - recall_m: 0.0012 - f1_m: 0.0021 - val_loss: 0.1347 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 28/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.1269 - acc: 0.9631 - precision_m: 0.0108 - recall_m: 0.0012 - f1_m: 0.0022     \n",
      "Epoch 28: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1275 - acc: 0.9629 - precision_m: 0.0103 - recall_m: 0.0012 - f1_m: 0.0021 - val_loss: 0.1336 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 29/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.1259 - acc: 0.9631 - precision_m: 0.0106 - recall_m: 9.4640e-04 - f1_m: 0.0017 \n",
      "Epoch 29: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1263 - acc: 0.9630 - precision_m: 0.0103 - recall_m: 9.1723e-04 - f1_m: 0.0017 - val_loss: 0.1317 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 30/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.1255 - acc: 0.9632 - precision_m: 0.0179 - recall_m: 0.0018 - f1_m: 0.0033    \n",
      "Epoch 30: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1258 - acc: 0.9630 - precision_m: 0.0171 - recall_m: 0.0017 - f1_m: 0.0031 - val_loss: 0.1315 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Score for fold 7: loss of 0.1566990166902542; acc of 96.24850749969482%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.13357412815093994; acc of 96.93064093589783%\n",
      "Test Precision: precision_m of 0.0%\n",
      "Test Recall: recall_m of 0.0%\n",
      "Test F1: f1_m of 0.0%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Epoch 1/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.6906 - acc: 0.8932 - precision_m: 0.0395 - recall_m: 0.0736 - f1_m: 0.0343\n",
      "Epoch 1: val_acc improved from -inf to 0.96299, saving model to models/best_model_3_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 2s 4ms/step - loss: 0.6765 - acc: 0.8951 - precision_m: 0.0390 - recall_m: 0.0715 - f1_m: 0.0335 - val_loss: 0.1836 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.1957 - acc: 0.9601 - precision_m: 0.0351 - recall_m: 0.0049 - f1_m: 0.0079\n",
      "Epoch 2: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1947 - acc: 0.9603 - precision_m: 0.0339 - recall_m: 0.0047 - f1_m: 0.0076 - val_loss: 0.1639 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 3/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.1743 - acc: 0.9627 - precision_m: 0.0246 - recall_m: 0.0030 - f1_m: 0.0052\n",
      "Epoch 3: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1741 - acc: 0.9627 - precision_m: 0.0240 - recall_m: 0.0029 - f1_m: 0.0050 - val_loss: 0.1548 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 4/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.1656 - acc: 0.9633 - precision_m: 0.0322 - recall_m: 0.0042 - f1_m: 0.0070\n",
      "Epoch 4: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1659 - acc: 0.9632 - precision_m: 0.0314 - recall_m: 0.0041 - f1_m: 0.0068 - val_loss: 0.1495 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 5/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.1606 - acc: 0.9630 - precision_m: 0.0159 - recall_m: 0.0014 - f1_m: 0.0025\n",
      "Epoch 5: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1600 - acc: 0.9632 - precision_m: 0.0154 - recall_m: 0.0013 - f1_m: 0.0025 - val_loss: 0.1484 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 6/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.1572 - acc: 0.9632 - precision_m: 0.0090 - recall_m: 0.0010 - f1_m: 0.0018\n",
      "Epoch 6: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1567 - acc: 0.9633 - precision_m: 0.0086 - recall_m: 9.5529e-04 - f1_m: 0.0017 - val_loss: 0.1438 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 7/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.1527 - acc: 0.9633 - precision_m: 0.0179 - recall_m: 0.0026 - f1_m: 0.0044 \n",
      "Epoch 7: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1525 - acc: 0.9633 - precision_m: 0.0171 - recall_m: 0.0025 - f1_m: 0.0042 - val_loss: 0.1409 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 8/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.1487 - acc: 0.9634 - precision_m: 0.0177 - recall_m: 0.0015 - f1_m: 0.0028\n",
      "Epoch 8: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1485 - acc: 0.9633 - precision_m: 0.0171 - recall_m: 0.0015 - f1_m: 0.0027 - val_loss: 0.1386 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 9/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.1457 - acc: 0.9635 - precision_m: 0.0143 - recall_m: 0.0013 - f1_m: 0.0025     \n",
      "Epoch 9: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1461 - acc: 0.9633 - precision_m: 0.0137 - recall_m: 0.0013 - f1_m: 0.0024 - val_loss: 0.1376 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 10/30\n",
      "275/292 [===========================>..] - ETA: 0s - loss: 0.1436 - acc: 0.9635 - precision_m: 0.0073 - recall_m: 7.4675e-04 - f1_m: 0.0013  \n",
      "Epoch 10: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1439 - acc: 0.9634 - precision_m: 0.0068 - recall_m: 7.0328e-04 - f1_m: 0.0013 - val_loss: 0.1359 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 11/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.1412 - acc: 0.9636 - precision_m: 0.0071 - recall_m: 0.0011 - f1_m: 0.0018    \n",
      "Epoch 11: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1416 - acc: 0.9634 - precision_m: 0.0068 - recall_m: 0.0010 - f1_m: 0.0018 - val_loss: 0.1359 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 12/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.1403 - acc: 0.9634 - precision_m: 0.0036 - recall_m: 2.7375e-04 - f1_m: 5.0839e-04   \n",
      "Epoch 12: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1402 - acc: 0.9634 - precision_m: 0.0034 - recall_m: 2.6344e-04 - f1_m: 4.8924e-04 - val_loss: 0.1358 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 13/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.1382 - acc: 0.9634 - precision_m: 0.0143 - recall_m: 0.0017 - f1_m: 0.0030\n",
      "Epoch 13: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1382 - acc: 0.9634 - precision_m: 0.0137 - recall_m: 0.0016 - f1_m: 0.0028 - val_loss: 0.1357 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 14/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.1379 - acc: 0.9634 - precision_m: 0.0070 - recall_m: 8.2556e-04 - f1_m: 0.0015     \n",
      "Epoch 14: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1378 - acc: 0.9634 - precision_m: 0.0068 - recall_m: 8.0860e-04 - f1_m: 0.0014 - val_loss: 0.1386 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 15/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.1377 - acc: 0.9634 - precision_m: 0.0071 - recall_m: 6.2008e-04 - f1_m: 0.0011 \n",
      "Epoch 15: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1374 - acc: 0.9634 - precision_m: 0.0068 - recall_m: 5.9672e-04 - f1_m: 0.0011 - val_loss: 0.1348 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 16/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.1358 - acc: 0.9632 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 16: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1353 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1346 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 17/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.1347 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 17: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1347 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1329 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 18/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.1335 - acc: 0.9635 - precision_m: 0.0071 - recall_m: 8.3333e-04 - f1_m: 0.0015\n",
      "Epoch 18: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1337 - acc: 0.9634 - precision_m: 0.0068 - recall_m: 7.9909e-04 - f1_m: 0.0014 - val_loss: 0.1336 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 19/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1332 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 19: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1332 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1342 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 20/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.1313 - acc: 0.9634 - precision_m: 0.0141 - recall_m: 0.0019 - f1_m: 0.0034\n",
      "Epoch 20: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1312 - acc: 0.9635 - precision_m: 0.0137 - recall_m: 0.0019 - f1_m: 0.0033 - val_loss: 0.1331 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 21/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.1328 - acc: 0.9633 - precision_m: 0.0106 - recall_m: 9.4307e-04 - f1_m: 0.0017\n",
      "Epoch 21: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1328 - acc: 0.9634 - precision_m: 0.0103 - recall_m: 9.1723e-04 - f1_m: 0.0017 - val_loss: 0.1342 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 22/30\n",
      "275/292 [===========================>..] - ETA: 0s - loss: 0.1328 - acc: 0.9633 - precision_m: 0.0109 - recall_m: 8.7768e-04 - f1_m: 0.0016 \n",
      "Epoch 22: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1321 - acc: 0.9634 - precision_m: 0.0103 - recall_m: 8.2659e-04 - f1_m: 0.0015 - val_loss: 0.1330 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 23/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.1320 - acc: 0.9632 - precision_m: 0.0106 - recall_m: 9.6712e-04 - f1_m: 0.0018\n",
      "Epoch 23: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1316 - acc: 0.9634 - precision_m: 0.0103 - recall_m: 9.3400e-04 - f1_m: 0.0017 - val_loss: 0.1344 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 24/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.1318 - acc: 0.9634 - precision_m: 0.0142 - recall_m: 0.0013 - f1_m: 0.0023\n",
      "Epoch 24: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1317 - acc: 0.9634 - precision_m: 0.0137 - recall_m: 0.0012 - f1_m: 0.0023 - val_loss: 0.1319 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 25/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.1317 - acc: 0.9633 - precision_m: 0.0177 - recall_m: 0.0018 - f1_m: 0.0032 \n",
      "Epoch 25: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1313 - acc: 0.9633 - precision_m: 0.0171 - recall_m: 0.0017 - f1_m: 0.0031 - val_loss: 0.1346 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 26/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.1300 - acc: 0.9633 - precision_m: 0.0265 - recall_m: 0.0033 - f1_m: 0.0055\n",
      "Epoch 26: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1299 - acc: 0.9633 - precision_m: 0.0257 - recall_m: 0.0032 - f1_m: 0.0053 - val_loss: 0.1343 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 27/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.1299 - acc: 0.9632 - precision_m: 0.0211 - recall_m: 0.0020 - f1_m: 0.0037\n",
      "Epoch 27: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1295 - acc: 0.9633 - precision_m: 0.0205 - recall_m: 0.0020 - f1_m: 0.0036 - val_loss: 0.1346 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 28/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.1298 - acc: 0.9635 - precision_m: 0.0249 - recall_m: 0.0022 - f1_m: 0.0041 \n",
      "Epoch 28: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1297 - acc: 0.9634 - precision_m: 0.0240 - recall_m: 0.0021 - f1_m: 0.0039 - val_loss: 0.1335 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 29/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.1291 - acc: 0.9633 - precision_m: 0.0230 - recall_m: 0.0030 - f1_m: 0.0051\n",
      "Epoch 29: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1289 - acc: 0.9634 - precision_m: 0.0257 - recall_m: 0.0033 - f1_m: 0.0057 - val_loss: 0.1341 - val_acc: 0.9629 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 30/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.1280 - acc: 0.9636 - precision_m: 0.0251 - recall_m: 0.0033 - f1_m: 0.0057 \n",
      "Epoch 30: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1285 - acc: 0.9633 - precision_m: 0.0274 - recall_m: 0.0034 - f1_m: 0.0059 - val_loss: 0.1324 - val_acc: 0.9629 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Score for fold 8: loss of 0.18358008563518524; acc of 96.29851579666138%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.16459937393665314; acc of 96.54828906059265%\n",
      "Test Precision: precision_m of 0.0%\n",
      "Test Recall: recall_m of 0.0%\n",
      "Test F1: f1_m of 0.0%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "Epoch 1/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.2433 - acc: 0.9464 - precision_m: 0.0251 - recall_m: 0.0205 - f1_m: 0.0155\n",
      "Epoch 1: val_acc improved from -inf to 0.96151, saving model to models/best_model_3_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 2s 4ms/step - loss: 0.2411 - acc: 0.9470 - precision_m: 0.0239 - recall_m: 0.0196 - f1_m: 0.0148 - val_loss: 0.1709 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.1705 - acc: 0.9638 - precision_m: 0.0035 - recall_m: 1.9701e-04 - f1_m: 3.7327e-04\n",
      "Epoch 2: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1705 - acc: 0.9637 - precision_m: 0.0034 - recall_m: 1.9091e-04 - f1_m: 3.6173e-04 - val_loss: 0.1616 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 3/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.1602 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 3: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1599 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1571 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 4/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.1520 - acc: 0.9643 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 4: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1524 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1499 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 5/30\n",
      "274/291 [===========================>..] - ETA: 0s - loss: 0.1455 - acc: 0.9643 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 5: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1459 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1463 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 6/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.1420 - acc: 0.9642 - precision_m: 0.0035 - recall_m: 3.5336e-04 - f1_m: 6.4247e-04    \n",
      "Epoch 6: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1415 - acc: 0.9643 - precision_m: 0.0034 - recall_m: 3.4364e-04 - f1_m: 6.2480e-04 - val_loss: 0.1495 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 7/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.1393 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 7: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1391 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1427 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 8/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.1366 - acc: 0.9642 - precision_m: 0.0035 - recall_m: 7.0423e-04 - f1_m: 0.0012 \n",
      "Epoch 8: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1367 - acc: 0.9642 - precision_m: 0.0034 - recall_m: 6.8729e-04 - f1_m: 0.0011 - val_loss: 0.1410 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 9/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.1346 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 9: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1346 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1413 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 10/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.1336 - acc: 0.9640 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 10: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1334 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1412 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 11/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.1320 - acc: 0.9641 - precision_m: 0.0072 - recall_m: 0.0012 - f1_m: 0.0019         \n",
      "Epoch 11: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1321 - acc: 0.9642 - precision_m: 0.0069 - recall_m: 0.0011 - f1_m: 0.0019 - val_loss: 0.1400 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 12/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.1316 - acc: 0.9643 - precision_m: 0.0035 - recall_m: 3.9262e-04 - f1_m: 7.0671e-04  \n",
      "Epoch 12: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1319 - acc: 0.9641 - precision_m: 0.0034 - recall_m: 3.8183e-04 - f1_m: 6.8729e-04 - val_loss: 0.1387 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 13/30\n",
      "273/291 [===========================>..] - ETA: 0s - loss: 0.1301 - acc: 0.9641 - precision_m: 0.0147 - recall_m: 0.0015 - f1_m: 0.0026\n",
      "Epoch 13: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1300 - acc: 0.9642 - precision_m: 0.0137 - recall_m: 0.0014 - f1_m: 0.0025 - val_loss: 0.1414 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 14/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.1301 - acc: 0.9640 - precision_m: 0.0106 - recall_m: 0.0015 - f1_m: 0.0027 \n",
      "Epoch 14: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1297 - acc: 0.9642 - precision_m: 0.0137 - recall_m: 0.0020 - f1_m: 0.0034 - val_loss: 0.1410 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 15/30\n",
      "276/291 [===========================>..] - ETA: 0s - loss: 0.1276 - acc: 0.9644 - precision_m: 0.0254 - recall_m: 0.0026 - f1_m: 0.0047\n",
      "Epoch 15: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1282 - acc: 0.9643 - precision_m: 0.0241 - recall_m: 0.0025 - f1_m: 0.0045 - val_loss: 0.1381 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 16/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.1286 - acc: 0.9644 - precision_m: 0.0248 - recall_m: 0.0028 - f1_m: 0.0050\n",
      "Epoch 16: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1286 - acc: 0.9643 - precision_m: 0.0241 - recall_m: 0.0027 - f1_m: 0.0049 - val_loss: 0.1387 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 17/30\n",
      "275/291 [===========================>..] - ETA: 0s - loss: 0.1274 - acc: 0.9642 - precision_m: 0.0291 - recall_m: 0.0034 - f1_m: 0.0060\n",
      "Epoch 17: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1276 - acc: 0.9643 - precision_m: 0.0309 - recall_m: 0.0037 - f1_m: 0.0065 - val_loss: 0.1380 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 18/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.1272 - acc: 0.9644 - precision_m: 0.0484 - recall_m: 0.0058 - f1_m: 0.0102\n",
      "Epoch 18: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1275 - acc: 0.9643 - precision_m: 0.0464 - recall_m: 0.0056 - f1_m: 0.0098 - val_loss: 0.1379 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 19/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.1256 - acc: 0.9644 - precision_m: 0.0411 - recall_m: 0.0039 - f1_m: 0.0071\n",
      "Epoch 19: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1262 - acc: 0.9643 - precision_m: 0.0395 - recall_m: 0.0038 - f1_m: 0.0068 - val_loss: 0.1380 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 20/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.1258 - acc: 0.9645 - precision_m: 0.0424 - recall_m: 0.0063 - f1_m: 0.0107 \n",
      "Epoch 20: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1263 - acc: 0.9643 - precision_m: 0.0412 - recall_m: 0.0061 - f1_m: 0.0104 - val_loss: 0.1380 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 21/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.1248 - acc: 0.9644 - precision_m: 0.0569 - recall_m: 0.0072 - f1_m: 0.0125\n",
      "Epoch 21: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1251 - acc: 0.9644 - precision_m: 0.0584 - recall_m: 0.0072 - f1_m: 0.0126 - val_loss: 0.1384 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 22/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.1269 - acc: 0.9642 - precision_m: 0.0493 - recall_m: 0.0057 - f1_m: 0.0101\n",
      "Epoch 22: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1265 - acc: 0.9643 - precision_m: 0.0515 - recall_m: 0.0059 - f1_m: 0.0105 - val_loss: 0.1468 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 23/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.1247 - acc: 0.9643 - precision_m: 0.0656 - recall_m: 0.0075 - f1_m: 0.0132\n",
      "Epoch 23: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1247 - acc: 0.9643 - precision_m: 0.0636 - recall_m: 0.0072 - f1_m: 0.0127 - val_loss: 0.1376 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 24/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.1247 - acc: 0.9645 - precision_m: 0.0560 - recall_m: 0.0065 - f1_m: 0.0117\n",
      "Epoch 24: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1249 - acc: 0.9643 - precision_m: 0.0601 - recall_m: 0.0068 - f1_m: 0.0122 - val_loss: 0.1352 - val_acc: 0.9614 - val_precision_m: 0.0303 - val_recall_m: 9.4697e-04 - val_f1_m: 0.0018\n",
      "Epoch 25/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.1241 - acc: 0.9647 - precision_m: 0.1190 - recall_m: 0.0155 - f1_m: 0.0269\n",
      "Epoch 25: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1242 - acc: 0.9645 - precision_m: 0.1137 - recall_m: 0.0148 - f1_m: 0.0257 - val_loss: 0.1372 - val_acc: 0.9614 - val_precision_m: 0.0303 - val_recall_m: 9.4697e-04 - val_f1_m: 0.0018\n",
      "Epoch 26/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.1232 - acc: 0.9647 - precision_m: 0.1061 - recall_m: 0.0125 - f1_m: 0.0221\n",
      "Epoch 26: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1239 - acc: 0.9644 - precision_m: 0.1082 - recall_m: 0.0125 - f1_m: 0.0221 - val_loss: 0.1350 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 27/30\n",
      "276/291 [===========================>..] - ETA: 0s - loss: 0.1248 - acc: 0.9640 - precision_m: 0.0851 - recall_m: 0.0086 - f1_m: 0.0155\n",
      "Epoch 27: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1239 - acc: 0.9644 - precision_m: 0.0876 - recall_m: 0.0090 - f1_m: 0.0162 - val_loss: 0.1389 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 28/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.1242 - acc: 0.9643 - precision_m: 0.0747 - recall_m: 0.0101 - f1_m: 0.0174\n",
      "Epoch 28: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1243 - acc: 0.9643 - precision_m: 0.0722 - recall_m: 0.0097 - f1_m: 0.0168 - val_loss: 0.1366 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 29/30\n",
      "275/291 [===========================>..] - ETA: 0s - loss: 0.1239 - acc: 0.9643 - precision_m: 0.0945 - recall_m: 0.0109 - f1_m: 0.0193\n",
      "Epoch 29: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1236 - acc: 0.9644 - precision_m: 0.0893 - recall_m: 0.0103 - f1_m: 0.0182 - val_loss: 0.1360 - val_acc: 0.9614 - val_precision_m: 0.0303 - val_recall_m: 9.4697e-04 - val_f1_m: 0.0018\n",
      "Epoch 30/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.1223 - acc: 0.9646 - precision_m: 0.1293 - recall_m: 0.0156 - f1_m: 0.0274\n",
      "Epoch 30: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1229 - acc: 0.9645 - precision_m: 0.1249 - recall_m: 0.0151 - f1_m: 0.0264 - val_loss: 0.1357 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Score for fold 9: loss of 0.1708604097366333; acc of 96.1510956287384%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.17159852385520935; acc of 96.01516127586365%\n",
      "Test Precision: precision_m of 0.0%\n",
      "Test Recall: recall_m of 0.0%\n",
      "Test F1: f1_m of 0.0%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "Epoch 1/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.6569 - acc: 0.8850 - precision_m: 0.0295 - recall_m: 0.0839 - f1_m: 0.0312\n",
      "Epoch 1: val_acc improved from -inf to 0.96034, saving model to models/best_model_3_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 2s 4ms/step - loss: 0.6466 - acc: 0.8869 - precision_m: 0.0299 - recall_m: 0.0824 - f1_m: 0.0312 - val_loss: 0.1984 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.1984 - acc: 0.9631 - precision_m: 0.0177 - recall_m: 0.0025 - f1_m: 0.0043\n",
      "Epoch 2: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1992 - acc: 0.9629 - precision_m: 0.0171 - recall_m: 0.0024 - f1_m: 0.0042 - val_loss: 0.1728 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 3/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.1770 - acc: 0.9641 - precision_m: 0.0034 - recall_m: 2.8637e-04 - f1_m: 5.2868e-04   \n",
      "Epoch 3: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1771 - acc: 0.9640 - precision_m: 0.0034 - recall_m: 2.8539e-04 - f1_m: 5.2687e-04 - val_loss: 0.1660 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 4/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.1667 - acc: 0.9641 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 4: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1662 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1596 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 5/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.1600 - acc: 0.9640 - precision_m: 0.0071 - recall_m: 5.6829e-04 - f1_m: 0.0011   \n",
      "Epoch 5: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1598 - acc: 0.9641 - precision_m: 0.0068 - recall_m: 5.4882e-04 - f1_m: 0.0010 - val_loss: 0.1566 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 6/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.1533 - acc: 0.9644 - precision_m: 0.0035 - recall_m: 5.0480e-04 - f1_m: 8.8339e-04\n",
      "Epoch 6: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1540 - acc: 0.9641 - precision_m: 0.0034 - recall_m: 4.8924e-04 - f1_m: 8.5616e-04 - val_loss: 0.1537 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 7/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.1509 - acc: 0.9643 - precision_m: 0.0036 - recall_m: 3.2819e-04 - f1_m: 6.0168e-04\n",
      "Epoch 7: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1512 - acc: 0.9642 - precision_m: 0.0034 - recall_m: 3.1133e-04 - f1_m: 5.7078e-04 - val_loss: 0.1507 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 8/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.1469 - acc: 0.9644 - precision_m: 0.0036 - recall_m: 4.4484e-04 - f1_m: 7.9083e-04\n",
      "Epoch 8: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1473 - acc: 0.9642 - precision_m: 0.0034 - recall_m: 4.2808e-04 - f1_m: 7.6103e-04 - val_loss: 0.1480 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 9/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.1442 - acc: 0.9642 - precision_m: 0.0036 - recall_m: 4.4484e-04 - f1_m: 7.9083e-04\n",
      "Epoch 9: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1441 - acc: 0.9642 - precision_m: 0.0034 - recall_m: 4.2808e-04 - f1_m: 7.6103e-04 - val_loss: 0.1479 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 10/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.1412 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 10: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1413 - acc: 0.9642 - precision_m: 0.0034 - recall_m: 3.1133e-04 - f1_m: 5.7078e-04 - val_loss: 0.1460 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 11/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.1390 - acc: 0.9645 - precision_m: 0.0108 - recall_m: 0.0015 - f1_m: 0.0025      \n",
      "Epoch 11: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1397 - acc: 0.9642 - precision_m: 0.0103 - recall_m: 0.0014 - f1_m: 0.0024 - val_loss: 0.1453 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 12/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.1386 - acc: 0.9641 - precision_m: 0.0035 - recall_m: 3.2010e-04 - f1_m: 5.8685e-04\n",
      "Epoch 12: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1383 - acc: 0.9642 - precision_m: 0.0034 - recall_m: 3.1133e-04 - f1_m: 5.7078e-04 - val_loss: 0.1477 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 13/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.1366 - acc: 0.9642 - precision_m: 0.0036 - recall_m: 2.7375e-04 - f1_m: 5.0839e-04\n",
      "Epoch 13: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1363 - acc: 0.9642 - precision_m: 0.0034 - recall_m: 2.6344e-04 - f1_m: 4.8924e-04 - val_loss: 0.1444 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 14/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.1348 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 14: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1352 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1445 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 15/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.1339 - acc: 0.9643 - precision_m: 0.0069 - recall_m: 7.7729e-04 - f1_m: 0.0014    \n",
      "Epoch 15: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1340 - acc: 0.9643 - precision_m: 0.0068 - recall_m: 7.7462e-04 - f1_m: 0.0014 - val_loss: 0.1455 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 16/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.1329 - acc: 0.9639 - precision_m: 0.0072 - recall_m: 8.4541e-04 - f1_m: 0.0015       \n",
      "Epoch 16: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1321 - acc: 0.9643 - precision_m: 0.0068 - recall_m: 7.9909e-04 - f1_m: 0.0014 - val_loss: 0.1464 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 17/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.1309 - acc: 0.9640 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 17: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1306 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1418 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 18/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.1300 - acc: 0.9643 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 18: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1303 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1402 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 19/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.1284 - acc: 0.9644 - precision_m: 0.0070 - recall_m: 0.0011 - f1_m: 0.0019\n",
      "Epoch 19: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1286 - acc: 0.9643 - precision_m: 0.0068 - recall_m: 0.0011 - f1_m: 0.0018 - val_loss: 0.1384 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 20/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.1281 - acc: 0.9641 - precision_m: 0.0036 - recall_m: 7.1174e-04 - f1_m: 0.0012       \n",
      "Epoch 20: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1279 - acc: 0.9643 - precision_m: 0.0034 - recall_m: 6.8493e-04 - f1_m: 0.0011 - val_loss: 0.1384 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 21/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.1279 - acc: 0.9642 - precision_m: 0.0108 - recall_m: 9.5638e-04 - f1_m: 0.0018  \n",
      "Epoch 21: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1275 - acc: 0.9643 - precision_m: 0.0103 - recall_m: 9.1052e-04 - f1_m: 0.0017 - val_loss: 0.1421 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 22/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.1269 - acc: 0.9644 - precision_m: 0.0143 - recall_m: 0.0017 - f1_m: 0.0031   \n",
      "Epoch 22: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1272 - acc: 0.9643 - precision_m: 0.0137 - recall_m: 0.0017 - f1_m: 0.0029 - val_loss: 0.1384 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 23/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.1255 - acc: 0.9643 - precision_m: 0.0071 - recall_m: 7.9787e-04 - f1_m: 0.0014  \n",
      "Epoch 23: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1254 - acc: 0.9642 - precision_m: 0.0068 - recall_m: 7.7055e-04 - f1_m: 0.0014 - val_loss: 0.1380 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 24/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.1255 - acc: 0.9645 - precision_m: 0.0144 - recall_m: 0.0014 - f1_m: 0.0026       \n",
      "Epoch 24: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1259 - acc: 0.9643 - precision_m: 0.0223 - recall_m: 0.0022 - f1_m: 0.0040 - val_loss: 0.1381 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 25/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.1261 - acc: 0.9643 - precision_m: 0.0213 - recall_m: 0.0020 - f1_m: 0.0036\n",
      "Epoch 25: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1259 - acc: 0.9643 - precision_m: 0.0205 - recall_m: 0.0019 - f1_m: 0.0034 - val_loss: 0.1393 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 26/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.1251 - acc: 0.9643 - precision_m: 0.0178 - recall_m: 0.0023 - f1_m: 0.0040\n",
      "Epoch 26: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1251 - acc: 0.9643 - precision_m: 0.0205 - recall_m: 0.0026 - f1_m: 0.0045 - val_loss: 0.1375 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 27/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.1249 - acc: 0.9641 - precision_m: 0.0248 - recall_m: 0.0028 - f1_m: 0.0050   \n",
      "Epoch 27: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1247 - acc: 0.9642 - precision_m: 0.0274 - recall_m: 0.0031 - f1_m: 0.0055 - val_loss: 0.1383 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 28/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.1244 - acc: 0.9642 - precision_m: 0.0442 - recall_m: 0.0045 - f1_m: 0.0080 \n",
      "Epoch 28: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1245 - acc: 0.9643 - precision_m: 0.0428 - recall_m: 0.0043 - f1_m: 0.0078 - val_loss: 0.1374 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 29/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.1248 - acc: 0.9641 - precision_m: 0.0399 - recall_m: 0.0048 - f1_m: 0.0084\n",
      "Epoch 29: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1246 - acc: 0.9642 - precision_m: 0.0451 - recall_m: 0.0053 - f1_m: 0.0092 - val_loss: 0.1402 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 30/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.1234 - acc: 0.9642 - precision_m: 0.0687 - recall_m: 0.0086 - f1_m: 0.0150\n",
      "Epoch 30: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1236 - acc: 0.9642 - precision_m: 0.0668 - recall_m: 0.0084 - f1_m: 0.0146 - val_loss: 0.1373 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Score for fold 10: loss of 0.1984279453754425; acc of 96.03365659713745%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.20417483150959015; acc of 96.1128830909729%\n",
      "Test Precision: precision_m of 0.0%\n",
      "Test Recall: recall_m of 0.0%\n",
      "Test F1: f1_m of 0.0%\n",
      "------------------------------------------------------------------------\n",
      "Validation score per fold\n",
      "> Fold 1 - Loss: 0.1741141378879547 - Accuracy: 96.02293372154236%\n",
      "> Fold 2 - Loss: 0.15798361599445343 - Accuracy: 96.335768699646%\n",
      "> Fold 3 - Loss: 0.13756074011325836 - Accuracy: 96.37038707733154%\n",
      "> Fold 4 - Loss: 0.17402151226997375 - Accuracy: 96.14328145980835%\n",
      "> Fold 5 - Loss: 0.13400809466838837 - Accuracy: 96.2471604347229%\n",
      "> Fold 6 - Loss: 0.17147700488567352 - Accuracy: 96.05881571769714%\n",
      "> Fold 7 - Loss: 0.1566990166902542 - Accuracy: 96.24850749969482%\n",
      "> Fold 8 - Loss: 0.18358008563518524 - Accuracy: 96.29851579666138%\n",
      "> Fold 9 - Loss: 0.1708604097366333 - Accuracy: 96.1510956287384%\n",
      "> Fold 10 - Loss: 0.1984279453754425 - Accuracy: 96.03365659713745%\n",
      "------------------------------------------------------------------------\n",
      "Testing score per fold\n",
      "> Fold 1 - Accuracy: 97.27052450180054 - Precision: 0.0 - Recall: 0.0 - F1: 0.0%\n",
      "> Fold 2 - Accuracy: 95.75244188308716 - Precision: 0.0 - Recall: 0.0 - F1: 0.0%\n",
      "> Fold 3 - Accuracy: 96.51274681091309 - Precision: 0.6802720483392477 - Recall: 0.29478457290679216 - F1: 0.38548747543245554%\n",
      "> Fold 4 - Accuracy: 95.7481324672699 - Precision: 0.0 - Recall: 0.0 - F1: 0.0%\n",
      "> Fold 5 - Accuracy: 96.28443121910095 - Precision: 0.0 - Recall: 0.0 - F1: 0.0%\n",
      "> Fold 6 - Accuracy: 96.38698697090149 - Precision: 0.0 - Recall: 0.0 - F1: 0.0%\n",
      "> Fold 7 - Accuracy: 96.93064093589783 - Precision: 0.0 - Recall: 0.0 - F1: 0.0%\n",
      "> Fold 8 - Accuracy: 96.54828906059265 - Precision: 0.0 - Recall: 0.0 - F1: 0.0%\n",
      "> Fold 9 - Accuracy: 96.01516127586365 - Precision: 0.0 - Recall: 0.0 - F1: 0.0%\n",
      "> Fold 10 - Accuracy: 96.1128830909729 - Precision: 0.0 - Recall: 0.0 - F1: 0.0%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Validation Accuracy: 96.19101226329803 (+- 0.12062494546266181)\n",
      "> Validation Loss: 0.16587325632572175\n",
      "> Testing Accuracy: 96.35622382164001 (+- 0.46295311880647094)\n",
      "> Testing Precision: 0.06802720483392477\n",
      "> Testing Recall: 0.029478457290679216\n",
      "> Testing F1: 0.038548747543245554\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Lists to hold cross-validation results\n",
    "acc_3_per_fold = []\n",
    "loss_3_per_fold = []\n",
    "precision_3_per_fold = []\n",
    "recall_3_per_fold = []\n",
    "f1_3_per_fold = []\n",
    "\n",
    "testing_acc_3_per_fold = []\n",
    "testing_precision_3_per_fold = []\n",
    "testing_recall_3_per_fold = []\n",
    "testing_f1_3_per_fold = []\n",
    "\n",
    "# Load data from .npz files\n",
    "for fold_no in range(1, 11):\n",
    "    with np.load(f'fold_{fold_no}.npz') as data:\n",
    "        x_train = data['x_train_fold.npy']\n",
    "        y_train = data['y_train_fold.npy']\n",
    "        x_val = data['x_val_fold.npy']\n",
    "        y_val = data['y_val_fold.npy']\n",
    "        x_test = data['x_test_fold.npy']\n",
    "        y_test = data['y_test_fold.npy']\n",
    "        \n",
    "        # Converting ground truth arrays to one wake word (1) and 'other' (0)\n",
    "        wake_word_index = all_targets.index(wake_word)\n",
    "        y_train = np.equal(y_train, wake_word_index).astype('float64')\n",
    "        y_val = np.equal(y_val, wake_word_index).astype('float64')\n",
    "        y_test = np.equal(y_test, wake_word_index).astype('float64')\n",
    "        \n",
    "        # CNN for TF expects (batch, height, width, channels)\n",
    "        x_train = x_train.reshape(x_train.shape[0], \n",
    "                          x_train.shape[1], \n",
    "                          x_train.shape[2], \n",
    "                          1)\n",
    "        x_val = x_val.reshape(x_val.shape[0], \n",
    "                          x_val.shape[1], \n",
    "                          x_val.shape[2], \n",
    "                          1)\n",
    "        x_test = x_test.reshape(x_test.shape[0], \n",
    "                          x_test.shape[1], \n",
    "                          x_test.shape[2], \n",
    "                          1)\n",
    "        sample_shape = x_test.shape[1:]\n",
    "\n",
    "    # CNN model\n",
    "    model_3 = models.Sequential()\n",
    "    model_3.add(layers.Conv2D(16,\n",
    "                              (3,3),\n",
    "                              activation=\"relu\",\n",
    "                              input_shape=sample_shape))\n",
    "    model_3.add(layers.MaxPooling2D(pool_size=(8, 8)))\n",
    "    \n",
    "    model_3.add(layers.Flatten())\n",
    "    model_3.add(layers.Dense(16, activation='relu'))\n",
    "    model_3.add(layers.Dropout(0.3))\n",
    "    model_3.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "\n",
    "    model_3.compile(loss='binary_crossentropy', \n",
    "              optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "              metrics=['acc', precision_m, recall_m, f1_m])\n",
    "\n",
    "    checkpoint_filepath = f'models/best_model_3_fold_{fold_no}.h5'\n",
    "    model_checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=False,\n",
    "        monitor='val_acc',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "        save_freq='epoch'\n",
    "    )\n",
    "\n",
    "    # Instantiate the custom callback\n",
    "    metrics_history = MetricsHistory()\n",
    "\n",
    "    # Print fold number\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Train\n",
    "    history_3 = model_3.fit(x_train, \n",
    "                    y_train, \n",
    "                    epochs=30, \n",
    "                    batch_size=256, \n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[model_checkpoint_callback, metrics_history])\n",
    "\n",
    "    model_3.load_weights(checkpoint_filepath)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    scores = model_3.evaluate(x_val, y_val, verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model_3.metrics_names[0]} of {scores[0]}; {model_3.metrics_names[1]} of {scores[1] * 100}%')\n",
    "    acc_3_per_fold.append(scores[1] * 100)\n",
    "    loss_3_per_fold.append(scores[0])\n",
    "    precision_3_per_fold.append(metrics_history.best_metrics['precision_m'] * 100)\n",
    "    recall_3_per_fold.append(metrics_history.best_metrics['recall_m'] * 100)\n",
    "    f1_3_per_fold.append(metrics_history.best_metrics['f1_m'] * 100)\n",
    "\n",
    "    # Final evaluation on test set\n",
    "    final_scores = model_3.evaluate(x_test, y_test, verbose=0)\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Final test score: {model_3.metrics_names[0]} of {final_scores[0]}; {model_3.metrics_names[1]} of {final_scores[1] * 100}%')\n",
    "    print(f'Test Precision: {model_3.metrics_names[2]} of {final_scores[2] * 100}%')\n",
    "    print(f'Test Recall: {model_3.metrics_names[3]} of {final_scores[3] * 100}%')\n",
    "    print(f'Test F1: {model_3.metrics_names[4]} of {final_scores[4] * 100}%')\n",
    "\n",
    "    # Append test metrics to lists\n",
    "    testing_acc_3_per_fold.append(final_scores[1] * 100)\n",
    "    testing_precision_3_per_fold.append(final_scores[2] * 100)\n",
    "    testing_recall_3_per_fold.append(final_scores[3] * 100)\n",
    "    testing_f1_3_per_fold.append(final_scores[4] * 100)\n",
    "\n",
    "# Print the results\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Validation score per fold')\n",
    "for i in range(0, len(acc_3_per_fold)):\n",
    "    print(f'> Fold {i+1} - Loss: {loss_3_per_fold[i]} - Accuracy: {acc_3_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Testing score per fold')\n",
    "for i in range(0, len(testing_acc_3_per_fold)):\n",
    "    print(f'> Fold {i+1} - Accuracy: {testing_acc_3_per_fold[i]} - Precision: {testing_precision_3_per_fold[i]} - Recall: {testing_recall_3_per_fold[i]} - F1: {testing_f1_3_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Validation Accuracy: {np.mean(acc_3_per_fold)} (+- {np.std(acc_3_per_fold)})')\n",
    "print(f'> Validation Loss: {np.mean(loss_3_per_fold)}')\n",
    "print(f'> Testing Accuracy: {np.mean(testing_acc_3_per_fold)} (+- {np.std(testing_acc_3_per_fold)})')\n",
    "print(f'> Testing Precision: {np.mean(testing_precision_3_per_fold)}')\n",
    "print(f'> Testing Recall: {np.mean(testing_recall_3_per_fold)}')\n",
    "print(f'> Testing F1: {np.mean(testing_f1_3_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1835 - acc: 0.9523 - precision_m: 6.2094e-04 - recall_m: 0.0117 - f1_m: 0.0012\n",
      "Epoch 1: val_acc improved from -inf to 0.96023, saving model to models/best_model_4_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 2s 4ms/step - loss: 0.1835 - acc: 0.9523 - precision_m: 6.2094e-04 - recall_m: 0.0117 - f1_m: 0.0012 - val_loss: 0.1299 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.1081 - acc: 0.9643 - precision_m: 0.2915 - recall_m: 0.0669 - f1_m: 0.1037\n",
      "Epoch 2: val_acc improved from 0.96023 to 0.96501, saving model to models/best_model_4_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1079 - acc: 0.9644 - precision_m: 0.3047 - recall_m: 0.0736 - f1_m: 0.1121 - val_loss: 0.1066 - val_acc: 0.9650 - val_precision_m: 0.5652 - val_recall_m: 0.1455 - val_f1_m: 0.2200\n",
      "Epoch 3/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0902 - acc: 0.9691 - precision_m: 0.6784 - recall_m: 0.2923 - f1_m: 0.3822\n",
      "Epoch 3: val_acc improved from 0.96501 to 0.96751, saving model to models/best_model_4_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0909 - acc: 0.9690 - precision_m: 0.6794 - recall_m: 0.2954 - f1_m: 0.3856 - val_loss: 0.0965 - val_acc: 0.9675 - val_precision_m: 0.6732 - val_recall_m: 0.2250 - val_f1_m: 0.3194\n",
      "Epoch 4/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0841 - acc: 0.9713 - precision_m: 0.7417 - recall_m: 0.3721 - f1_m: 0.4652\n",
      "Epoch 4: val_acc improved from 0.96751 to 0.97014, saving model to models/best_model_4_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0839 - acc: 0.9714 - precision_m: 0.7406 - recall_m: 0.3763 - f1_m: 0.4673 - val_loss: 0.0877 - val_acc: 0.9701 - val_precision_m: 0.6835 - val_recall_m: 0.3900 - val_f1_m: 0.4728\n",
      "Epoch 5/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0769 - acc: 0.9738 - precision_m: 0.7686 - recall_m: 0.4332 - f1_m: 0.5224\n",
      "Epoch 5: val_acc did not improve from 0.97014\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0771 - acc: 0.9737 - precision_m: 0.7698 - recall_m: 0.4357 - f1_m: 0.5250 - val_loss: 0.0863 - val_acc: 0.9698 - val_precision_m: 0.7307 - val_recall_m: 0.3068 - val_f1_m: 0.4041\n",
      "Epoch 6/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0718 - acc: 0.9754 - precision_m: 0.7860 - recall_m: 0.4618 - f1_m: 0.5546\n",
      "Epoch 6: val_acc improved from 0.97014 to 0.97038, saving model to models/best_model_4_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0726 - acc: 0.9753 - precision_m: 0.7835 - recall_m: 0.4615 - f1_m: 0.5537 - val_loss: 0.0871 - val_acc: 0.9704 - val_precision_m: 0.8043 - val_recall_m: 0.2918 - val_f1_m: 0.4034\n",
      "Epoch 7/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0708 - acc: 0.9751 - precision_m: 0.7835 - recall_m: 0.4811 - f1_m: 0.5666\n",
      "Epoch 7: val_acc improved from 0.97038 to 0.97301, saving model to models/best_model_4_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0707 - acc: 0.9750 - precision_m: 0.7805 - recall_m: 0.4808 - f1_m: 0.5660 - val_loss: 0.0803 - val_acc: 0.9730 - val_precision_m: 0.7652 - val_recall_m: 0.4500 - val_f1_m: 0.5357\n",
      "Epoch 8/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0689 - acc: 0.9758 - precision_m: 0.7961 - recall_m: 0.4968 - f1_m: 0.5798\n",
      "Epoch 8: val_acc did not improve from 0.97301\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0686 - acc: 0.9759 - precision_m: 0.7981 - recall_m: 0.4967 - f1_m: 0.5796 - val_loss: 0.0786 - val_acc: 0.9721 - val_precision_m: 0.6804 - val_recall_m: 0.5163 - val_f1_m: 0.5538\n",
      "Epoch 9/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0656 - acc: 0.9773 - precision_m: 0.7970 - recall_m: 0.5378 - f1_m: 0.6140\n",
      "Epoch 9: val_acc improved from 0.97301 to 0.97396, saving model to models/best_model_4_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0652 - acc: 0.9774 - precision_m: 0.7998 - recall_m: 0.5382 - f1_m: 0.6154 - val_loss: 0.0763 - val_acc: 0.9740 - val_precision_m: 0.7219 - val_recall_m: 0.5216 - val_f1_m: 0.5764\n",
      "Epoch 10/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0650 - acc: 0.9777 - precision_m: 0.8090 - recall_m: 0.5376 - f1_m: 0.6152\n",
      "Epoch 10: val_acc did not improve from 0.97396\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0651 - acc: 0.9777 - precision_m: 0.8083 - recall_m: 0.5389 - f1_m: 0.6167 - val_loss: 0.0783 - val_acc: 0.9734 - val_precision_m: 0.7788 - val_recall_m: 0.4388 - val_f1_m: 0.5300\n",
      "Epoch 11/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0613 - acc: 0.9786 - precision_m: 0.8191 - recall_m: 0.5670 - f1_m: 0.6464\n",
      "Epoch 11: val_acc improved from 0.97396 to 0.97516, saving model to models/best_model_4_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0612 - acc: 0.9787 - precision_m: 0.8212 - recall_m: 0.5639 - f1_m: 0.6447 - val_loss: 0.0763 - val_acc: 0.9752 - val_precision_m: 0.7414 - val_recall_m: 0.5148 - val_f1_m: 0.5760\n",
      "Epoch 12/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0600 - acc: 0.9796 - precision_m: 0.8303 - recall_m: 0.5821 - f1_m: 0.6609\n",
      "Epoch 12: val_acc did not improve from 0.97516\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0600 - acc: 0.9795 - precision_m: 0.8280 - recall_m: 0.5820 - f1_m: 0.6599 - val_loss: 0.0905 - val_acc: 0.9710 - val_precision_m: 0.7620 - val_recall_m: 0.3140 - val_f1_m: 0.4116\n",
      "Epoch 13/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9793 - precision_m: 0.8292 - recall_m: 0.5773 - f1_m: 0.6535\n",
      "Epoch 13: val_acc did not improve from 0.97516\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0599 - acc: 0.9793 - precision_m: 0.8308 - recall_m: 0.5773 - f1_m: 0.6537 - val_loss: 0.0756 - val_acc: 0.9750 - val_precision_m: 0.7208 - val_recall_m: 0.5848 - val_f1_m: 0.6142\n",
      "Epoch 14/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0584 - acc: 0.9799 - precision_m: 0.8294 - recall_m: 0.5969 - f1_m: 0.6671\n",
      "Epoch 14: val_acc did not improve from 0.97516\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0583 - acc: 0.9800 - precision_m: 0.8292 - recall_m: 0.5982 - f1_m: 0.6680 - val_loss: 0.0866 - val_acc: 0.9737 - val_precision_m: 0.8799 - val_recall_m: 0.3864 - val_f1_m: 0.5064\n",
      "Epoch 15/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.0585 - acc: 0.9800 - precision_m: 0.8337 - recall_m: 0.5994 - f1_m: 0.6703\n",
      "Epoch 15: val_acc did not improve from 0.97516\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0587 - acc: 0.9799 - precision_m: 0.8329 - recall_m: 0.6000 - f1_m: 0.6711 - val_loss: 0.0772 - val_acc: 0.9750 - val_precision_m: 0.7972 - val_recall_m: 0.4593 - val_f1_m: 0.5521\n",
      "Epoch 16/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0550 - acc: 0.9813 - precision_m: 0.8432 - recall_m: 0.6225 - f1_m: 0.6954\n",
      "Epoch 16: val_acc did not improve from 0.97516\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0547 - acc: 0.9813 - precision_m: 0.8449 - recall_m: 0.6195 - f1_m: 0.6938 - val_loss: 0.0737 - val_acc: 0.9746 - val_precision_m: 0.7214 - val_recall_m: 0.5576 - val_f1_m: 0.5961\n",
      "Epoch 17/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0535 - acc: 0.9811 - precision_m: 0.8266 - recall_m: 0.6169 - f1_m: 0.6872\n",
      "Epoch 17: val_acc did not improve from 0.97516\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0537 - acc: 0.9811 - precision_m: 0.8257 - recall_m: 0.6181 - f1_m: 0.6881 - val_loss: 0.0721 - val_acc: 0.9748 - val_precision_m: 0.7039 - val_recall_m: 0.5630 - val_f1_m: 0.5940\n",
      "Epoch 18/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0535 - acc: 0.9815 - precision_m: 0.8413 - recall_m: 0.6326 - f1_m: 0.7039\n",
      "Epoch 18: val_acc did not improve from 0.97516\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0533 - acc: 0.9815 - precision_m: 0.8401 - recall_m: 0.6309 - f1_m: 0.7025 - val_loss: 0.0842 - val_acc: 0.9748 - val_precision_m: 0.8201 - val_recall_m: 0.4350 - val_f1_m: 0.5390\n",
      "Epoch 19/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0528 - acc: 0.9819 - precision_m: 0.8502 - recall_m: 0.6410 - f1_m: 0.7097\n",
      "Epoch 19: val_acc did not improve from 0.97516\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0530 - acc: 0.9819 - precision_m: 0.8494 - recall_m: 0.6397 - f1_m: 0.7086 - val_loss: 0.0745 - val_acc: 0.9749 - val_precision_m: 0.7352 - val_recall_m: 0.5231 - val_f1_m: 0.5791\n",
      "Epoch 20/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0504 - acc: 0.9822 - precision_m: 0.8444 - recall_m: 0.6489 - f1_m: 0.7151\n",
      "Epoch 20: val_acc improved from 0.97516 to 0.97647, saving model to models/best_model_4_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0513 - acc: 0.9820 - precision_m: 0.8469 - recall_m: 0.6476 - f1_m: 0.7145 - val_loss: 0.0784 - val_acc: 0.9765 - val_precision_m: 0.8081 - val_recall_m: 0.4697 - val_f1_m: 0.5671\n",
      "Epoch 21/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9828 - precision_m: 0.8586 - recall_m: 0.6563 - f1_m: 0.7226\n",
      "Epoch 21: val_acc did not improve from 0.97647\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0505 - acc: 0.9828 - precision_m: 0.8561 - recall_m: 0.6534 - f1_m: 0.7202 - val_loss: 0.0725 - val_acc: 0.9764 - val_precision_m: 0.7969 - val_recall_m: 0.5177 - val_f1_m: 0.5983\n",
      "Epoch 22/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0494 - acc: 0.9830 - precision_m: 0.8602 - recall_m: 0.6645 - f1_m: 0.7305\n",
      "Epoch 22: val_acc did not improve from 0.97647\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0494 - acc: 0.9830 - precision_m: 0.8609 - recall_m: 0.6623 - f1_m: 0.7290 - val_loss: 0.0766 - val_acc: 0.9730 - val_precision_m: 0.6199 - val_recall_m: 0.6198 - val_f1_m: 0.5947\n",
      "Epoch 23/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9830 - precision_m: 0.8621 - recall_m: 0.6637 - f1_m: 0.7297\n",
      "Epoch 23: val_acc improved from 0.97647 to 0.97671, saving model to models/best_model_4_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0494 - acc: 0.9831 - precision_m: 0.8625 - recall_m: 0.6667 - f1_m: 0.7319 - val_loss: 0.0738 - val_acc: 0.9767 - val_precision_m: 0.7393 - val_recall_m: 0.5753 - val_f1_m: 0.6238\n",
      "Epoch 24/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9835 - precision_m: 0.8667 - recall_m: 0.6630 - f1_m: 0.7324\n",
      "Epoch 24: val_acc improved from 0.97671 to 0.97802, saving model to models/best_model_4_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0481 - acc: 0.9835 - precision_m: 0.8632 - recall_m: 0.6626 - f1_m: 0.7310 - val_loss: 0.0780 - val_acc: 0.9780 - val_precision_m: 0.8377 - val_recall_m: 0.5251 - val_f1_m: 0.6183\n",
      "Epoch 25/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0485 - acc: 0.9835 - precision_m: 0.8622 - recall_m: 0.6812 - f1_m: 0.7402\n",
      "Epoch 25: val_acc did not improve from 0.97802\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0484 - acc: 0.9835 - precision_m: 0.8604 - recall_m: 0.6801 - f1_m: 0.7393 - val_loss: 0.0759 - val_acc: 0.9750 - val_precision_m: 0.6491 - val_recall_m: 0.6303 - val_f1_m: 0.6214\n",
      "Epoch 26/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0465 - acc: 0.9841 - precision_m: 0.8632 - recall_m: 0.6922 - f1_m: 0.7504\n",
      "Epoch 26: val_acc did not improve from 0.97802\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0464 - acc: 0.9842 - precision_m: 0.8652 - recall_m: 0.6923 - f1_m: 0.7516 - val_loss: 0.0711 - val_acc: 0.9777 - val_precision_m: 0.7166 - val_recall_m: 0.6308 - val_f1_m: 0.6425\n",
      "Epoch 27/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0453 - acc: 0.9846 - precision_m: 0.8678 - recall_m: 0.6980 - f1_m: 0.7551\n",
      "Epoch 27: val_acc did not improve from 0.97802\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0454 - acc: 0.9845 - precision_m: 0.8672 - recall_m: 0.6957 - f1_m: 0.7533 - val_loss: 0.0702 - val_acc: 0.9767 - val_precision_m: 0.6768 - val_recall_m: 0.6497 - val_f1_m: 0.6408\n",
      "Epoch 28/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0464 - acc: 0.9841 - precision_m: 0.8609 - recall_m: 0.6860 - f1_m: 0.7457\n",
      "Epoch 28: val_acc did not improve from 0.97802\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0467 - acc: 0.9839 - precision_m: 0.8586 - recall_m: 0.6826 - f1_m: 0.7417 - val_loss: 0.0728 - val_acc: 0.9777 - val_precision_m: 0.7737 - val_recall_m: 0.5780 - val_f1_m: 0.6312\n",
      "Epoch 29/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0448 - acc: 0.9842 - precision_m: 0.8576 - recall_m: 0.6951 - f1_m: 0.7502\n",
      "Epoch 29: val_acc did not improve from 0.97802\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0450 - acc: 0.9842 - precision_m: 0.8576 - recall_m: 0.6949 - f1_m: 0.7502 - val_loss: 0.0713 - val_acc: 0.9756 - val_precision_m: 0.7171 - val_recall_m: 0.5820 - val_f1_m: 0.6113\n",
      "Epoch 30/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0450 - acc: 0.9848 - precision_m: 0.8776 - recall_m: 0.7036 - f1_m: 0.7589\n",
      "Epoch 30: val_acc did not improve from 0.97802\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0454 - acc: 0.9846 - precision_m: 0.8766 - recall_m: 0.6991 - f1_m: 0.7556 - val_loss: 0.0888 - val_acc: 0.9748 - val_precision_m: 0.8530 - val_recall_m: 0.4220 - val_f1_m: 0.5291\n",
      "Score for fold 1: loss of 0.07800406962633133; acc of 97.80246019363403%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.0502900667488575; acc of 98.44816327095032%\n",
      "Test Precision: precision_m of 24.17840212583542%\n",
      "Test Recall: recall_m of 18.54557991027832%\n",
      "Test F1: f1_m of 20.06351500749588%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.1525 - acc: 0.9603 - precision_m: 0.0815 - recall_m: 0.0187 - f1_m: 0.0243\n",
      "Epoch 1: val_acc improved from -inf to 0.96408, saving model to models/best_model_4_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 2s 4ms/step - loss: 0.1525 - acc: 0.9603 - precision_m: 0.0815 - recall_m: 0.0187 - f1_m: 0.0243 - val_loss: 0.1116 - val_acc: 0.9641 - val_precision_m: 0.3626 - val_recall_m: 0.0877 - val_f1_m: 0.1334\n",
      "Epoch 2/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0971 - acc: 0.9680 - precision_m: 0.6269 - recall_m: 0.2069 - f1_m: 0.2868\n",
      "Epoch 2: val_acc improved from 0.96408 to 0.96779, saving model to models/best_model_4_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0968 - acc: 0.9681 - precision_m: 0.6303 - recall_m: 0.2078 - f1_m: 0.2886 - val_loss: 0.0935 - val_acc: 0.9678 - val_precision_m: 0.5571 - val_recall_m: 0.1971 - val_f1_m: 0.2791\n",
      "Epoch 3/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0827 - acc: 0.9720 - precision_m: 0.7267 - recall_m: 0.3477 - f1_m: 0.4420\n",
      "Epoch 3: val_acc improved from 0.96779 to 0.96923, saving model to models/best_model_4_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0827 - acc: 0.9720 - precision_m: 0.7240 - recall_m: 0.3495 - f1_m: 0.4432 - val_loss: 0.0884 - val_acc: 0.9692 - val_precision_m: 0.6663 - val_recall_m: 0.2028 - val_f1_m: 0.2957\n",
      "Epoch 4/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0768 - acc: 0.9741 - precision_m: 0.7521 - recall_m: 0.4201 - f1_m: 0.5076\n",
      "Epoch 4: val_acc improved from 0.96923 to 0.97485, saving model to models/best_model_4_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0766 - acc: 0.9742 - precision_m: 0.7529 - recall_m: 0.4168 - f1_m: 0.5046 - val_loss: 0.0787 - val_acc: 0.9749 - val_precision_m: 0.7912 - val_recall_m: 0.3986 - val_f1_m: 0.4999\n",
      "Epoch 5/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0722 - acc: 0.9756 - precision_m: 0.7881 - recall_m: 0.4641 - f1_m: 0.5488\n",
      "Epoch 5: val_acc did not improve from 0.97485\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0720 - acc: 0.9756 - precision_m: 0.7870 - recall_m: 0.4658 - f1_m: 0.5498 - val_loss: 0.0775 - val_acc: 0.9749 - val_precision_m: 0.7080 - val_recall_m: 0.4771 - val_f1_m: 0.5355\n",
      "Epoch 6/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0677 - acc: 0.9772 - precision_m: 0.8012 - recall_m: 0.4950 - f1_m: 0.5818\n",
      "Epoch 6: val_acc improved from 0.97485 to 0.97617, saving model to models/best_model_4_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0676 - acc: 0.9772 - precision_m: 0.8001 - recall_m: 0.4969 - f1_m: 0.5829 - val_loss: 0.0736 - val_acc: 0.9762 - val_precision_m: 0.7588 - val_recall_m: 0.4582 - val_f1_m: 0.5364\n",
      "Epoch 7/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0683 - acc: 0.9768 - precision_m: 0.7965 - recall_m: 0.5005 - f1_m: 0.5780\n",
      "Epoch 7: val_acc did not improve from 0.97617\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0681 - acc: 0.9768 - precision_m: 0.7957 - recall_m: 0.4988 - f1_m: 0.5768 - val_loss: 0.0721 - val_acc: 0.9755 - val_precision_m: 0.7090 - val_recall_m: 0.5163 - val_f1_m: 0.5730\n",
      "Epoch 8/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9782 - precision_m: 0.8000 - recall_m: 0.5310 - f1_m: 0.6133\n",
      "Epoch 8: val_acc did not improve from 0.97617\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0626 - acc: 0.9783 - precision_m: 0.7998 - recall_m: 0.5311 - f1_m: 0.6135 - val_loss: 0.0750 - val_acc: 0.9750 - val_precision_m: 0.8267 - val_recall_m: 0.3498 - val_f1_m: 0.4684\n",
      "Epoch 9/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9794 - precision_m: 0.8192 - recall_m: 0.5632 - f1_m: 0.6453\n",
      "Epoch 9: val_acc did not improve from 0.97617\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0598 - acc: 0.9794 - precision_m: 0.8182 - recall_m: 0.5622 - f1_m: 0.6447 - val_loss: 0.0803 - val_acc: 0.9728 - val_precision_m: 0.7701 - val_recall_m: 0.3304 - val_f1_m: 0.4311\n",
      "Epoch 10/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0579 - acc: 0.9800 - precision_m: 0.8272 - recall_m: 0.5641 - f1_m: 0.6477\n",
      "Epoch 10: val_acc improved from 0.97617 to 0.97629, saving model to models/best_model_4_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0579 - acc: 0.9801 - precision_m: 0.8268 - recall_m: 0.5671 - f1_m: 0.6490 - val_loss: 0.0724 - val_acc: 0.9763 - val_precision_m: 0.8096 - val_recall_m: 0.4320 - val_f1_m: 0.5336\n",
      "Epoch 11/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0587 - acc: 0.9799 - precision_m: 0.8342 - recall_m: 0.5698 - f1_m: 0.6509\n",
      "Epoch 11: val_acc improved from 0.97629 to 0.97761, saving model to models/best_model_4_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0583 - acc: 0.9801 - precision_m: 0.8348 - recall_m: 0.5723 - f1_m: 0.6530 - val_loss: 0.0666 - val_acc: 0.9776 - val_precision_m: 0.7761 - val_recall_m: 0.4723 - val_f1_m: 0.5591\n",
      "Epoch 12/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0576 - acc: 0.9799 - precision_m: 0.8235 - recall_m: 0.5796 - f1_m: 0.6513\n",
      "Epoch 12: val_acc improved from 0.97761 to 0.97809, saving model to models/best_model_4_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0575 - acc: 0.9799 - precision_m: 0.8241 - recall_m: 0.5801 - f1_m: 0.6522 - val_loss: 0.0678 - val_acc: 0.9781 - val_precision_m: 0.7262 - val_recall_m: 0.5510 - val_f1_m: 0.5979\n",
      "Epoch 13/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.0543 - acc: 0.9813 - precision_m: 0.8236 - recall_m: 0.6003 - f1_m: 0.6721\n",
      "Epoch 13: val_acc did not improve from 0.97809\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0548 - acc: 0.9811 - precision_m: 0.8235 - recall_m: 0.5962 - f1_m: 0.6685 - val_loss: 0.0712 - val_acc: 0.9745 - val_precision_m: 0.6141 - val_recall_m: 0.6574 - val_f1_m: 0.6106\n",
      "Epoch 14/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0545 - acc: 0.9810 - precision_m: 0.8306 - recall_m: 0.6084 - f1_m: 0.6768\n",
      "Epoch 14: val_acc did not improve from 0.97809\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0543 - acc: 0.9811 - precision_m: 0.8321 - recall_m: 0.6099 - f1_m: 0.6781 - val_loss: 0.0694 - val_acc: 0.9775 - val_precision_m: 0.7893 - val_recall_m: 0.4250 - val_f1_m: 0.5302\n",
      "Epoch 15/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0515 - acc: 0.9824 - precision_m: 0.8568 - recall_m: 0.6330 - f1_m: 0.7076\n",
      "Epoch 15: val_acc improved from 0.97809 to 0.97964, saving model to models/best_model_4_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0514 - acc: 0.9824 - precision_m: 0.8574 - recall_m: 0.6313 - f1_m: 0.7064 - val_loss: 0.0634 - val_acc: 0.9796 - val_precision_m: 0.8081 - val_recall_m: 0.5372 - val_f1_m: 0.6121\n",
      "Epoch 16/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9824 - precision_m: 0.8390 - recall_m: 0.6295 - f1_m: 0.7009\n",
      "Epoch 16: val_acc did not improve from 0.97964\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0499 - acc: 0.9824 - precision_m: 0.8390 - recall_m: 0.6298 - f1_m: 0.7012 - val_loss: 0.0666 - val_acc: 0.9775 - val_precision_m: 0.7230 - val_recall_m: 0.5492 - val_f1_m: 0.5986\n",
      "Epoch 17/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9828 - precision_m: 0.8545 - recall_m: 0.6486 - f1_m: 0.7156\n",
      "Epoch 17: val_acc did not improve from 0.97964\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0499 - acc: 0.9829 - precision_m: 0.8537 - recall_m: 0.6504 - f1_m: 0.7167 - val_loss: 0.0682 - val_acc: 0.9796 - val_precision_m: 0.7681 - val_recall_m: 0.5570 - val_f1_m: 0.6134\n",
      "Epoch 18/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0491 - acc: 0.9828 - precision_m: 0.8426 - recall_m: 0.6475 - f1_m: 0.7124\n",
      "Epoch 18: val_acc did not improve from 0.97964\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0490 - acc: 0.9828 - precision_m: 0.8400 - recall_m: 0.6487 - f1_m: 0.7122 - val_loss: 0.0775 - val_acc: 0.9769 - val_precision_m: 0.8525 - val_recall_m: 0.4143 - val_f1_m: 0.5334\n",
      "Epoch 19/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0485 - acc: 0.9832 - precision_m: 0.8519 - recall_m: 0.6572 - f1_m: 0.7238\n",
      "Epoch 19: val_acc did not improve from 0.97964\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0484 - acc: 0.9831 - precision_m: 0.8511 - recall_m: 0.6580 - f1_m: 0.7240 - val_loss: 0.0621 - val_acc: 0.9792 - val_precision_m: 0.7186 - val_recall_m: 0.5854 - val_f1_m: 0.6191\n",
      "Epoch 20/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0485 - acc: 0.9832 - precision_m: 0.8520 - recall_m: 0.6508 - f1_m: 0.7176\n",
      "Epoch 20: val_acc did not improve from 0.97964\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0484 - acc: 0.9833 - precision_m: 0.8520 - recall_m: 0.6529 - f1_m: 0.7190 - val_loss: 0.0691 - val_acc: 0.9772 - val_precision_m: 0.7855 - val_recall_m: 0.4775 - val_f1_m: 0.5702\n",
      "Epoch 21/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9833 - precision_m: 0.8542 - recall_m: 0.6589 - f1_m: 0.7233\n",
      "Epoch 21: val_acc did not improve from 0.97964\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0478 - acc: 0.9834 - precision_m: 0.8557 - recall_m: 0.6595 - f1_m: 0.7243 - val_loss: 0.0638 - val_acc: 0.9774 - val_precision_m: 0.7151 - val_recall_m: 0.5857 - val_f1_m: 0.6196\n",
      "Epoch 22/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9845 - precision_m: 0.8678 - recall_m: 0.6771 - f1_m: 0.7437\n",
      "Epoch 22: val_acc did not improve from 0.97964\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0461 - acc: 0.9845 - precision_m: 0.8657 - recall_m: 0.6787 - f1_m: 0.7439 - val_loss: 0.0702 - val_acc: 0.9784 - val_precision_m: 0.7919 - val_recall_m: 0.4679 - val_f1_m: 0.5615\n",
      "Epoch 23/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9838 - precision_m: 0.8534 - recall_m: 0.6684 - f1_m: 0.7276\n",
      "Epoch 23: val_acc did not improve from 0.97964\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0463 - acc: 0.9837 - precision_m: 0.8535 - recall_m: 0.6687 - f1_m: 0.7278 - val_loss: 0.0697 - val_acc: 0.9764 - val_precision_m: 0.6501 - val_recall_m: 0.6504 - val_f1_m: 0.6279\n",
      "Epoch 24/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9838 - precision_m: 0.8583 - recall_m: 0.6696 - f1_m: 0.7317\n",
      "Epoch 24: val_acc did not improve from 0.97964\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0456 - acc: 0.9838 - precision_m: 0.8588 - recall_m: 0.6714 - f1_m: 0.7331 - val_loss: 0.0654 - val_acc: 0.9790 - val_precision_m: 0.7459 - val_recall_m: 0.5476 - val_f1_m: 0.6011\n",
      "Epoch 25/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.0438 - acc: 0.9846 - precision_m: 0.8626 - recall_m: 0.6917 - f1_m: 0.7482\n",
      "Epoch 25: val_acc improved from 0.97964 to 0.97988, saving model to models/best_model_4_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0441 - acc: 0.9845 - precision_m: 0.8619 - recall_m: 0.6904 - f1_m: 0.7473 - val_loss: 0.0635 - val_acc: 0.9799 - val_precision_m: 0.7588 - val_recall_m: 0.5888 - val_f1_m: 0.6368\n",
      "Epoch 26/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9843 - precision_m: 0.8604 - recall_m: 0.6780 - f1_m: 0.7377\n",
      "Epoch 26: val_acc improved from 0.97988 to 0.98012, saving model to models/best_model_4_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0448 - acc: 0.9842 - precision_m: 0.8610 - recall_m: 0.6787 - f1_m: 0.7381 - val_loss: 0.0628 - val_acc: 0.9801 - val_precision_m: 0.7596 - val_recall_m: 0.6171 - val_f1_m: 0.6518\n",
      "Epoch 27/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0441 - acc: 0.9851 - precision_m: 0.8670 - recall_m: 0.6912 - f1_m: 0.7480\n",
      "Epoch 27: val_acc did not improve from 0.98012\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0441 - acc: 0.9850 - precision_m: 0.8675 - recall_m: 0.6896 - f1_m: 0.7470 - val_loss: 0.0648 - val_acc: 0.9796 - val_precision_m: 0.7578 - val_recall_m: 0.5906 - val_f1_m: 0.6331\n",
      "Epoch 28/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9854 - precision_m: 0.8619 - recall_m: 0.7085 - f1_m: 0.7607\n",
      "Epoch 28: val_acc did not improve from 0.98012\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0419 - acc: 0.9854 - precision_m: 0.8602 - recall_m: 0.7112 - f1_m: 0.7615 - val_loss: 0.0722 - val_acc: 0.9799 - val_precision_m: 0.8070 - val_recall_m: 0.5231 - val_f1_m: 0.6051\n",
      "Epoch 29/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9850 - precision_m: 0.8697 - recall_m: 0.6981 - f1_m: 0.7552\n",
      "Epoch 29: val_acc did not improve from 0.98012\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0425 - acc: 0.9851 - precision_m: 0.8708 - recall_m: 0.6980 - f1_m: 0.7558 - val_loss: 0.0627 - val_acc: 0.9792 - val_precision_m: 0.7321 - val_recall_m: 0.6208 - val_f1_m: 0.6489\n",
      "Epoch 30/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9855 - precision_m: 0.8688 - recall_m: 0.7110 - f1_m: 0.7635\n",
      "Epoch 30: val_acc did not improve from 0.98012\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0415 - acc: 0.9855 - precision_m: 0.8676 - recall_m: 0.7106 - f1_m: 0.7627 - val_loss: 0.0628 - val_acc: 0.9786 - val_precision_m: 0.6995 - val_recall_m: 0.6319 - val_f1_m: 0.6416\n",
      "Score for fold 2: loss of 0.0628446489572525; acc of 98.01221489906311%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.06286802887916565; acc of 97.83331751823425%\n",
      "Test Precision: precision_m of 28.80992889404297%\n",
      "Test Recall: recall_m of 24.328114092350006%\n",
      "Test F1: f1_m of 25.60848295688629%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.1350 - acc: 0.9630 - precision_m: 0.2222 - recall_m: 0.0561 - f1_m: 0.0828\n",
      "Epoch 1: val_acc improved from -inf to 0.96454, saving model to models/best_model_4_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 2s 4ms/step - loss: 0.1350 - acc: 0.9630 - precision_m: 0.2222 - recall_m: 0.0561 - f1_m: 0.0828 - val_loss: 0.1111 - val_acc: 0.9645 - val_precision_m: 0.3182 - val_recall_m: 0.0488 - val_f1_m: 0.0818\n",
      "Epoch 2/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0942 - acc: 0.9687 - precision_m: 0.6477 - recall_m: 0.2790 - f1_m: 0.3539\n",
      "Epoch 2: val_acc improved from 0.96454 to 0.96790, saving model to models/best_model_4_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0945 - acc: 0.9685 - precision_m: 0.6501 - recall_m: 0.2819 - f1_m: 0.3565 - val_loss: 0.0939 - val_acc: 0.9679 - val_precision_m: 0.5032 - val_recall_m: 0.1389 - val_f1_m: 0.2063\n",
      "Epoch 3/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0799 - acc: 0.9721 - precision_m: 0.7368 - recall_m: 0.3787 - f1_m: 0.4692\n",
      "Epoch 3: val_acc improved from 0.96790 to 0.97065, saving model to models/best_model_4_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0798 - acc: 0.9721 - precision_m: 0.7387 - recall_m: 0.3809 - f1_m: 0.4716 - val_loss: 0.0851 - val_acc: 0.9707 - val_precision_m: 0.6698 - val_recall_m: 0.2562 - val_f1_m: 0.3538\n",
      "Epoch 4/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0738 - acc: 0.9743 - precision_m: 0.7533 - recall_m: 0.4400 - f1_m: 0.5250\n",
      "Epoch 4: val_acc did not improve from 0.97065\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0739 - acc: 0.9743 - precision_m: 0.7552 - recall_m: 0.4419 - f1_m: 0.5269 - val_loss: 0.0872 - val_acc: 0.9701 - val_precision_m: 0.7040 - val_recall_m: 0.1965 - val_f1_m: 0.2913\n",
      "Epoch 5/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0715 - acc: 0.9751 - precision_m: 0.7875 - recall_m: 0.4791 - f1_m: 0.5614\n",
      "Epoch 5: val_acc improved from 0.97065 to 0.97257, saving model to models/best_model_4_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0714 - acc: 0.9751 - precision_m: 0.7851 - recall_m: 0.4762 - f1_m: 0.5585 - val_loss: 0.0805 - val_acc: 0.9726 - val_precision_m: 0.6606 - val_recall_m: 0.5342 - val_f1_m: 0.5682\n",
      "Epoch 6/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 0.9767 - precision_m: 0.8049 - recall_m: 0.5119 - f1_m: 0.5937\n",
      "Epoch 6: val_acc did not improve from 0.97257\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0679 - acc: 0.9767 - precision_m: 0.8024 - recall_m: 0.5106 - f1_m: 0.5922 - val_loss: 0.0836 - val_acc: 0.9711 - val_precision_m: 0.7273 - val_recall_m: 0.2194 - val_f1_m: 0.3237\n",
      "Epoch 7/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0635 - acc: 0.9780 - precision_m: 0.8112 - recall_m: 0.5292 - f1_m: 0.6125\n",
      "Epoch 7: val_acc improved from 0.97257 to 0.97544, saving model to models/best_model_4_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0633 - acc: 0.9781 - precision_m: 0.8137 - recall_m: 0.5319 - f1_m: 0.6157 - val_loss: 0.0733 - val_acc: 0.9754 - val_precision_m: 0.7841 - val_recall_m: 0.3630 - val_f1_m: 0.4759\n",
      "Epoch 8/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0620 - acc: 0.9789 - precision_m: 0.8202 - recall_m: 0.5534 - f1_m: 0.6331\n",
      "Epoch 8: val_acc did not improve from 0.97544\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0623 - acc: 0.9788 - precision_m: 0.8194 - recall_m: 0.5544 - f1_m: 0.6338 - val_loss: 0.0851 - val_acc: 0.9718 - val_precision_m: 0.5920 - val_recall_m: 0.7066 - val_f1_m: 0.6221\n",
      "Epoch 9/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.0610 - acc: 0.9789 - precision_m: 0.8270 - recall_m: 0.5600 - f1_m: 0.6396\n",
      "Epoch 9: val_acc improved from 0.97544 to 0.97676, saving model to models/best_model_4_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0610 - acc: 0.9789 - precision_m: 0.8267 - recall_m: 0.5613 - f1_m: 0.6407 - val_loss: 0.0729 - val_acc: 0.9768 - val_precision_m: 0.7237 - val_recall_m: 0.5952 - val_f1_m: 0.6347\n",
      "Epoch 10/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.0582 - acc: 0.9801 - precision_m: 0.8284 - recall_m: 0.5853 - f1_m: 0.6604\n",
      "Epoch 10: val_acc improved from 0.97676 to 0.97772, saving model to models/best_model_4_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0582 - acc: 0.9801 - precision_m: 0.8299 - recall_m: 0.5853 - f1_m: 0.6608 - val_loss: 0.0721 - val_acc: 0.9777 - val_precision_m: 0.7622 - val_recall_m: 0.5571 - val_f1_m: 0.6303\n",
      "Epoch 11/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0576 - acc: 0.9804 - precision_m: 0.8357 - recall_m: 0.5986 - f1_m: 0.6716\n",
      "Epoch 11: val_acc did not improve from 0.97772\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0576 - acc: 0.9803 - precision_m: 0.8348 - recall_m: 0.5970 - f1_m: 0.6704 - val_loss: 0.0735 - val_acc: 0.9759 - val_precision_m: 0.6758 - val_recall_m: 0.5764 - val_f1_m: 0.5970\n",
      "Epoch 12/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0567 - acc: 0.9804 - precision_m: 0.8412 - recall_m: 0.5930 - f1_m: 0.6712\n",
      "Epoch 12: val_acc improved from 0.97772 to 0.97784, saving model to models/best_model_4_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0567 - acc: 0.9804 - precision_m: 0.8399 - recall_m: 0.5952 - f1_m: 0.6720 - val_loss: 0.0659 - val_acc: 0.9778 - val_precision_m: 0.6905 - val_recall_m: 0.5872 - val_f1_m: 0.6216\n",
      "Epoch 13/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0553 - acc: 0.9810 - precision_m: 0.8332 - recall_m: 0.6185 - f1_m: 0.6850\n",
      "Epoch 13: val_acc did not improve from 0.97784\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0550 - acc: 0.9810 - precision_m: 0.8330 - recall_m: 0.6182 - f1_m: 0.6850 - val_loss: 0.0691 - val_acc: 0.9757 - val_precision_m: 0.6534 - val_recall_m: 0.6085 - val_f1_m: 0.6178\n",
      "Epoch 14/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0558 - acc: 0.9807 - precision_m: 0.8474 - recall_m: 0.6075 - f1_m: 0.6765\n",
      "Epoch 14: val_acc did not improve from 0.97784\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0559 - acc: 0.9807 - precision_m: 0.8470 - recall_m: 0.6018 - f1_m: 0.6719 - val_loss: 0.0848 - val_acc: 0.9707 - val_precision_m: 0.5708 - val_recall_m: 0.6744 - val_f1_m: 0.6010\n",
      "Epoch 15/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0513 - acc: 0.9827 - precision_m: 0.8559 - recall_m: 0.6402 - f1_m: 0.7133\n",
      "Epoch 15: val_acc did not improve from 0.97784\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0515 - acc: 0.9826 - precision_m: 0.8540 - recall_m: 0.6395 - f1_m: 0.7122 - val_loss: 0.0668 - val_acc: 0.9768 - val_precision_m: 0.6986 - val_recall_m: 0.5296 - val_f1_m: 0.5816\n",
      "Epoch 16/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0511 - acc: 0.9822 - precision_m: 0.8461 - recall_m: 0.6437 - f1_m: 0.7098\n",
      "Epoch 16: val_acc improved from 0.97784 to 0.97904, saving model to models/best_model_4_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0518 - acc: 0.9819 - precision_m: 0.8455 - recall_m: 0.6423 - f1_m: 0.7078 - val_loss: 0.0642 - val_acc: 0.9790 - val_precision_m: 0.7860 - val_recall_m: 0.5511 - val_f1_m: 0.6272\n",
      "Epoch 17/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0504 - acc: 0.9825 - precision_m: 0.8510 - recall_m: 0.6348 - f1_m: 0.7031\n",
      "Epoch 17: val_acc did not improve from 0.97904\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0507 - acc: 0.9825 - precision_m: 0.8516 - recall_m: 0.6359 - f1_m: 0.7038 - val_loss: 0.0683 - val_acc: 0.9758 - val_precision_m: 0.6550 - val_recall_m: 0.6505 - val_f1_m: 0.6340\n",
      "Epoch 18/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0506 - acc: 0.9825 - precision_m: 0.8532 - recall_m: 0.6496 - f1_m: 0.7128\n",
      "Epoch 18: val_acc did not improve from 0.97904\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0503 - acc: 0.9826 - precision_m: 0.8533 - recall_m: 0.6508 - f1_m: 0.7134 - val_loss: 0.0703 - val_acc: 0.9770 - val_precision_m: 0.8215 - val_recall_m: 0.4185 - val_f1_m: 0.5337\n",
      "Epoch 19/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9826 - precision_m: 0.8595 - recall_m: 0.6563 - f1_m: 0.7177\n",
      "Epoch 19: val_acc did not improve from 0.97904\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0506 - acc: 0.9827 - precision_m: 0.8596 - recall_m: 0.6568 - f1_m: 0.7184 - val_loss: 0.0646 - val_acc: 0.9790 - val_precision_m: 0.7559 - val_recall_m: 0.5419 - val_f1_m: 0.6196\n",
      "Epoch 20/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9834 - precision_m: 0.8413 - recall_m: 0.6705 - f1_m: 0.7292\n",
      "Epoch 20: val_acc did not improve from 0.97904\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0478 - acc: 0.9835 - precision_m: 0.8429 - recall_m: 0.6719 - f1_m: 0.7309 - val_loss: 0.0761 - val_acc: 0.9760 - val_precision_m: 0.8557 - val_recall_m: 0.3706 - val_f1_m: 0.4939\n",
      "Epoch 21/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0485 - acc: 0.9831 - precision_m: 0.8645 - recall_m: 0.6669 - f1_m: 0.7287\n",
      "Epoch 21: val_acc did not improve from 0.97904\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0486 - acc: 0.9831 - precision_m: 0.8609 - recall_m: 0.6635 - f1_m: 0.7256 - val_loss: 0.0688 - val_acc: 0.9778 - val_precision_m: 0.7438 - val_recall_m: 0.4163 - val_f1_m: 0.5210\n",
      "Epoch 22/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.0469 - acc: 0.9838 - precision_m: 0.8590 - recall_m: 0.6853 - f1_m: 0.7435\n",
      "Epoch 22: val_acc did not improve from 0.97904\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0469 - acc: 0.9838 - precision_m: 0.8586 - recall_m: 0.6800 - f1_m: 0.7401 - val_loss: 0.0632 - val_acc: 0.9790 - val_precision_m: 0.7530 - val_recall_m: 0.5457 - val_f1_m: 0.6106\n",
      "Epoch 23/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9840 - precision_m: 0.8607 - recall_m: 0.6958 - f1_m: 0.7477\n",
      "Epoch 23: val_acc did not improve from 0.97904\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0469 - acc: 0.9840 - precision_m: 0.8625 - recall_m: 0.6930 - f1_m: 0.7467 - val_loss: 0.0664 - val_acc: 0.9763 - val_precision_m: 0.6523 - val_recall_m: 0.6005 - val_f1_m: 0.6054\n",
      "Epoch 24/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.0452 - acc: 0.9843 - precision_m: 0.8621 - recall_m: 0.6896 - f1_m: 0.7491\n",
      "Epoch 24: val_acc did not improve from 0.97904\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0448 - acc: 0.9845 - precision_m: 0.8624 - recall_m: 0.6921 - f1_m: 0.7512 - val_loss: 0.0658 - val_acc: 0.9784 - val_precision_m: 0.7181 - val_recall_m: 0.5405 - val_f1_m: 0.6005\n",
      "Epoch 25/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0449 - acc: 0.9843 - precision_m: 0.8629 - recall_m: 0.6953 - f1_m: 0.7496\n",
      "Epoch 25: val_acc improved from 0.97904 to 0.97940, saving model to models/best_model_4_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0446 - acc: 0.9844 - precision_m: 0.8645 - recall_m: 0.6970 - f1_m: 0.7515 - val_loss: 0.0640 - val_acc: 0.9794 - val_precision_m: 0.7622 - val_recall_m: 0.5502 - val_f1_m: 0.6155\n",
      "Epoch 26/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9847 - precision_m: 0.8676 - recall_m: 0.7039 - f1_m: 0.7571\n",
      "Epoch 26: val_acc did not improve from 0.97940\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0431 - acc: 0.9848 - precision_m: 0.8688 - recall_m: 0.7058 - f1_m: 0.7591 - val_loss: 0.0643 - val_acc: 0.9793 - val_precision_m: 0.7249 - val_recall_m: 0.6064 - val_f1_m: 0.6420\n",
      "Epoch 27/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9849 - precision_m: 0.8691 - recall_m: 0.7008 - f1_m: 0.7582\n",
      "Epoch 27: val_acc did not improve from 0.97940\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0427 - acc: 0.9849 - precision_m: 0.8689 - recall_m: 0.6991 - f1_m: 0.7564 - val_loss: 0.0639 - val_acc: 0.9774 - val_precision_m: 0.6491 - val_recall_m: 0.6416 - val_f1_m: 0.6288\n",
      "Epoch 28/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9847 - precision_m: 0.8756 - recall_m: 0.7092 - f1_m: 0.7608\n",
      "Epoch 28: val_acc did not improve from 0.97940\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0433 - acc: 0.9847 - precision_m: 0.8737 - recall_m: 0.7112 - f1_m: 0.7613 - val_loss: 0.0688 - val_acc: 0.9774 - val_precision_m: 0.6703 - val_recall_m: 0.6235 - val_f1_m: 0.6287\n",
      "Epoch 29/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0426 - acc: 0.9852 - precision_m: 0.8801 - recall_m: 0.7075 - f1_m: 0.7623\n",
      "Epoch 29: val_acc did not improve from 0.97940\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0428 - acc: 0.9851 - precision_m: 0.8777 - recall_m: 0.7077 - f1_m: 0.7621 - val_loss: 0.0627 - val_acc: 0.9790 - val_precision_m: 0.7094 - val_recall_m: 0.5953 - val_f1_m: 0.6315\n",
      "Epoch 30/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9856 - precision_m: 0.8736 - recall_m: 0.7170 - f1_m: 0.7702\n",
      "Epoch 30: val_acc did not improve from 0.97940\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0407 - acc: 0.9856 - precision_m: 0.8721 - recall_m: 0.7181 - f1_m: 0.7704 - val_loss: 0.0644 - val_acc: 0.9784 - val_precision_m: 0.7274 - val_recall_m: 0.5484 - val_f1_m: 0.6070\n",
      "Score for fold 3: loss of 0.06404568254947662; acc of 97.93962836265564%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.06335069984197617; acc of 97.99509644508362%\n",
      "Test Precision: precision_m of 27.96485126018524%\n",
      "Test Recall: recall_m of 22.140425443649292%\n",
      "Test F1: f1_m of 23.42899888753891%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1679 - acc: 0.9590 - precision_m: 0.0729 - recall_m: 0.0161 - f1_m: 0.0185\n",
      "Epoch 1: val_acc improved from -inf to 0.96203, saving model to models/best_model_4_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 2s 4ms/step - loss: 0.1679 - acc: 0.9590 - precision_m: 0.0729 - recall_m: 0.0161 - f1_m: 0.0185 - val_loss: 0.1197 - val_acc: 0.9620 - val_precision_m: 0.1212 - val_recall_m: 0.0128 - val_f1_m: 0.0225\n",
      "Epoch 2/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0981 - acc: 0.9677 - precision_m: 0.5842 - recall_m: 0.1839 - f1_m: 0.2605\n",
      "Epoch 2: val_acc improved from 0.96203 to 0.96585, saving model to models/best_model_4_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0980 - acc: 0.9677 - precision_m: 0.5834 - recall_m: 0.1852 - f1_m: 0.2620 - val_loss: 0.1040 - val_acc: 0.9659 - val_precision_m: 0.4960 - val_recall_m: 0.1406 - val_f1_m: 0.2041\n",
      "Epoch 3/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0876 - acc: 0.9709 - precision_m: 0.6895 - recall_m: 0.3129 - f1_m: 0.3991\n",
      "Epoch 3: val_acc improved from 0.96585 to 0.96860, saving model to models/best_model_4_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0875 - acc: 0.9708 - precision_m: 0.6856 - recall_m: 0.3120 - f1_m: 0.3978 - val_loss: 0.0956 - val_acc: 0.9686 - val_precision_m: 0.6128 - val_recall_m: 0.2397 - val_f1_m: 0.3179\n",
      "Epoch 4/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0810 - acc: 0.9725 - precision_m: 0.7184 - recall_m: 0.3623 - f1_m: 0.4477\n",
      "Epoch 4: val_acc improved from 0.96860 to 0.96872, saving model to models/best_model_4_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0807 - acc: 0.9726 - precision_m: 0.7151 - recall_m: 0.3618 - f1_m: 0.4471 - val_loss: 0.0935 - val_acc: 0.9687 - val_precision_m: 0.6097 - val_recall_m: 0.2610 - val_f1_m: 0.3392\n",
      "Epoch 5/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0771 - acc: 0.9739 - precision_m: 0.7623 - recall_m: 0.4088 - f1_m: 0.4948\n",
      "Epoch 5: val_acc improved from 0.96872 to 0.97134, saving model to models/best_model_4_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0769 - acc: 0.9740 - precision_m: 0.7606 - recall_m: 0.4080 - f1_m: 0.4943 - val_loss: 0.0852 - val_acc: 0.9713 - val_precision_m: 0.7077 - val_recall_m: 0.3546 - val_f1_m: 0.4381\n",
      "Epoch 6/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0725 - acc: 0.9752 - precision_m: 0.7913 - recall_m: 0.4406 - f1_m: 0.5334\n",
      "Epoch 6: val_acc improved from 0.97134 to 0.97254, saving model to models/best_model_4_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0728 - acc: 0.9752 - precision_m: 0.7850 - recall_m: 0.4378 - f1_m: 0.5293 - val_loss: 0.0829 - val_acc: 0.9725 - val_precision_m: 0.7072 - val_recall_m: 0.3949 - val_f1_m: 0.4831\n",
      "Epoch 7/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0691 - acc: 0.9761 - precision_m: 0.7664 - recall_m: 0.4661 - f1_m: 0.5504\n",
      "Epoch 7: val_acc improved from 0.97254 to 0.97278, saving model to models/best_model_4_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0692 - acc: 0.9760 - precision_m: 0.7651 - recall_m: 0.4651 - f1_m: 0.5497 - val_loss: 0.0784 - val_acc: 0.9728 - val_precision_m: 0.6933 - val_recall_m: 0.4724 - val_f1_m: 0.5406\n",
      "Epoch 8/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0684 - acc: 0.9761 - precision_m: 0.7793 - recall_m: 0.4814 - f1_m: 0.5627\n",
      "Epoch 8: val_acc did not improve from 0.97278\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0684 - acc: 0.9761 - precision_m: 0.7782 - recall_m: 0.4789 - f1_m: 0.5603 - val_loss: 0.0787 - val_acc: 0.9719 - val_precision_m: 0.6707 - val_recall_m: 0.4581 - val_f1_m: 0.5138\n",
      "Epoch 9/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0661 - acc: 0.9774 - precision_m: 0.7887 - recall_m: 0.5132 - f1_m: 0.5905\n",
      "Epoch 9: val_acc did not improve from 0.97278\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0660 - acc: 0.9774 - precision_m: 0.7840 - recall_m: 0.5082 - f1_m: 0.5854 - val_loss: 0.0802 - val_acc: 0.9728 - val_precision_m: 0.6322 - val_recall_m: 0.5680 - val_f1_m: 0.5723\n",
      "Epoch 10/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0652 - acc: 0.9777 - precision_m: 0.8003 - recall_m: 0.5134 - f1_m: 0.5927\n",
      "Epoch 10: val_acc improved from 0.97278 to 0.97313, saving model to models/best_model_4_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0655 - acc: 0.9776 - precision_m: 0.7955 - recall_m: 0.5128 - f1_m: 0.5906 - val_loss: 0.0804 - val_acc: 0.9731 - val_precision_m: 0.6917 - val_recall_m: 0.4588 - val_f1_m: 0.5176\n",
      "Epoch 11/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0624 - acc: 0.9781 - precision_m: 0.8045 - recall_m: 0.5317 - f1_m: 0.6105\n",
      "Epoch 11: val_acc did not improve from 0.97313\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0622 - acc: 0.9782 - precision_m: 0.8027 - recall_m: 0.5297 - f1_m: 0.6089 - val_loss: 0.0784 - val_acc: 0.9715 - val_precision_m: 0.7605 - val_recall_m: 0.3153 - val_f1_m: 0.4139\n",
      "Epoch 12/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0592 - acc: 0.9798 - precision_m: 0.8304 - recall_m: 0.5617 - f1_m: 0.6442\n",
      "Epoch 12: val_acc improved from 0.97313 to 0.97385, saving model to models/best_model_4_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0591 - acc: 0.9798 - precision_m: 0.8285 - recall_m: 0.5592 - f1_m: 0.6415 - val_loss: 0.0798 - val_acc: 0.9739 - val_precision_m: 0.7780 - val_recall_m: 0.3649 - val_f1_m: 0.4626\n",
      "Epoch 13/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9805 - precision_m: 0.8250 - recall_m: 0.5821 - f1_m: 0.6566\n",
      "Epoch 13: val_acc did not improve from 0.97385\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0574 - acc: 0.9805 - precision_m: 0.8240 - recall_m: 0.5792 - f1_m: 0.6543 - val_loss: 0.0970 - val_acc: 0.9697 - val_precision_m: 0.6970 - val_recall_m: 0.2334 - val_f1_m: 0.3190\n",
      "Epoch 14/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9794 - precision_m: 0.8073 - recall_m: 0.5569 - f1_m: 0.6287\n",
      "Epoch 14: val_acc improved from 0.97385 to 0.97612, saving model to models/best_model_4_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0595 - acc: 0.9794 - precision_m: 0.8048 - recall_m: 0.5550 - f1_m: 0.6270 - val_loss: 0.0700 - val_acc: 0.9761 - val_precision_m: 0.6826 - val_recall_m: 0.5952 - val_f1_m: 0.6088\n",
      "Epoch 15/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0584 - acc: 0.9797 - precision_m: 0.8235 - recall_m: 0.5689 - f1_m: 0.6455\n",
      "Epoch 15: val_acc improved from 0.97612 to 0.97672, saving model to models/best_model_4_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0583 - acc: 0.9797 - precision_m: 0.8209 - recall_m: 0.5671 - f1_m: 0.6438 - val_loss: 0.0686 - val_acc: 0.9767 - val_precision_m: 0.7694 - val_recall_m: 0.5079 - val_f1_m: 0.5811\n",
      "Epoch 16/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9814 - precision_m: 0.8299 - recall_m: 0.6036 - f1_m: 0.6784\n",
      "Epoch 16: val_acc did not improve from 0.97672\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0542 - acc: 0.9815 - precision_m: 0.8296 - recall_m: 0.5998 - f1_m: 0.6753 - val_loss: 0.0699 - val_acc: 0.9756 - val_precision_m: 0.6670 - val_recall_m: 0.5843 - val_f1_m: 0.5961\n",
      "Epoch 17/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0520 - acc: 0.9824 - precision_m: 0.8535 - recall_m: 0.6180 - f1_m: 0.6962\n",
      "Epoch 17: val_acc improved from 0.97672 to 0.97707, saving model to models/best_model_4_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0523 - acc: 0.9823 - precision_m: 0.8480 - recall_m: 0.6158 - f1_m: 0.6928 - val_loss: 0.0661 - val_acc: 0.9771 - val_precision_m: 0.7621 - val_recall_m: 0.5063 - val_f1_m: 0.5853\n",
      "Epoch 18/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0512 - acc: 0.9824 - precision_m: 0.8506 - recall_m: 0.6301 - f1_m: 0.7025\n",
      "Epoch 18: val_acc did not improve from 0.97707\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0512 - acc: 0.9824 - precision_m: 0.8456 - recall_m: 0.6272 - f1_m: 0.6987 - val_loss: 0.0904 - val_acc: 0.9680 - val_precision_m: 0.5319 - val_recall_m: 0.7163 - val_f1_m: 0.5870\n",
      "Epoch 19/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0530 - acc: 0.9814 - precision_m: 0.8342 - recall_m: 0.6161 - f1_m: 0.6813\n",
      "Epoch 19: val_acc improved from 0.97707 to 0.97731, saving model to models/best_model_4_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0532 - acc: 0.9813 - precision_m: 0.8325 - recall_m: 0.6122 - f1_m: 0.6780 - val_loss: 0.0669 - val_acc: 0.9773 - val_precision_m: 0.6561 - val_recall_m: 0.6495 - val_f1_m: 0.6279\n",
      "Epoch 20/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0506 - acc: 0.9825 - precision_m: 0.8448 - recall_m: 0.6318 - f1_m: 0.6982\n",
      "Epoch 20: val_acc did not improve from 0.97731\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0507 - acc: 0.9825 - precision_m: 0.8410 - recall_m: 0.6295 - f1_m: 0.6953 - val_loss: 0.1455 - val_acc: 0.9463 - val_precision_m: 0.3869 - val_recall_m: 0.7838 - val_f1_m: 0.4956\n",
      "Epoch 21/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0587 - acc: 0.9798 - precision_m: 0.8212 - recall_m: 0.5908 - f1_m: 0.6582\n",
      "Epoch 21: val_acc did not improve from 0.97731\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0583 - acc: 0.9800 - precision_m: 0.8197 - recall_m: 0.5925 - f1_m: 0.6595 - val_loss: 0.0666 - val_acc: 0.9770 - val_precision_m: 0.7547 - val_recall_m: 0.4766 - val_f1_m: 0.5537\n",
      "Epoch 22/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.9839 - precision_m: 0.8686 - recall_m: 0.6532 - f1_m: 0.7236\n",
      "Epoch 22: val_acc did not improve from 0.97731\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0474 - acc: 0.9839 - precision_m: 0.8703 - recall_m: 0.6543 - f1_m: 0.7251 - val_loss: 0.0750 - val_acc: 0.9735 - val_precision_m: 0.5922 - val_recall_m: 0.7014 - val_f1_m: 0.6155\n",
      "Epoch 23/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0479 - acc: 0.9837 - precision_m: 0.8629 - recall_m: 0.6601 - f1_m: 0.7265\n",
      "Epoch 23: val_acc improved from 0.97731 to 0.97743, saving model to models/best_model_4_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0480 - acc: 0.9836 - precision_m: 0.8582 - recall_m: 0.6593 - f1_m: 0.7243 - val_loss: 0.0698 - val_acc: 0.9774 - val_precision_m: 0.7739 - val_recall_m: 0.4630 - val_f1_m: 0.5487\n",
      "Epoch 24/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9845 - precision_m: 0.8630 - recall_m: 0.6742 - f1_m: 0.7367\n",
      "Epoch 24: val_acc improved from 0.97743 to 0.97827, saving model to models/best_model_4_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0453 - acc: 0.9846 - precision_m: 0.8642 - recall_m: 0.6769 - f1_m: 0.7393 - val_loss: 0.0632 - val_acc: 0.9783 - val_precision_m: 0.7424 - val_recall_m: 0.6008 - val_f1_m: 0.6353\n",
      "Epoch 25/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9845 - precision_m: 0.8597 - recall_m: 0.6756 - f1_m: 0.7407\n",
      "Epoch 25: val_acc did not improve from 0.97827\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0450 - acc: 0.9845 - precision_m: 0.8572 - recall_m: 0.6743 - f1_m: 0.7391 - val_loss: 0.0729 - val_acc: 0.9774 - val_precision_m: 0.7842 - val_recall_m: 0.4634 - val_f1_m: 0.5525\n",
      "Epoch 26/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9854 - precision_m: 0.8788 - recall_m: 0.6997 - f1_m: 0.7627\n",
      "Epoch 26: val_acc did not improve from 0.97827\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0434 - acc: 0.9855 - precision_m: 0.8764 - recall_m: 0.6982 - f1_m: 0.7610 - val_loss: 0.0775 - val_acc: 0.9773 - val_precision_m: 0.8171 - val_recall_m: 0.4398 - val_f1_m: 0.5466\n",
      "Epoch 27/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0444 - acc: 0.9849 - precision_m: 0.8744 - recall_m: 0.6817 - f1_m: 0.7458\n",
      "Epoch 27: val_acc improved from 0.97827 to 0.97922, saving model to models/best_model_4_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0443 - acc: 0.9850 - precision_m: 0.8723 - recall_m: 0.6794 - f1_m: 0.7434 - val_loss: 0.0618 - val_acc: 0.9792 - val_precision_m: 0.7271 - val_recall_m: 0.6164 - val_f1_m: 0.6341\n",
      "Epoch 28/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0429 - acc: 0.9851 - precision_m: 0.8680 - recall_m: 0.6923 - f1_m: 0.7498\n",
      "Epoch 28: val_acc did not improve from 0.97922\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0429 - acc: 0.9851 - precision_m: 0.8645 - recall_m: 0.6905 - f1_m: 0.7474 - val_loss: 0.0735 - val_acc: 0.9768 - val_precision_m: 0.7828 - val_recall_m: 0.5022 - val_f1_m: 0.5839\n",
      "Epoch 29/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0423 - acc: 0.9852 - precision_m: 0.8744 - recall_m: 0.6952 - f1_m: 0.7549\n",
      "Epoch 29: val_acc improved from 0.97922 to 0.97934, saving model to models/best_model_4_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0424 - acc: 0.9852 - precision_m: 0.8702 - recall_m: 0.6933 - f1_m: 0.7522 - val_loss: 0.0654 - val_acc: 0.9793 - val_precision_m: 0.7628 - val_recall_m: 0.5493 - val_f1_m: 0.6078\n",
      "Epoch 30/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9855 - precision_m: 0.8748 - recall_m: 0.7049 - f1_m: 0.7589\n",
      "Epoch 30: val_acc did not improve from 0.97934\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0423 - acc: 0.9856 - precision_m: 0.8726 - recall_m: 0.7049 - f1_m: 0.7582 - val_loss: 0.0798 - val_acc: 0.9754 - val_precision_m: 0.8005 - val_recall_m: 0.4056 - val_f1_m: 0.5091\n",
      "Score for fold 4: loss of 0.06544382870197296; acc of 97.93432950973511%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.07306991517543793; acc of 97.7388322353363%\n",
      "Test Precision: precision_m of 30.68050742149353%\n",
      "Test Recall: recall_m of 23.023825883865356%\n",
      "Test F1: f1_m of 25.06592571735382%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.1586 - acc: 0.9562 - precision_m: 7.9550e-04 - recall_m: 0.0084 - f1_m: 0.0011\n",
      "Epoch 1: val_acc improved from -inf to 0.96211, saving model to models/best_model_4_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 2s 4ms/step - loss: 0.1582 - acc: 0.9562 - precision_m: 7.8730e-04 - recall_m: 0.0083 - f1_m: 0.0011 - val_loss: 0.1244 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.0997 - acc: 0.9638 - precision_m: 0.0036 - recall_m: 5.1020e-04 - f1_m: 8.9286e-04    \n",
      "Epoch 2: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0994 - acc: 0.9638 - precision_m: 0.0034 - recall_m: 4.9092e-04 - f1_m: 8.5911e-04 - val_loss: 0.1016 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 3/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0879 - acc: 0.9661 - precision_m: 0.3726 - recall_m: 0.0775 - f1_m: 0.1217  \n",
      "Epoch 3: val_acc improved from 0.96211 to 0.96630, saving model to models/best_model_4_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0879 - acc: 0.9660 - precision_m: 0.3743 - recall_m: 0.0795 - f1_m: 0.1240 - val_loss: 0.0913 - val_acc: 0.9663 - val_precision_m: 0.5333 - val_recall_m: 0.1176 - val_f1_m: 0.1842\n",
      "Epoch 4/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0826 - acc: 0.9696 - precision_m: 0.7009 - recall_m: 0.2403 - f1_m: 0.3310\n",
      "Epoch 4: val_acc improved from 0.96630 to 0.96940, saving model to models/best_model_4_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0826 - acc: 0.9696 - precision_m: 0.6990 - recall_m: 0.2457 - f1_m: 0.3342 - val_loss: 0.0877 - val_acc: 0.9694 - val_precision_m: 0.6969 - val_recall_m: 0.3249 - val_f1_m: 0.4150\n",
      "Epoch 5/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.0774 - acc: 0.9730 - precision_m: 0.7311 - recall_m: 0.4193 - f1_m: 0.4960\n",
      "Epoch 5: val_acc improved from 0.96940 to 0.97299, saving model to models/best_model_4_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0775 - acc: 0.9730 - precision_m: 0.7301 - recall_m: 0.4190 - f1_m: 0.4960 - val_loss: 0.0802 - val_acc: 0.9730 - val_precision_m: 0.7055 - val_recall_m: 0.4296 - val_f1_m: 0.5088\n",
      "Epoch 6/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.0735 - acc: 0.9744 - precision_m: 0.7701 - recall_m: 0.4476 - f1_m: 0.5275\n",
      "Epoch 6: val_acc improved from 0.97299 to 0.97323, saving model to models/best_model_4_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0731 - acc: 0.9745 - precision_m: 0.7729 - recall_m: 0.4501 - f1_m: 0.5302 - val_loss: 0.0808 - val_acc: 0.9732 - val_precision_m: 0.8176 - val_recall_m: 0.3825 - val_f1_m: 0.4818\n",
      "Epoch 7/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0696 - acc: 0.9753 - precision_m: 0.7626 - recall_m: 0.4756 - f1_m: 0.5551\n",
      "Epoch 7: val_acc did not improve from 0.97323\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0696 - acc: 0.9754 - precision_m: 0.7651 - recall_m: 0.4758 - f1_m: 0.5559 - val_loss: 0.0790 - val_acc: 0.9729 - val_precision_m: 0.8433 - val_recall_m: 0.3782 - val_f1_m: 0.4880\n",
      "Epoch 8/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0657 - acc: 0.9772 - precision_m: 0.7939 - recall_m: 0.5174 - f1_m: 0.5971\n",
      "Epoch 8: val_acc did not improve from 0.97323\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0658 - acc: 0.9772 - precision_m: 0.7933 - recall_m: 0.5222 - f1_m: 0.6003 - val_loss: 0.0934 - val_acc: 0.9712 - val_precision_m: 0.7594 - val_recall_m: 0.2656 - val_f1_m: 0.3715\n",
      "Epoch 9/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9779 - precision_m: 0.7982 - recall_m: 0.5389 - f1_m: 0.6167\n",
      "Epoch 9: val_acc improved from 0.97323 to 0.97729, saving model to models/best_model_4_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0631 - acc: 0.9780 - precision_m: 0.7984 - recall_m: 0.5380 - f1_m: 0.6158 - val_loss: 0.0717 - val_acc: 0.9773 - val_precision_m: 0.7893 - val_recall_m: 0.5542 - val_f1_m: 0.6131\n",
      "Epoch 10/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0617 - acc: 0.9785 - precision_m: 0.8054 - recall_m: 0.5525 - f1_m: 0.6272\n",
      "Epoch 10: val_acc did not improve from 0.97729\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0618 - acc: 0.9785 - precision_m: 0.8049 - recall_m: 0.5549 - f1_m: 0.6287 - val_loss: 0.0719 - val_acc: 0.9765 - val_precision_m: 0.8509 - val_recall_m: 0.4912 - val_f1_m: 0.5793\n",
      "Epoch 11/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9788 - precision_m: 0.8055 - recall_m: 0.5565 - f1_m: 0.6293\n",
      "Epoch 11: val_acc did not improve from 0.97729\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0619 - acc: 0.9787 - precision_m: 0.8040 - recall_m: 0.5562 - f1_m: 0.6282 - val_loss: 0.0749 - val_acc: 0.9753 - val_precision_m: 0.8252 - val_recall_m: 0.4830 - val_f1_m: 0.5601\n",
      "Epoch 12/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0581 - acc: 0.9800 - precision_m: 0.8177 - recall_m: 0.5791 - f1_m: 0.6609\n",
      "Epoch 12: val_acc did not improve from 0.97729\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0580 - acc: 0.9800 - precision_m: 0.8161 - recall_m: 0.5817 - f1_m: 0.6620 - val_loss: 0.0788 - val_acc: 0.9741 - val_precision_m: 0.8304 - val_recall_m: 0.4364 - val_f1_m: 0.5333\n",
      "Epoch 13/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0570 - acc: 0.9804 - precision_m: 0.8265 - recall_m: 0.6044 - f1_m: 0.6752\n",
      "Epoch 13: val_acc improved from 0.97729 to 0.97741, saving model to models/best_model_4_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0570 - acc: 0.9804 - precision_m: 0.8283 - recall_m: 0.6042 - f1_m: 0.6756 - val_loss: 0.0700 - val_acc: 0.9774 - val_precision_m: 0.7233 - val_recall_m: 0.6619 - val_f1_m: 0.6533\n",
      "Epoch 14/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0559 - acc: 0.9805 - precision_m: 0.8289 - recall_m: 0.6098 - f1_m: 0.6781\n",
      "Epoch 14: val_acc did not improve from 0.97741\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0564 - acc: 0.9804 - precision_m: 0.8287 - recall_m: 0.6077 - f1_m: 0.6762 - val_loss: 0.0734 - val_acc: 0.9753 - val_precision_m: 0.6866 - val_recall_m: 0.6744 - val_f1_m: 0.6387\n",
      "Epoch 15/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0539 - acc: 0.9814 - precision_m: 0.8345 - recall_m: 0.6176 - f1_m: 0.6859\n",
      "Epoch 15: val_acc improved from 0.97741 to 0.97801, saving model to models/best_model_4_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0539 - acc: 0.9813 - precision_m: 0.8323 - recall_m: 0.6162 - f1_m: 0.6843 - val_loss: 0.0698 - val_acc: 0.9780 - val_precision_m: 0.8341 - val_recall_m: 0.5433 - val_f1_m: 0.6130\n",
      "Epoch 16/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0546 - acc: 0.9815 - precision_m: 0.8311 - recall_m: 0.6264 - f1_m: 0.6870\n",
      "Epoch 16: val_acc did not improve from 0.97801\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0547 - acc: 0.9814 - precision_m: 0.8309 - recall_m: 0.6279 - f1_m: 0.6879 - val_loss: 0.0665 - val_acc: 0.9775 - val_precision_m: 0.7787 - val_recall_m: 0.6163 - val_f1_m: 0.6490\n",
      "Epoch 17/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0539 - acc: 0.9815 - precision_m: 0.8432 - recall_m: 0.6315 - f1_m: 0.6951\n",
      "Epoch 17: val_acc did not improve from 0.97801\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0539 - acc: 0.9814 - precision_m: 0.8433 - recall_m: 0.6277 - f1_m: 0.6924 - val_loss: 0.0784 - val_acc: 0.9733 - val_precision_m: 0.6453 - val_recall_m: 0.7436 - val_f1_m: 0.6561\n",
      "Epoch 18/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9820 - precision_m: 0.8346 - recall_m: 0.6313 - f1_m: 0.6972\n",
      "Epoch 18: val_acc did not improve from 0.97801\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0514 - acc: 0.9821 - precision_m: 0.8370 - recall_m: 0.6326 - f1_m: 0.6991 - val_loss: 0.0692 - val_acc: 0.9774 - val_precision_m: 0.7113 - val_recall_m: 0.6617 - val_f1_m: 0.6504\n",
      "Epoch 19/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0519 - acc: 0.9823 - precision_m: 0.8416 - recall_m: 0.6304 - f1_m: 0.7002\n",
      "Epoch 19: val_acc did not improve from 0.97801\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0518 - acc: 0.9824 - precision_m: 0.8413 - recall_m: 0.6330 - f1_m: 0.7017 - val_loss: 0.0911 - val_acc: 0.9735 - val_precision_m: 0.8538 - val_recall_m: 0.3520 - val_f1_m: 0.4676\n",
      "Epoch 20/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9831 - precision_m: 0.8549 - recall_m: 0.6427 - f1_m: 0.7130\n",
      "Epoch 20: val_acc improved from 0.97801 to 0.97920, saving model to models/best_model_4_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0500 - acc: 0.9831 - precision_m: 0.8540 - recall_m: 0.6452 - f1_m: 0.7143 - val_loss: 0.0686 - val_acc: 0.9792 - val_precision_m: 0.8569 - val_recall_m: 0.5924 - val_f1_m: 0.6584\n",
      "Epoch 21/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0491 - acc: 0.9836 - precision_m: 0.8610 - recall_m: 0.6651 - f1_m: 0.7273\n",
      "Epoch 21: val_acc did not improve from 0.97920\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0489 - acc: 0.9837 - precision_m: 0.8618 - recall_m: 0.6657 - f1_m: 0.7278 - val_loss: 0.0689 - val_acc: 0.9781 - val_precision_m: 0.7420 - val_recall_m: 0.6675 - val_f1_m: 0.6645\n",
      "Epoch 22/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9835 - precision_m: 0.8548 - recall_m: 0.6670 - f1_m: 0.7306\n",
      "Epoch 22: val_acc did not improve from 0.97920\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0477 - acc: 0.9834 - precision_m: 0.8523 - recall_m: 0.6653 - f1_m: 0.7279 - val_loss: 0.0758 - val_acc: 0.9779 - val_precision_m: 0.8536 - val_recall_m: 0.5193 - val_f1_m: 0.6040\n",
      "Epoch 23/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0471 - acc: 0.9836 - precision_m: 0.8591 - recall_m: 0.6689 - f1_m: 0.7323\n",
      "Epoch 23: val_acc did not improve from 0.97920\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0470 - acc: 0.9836 - precision_m: 0.8604 - recall_m: 0.6679 - f1_m: 0.7325 - val_loss: 0.0695 - val_acc: 0.9774 - val_precision_m: 0.7479 - val_recall_m: 0.6402 - val_f1_m: 0.6559\n",
      "Epoch 24/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0463 - acc: 0.9841 - precision_m: 0.8591 - recall_m: 0.6804 - f1_m: 0.7420\n",
      "Epoch 24: val_acc did not improve from 0.97920\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0465 - acc: 0.9840 - precision_m: 0.8599 - recall_m: 0.6791 - f1_m: 0.7413 - val_loss: 0.0751 - val_acc: 0.9754 - val_precision_m: 0.6542 - val_recall_m: 0.7197 - val_f1_m: 0.6621\n",
      "Epoch 25/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9839 - precision_m: 0.8618 - recall_m: 0.6853 - f1_m: 0.7406\n",
      "Epoch 25: val_acc did not improve from 0.97920\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0468 - acc: 0.9839 - precision_m: 0.8612 - recall_m: 0.6845 - f1_m: 0.7400 - val_loss: 0.0671 - val_acc: 0.9788 - val_precision_m: 0.7921 - val_recall_m: 0.6481 - val_f1_m: 0.6826\n",
      "Epoch 26/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9843 - precision_m: 0.8506 - recall_m: 0.6935 - f1_m: 0.7464\n",
      "Epoch 26: val_acc did not improve from 0.97920\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0448 - acc: 0.9843 - precision_m: 0.8501 - recall_m: 0.6930 - f1_m: 0.7460 - val_loss: 0.0772 - val_acc: 0.9769 - val_precision_m: 0.8257 - val_recall_m: 0.5014 - val_f1_m: 0.5889\n",
      "Epoch 27/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.0447 - acc: 0.9847 - precision_m: 0.8587 - recall_m: 0.6980 - f1_m: 0.7514\n",
      "Epoch 27: val_acc did not improve from 0.97920\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0448 - acc: 0.9846 - precision_m: 0.8563 - recall_m: 0.6955 - f1_m: 0.7490 - val_loss: 0.0699 - val_acc: 0.9782 - val_precision_m: 0.7488 - val_recall_m: 0.6707 - val_f1_m: 0.6748\n",
      "Epoch 28/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.0439 - acc: 0.9852 - precision_m: 0.8669 - recall_m: 0.7082 - f1_m: 0.7625\n",
      "Epoch 28: val_acc did not improve from 0.97920\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0437 - acc: 0.9853 - precision_m: 0.8694 - recall_m: 0.7096 - f1_m: 0.7647 - val_loss: 0.0759 - val_acc: 0.9767 - val_precision_m: 0.8094 - val_recall_m: 0.5356 - val_f1_m: 0.6087\n",
      "Epoch 29/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9856 - precision_m: 0.8643 - recall_m: 0.7068 - f1_m: 0.7645\n",
      "Epoch 29: val_acc did not improve from 0.97920\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0416 - acc: 0.9855 - precision_m: 0.8630 - recall_m: 0.7055 - f1_m: 0.7628 - val_loss: 0.0698 - val_acc: 0.9775 - val_precision_m: 0.7267 - val_recall_m: 0.6748 - val_f1_m: 0.6710\n",
      "Epoch 30/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9846 - precision_m: 0.8580 - recall_m: 0.7041 - f1_m: 0.7545\n",
      "Epoch 30: val_acc did not improve from 0.97920\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0441 - acc: 0.9844 - precision_m: 0.8569 - recall_m: 0.7043 - f1_m: 0.7538 - val_loss: 0.0892 - val_acc: 0.9767 - val_precision_m: 0.8879 - val_recall_m: 0.4948 - val_f1_m: 0.5886\n",
      "Score for fold 5: loss of 0.06855207681655884; acc of 97.9203999042511%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.06458530575037003; acc of 97.83258438110352%\n",
      "Test Precision: precision_m of 28.048917651176453%\n",
      "Test Recall: recall_m of 22.909292578697205%\n",
      "Test F1: f1_m of 24.304035305976868%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1150 - acc: 0.9662 - precision_m: 0.4129 - recall_m: 0.1270 - f1_m: 0.1805\n",
      "Epoch 1: val_acc improved from -inf to 0.96505, saving model to models/best_model_4_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 2s 4ms/step - loss: 0.1150 - acc: 0.9662 - precision_m: 0.4129 - recall_m: 0.1270 - f1_m: 0.1805 - val_loss: 0.1034 - val_acc: 0.9650 - val_precision_m: 0.6266 - val_recall_m: 0.1615 - val_f1_m: 0.2409\n",
      "Epoch 2/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0895 - acc: 0.9703 - precision_m: 0.6712 - recall_m: 0.3164 - f1_m: 0.3926\n",
      "Epoch 2: val_acc improved from 0.96505 to 0.96589, saving model to models/best_model_4_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0894 - acc: 0.9703 - precision_m: 0.6759 - recall_m: 0.3176 - f1_m: 0.3954 - val_loss: 0.1038 - val_acc: 0.9659 - val_precision_m: 0.5909 - val_recall_m: 0.5364 - val_f1_m: 0.5343\n",
      "Epoch 3/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0788 - acc: 0.9727 - precision_m: 0.7575 - recall_m: 0.3954 - f1_m: 0.4856\n",
      "Epoch 3: val_acc improved from 0.96589 to 0.96818, saving model to models/best_model_4_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0787 - acc: 0.9728 - precision_m: 0.7577 - recall_m: 0.3937 - f1_m: 0.4847 - val_loss: 0.0942 - val_acc: 0.9682 - val_precision_m: 0.7559 - val_recall_m: 0.2525 - val_f1_m: 0.3511\n",
      "Epoch 4/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0738 - acc: 0.9743 - precision_m: 0.7702 - recall_m: 0.4351 - f1_m: 0.5253\n",
      "Epoch 4: val_acc did not improve from 0.96818\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0738 - acc: 0.9742 - precision_m: 0.7736 - recall_m: 0.4365 - f1_m: 0.5279 - val_loss: 0.1024 - val_acc: 0.9655 - val_precision_m: 0.5609 - val_recall_m: 0.6816 - val_f1_m: 0.5862\n",
      "Epoch 5/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0699 - acc: 0.9757 - precision_m: 0.7931 - recall_m: 0.4794 - f1_m: 0.5665\n",
      "Epoch 5: val_acc improved from 0.96818 to 0.97047, saving model to models/best_model_4_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0695 - acc: 0.9758 - precision_m: 0.7920 - recall_m: 0.4806 - f1_m: 0.5677 - val_loss: 0.0840 - val_acc: 0.9705 - val_precision_m: 0.8178 - val_recall_m: 0.2975 - val_f1_m: 0.4138\n",
      "Epoch 6/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0683 - acc: 0.9762 - precision_m: 0.7912 - recall_m: 0.4998 - f1_m: 0.5777\n",
      "Epoch 6: val_acc improved from 0.97047 to 0.97373, saving model to models/best_model_4_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0678 - acc: 0.9764 - precision_m: 0.7940 - recall_m: 0.5019 - f1_m: 0.5813 - val_loss: 0.0785 - val_acc: 0.9737 - val_precision_m: 0.7353 - val_recall_m: 0.5775 - val_f1_m: 0.6057\n",
      "Epoch 7/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0641 - acc: 0.9776 - precision_m: 0.7973 - recall_m: 0.5311 - f1_m: 0.6089\n",
      "Epoch 7: val_acc improved from 0.97373 to 0.97565, saving model to models/best_model_4_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0643 - acc: 0.9777 - precision_m: 0.7972 - recall_m: 0.5335 - f1_m: 0.6109 - val_loss: 0.0755 - val_acc: 0.9757 - val_precision_m: 0.7097 - val_recall_m: 0.6282 - val_f1_m: 0.6409\n",
      "Epoch 8/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0633 - acc: 0.9782 - precision_m: 0.8072 - recall_m: 0.5387 - f1_m: 0.6137\n",
      "Epoch 8: val_acc did not improve from 0.97565\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0634 - acc: 0.9780 - precision_m: 0.8052 - recall_m: 0.5405 - f1_m: 0.6149 - val_loss: 0.0778 - val_acc: 0.9743 - val_precision_m: 0.8644 - val_recall_m: 0.4224 - val_f1_m: 0.5262\n",
      "Epoch 9/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0593 - acc: 0.9800 - precision_m: 0.8272 - recall_m: 0.5782 - f1_m: 0.6556\n",
      "Epoch 9: val_acc improved from 0.97565 to 0.97710, saving model to models/best_model_4_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0595 - acc: 0.9800 - precision_m: 0.8266 - recall_m: 0.5771 - f1_m: 0.6551 - val_loss: 0.0721 - val_acc: 0.9771 - val_precision_m: 0.7833 - val_recall_m: 0.6011 - val_f1_m: 0.6446\n",
      "Epoch 10/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9795 - precision_m: 0.8215 - recall_m: 0.5837 - f1_m: 0.6538\n",
      "Epoch 10: val_acc did not improve from 0.97710\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0598 - acc: 0.9797 - precision_m: 0.8227 - recall_m: 0.5826 - f1_m: 0.6536 - val_loss: 0.0735 - val_acc: 0.9766 - val_precision_m: 0.8354 - val_recall_m: 0.5342 - val_f1_m: 0.6104\n",
      "Epoch 11/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0574 - acc: 0.9801 - precision_m: 0.8261 - recall_m: 0.5934 - f1_m: 0.6613\n",
      "Epoch 11: val_acc did not improve from 0.97710\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0577 - acc: 0.9800 - precision_m: 0.8253 - recall_m: 0.5961 - f1_m: 0.6633 - val_loss: 0.0725 - val_acc: 0.9761 - val_precision_m: 0.7322 - val_recall_m: 0.6048 - val_f1_m: 0.6306\n",
      "Epoch 12/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0548 - acc: 0.9810 - precision_m: 0.8293 - recall_m: 0.6044 - f1_m: 0.6785\n",
      "Epoch 12: val_acc did not improve from 0.97710\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0548 - acc: 0.9810 - precision_m: 0.8295 - recall_m: 0.6041 - f1_m: 0.6786 - val_loss: 0.0732 - val_acc: 0.9763 - val_precision_m: 0.8364 - val_recall_m: 0.4782 - val_f1_m: 0.5743\n",
      "Epoch 13/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0540 - acc: 0.9814 - precision_m: 0.8357 - recall_m: 0.6080 - f1_m: 0.6815\n",
      "Epoch 13: val_acc did not improve from 0.97710\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0543 - acc: 0.9814 - precision_m: 0.8343 - recall_m: 0.6089 - f1_m: 0.6817 - val_loss: 0.0758 - val_acc: 0.9761 - val_precision_m: 0.8475 - val_recall_m: 0.5091 - val_f1_m: 0.5981\n",
      "Epoch 14/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0546 - acc: 0.9813 - precision_m: 0.8437 - recall_m: 0.6182 - f1_m: 0.6871\n",
      "Epoch 14: val_acc improved from 0.97710 to 0.97758, saving model to models/best_model_4_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0543 - acc: 0.9815 - precision_m: 0.8460 - recall_m: 0.6198 - f1_m: 0.6893 - val_loss: 0.0696 - val_acc: 0.9776 - val_precision_m: 0.7811 - val_recall_m: 0.5856 - val_f1_m: 0.6271\n",
      "Epoch 15/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0525 - acc: 0.9819 - precision_m: 0.8329 - recall_m: 0.6252 - f1_m: 0.6902\n",
      "Epoch 15: val_acc did not improve from 0.97758\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0525 - acc: 0.9818 - precision_m: 0.8327 - recall_m: 0.6280 - f1_m: 0.6911 - val_loss: 0.0723 - val_acc: 0.9759 - val_precision_m: 0.7256 - val_recall_m: 0.6649 - val_f1_m: 0.6523\n",
      "Epoch 16/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0506 - acc: 0.9822 - precision_m: 0.8405 - recall_m: 0.6392 - f1_m: 0.7052\n",
      "Epoch 16: val_acc did not improve from 0.97758\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0505 - acc: 0.9822 - precision_m: 0.8382 - recall_m: 0.6360 - f1_m: 0.7023 - val_loss: 0.0716 - val_acc: 0.9766 - val_precision_m: 0.8180 - val_recall_m: 0.5049 - val_f1_m: 0.5870\n",
      "Epoch 17/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0493 - acc: 0.9826 - precision_m: 0.8440 - recall_m: 0.6494 - f1_m: 0.7146\n",
      "Epoch 17: val_acc did not improve from 0.97758\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0490 - acc: 0.9829 - precision_m: 0.8479 - recall_m: 0.6506 - f1_m: 0.7162 - val_loss: 0.0681 - val_acc: 0.9769 - val_precision_m: 0.7145 - val_recall_m: 0.6975 - val_f1_m: 0.6697\n",
      "Epoch 18/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9830 - precision_m: 0.8558 - recall_m: 0.6578 - f1_m: 0.7231\n",
      "Epoch 18: val_acc improved from 0.97758 to 0.97818, saving model to models/best_model_4_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0481 - acc: 0.9830 - precision_m: 0.8576 - recall_m: 0.6575 - f1_m: 0.7230 - val_loss: 0.0664 - val_acc: 0.9782 - val_precision_m: 0.7550 - val_recall_m: 0.6982 - val_f1_m: 0.6870\n",
      "Epoch 19/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9836 - precision_m: 0.8596 - recall_m: 0.6680 - f1_m: 0.7329\n",
      "Epoch 19: val_acc did not improve from 0.97818\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0480 - acc: 0.9837 - precision_m: 0.8590 - recall_m: 0.6672 - f1_m: 0.7321 - val_loss: 0.0788 - val_acc: 0.9759 - val_precision_m: 0.8994 - val_recall_m: 0.4498 - val_f1_m: 0.5513\n",
      "Epoch 20/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0476 - acc: 0.9837 - precision_m: 0.8673 - recall_m: 0.6664 - f1_m: 0.7257\n",
      "Epoch 20: val_acc did not improve from 0.97818\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0484 - acc: 0.9834 - precision_m: 0.8630 - recall_m: 0.6639 - f1_m: 0.7226 - val_loss: 0.0765 - val_acc: 0.9763 - val_precision_m: 0.8302 - val_recall_m: 0.4700 - val_f1_m: 0.5565\n",
      "Epoch 21/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0466 - acc: 0.9834 - precision_m: 0.8519 - recall_m: 0.6635 - f1_m: 0.7262\n",
      "Epoch 21: val_acc improved from 0.97818 to 0.97879, saving model to models/best_model_4_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0467 - acc: 0.9833 - precision_m: 0.8507 - recall_m: 0.6659 - f1_m: 0.7273 - val_loss: 0.0674 - val_acc: 0.9788 - val_precision_m: 0.7726 - val_recall_m: 0.6650 - val_f1_m: 0.6788\n",
      "Epoch 22/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0455 - acc: 0.9838 - precision_m: 0.8566 - recall_m: 0.6655 - f1_m: 0.7267\n",
      "Epoch 22: val_acc did not improve from 0.97879\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0453 - acc: 0.9839 - precision_m: 0.8544 - recall_m: 0.6682 - f1_m: 0.7274 - val_loss: 0.0729 - val_acc: 0.9775 - val_precision_m: 0.8098 - val_recall_m: 0.5230 - val_f1_m: 0.6044\n",
      "Epoch 23/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0440 - acc: 0.9846 - precision_m: 0.8611 - recall_m: 0.6927 - f1_m: 0.7476\n",
      "Epoch 23: val_acc did not improve from 0.97879\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0443 - acc: 0.9843 - precision_m: 0.8596 - recall_m: 0.6874 - f1_m: 0.7430 - val_loss: 0.0777 - val_acc: 0.9716 - val_precision_m: 0.6241 - val_recall_m: 0.8008 - val_f1_m: 0.6648\n",
      "Epoch 24/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0450 - acc: 0.9842 - precision_m: 0.8537 - recall_m: 0.6901 - f1_m: 0.7423\n",
      "Epoch 24: val_acc improved from 0.97879 to 0.97891, saving model to models/best_model_4_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0447 - acc: 0.9843 - precision_m: 0.8558 - recall_m: 0.6911 - f1_m: 0.7438 - val_loss: 0.0708 - val_acc: 0.9789 - val_precision_m: 0.8762 - val_recall_m: 0.5706 - val_f1_m: 0.6514\n",
      "Epoch 25/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9854 - precision_m: 0.8769 - recall_m: 0.7088 - f1_m: 0.7647\n",
      "Epoch 25: val_acc did not improve from 0.97891\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0425 - acc: 0.9852 - precision_m: 0.8755 - recall_m: 0.7072 - f1_m: 0.7629 - val_loss: 0.0688 - val_acc: 0.9788 - val_precision_m: 0.8265 - val_recall_m: 0.5752 - val_f1_m: 0.6444\n",
      "Epoch 26/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9856 - precision_m: 0.8712 - recall_m: 0.7162 - f1_m: 0.7680\n",
      "Epoch 26: val_acc did not improve from 0.97891\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0419 - acc: 0.9856 - precision_m: 0.8705 - recall_m: 0.7146 - f1_m: 0.7663 - val_loss: 0.0761 - val_acc: 0.9783 - val_precision_m: 0.8985 - val_recall_m: 0.5489 - val_f1_m: 0.6320\n",
      "Epoch 27/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0436 - acc: 0.9848 - precision_m: 0.8636 - recall_m: 0.7059 - f1_m: 0.7560\n",
      "Epoch 27: val_acc did not improve from 0.97891\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0442 - acc: 0.9846 - precision_m: 0.8598 - recall_m: 0.7024 - f1_m: 0.7513 - val_loss: 0.0710 - val_acc: 0.9776 - val_precision_m: 0.8057 - val_recall_m: 0.5512 - val_f1_m: 0.6166\n",
      "Epoch 28/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0431 - acc: 0.9850 - precision_m: 0.8745 - recall_m: 0.7101 - f1_m: 0.7614\n",
      "Epoch 28: val_acc did not improve from 0.97891\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0433 - acc: 0.9849 - precision_m: 0.8731 - recall_m: 0.7110 - f1_m: 0.7615 - val_loss: 0.0683 - val_acc: 0.9775 - val_precision_m: 0.7622 - val_recall_m: 0.6067 - val_f1_m: 0.6409\n",
      "Epoch 29/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0417 - acc: 0.9855 - precision_m: 0.8707 - recall_m: 0.7166 - f1_m: 0.7645\n",
      "Epoch 29: val_acc improved from 0.97891 to 0.97987, saving model to models/best_model_4_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0417 - acc: 0.9855 - precision_m: 0.8697 - recall_m: 0.7175 - f1_m: 0.7650 - val_loss: 0.0738 - val_acc: 0.9799 - val_precision_m: 0.8539 - val_recall_m: 0.5964 - val_f1_m: 0.6600\n",
      "Epoch 30/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9859 - precision_m: 0.8738 - recall_m: 0.7306 - f1_m: 0.7789\n",
      "Epoch 30: val_acc did not improve from 0.97987\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0396 - acc: 0.9860 - precision_m: 0.8743 - recall_m: 0.7310 - f1_m: 0.7793 - val_loss: 0.0680 - val_acc: 0.9783 - val_precision_m: 0.8416 - val_recall_m: 0.5810 - val_f1_m: 0.6410\n",
      "Score for fold 6: loss of 0.07384378463029861; acc of 97.98722267150879%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.07692164927721024; acc of 97.79083728790283%\n",
      "Test Precision: precision_m of 26.38888955116272%\n",
      "Test Recall: recall_m of 20.301753282546997%\n",
      "Test F1: f1_m of 21.80010676383972%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1153 - acc: 0.9655 - precision_m: 0.3945 - recall_m: 0.1431 - f1_m: 0.1914\n",
      "Epoch 1: val_acc improved from -inf to 0.96535, saving model to models/best_model_4_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 2s 4ms/step - loss: 0.1153 - acc: 0.9655 - precision_m: 0.3945 - recall_m: 0.1431 - f1_m: 0.1914 - val_loss: 0.1115 - val_acc: 0.9654 - val_precision_m: 0.4232 - val_recall_m: 0.0871 - val_f1_m: 0.1347\n",
      "Epoch 2/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0875 - acc: 0.9706 - precision_m: 0.7232 - recall_m: 0.3480 - f1_m: 0.4314\n",
      "Epoch 2: val_acc improved from 0.96535 to 0.96953, saving model to models/best_model_4_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0875 - acc: 0.9706 - precision_m: 0.7267 - recall_m: 0.3502 - f1_m: 0.4344 - val_loss: 0.0870 - val_acc: 0.9695 - val_precision_m: 0.6225 - val_recall_m: 0.3452 - val_f1_m: 0.4142\n",
      "Epoch 3/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0783 - acc: 0.9735 - precision_m: 0.7717 - recall_m: 0.4257 - f1_m: 0.5196\n",
      "Epoch 3: val_acc improved from 0.96953 to 0.97312, saving model to models/best_model_4_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0780 - acc: 0.9736 - precision_m: 0.7714 - recall_m: 0.4277 - f1_m: 0.5208 - val_loss: 0.0806 - val_acc: 0.9731 - val_precision_m: 0.7071 - val_recall_m: 0.4190 - val_f1_m: 0.4900\n",
      "Epoch 4/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0740 - acc: 0.9745 - precision_m: 0.7797 - recall_m: 0.4670 - f1_m: 0.5541\n",
      "Epoch 4: val_acc did not improve from 0.97312\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0740 - acc: 0.9745 - precision_m: 0.7750 - recall_m: 0.4664 - f1_m: 0.5511 - val_loss: 0.1061 - val_acc: 0.9676 - val_precision_m: 0.5939 - val_recall_m: 0.1313 - val_f1_m: 0.2019\n",
      "Epoch 5/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0724 - acc: 0.9751 - precision_m: 0.7938 - recall_m: 0.4831 - f1_m: 0.5642\n",
      "Epoch 5: val_acc did not improve from 0.97312\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0724 - acc: 0.9751 - precision_m: 0.7947 - recall_m: 0.4846 - f1_m: 0.5649 - val_loss: 0.0896 - val_acc: 0.9701 - val_precision_m: 0.6803 - val_recall_m: 0.2304 - val_f1_m: 0.3224\n",
      "Epoch 6/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0698 - acc: 0.9760 - precision_m: 0.7894 - recall_m: 0.5004 - f1_m: 0.5768\n",
      "Epoch 6: val_acc did not improve from 0.97312\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0696 - acc: 0.9762 - precision_m: 0.7915 - recall_m: 0.5044 - f1_m: 0.5809 - val_loss: 0.0829 - val_acc: 0.9723 - val_precision_m: 0.6284 - val_recall_m: 0.5636 - val_f1_m: 0.5638\n",
      "Epoch 7/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0658 - acc: 0.9781 - precision_m: 0.8122 - recall_m: 0.5396 - f1_m: 0.6193\n",
      "Epoch 7: val_acc did not improve from 0.97312\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0659 - acc: 0.9780 - precision_m: 0.8122 - recall_m: 0.5377 - f1_m: 0.6182 - val_loss: 0.0832 - val_acc: 0.9722 - val_precision_m: 0.7982 - val_recall_m: 0.2869 - val_f1_m: 0.3993\n",
      "Epoch 8/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9782 - precision_m: 0.8078 - recall_m: 0.5464 - f1_m: 0.6240\n",
      "Epoch 8: val_acc improved from 0.97312 to 0.97443, saving model to models/best_model_4_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0629 - acc: 0.9783 - precision_m: 0.8092 - recall_m: 0.5465 - f1_m: 0.6249 - val_loss: 0.0750 - val_acc: 0.9744 - val_precision_m: 0.8352 - val_recall_m: 0.4035 - val_f1_m: 0.5038\n",
      "Epoch 9/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0618 - acc: 0.9791 - precision_m: 0.8329 - recall_m: 0.5663 - f1_m: 0.6484\n",
      "Epoch 9: val_acc improved from 0.97443 to 0.97611, saving model to models/best_model_4_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0616 - acc: 0.9791 - precision_m: 0.8314 - recall_m: 0.5669 - f1_m: 0.6481 - val_loss: 0.0719 - val_acc: 0.9761 - val_precision_m: 0.7995 - val_recall_m: 0.4394 - val_f1_m: 0.5338\n",
      "Epoch 10/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0594 - acc: 0.9793 - precision_m: 0.8111 - recall_m: 0.5719 - f1_m: 0.6472\n",
      "Epoch 10: val_acc improved from 0.97611 to 0.97682, saving model to models/best_model_4_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0594 - acc: 0.9793 - precision_m: 0.8135 - recall_m: 0.5720 - f1_m: 0.6482 - val_loss: 0.0707 - val_acc: 0.9768 - val_precision_m: 0.8144 - val_recall_m: 0.5008 - val_f1_m: 0.5799\n",
      "Epoch 11/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0581 - acc: 0.9799 - precision_m: 0.8327 - recall_m: 0.5920 - f1_m: 0.6654\n",
      "Epoch 11: val_acc did not improve from 0.97682\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0585 - acc: 0.9798 - precision_m: 0.8301 - recall_m: 0.5924 - f1_m: 0.6650 - val_loss: 0.0863 - val_acc: 0.9731 - val_precision_m: 0.8864 - val_recall_m: 0.2939 - val_f1_m: 0.4168\n",
      "Epoch 12/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.0587 - acc: 0.9792 - precision_m: 0.8203 - recall_m: 0.5777 - f1_m: 0.6476\n",
      "Epoch 12: val_acc improved from 0.97682 to 0.97694, saving model to models/best_model_4_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0584 - acc: 0.9794 - precision_m: 0.8245 - recall_m: 0.5809 - f1_m: 0.6521 - val_loss: 0.0694 - val_acc: 0.9769 - val_precision_m: 0.7855 - val_recall_m: 0.4648 - val_f1_m: 0.5562\n",
      "Epoch 13/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0571 - acc: 0.9797 - precision_m: 0.8188 - recall_m: 0.5923 - f1_m: 0.6557\n",
      "Epoch 13: val_acc improved from 0.97694 to 0.97706, saving model to models/best_model_4_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0573 - acc: 0.9797 - precision_m: 0.8193 - recall_m: 0.5956 - f1_m: 0.6583 - val_loss: 0.0686 - val_acc: 0.9771 - val_precision_m: 0.8164 - val_recall_m: 0.4782 - val_f1_m: 0.5671\n",
      "Epoch 14/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0570 - acc: 0.9802 - precision_m: 0.8413 - recall_m: 0.6134 - f1_m: 0.6764\n",
      "Epoch 14: val_acc did not improve from 0.97706\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0570 - acc: 0.9802 - precision_m: 0.8390 - recall_m: 0.6169 - f1_m: 0.6778 - val_loss: 0.0856 - val_acc: 0.9753 - val_precision_m: 0.8672 - val_recall_m: 0.3609 - val_f1_m: 0.4770\n",
      "Epoch 15/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0523 - acc: 0.9820 - precision_m: 0.8557 - recall_m: 0.6287 - f1_m: 0.7031\n",
      "Epoch 15: val_acc did not improve from 0.97706\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0522 - acc: 0.9820 - precision_m: 0.8558 - recall_m: 0.6304 - f1_m: 0.7042 - val_loss: 0.0939 - val_acc: 0.9728 - val_precision_m: 0.8636 - val_recall_m: 0.2789 - val_f1_m: 0.3938\n",
      "Epoch 16/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0536 - acc: 0.9815 - precision_m: 0.8432 - recall_m: 0.6175 - f1_m: 0.6847\n",
      "Epoch 16: val_acc did not improve from 0.97706\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0536 - acc: 0.9815 - precision_m: 0.8419 - recall_m: 0.6208 - f1_m: 0.6863 - val_loss: 0.0905 - val_acc: 0.9730 - val_precision_m: 0.8348 - val_recall_m: 0.3005 - val_f1_m: 0.4179\n",
      "Epoch 17/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0500 - acc: 0.9831 - precision_m: 0.8621 - recall_m: 0.6546 - f1_m: 0.7255\n",
      "Epoch 17: val_acc improved from 0.97706 to 0.97790, saving model to models/best_model_4_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0501 - acc: 0.9831 - precision_m: 0.8626 - recall_m: 0.6562 - f1_m: 0.7267 - val_loss: 0.0662 - val_acc: 0.9779 - val_precision_m: 0.7352 - val_recall_m: 0.5806 - val_f1_m: 0.6231\n",
      "Epoch 18/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0495 - acc: 0.9827 - precision_m: 0.8532 - recall_m: 0.6584 - f1_m: 0.7195\n",
      "Epoch 18: val_acc improved from 0.97790 to 0.97838, saving model to models/best_model_4_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0494 - acc: 0.9828 - precision_m: 0.8511 - recall_m: 0.6609 - f1_m: 0.7194 - val_loss: 0.0662 - val_acc: 0.9784 - val_precision_m: 0.7147 - val_recall_m: 0.6264 - val_f1_m: 0.6403\n",
      "Epoch 19/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.0487 - acc: 0.9829 - precision_m: 0.8563 - recall_m: 0.6622 - f1_m: 0.7262\n",
      "Epoch 19: val_acc improved from 0.97838 to 0.97957, saving model to models/best_model_4_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0489 - acc: 0.9829 - precision_m: 0.8602 - recall_m: 0.6609 - f1_m: 0.7259 - val_loss: 0.0647 - val_acc: 0.9796 - val_precision_m: 0.8218 - val_recall_m: 0.5317 - val_f1_m: 0.6181\n",
      "Epoch 20/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.0494 - acc: 0.9832 - precision_m: 0.8680 - recall_m: 0.6599 - f1_m: 0.7232\n",
      "Epoch 20: val_acc did not improve from 0.97957\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0493 - acc: 0.9832 - precision_m: 0.8668 - recall_m: 0.6631 - f1_m: 0.7254 - val_loss: 0.0677 - val_acc: 0.9784 - val_precision_m: 0.8321 - val_recall_m: 0.5062 - val_f1_m: 0.5952\n",
      "Epoch 21/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.0481 - acc: 0.9832 - precision_m: 0.8540 - recall_m: 0.6714 - f1_m: 0.7313\n",
      "Epoch 21: val_acc improved from 0.97957 to 0.97981, saving model to models/best_model_4_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0480 - acc: 0.9832 - precision_m: 0.8545 - recall_m: 0.6725 - f1_m: 0.7323 - val_loss: 0.0645 - val_acc: 0.9798 - val_precision_m: 0.7966 - val_recall_m: 0.5619 - val_f1_m: 0.6325\n",
      "Epoch 22/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0457 - acc: 0.9837 - precision_m: 0.8604 - recall_m: 0.6795 - f1_m: 0.7413\n",
      "Epoch 22: val_acc did not improve from 0.97981\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0456 - acc: 0.9838 - precision_m: 0.8602 - recall_m: 0.6796 - f1_m: 0.7415 - val_loss: 0.0659 - val_acc: 0.9789 - val_precision_m: 0.7341 - val_recall_m: 0.6065 - val_f1_m: 0.6425\n",
      "Epoch 23/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9843 - precision_m: 0.8628 - recall_m: 0.6922 - f1_m: 0.7509\n",
      "Epoch 23: val_acc did not improve from 0.97981\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0447 - acc: 0.9843 - precision_m: 0.8610 - recall_m: 0.6913 - f1_m: 0.7498 - val_loss: 0.0633 - val_acc: 0.9797 - val_precision_m: 0.7722 - val_recall_m: 0.6082 - val_f1_m: 0.6532\n",
      "Epoch 24/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0453 - acc: 0.9838 - precision_m: 0.8572 - recall_m: 0.6852 - f1_m: 0.7416\n",
      "Epoch 24: val_acc did not improve from 0.97981\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0453 - acc: 0.9838 - precision_m: 0.8583 - recall_m: 0.6862 - f1_m: 0.7428 - val_loss: 0.0657 - val_acc: 0.9789 - val_precision_m: 0.7510 - val_recall_m: 0.5492 - val_f1_m: 0.6160\n",
      "Epoch 25/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0437 - acc: 0.9847 - precision_m: 0.8700 - recall_m: 0.6979 - f1_m: 0.7573\n",
      "Epoch 25: val_acc did not improve from 0.97981\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0437 - acc: 0.9847 - precision_m: 0.8699 - recall_m: 0.6971 - f1_m: 0.7563 - val_loss: 0.0655 - val_acc: 0.9781 - val_precision_m: 0.7653 - val_recall_m: 0.5374 - val_f1_m: 0.6026\n",
      "Epoch 26/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0441 - acc: 0.9847 - precision_m: 0.8803 - recall_m: 0.7069 - f1_m: 0.7649\n",
      "Epoch 26: val_acc did not improve from 0.97981\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0439 - acc: 0.9847 - precision_m: 0.8757 - recall_m: 0.7073 - f1_m: 0.7633 - val_loss: 0.0713 - val_acc: 0.9780 - val_precision_m: 0.8471 - val_recall_m: 0.4853 - val_f1_m: 0.5865\n",
      "Epoch 27/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9851 - precision_m: 0.8719 - recall_m: 0.7135 - f1_m: 0.7681\n",
      "Epoch 27: val_acc did not improve from 0.97981\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0419 - acc: 0.9851 - precision_m: 0.8710 - recall_m: 0.7146 - f1_m: 0.7682 - val_loss: 0.0664 - val_acc: 0.9783 - val_precision_m: 0.7884 - val_recall_m: 0.5660 - val_f1_m: 0.6210\n",
      "Epoch 28/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0428 - acc: 0.9848 - precision_m: 0.8735 - recall_m: 0.6964 - f1_m: 0.7544\n",
      "Epoch 28: val_acc did not improve from 0.97981\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0430 - acc: 0.9846 - precision_m: 0.8708 - recall_m: 0.6949 - f1_m: 0.7523 - val_loss: 0.0666 - val_acc: 0.9768 - val_precision_m: 0.6739 - val_recall_m: 0.6809 - val_f1_m: 0.6519\n",
      "Epoch 29/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0401 - acc: 0.9857 - precision_m: 0.8752 - recall_m: 0.7262 - f1_m: 0.7795\n",
      "Epoch 29: val_acc did not improve from 0.97981\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0397 - acc: 0.9858 - precision_m: 0.8762 - recall_m: 0.7262 - f1_m: 0.7793 - val_loss: 0.0745 - val_acc: 0.9781 - val_precision_m: 0.8370 - val_recall_m: 0.4899 - val_f1_m: 0.5886\n",
      "Epoch 30/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0408 - acc: 0.9853 - precision_m: 0.8720 - recall_m: 0.7177 - f1_m: 0.7688\n",
      "Epoch 30: val_acc improved from 0.97981 to 0.98065, saving model to models/best_model_4_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0409 - acc: 0.9853 - precision_m: 0.8724 - recall_m: 0.7171 - f1_m: 0.7683 - val_loss: 0.0629 - val_acc: 0.9806 - val_precision_m: 0.7606 - val_recall_m: 0.6463 - val_f1_m: 0.6762\n",
      "Score for fold 7: loss of 0.06293405592441559; acc of 98.06451797485352%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.058879803866147995; acc of 98.12124371528625%\n",
      "Test Precision: precision_m of 26.174989342689514%\n",
      "Test Recall: recall_m of 21.219511330127716%\n",
      "Test F1: f1_m of 22.293618321418762%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1177 - acc: 0.9656 - precision_m: 0.3765 - recall_m: 0.1182 - f1_m: 0.1630\n",
      "Epoch 1: val_acc improved from -inf to 0.96730, saving model to models/best_model_4_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 2s 4ms/step - loss: 0.1177 - acc: 0.9656 - precision_m: 0.3765 - recall_m: 0.1182 - f1_m: 0.1630 - val_loss: 0.0951 - val_acc: 0.9673 - val_precision_m: 0.5137 - val_recall_m: 0.2708 - val_f1_m: 0.3208\n",
      "Epoch 2/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0877 - acc: 0.9710 - precision_m: 0.6938 - recall_m: 0.3409 - f1_m: 0.4273\n",
      "Epoch 2: val_acc improved from 0.96730 to 0.96897, saving model to models/best_model_4_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0871 - acc: 0.9712 - precision_m: 0.7012 - recall_m: 0.3432 - f1_m: 0.4304 - val_loss: 0.0889 - val_acc: 0.9690 - val_precision_m: 0.5712 - val_recall_m: 0.3800 - val_f1_m: 0.4205\n",
      "Epoch 3/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0785 - acc: 0.9730 - precision_m: 0.7449 - recall_m: 0.4069 - f1_m: 0.4964\n",
      "Epoch 3: val_acc improved from 0.96897 to 0.96957, saving model to models/best_model_4_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0785 - acc: 0.9731 - precision_m: 0.7476 - recall_m: 0.4071 - f1_m: 0.4976 - val_loss: 0.0870 - val_acc: 0.9696 - val_precision_m: 0.5869 - val_recall_m: 0.4103 - val_f1_m: 0.4558\n",
      "Epoch 4/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0734 - acc: 0.9749 - precision_m: 0.7623 - recall_m: 0.4455 - f1_m: 0.5368\n",
      "Epoch 4: val_acc improved from 0.96957 to 0.97137, saving model to models/best_model_4_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0732 - acc: 0.9750 - precision_m: 0.7616 - recall_m: 0.4508 - f1_m: 0.5404 - val_loss: 0.0852 - val_acc: 0.9714 - val_precision_m: 0.6378 - val_recall_m: 0.2727 - val_f1_m: 0.3536\n",
      "Epoch 5/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0716 - acc: 0.9756 - precision_m: 0.7815 - recall_m: 0.4829 - f1_m: 0.5629\n",
      "Epoch 5: val_acc improved from 0.97137 to 0.97209, saving model to models/best_model_4_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0716 - acc: 0.9757 - precision_m: 0.7756 - recall_m: 0.4821 - f1_m: 0.5606 - val_loss: 0.0774 - val_acc: 0.9721 - val_precision_m: 0.6152 - val_recall_m: 0.4494 - val_f1_m: 0.4864\n",
      "Epoch 6/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0687 - acc: 0.9763 - precision_m: 0.7902 - recall_m: 0.5084 - f1_m: 0.5874\n",
      "Epoch 6: val_acc improved from 0.97209 to 0.97353, saving model to models/best_model_4_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0688 - acc: 0.9763 - precision_m: 0.7885 - recall_m: 0.5107 - f1_m: 0.5889 - val_loss: 0.0749 - val_acc: 0.9735 - val_precision_m: 0.6420 - val_recall_m: 0.3433 - val_f1_m: 0.4199\n",
      "Epoch 7/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0655 - acc: 0.9777 - precision_m: 0.8150 - recall_m: 0.5342 - f1_m: 0.6179\n",
      "Epoch 7: val_acc did not improve from 0.97353\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0651 - acc: 0.9779 - precision_m: 0.8187 - recall_m: 0.5371 - f1_m: 0.6217 - val_loss: 0.0771 - val_acc: 0.9732 - val_precision_m: 0.6475 - val_recall_m: 0.3779 - val_f1_m: 0.4421\n",
      "Epoch 8/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0633 - acc: 0.9783 - precision_m: 0.8115 - recall_m: 0.5481 - f1_m: 0.6253\n",
      "Epoch 8: val_acc improved from 0.97353 to 0.97389, saving model to models/best_model_4_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0636 - acc: 0.9782 - precision_m: 0.8108 - recall_m: 0.5497 - f1_m: 0.6262 - val_loss: 0.0745 - val_acc: 0.9739 - val_precision_m: 0.6845 - val_recall_m: 0.3829 - val_f1_m: 0.4600\n",
      "Epoch 9/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9792 - precision_m: 0.8168 - recall_m: 0.5707 - f1_m: 0.6474\n",
      "Epoch 9: val_acc improved from 0.97389 to 0.97472, saving model to models/best_model_4_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0606 - acc: 0.9791 - precision_m: 0.8153 - recall_m: 0.5702 - f1_m: 0.6468 - val_loss: 0.0718 - val_acc: 0.9747 - val_precision_m: 0.6525 - val_recall_m: 0.4508 - val_f1_m: 0.4958\n",
      "Epoch 10/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0595 - acc: 0.9795 - precision_m: 0.8096 - recall_m: 0.5666 - f1_m: 0.6443\n",
      "Epoch 10: val_acc did not improve from 0.97472\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0594 - acc: 0.9796 - precision_m: 0.8146 - recall_m: 0.5673 - f1_m: 0.6460 - val_loss: 0.0724 - val_acc: 0.9735 - val_precision_m: 0.5935 - val_recall_m: 0.5314 - val_f1_m: 0.5323\n",
      "Epoch 11/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0582 - acc: 0.9801 - precision_m: 0.8396 - recall_m: 0.5938 - f1_m: 0.6680\n",
      "Epoch 11: val_acc improved from 0.97472 to 0.97568, saving model to models/best_model_4_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0583 - acc: 0.9801 - precision_m: 0.8369 - recall_m: 0.5921 - f1_m: 0.6664 - val_loss: 0.0687 - val_acc: 0.9757 - val_precision_m: 0.6193 - val_recall_m: 0.5099 - val_f1_m: 0.5390\n",
      "Epoch 12/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.0572 - acc: 0.9805 - precision_m: 0.8277 - recall_m: 0.6007 - f1_m: 0.6708\n",
      "Epoch 12: val_acc did not improve from 0.97568\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0575 - acc: 0.9804 - precision_m: 0.8269 - recall_m: 0.5956 - f1_m: 0.6654 - val_loss: 0.0730 - val_acc: 0.9745 - val_precision_m: 0.6034 - val_recall_m: 0.6098 - val_f1_m: 0.5737\n",
      "Epoch 13/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0547 - acc: 0.9811 - precision_m: 0.8359 - recall_m: 0.6073 - f1_m: 0.6795\n",
      "Epoch 13: val_acc improved from 0.97568 to 0.97580, saving model to models/best_model_4_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0551 - acc: 0.9810 - precision_m: 0.8374 - recall_m: 0.6053 - f1_m: 0.6783 - val_loss: 0.0713 - val_acc: 0.9758 - val_precision_m: 0.6709 - val_recall_m: 0.5088 - val_f1_m: 0.5433\n",
      "Epoch 14/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0554 - acc: 0.9810 - precision_m: 0.8460 - recall_m: 0.6203 - f1_m: 0.6905\n",
      "Epoch 14: val_acc improved from 0.97580 to 0.97664, saving model to models/best_model_4_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0551 - acc: 0.9811 - precision_m: 0.8477 - recall_m: 0.6224 - f1_m: 0.6926 - val_loss: 0.0679 - val_acc: 0.9766 - val_precision_m: 0.7049 - val_recall_m: 0.4716 - val_f1_m: 0.5267\n",
      "Epoch 15/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9822 - precision_m: 0.8506 - recall_m: 0.6372 - f1_m: 0.7067\n",
      "Epoch 15: val_acc did not improve from 0.97664\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0525 - acc: 0.9821 - precision_m: 0.8486 - recall_m: 0.6369 - f1_m: 0.7055 - val_loss: 0.0718 - val_acc: 0.9765 - val_precision_m: 0.7437 - val_recall_m: 0.4054 - val_f1_m: 0.5010\n",
      "Epoch 16/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0546 - acc: 0.9813 - precision_m: 0.8424 - recall_m: 0.6176 - f1_m: 0.6862\n",
      "Epoch 16: val_acc improved from 0.97664 to 0.97856, saving model to models/best_model_4_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0541 - acc: 0.9815 - precision_m: 0.8444 - recall_m: 0.6202 - f1_m: 0.6893 - val_loss: 0.0675 - val_acc: 0.9786 - val_precision_m: 0.7789 - val_recall_m: 0.4486 - val_f1_m: 0.5441\n",
      "Epoch 17/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0512 - acc: 0.9825 - precision_m: 0.8490 - recall_m: 0.6513 - f1_m: 0.7149\n",
      "Epoch 17: val_acc did not improve from 0.97856\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0514 - acc: 0.9825 - precision_m: 0.8507 - recall_m: 0.6508 - f1_m: 0.7148 - val_loss: 0.0740 - val_acc: 0.9764 - val_precision_m: 0.7492 - val_recall_m: 0.4045 - val_f1_m: 0.4985\n",
      "Epoch 18/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0517 - acc: 0.9820 - precision_m: 0.8503 - recall_m: 0.6373 - f1_m: 0.7013\n",
      "Epoch 18: val_acc did not improve from 0.97856\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0518 - acc: 0.9821 - precision_m: 0.8508 - recall_m: 0.6385 - f1_m: 0.7028 - val_loss: 0.0657 - val_acc: 0.9778 - val_precision_m: 0.7417 - val_recall_m: 0.4738 - val_f1_m: 0.5457\n",
      "Epoch 19/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0485 - acc: 0.9838 - precision_m: 0.8622 - recall_m: 0.6670 - f1_m: 0.7333\n",
      "Epoch 19: val_acc did not improve from 0.97856\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0490 - acc: 0.9838 - precision_m: 0.8602 - recall_m: 0.6659 - f1_m: 0.7317 - val_loss: 0.0708 - val_acc: 0.9768 - val_precision_m: 0.7013 - val_recall_m: 0.4518 - val_f1_m: 0.5144\n",
      "Epoch 20/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0485 - acc: 0.9835 - precision_m: 0.8633 - recall_m: 0.6776 - f1_m: 0.7394\n",
      "Epoch 20: val_acc did not improve from 0.97856\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0487 - acc: 0.9833 - precision_m: 0.8621 - recall_m: 0.6771 - f1_m: 0.7377 - val_loss: 0.0732 - val_acc: 0.9774 - val_precision_m: 0.7350 - val_recall_m: 0.4472 - val_f1_m: 0.5316\n",
      "Epoch 21/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0477 - acc: 0.9832 - precision_m: 0.8541 - recall_m: 0.6654 - f1_m: 0.7273\n",
      "Epoch 21: val_acc did not improve from 0.97856\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0486 - acc: 0.9830 - precision_m: 0.8519 - recall_m: 0.6618 - f1_m: 0.7234 - val_loss: 0.0748 - val_acc: 0.9732 - val_precision_m: 0.5561 - val_recall_m: 0.6564 - val_f1_m: 0.5838\n",
      "Epoch 22/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0486 - acc: 0.9831 - precision_m: 0.8562 - recall_m: 0.6629 - f1_m: 0.7258\n",
      "Epoch 22: val_acc did not improve from 0.97856\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0484 - acc: 0.9832 - precision_m: 0.8569 - recall_m: 0.6628 - f1_m: 0.7260 - val_loss: 0.0645 - val_acc: 0.9784 - val_precision_m: 0.6917 - val_recall_m: 0.5329 - val_f1_m: 0.5805\n",
      "Epoch 23/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0472 - acc: 0.9838 - precision_m: 0.8602 - recall_m: 0.6732 - f1_m: 0.7348\n",
      "Epoch 23: val_acc improved from 0.97856 to 0.97916, saving model to models/best_model_4_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0469 - acc: 0.9839 - precision_m: 0.8617 - recall_m: 0.6759 - f1_m: 0.7372 - val_loss: 0.0634 - val_acc: 0.9792 - val_precision_m: 0.7145 - val_recall_m: 0.5166 - val_f1_m: 0.5774\n",
      "Epoch 24/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0462 - acc: 0.9839 - precision_m: 0.8504 - recall_m: 0.6791 - f1_m: 0.7347\n",
      "Epoch 24: val_acc did not improve from 0.97916\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0461 - acc: 0.9840 - precision_m: 0.8525 - recall_m: 0.6796 - f1_m: 0.7356 - val_loss: 0.0740 - val_acc: 0.9780 - val_precision_m: 0.7937 - val_recall_m: 0.4484 - val_f1_m: 0.5401\n",
      "Epoch 25/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0449 - acc: 0.9842 - precision_m: 0.8707 - recall_m: 0.6857 - f1_m: 0.7457\n",
      "Epoch 25: val_acc did not improve from 0.97916\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0451 - acc: 0.9841 - precision_m: 0.8702 - recall_m: 0.6837 - f1_m: 0.7441 - val_loss: 0.0735 - val_acc: 0.9772 - val_precision_m: 0.7995 - val_recall_m: 0.4340 - val_f1_m: 0.5265\n",
      "Epoch 26/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.0456 - acc: 0.9843 - precision_m: 0.8663 - recall_m: 0.6916 - f1_m: 0.7479\n",
      "Epoch 26: val_acc did not improve from 0.97916\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0452 - acc: 0.9843 - precision_m: 0.8681 - recall_m: 0.6945 - f1_m: 0.7495 - val_loss: 0.0638 - val_acc: 0.9782 - val_precision_m: 0.6817 - val_recall_m: 0.5284 - val_f1_m: 0.5721\n",
      "Epoch 27/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9856 - precision_m: 0.8756 - recall_m: 0.7149 - f1_m: 0.7718\n",
      "Epoch 27: val_acc did not improve from 0.97916\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0434 - acc: 0.9856 - precision_m: 0.8747 - recall_m: 0.7164 - f1_m: 0.7722 - val_loss: 0.0706 - val_acc: 0.9781 - val_precision_m: 0.7550 - val_recall_m: 0.4743 - val_f1_m: 0.5590\n",
      "Epoch 28/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0453 - acc: 0.9843 - precision_m: 0.8623 - recall_m: 0.6998 - f1_m: 0.7504\n",
      "Epoch 28: val_acc did not improve from 0.97916\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0448 - acc: 0.9844 - precision_m: 0.8645 - recall_m: 0.6980 - f1_m: 0.7504 - val_loss: 0.0697 - val_acc: 0.9787 - val_precision_m: 0.7962 - val_recall_m: 0.4695 - val_f1_m: 0.5638\n",
      "Epoch 29/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0422 - acc: 0.9860 - precision_m: 0.8889 - recall_m: 0.7147 - f1_m: 0.7766\n",
      "Epoch 29: val_acc did not improve from 0.97916\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0420 - acc: 0.9860 - precision_m: 0.8872 - recall_m: 0.7121 - f1_m: 0.7744 - val_loss: 0.0644 - val_acc: 0.9787 - val_precision_m: 0.7597 - val_recall_m: 0.4986 - val_f1_m: 0.5856\n",
      "Epoch 30/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0429 - acc: 0.9849 - precision_m: 0.8631 - recall_m: 0.7088 - f1_m: 0.7591\n",
      "Epoch 30: val_acc did not improve from 0.97916\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0430 - acc: 0.9849 - precision_m: 0.8623 - recall_m: 0.7089 - f1_m: 0.7591 - val_loss: 0.0670 - val_acc: 0.9747 - val_precision_m: 0.5702 - val_recall_m: 0.6146 - val_f1_m: 0.5788\n",
      "Score for fold 8: loss of 0.06343943625688553; acc of 97.91566729545593%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.06760629266500473; acc of 98.03075790405273%\n",
      "Test Precision: precision_m of 25.38280189037323%\n",
      "Test Recall: recall_m of 20.100751519203186%\n",
      "Test F1: f1_m of 21.601267158985138%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "Epoch 1/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.1469 - acc: 0.9603 - precision_m: 0.0925 - recall_m: 0.0203 - f1_m: 0.0270\n",
      "Epoch 1: val_acc improved from -inf to 0.96235, saving model to models/best_model_4_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 2s 4ms/step - loss: 0.1469 - acc: 0.9603 - precision_m: 0.0925 - recall_m: 0.0203 - f1_m: 0.0270 - val_loss: 0.1141 - val_acc: 0.9623 - val_precision_m: 0.2424 - val_recall_m: 0.0296 - val_f1_m: 0.0513\n",
      "Epoch 2/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0983 - acc: 0.9684 - precision_m: 0.6091 - recall_m: 0.2038 - f1_m: 0.2801\n",
      "Epoch 2: val_acc improved from 0.96235 to 0.96795, saving model to models/best_model_4_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0976 - acc: 0.9686 - precision_m: 0.6165 - recall_m: 0.2103 - f1_m: 0.2880 - val_loss: 0.0960 - val_acc: 0.9679 - val_precision_m: 0.6861 - val_recall_m: 0.2472 - val_f1_m: 0.3353\n",
      "Epoch 3/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0856 - acc: 0.9718 - precision_m: 0.7122 - recall_m: 0.3339 - f1_m: 0.4238\n",
      "Epoch 3: val_acc did not improve from 0.96795\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0857 - acc: 0.9716 - precision_m: 0.7125 - recall_m: 0.3352 - f1_m: 0.4251 - val_loss: 0.0968 - val_acc: 0.9676 - val_precision_m: 0.6361 - val_recall_m: 0.1958 - val_f1_m: 0.2813\n",
      "Epoch 4/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.0812 - acc: 0.9731 - precision_m: 0.7489 - recall_m: 0.3896 - f1_m: 0.4783\n",
      "Epoch 4: val_acc improved from 0.96795 to 0.97152, saving model to models/best_model_4_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0808 - acc: 0.9732 - precision_m: 0.7544 - recall_m: 0.3917 - f1_m: 0.4817 - val_loss: 0.0880 - val_acc: 0.9715 - val_precision_m: 0.8114 - val_recall_m: 0.3744 - val_f1_m: 0.4630\n",
      "Epoch 5/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0746 - acc: 0.9748 - precision_m: 0.7558 - recall_m: 0.4401 - f1_m: 0.5307\n",
      "Epoch 5: val_acc improved from 0.97152 to 0.97283, saving model to models/best_model_4_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0746 - acc: 0.9747 - precision_m: 0.7546 - recall_m: 0.4389 - f1_m: 0.5295 - val_loss: 0.0858 - val_acc: 0.9728 - val_precision_m: 0.7099 - val_recall_m: 0.4852 - val_f1_m: 0.5253\n",
      "Epoch 6/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.0725 - acc: 0.9757 - precision_m: 0.7883 - recall_m: 0.4638 - f1_m: 0.5559\n",
      "Epoch 6: val_acc improved from 0.97283 to 0.97402, saving model to models/best_model_4_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0716 - acc: 0.9760 - precision_m: 0.7918 - recall_m: 0.4679 - f1_m: 0.5606 - val_loss: 0.0779 - val_acc: 0.9740 - val_precision_m: 0.7902 - val_recall_m: 0.4544 - val_f1_m: 0.5395\n",
      "Epoch 7/30\n",
      "275/291 [===========================>..] - ETA: 0s - loss: 0.0691 - acc: 0.9768 - precision_m: 0.7912 - recall_m: 0.4872 - f1_m: 0.5718\n",
      "Epoch 7: val_acc did not improve from 0.97402\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0693 - acc: 0.9768 - precision_m: 0.7931 - recall_m: 0.4879 - f1_m: 0.5736 - val_loss: 0.0894 - val_acc: 0.9722 - val_precision_m: 0.5968 - val_recall_m: 0.6590 - val_f1_m: 0.5980\n",
      "Epoch 8/30\n",
      "276/291 [===========================>..] - ETA: 0s - loss: 0.0670 - acc: 0.9770 - precision_m: 0.8026 - recall_m: 0.4982 - f1_m: 0.5797\n",
      "Epoch 8: val_acc did not improve from 0.97402\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0668 - acc: 0.9770 - precision_m: 0.8000 - recall_m: 0.4986 - f1_m: 0.5801 - val_loss: 0.0771 - val_acc: 0.9737 - val_precision_m: 0.7535 - val_recall_m: 0.4712 - val_f1_m: 0.5408\n",
      "Epoch 9/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0651 - acc: 0.9776 - precision_m: 0.7997 - recall_m: 0.5205 - f1_m: 0.6021\n",
      "Epoch 9: val_acc improved from 0.97402 to 0.97498, saving model to models/best_model_4_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0649 - acc: 0.9777 - precision_m: 0.8021 - recall_m: 0.5193 - f1_m: 0.6021 - val_loss: 0.0754 - val_acc: 0.9750 - val_precision_m: 0.6694 - val_recall_m: 0.5776 - val_f1_m: 0.5885\n",
      "Epoch 10/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.0623 - acc: 0.9789 - precision_m: 0.8170 - recall_m: 0.5477 - f1_m: 0.6258\n",
      "Epoch 10: val_acc did not improve from 0.97498\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0618 - acc: 0.9791 - precision_m: 0.8203 - recall_m: 0.5527 - f1_m: 0.6312 - val_loss: 0.0753 - val_acc: 0.9741 - val_precision_m: 0.6754 - val_recall_m: 0.6180 - val_f1_m: 0.6077\n",
      "Epoch 11/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0603 - acc: 0.9794 - precision_m: 0.8129 - recall_m: 0.5683 - f1_m: 0.6427\n",
      "Epoch 11: val_acc improved from 0.97498 to 0.97605, saving model to models/best_model_4_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0602 - acc: 0.9795 - precision_m: 0.8166 - recall_m: 0.5671 - f1_m: 0.6421 - val_loss: 0.0698 - val_acc: 0.9760 - val_precision_m: 0.7483 - val_recall_m: 0.5222 - val_f1_m: 0.5916\n",
      "Epoch 12/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.0582 - acc: 0.9802 - precision_m: 0.8218 - recall_m: 0.5742 - f1_m: 0.6544\n",
      "Epoch 12: val_acc did not improve from 0.97605\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0582 - acc: 0.9802 - precision_m: 0.8203 - recall_m: 0.5758 - f1_m: 0.6551 - val_loss: 0.0883 - val_acc: 0.9725 - val_precision_m: 0.8090 - val_recall_m: 0.3129 - val_f1_m: 0.4194\n",
      "Epoch 13/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0582 - acc: 0.9803 - precision_m: 0.8422 - recall_m: 0.5797 - f1_m: 0.6555\n",
      "Epoch 13: val_acc improved from 0.97605 to 0.97736, saving model to models/best_model_4_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0582 - acc: 0.9803 - precision_m: 0.8387 - recall_m: 0.5783 - f1_m: 0.6542 - val_loss: 0.0703 - val_acc: 0.9774 - val_precision_m: 0.7976 - val_recall_m: 0.5317 - val_f1_m: 0.5992\n",
      "Epoch 14/30\n",
      "274/291 [===========================>..] - ETA: 0s - loss: 0.0556 - acc: 0.9808 - precision_m: 0.8380 - recall_m: 0.5985 - f1_m: 0.6733\n",
      "Epoch 14: val_acc did not improve from 0.97736\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0555 - acc: 0.9809 - precision_m: 0.8402 - recall_m: 0.5975 - f1_m: 0.6734 - val_loss: 0.0724 - val_acc: 0.9757 - val_precision_m: 0.7941 - val_recall_m: 0.4219 - val_f1_m: 0.5078\n",
      "Epoch 15/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.0552 - acc: 0.9811 - precision_m: 0.8365 - recall_m: 0.6053 - f1_m: 0.6750\n",
      "Epoch 15: val_acc did not improve from 0.97736\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0552 - acc: 0.9810 - precision_m: 0.8346 - recall_m: 0.6057 - f1_m: 0.6753 - val_loss: 0.0701 - val_acc: 0.9765 - val_precision_m: 0.7931 - val_recall_m: 0.5044 - val_f1_m: 0.5744\n",
      "Epoch 16/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0528 - acc: 0.9815 - precision_m: 0.8322 - recall_m: 0.6104 - f1_m: 0.6825\n",
      "Epoch 16: val_acc did not improve from 0.97736\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0533 - acc: 0.9814 - precision_m: 0.8325 - recall_m: 0.6103 - f1_m: 0.6830 - val_loss: 0.0681 - val_acc: 0.9766 - val_precision_m: 0.6931 - val_recall_m: 0.6257 - val_f1_m: 0.6294\n",
      "Epoch 17/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.0546 - acc: 0.9814 - precision_m: 0.8373 - recall_m: 0.6206 - f1_m: 0.6855\n",
      "Epoch 17: val_acc did not improve from 0.97736\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0544 - acc: 0.9815 - precision_m: 0.8381 - recall_m: 0.6205 - f1_m: 0.6863 - val_loss: 0.0714 - val_acc: 0.9769 - val_precision_m: 0.8271 - val_recall_m: 0.4622 - val_f1_m: 0.5525\n",
      "Epoch 18/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.0523 - acc: 0.9814 - precision_m: 0.8352 - recall_m: 0.6186 - f1_m: 0.6866\n",
      "Epoch 18: val_acc did not improve from 0.97736\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0521 - acc: 0.9815 - precision_m: 0.8367 - recall_m: 0.6191 - f1_m: 0.6876 - val_loss: 0.0670 - val_acc: 0.9774 - val_precision_m: 0.6933 - val_recall_m: 0.6391 - val_f1_m: 0.6349\n",
      "Epoch 19/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.0498 - acc: 0.9830 - precision_m: 0.8544 - recall_m: 0.6459 - f1_m: 0.7141\n",
      "Epoch 19: val_acc did not improve from 0.97736\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0498 - acc: 0.9830 - precision_m: 0.8552 - recall_m: 0.6455 - f1_m: 0.7138 - val_loss: 0.0714 - val_acc: 0.9764 - val_precision_m: 0.8571 - val_recall_m: 0.4547 - val_f1_m: 0.5568\n",
      "Epoch 20/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.0498 - acc: 0.9834 - precision_m: 0.8566 - recall_m: 0.6561 - f1_m: 0.7214\n",
      "Epoch 20: val_acc improved from 0.97736 to 0.97748, saving model to models/best_model_4_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0498 - acc: 0.9834 - precision_m: 0.8566 - recall_m: 0.6561 - f1_m: 0.7214 - val_loss: 0.0676 - val_acc: 0.9775 - val_precision_m: 0.7536 - val_recall_m: 0.5735 - val_f1_m: 0.6224\n",
      "Epoch 21/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0493 - acc: 0.9832 - precision_m: 0.8500 - recall_m: 0.6498 - f1_m: 0.7175\n",
      "Epoch 21: val_acc did not improve from 0.97748\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0494 - acc: 0.9832 - precision_m: 0.8508 - recall_m: 0.6492 - f1_m: 0.7174 - val_loss: 0.0738 - val_acc: 0.9743 - val_precision_m: 0.6184 - val_recall_m: 0.6938 - val_f1_m: 0.6269\n",
      "Epoch 22/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.0505 - acc: 0.9825 - precision_m: 0.8477 - recall_m: 0.6447 - f1_m: 0.7030\n",
      "Epoch 22: val_acc improved from 0.97748 to 0.97879, saving model to models/best_model_4_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0505 - acc: 0.9825 - precision_m: 0.8477 - recall_m: 0.6447 - f1_m: 0.7030 - val_loss: 0.0674 - val_acc: 0.9788 - val_precision_m: 0.7709 - val_recall_m: 0.5819 - val_f1_m: 0.6339\n",
      "Epoch 23/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.0483 - acc: 0.9833 - precision_m: 0.8493 - recall_m: 0.6582 - f1_m: 0.7190\n",
      "Epoch 23: val_acc did not improve from 0.97879\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0483 - acc: 0.9833 - precision_m: 0.8503 - recall_m: 0.6611 - f1_m: 0.7217 - val_loss: 0.0724 - val_acc: 0.9768 - val_precision_m: 0.7979 - val_recall_m: 0.4804 - val_f1_m: 0.5716\n",
      "Epoch 24/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.0480 - acc: 0.9835 - precision_m: 0.8550 - recall_m: 0.6667 - f1_m: 0.7253\n",
      "Epoch 24: val_acc improved from 0.97879 to 0.97903, saving model to models/best_model_4_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0480 - acc: 0.9835 - precision_m: 0.8550 - recall_m: 0.6667 - f1_m: 0.7253 - val_loss: 0.0668 - val_acc: 0.9790 - val_precision_m: 0.7618 - val_recall_m: 0.5934 - val_f1_m: 0.6364\n",
      "Epoch 25/30\n",
      "275/291 [===========================>..] - ETA: 0s - loss: 0.0454 - acc: 0.9840 - precision_m: 0.8617 - recall_m: 0.6729 - f1_m: 0.7362\n",
      "Epoch 25: val_acc did not improve from 0.97903\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0454 - acc: 0.9840 - precision_m: 0.8619 - recall_m: 0.6732 - f1_m: 0.7366 - val_loss: 0.0690 - val_acc: 0.9774 - val_precision_m: 0.7480 - val_recall_m: 0.5496 - val_f1_m: 0.6012\n",
      "Epoch 26/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9837 - precision_m: 0.8596 - recall_m: 0.6693 - f1_m: 0.7285\n",
      "Epoch 26: val_acc did not improve from 0.97903\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0471 - acc: 0.9836 - precision_m: 0.8597 - recall_m: 0.6673 - f1_m: 0.7269 - val_loss: 0.0669 - val_acc: 0.9771 - val_precision_m: 0.7821 - val_recall_m: 0.4990 - val_f1_m: 0.5707\n",
      "Epoch 27/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.0464 - acc: 0.9840 - precision_m: 0.8566 - recall_m: 0.6814 - f1_m: 0.7363\n",
      "Epoch 27: val_acc did not improve from 0.97903\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0465 - acc: 0.9839 - precision_m: 0.8561 - recall_m: 0.6824 - f1_m: 0.7366 - val_loss: 0.0738 - val_acc: 0.9778 - val_precision_m: 0.8010 - val_recall_m: 0.4997 - val_f1_m: 0.5802\n",
      "Epoch 28/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0448 - acc: 0.9842 - precision_m: 0.8565 - recall_m: 0.6819 - f1_m: 0.7432\n",
      "Epoch 28: val_acc did not improve from 0.97903\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0446 - acc: 0.9844 - precision_m: 0.8562 - recall_m: 0.6851 - f1_m: 0.7447 - val_loss: 0.0673 - val_acc: 0.9778 - val_precision_m: 0.7393 - val_recall_m: 0.5629 - val_f1_m: 0.6100\n",
      "Epoch 29/30\n",
      "276/291 [===========================>..] - ETA: 0s - loss: 0.0448 - acc: 0.9842 - precision_m: 0.8649 - recall_m: 0.6842 - f1_m: 0.7442\n",
      "Epoch 29: val_acc did not improve from 0.97903\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0452 - acc: 0.9841 - precision_m: 0.8622 - recall_m: 0.6830 - f1_m: 0.7410 - val_loss: 0.0692 - val_acc: 0.9774 - val_precision_m: 0.7813 - val_recall_m: 0.5411 - val_f1_m: 0.6045\n",
      "Epoch 30/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9850 - precision_m: 0.8554 - recall_m: 0.6982 - f1_m: 0.7543\n",
      "Epoch 30: val_acc did not improve from 0.97903\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0425 - acc: 0.9850 - precision_m: 0.8565 - recall_m: 0.6981 - f1_m: 0.7548 - val_loss: 0.0674 - val_acc: 0.9765 - val_precision_m: 0.6541 - val_recall_m: 0.6508 - val_f1_m: 0.6262\n",
      "Score for fold 9: loss of 0.06683529913425446; acc of 97.90276288986206%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.06515807658433914; acc of 97.80184030532837%\n",
      "Test Precision: precision_m of 28.14302146434784%\n",
      "Test Recall: recall_m of 23.810896277427673%\n",
      "Test F1: f1_m of 25.03461241722107%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1135 - acc: 0.9668 - precision_m: 0.4012 - recall_m: 0.1252 - f1_m: 0.1745\n",
      "Epoch 1: val_acc improved from -inf to 0.96659, saving model to models/best_model_4_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 2s 4ms/step - loss: 0.1135 - acc: 0.9668 - precision_m: 0.4012 - recall_m: 0.1252 - f1_m: 0.1745 - val_loss: 0.1028 - val_acc: 0.9666 - val_precision_m: 0.6925 - val_recall_m: 0.2852 - val_f1_m: 0.3656\n",
      "Epoch 2/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0841 - acc: 0.9719 - precision_m: 0.7238 - recall_m: 0.3446 - f1_m: 0.4362\n",
      "Epoch 2: val_acc improved from 0.96659 to 0.96923, saving model to models/best_model_4_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0840 - acc: 0.9717 - precision_m: 0.7240 - recall_m: 0.3454 - f1_m: 0.4365 - val_loss: 0.0922 - val_acc: 0.9692 - val_precision_m: 0.8538 - val_recall_m: 0.2738 - val_f1_m: 0.3863\n",
      "Epoch 3/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0775 - acc: 0.9738 - precision_m: 0.7410 - recall_m: 0.4066 - f1_m: 0.4929\n",
      "Epoch 3: val_acc improved from 0.96923 to 0.97380, saving model to models/best_model_4_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0772 - acc: 0.9739 - precision_m: 0.7386 - recall_m: 0.4069 - f1_m: 0.4925 - val_loss: 0.0796 - val_acc: 0.9738 - val_precision_m: 0.8273 - val_recall_m: 0.4673 - val_f1_m: 0.5674\n",
      "Epoch 4/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0716 - acc: 0.9757 - precision_m: 0.7845 - recall_m: 0.4664 - f1_m: 0.5529\n",
      "Epoch 4: val_acc did not improve from 0.97380\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0713 - acc: 0.9759 - precision_m: 0.7840 - recall_m: 0.4660 - f1_m: 0.5519 - val_loss: 0.0945 - val_acc: 0.9671 - val_precision_m: 0.5676 - val_recall_m: 0.6592 - val_f1_m: 0.5849\n",
      "Epoch 5/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0669 - acc: 0.9772 - precision_m: 0.8002 - recall_m: 0.4946 - f1_m: 0.5840\n",
      "Epoch 5: val_acc did not improve from 0.97380\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0668 - acc: 0.9773 - precision_m: 0.8004 - recall_m: 0.4970 - f1_m: 0.5858 - val_loss: 0.0806 - val_acc: 0.9730 - val_precision_m: 0.7092 - val_recall_m: 0.5884 - val_f1_m: 0.6161\n",
      "Epoch 6/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0657 - acc: 0.9771 - precision_m: 0.8082 - recall_m: 0.5112 - f1_m: 0.5940\n",
      "Epoch 6: val_acc improved from 0.97380 to 0.97524, saving model to models/best_model_4_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0654 - acc: 0.9773 - precision_m: 0.8094 - recall_m: 0.5163 - f1_m: 0.5986 - val_loss: 0.0778 - val_acc: 0.9752 - val_precision_m: 0.9120 - val_recall_m: 0.4488 - val_f1_m: 0.5751\n",
      "Epoch 7/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0615 - acc: 0.9792 - precision_m: 0.8214 - recall_m: 0.5513 - f1_m: 0.6330\n",
      "Epoch 7: val_acc did not improve from 0.97524\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0615 - acc: 0.9792 - precision_m: 0.8201 - recall_m: 0.5517 - f1_m: 0.6335 - val_loss: 0.0847 - val_acc: 0.9720 - val_precision_m: 0.8531 - val_recall_m: 0.3512 - val_f1_m: 0.4717\n",
      "Epoch 8/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0599 - acc: 0.9797 - precision_m: 0.8311 - recall_m: 0.5713 - f1_m: 0.6473\n",
      "Epoch 8: val_acc improved from 0.97524 to 0.97584, saving model to models/best_model_4_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0601 - acc: 0.9797 - precision_m: 0.8299 - recall_m: 0.5701 - f1_m: 0.6462 - val_loss: 0.0726 - val_acc: 0.9758 - val_precision_m: 0.7879 - val_recall_m: 0.5544 - val_f1_m: 0.6219\n",
      "Epoch 9/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0572 - acc: 0.9804 - precision_m: 0.8139 - recall_m: 0.5796 - f1_m: 0.6547\n",
      "Epoch 9: val_acc did not improve from 0.97584\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0578 - acc: 0.9802 - precision_m: 0.8145 - recall_m: 0.5799 - f1_m: 0.6551 - val_loss: 0.0747 - val_acc: 0.9743 - val_precision_m: 0.8603 - val_recall_m: 0.4711 - val_f1_m: 0.5793\n",
      "Epoch 10/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0578 - acc: 0.9803 - precision_m: 0.8465 - recall_m: 0.5879 - f1_m: 0.6610\n",
      "Epoch 10: val_acc did not improve from 0.97584\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0579 - acc: 0.9804 - precision_m: 0.8487 - recall_m: 0.5878 - f1_m: 0.6622 - val_loss: 0.0708 - val_acc: 0.9756 - val_precision_m: 0.7682 - val_recall_m: 0.5845 - val_f1_m: 0.6350\n",
      "Epoch 11/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.0548 - acc: 0.9813 - precision_m: 0.8343 - recall_m: 0.6087 - f1_m: 0.6784\n",
      "Epoch 11: val_acc did not improve from 0.97584\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0548 - acc: 0.9814 - precision_m: 0.8365 - recall_m: 0.6133 - f1_m: 0.6831 - val_loss: 0.0769 - val_acc: 0.9742 - val_precision_m: 0.8226 - val_recall_m: 0.4613 - val_f1_m: 0.5665\n",
      "Epoch 12/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.0545 - acc: 0.9816 - precision_m: 0.8546 - recall_m: 0.6195 - f1_m: 0.6879\n",
      "Epoch 12: val_acc did not improve from 0.97584\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0545 - acc: 0.9816 - precision_m: 0.8546 - recall_m: 0.6195 - f1_m: 0.6879 - val_loss: 0.0712 - val_acc: 0.9755 - val_precision_m: 0.7214 - val_recall_m: 0.6716 - val_f1_m: 0.6642\n",
      "Epoch 13/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0526 - acc: 0.9820 - precision_m: 0.8387 - recall_m: 0.6244 - f1_m: 0.6954\n",
      "Epoch 13: val_acc did not improve from 0.97584\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0528 - acc: 0.9819 - precision_m: 0.8364 - recall_m: 0.6233 - f1_m: 0.6929 - val_loss: 0.0698 - val_acc: 0.9757 - val_precision_m: 0.7351 - val_recall_m: 0.6508 - val_f1_m: 0.6628\n",
      "Epoch 14/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0516 - acc: 0.9826 - precision_m: 0.8499 - recall_m: 0.6277 - f1_m: 0.7012\n",
      "Epoch 14: val_acc improved from 0.97584 to 0.97692, saving model to models/best_model_4_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0512 - acc: 0.9827 - precision_m: 0.8507 - recall_m: 0.6295 - f1_m: 0.7027 - val_loss: 0.0698 - val_acc: 0.9769 - val_precision_m: 0.8133 - val_recall_m: 0.5933 - val_f1_m: 0.6552\n",
      "Epoch 15/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.0511 - acc: 0.9827 - precision_m: 0.8513 - recall_m: 0.6394 - f1_m: 0.7053\n",
      "Epoch 15: val_acc improved from 0.97692 to 0.97704, saving model to models/best_model_4_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0514 - acc: 0.9824 - precision_m: 0.8479 - recall_m: 0.6368 - f1_m: 0.7029 - val_loss: 0.0664 - val_acc: 0.9770 - val_precision_m: 0.7656 - val_recall_m: 0.6500 - val_f1_m: 0.6701\n",
      "Epoch 16/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0488 - acc: 0.9833 - precision_m: 0.8481 - recall_m: 0.6581 - f1_m: 0.7165\n",
      "Epoch 16: val_acc did not improve from 0.97704\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0488 - acc: 0.9833 - precision_m: 0.8480 - recall_m: 0.6579 - f1_m: 0.7165 - val_loss: 0.0682 - val_acc: 0.9755 - val_precision_m: 0.7258 - val_recall_m: 0.6259 - val_f1_m: 0.6442\n",
      "Epoch 17/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0495 - acc: 0.9830 - precision_m: 0.8557 - recall_m: 0.6491 - f1_m: 0.7156\n",
      "Epoch 17: val_acc did not improve from 0.97704\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0493 - acc: 0.9831 - precision_m: 0.8557 - recall_m: 0.6516 - f1_m: 0.7177 - val_loss: 0.0721 - val_acc: 0.9768 - val_precision_m: 0.7700 - val_recall_m: 0.6251 - val_f1_m: 0.6617\n",
      "Epoch 18/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0485 - acc: 0.9833 - precision_m: 0.8572 - recall_m: 0.6617 - f1_m: 0.7202\n",
      "Epoch 18: val_acc improved from 0.97704 to 0.97873, saving model to models/best_model_4_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0484 - acc: 0.9833 - precision_m: 0.8555 - recall_m: 0.6645 - f1_m: 0.7214 - val_loss: 0.0661 - val_acc: 0.9787 - val_precision_m: 0.8221 - val_recall_m: 0.6275 - val_f1_m: 0.6833\n",
      "Epoch 19/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0467 - acc: 0.9837 - precision_m: 0.8565 - recall_m: 0.6695 - f1_m: 0.7329\n",
      "Epoch 19: val_acc did not improve from 0.97873\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0463 - acc: 0.9839 - precision_m: 0.8594 - recall_m: 0.6725 - f1_m: 0.7360 - val_loss: 0.0697 - val_acc: 0.9776 - val_precision_m: 0.8674 - val_recall_m: 0.5719 - val_f1_m: 0.6579\n",
      "Epoch 20/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0449 - acc: 0.9849 - precision_m: 0.8611 - recall_m: 0.6864 - f1_m: 0.7442\n",
      "Epoch 20: val_acc did not improve from 0.97873\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0456 - acc: 0.9846 - precision_m: 0.8604 - recall_m: 0.6846 - f1_m: 0.7422 - val_loss: 0.0689 - val_acc: 0.9760 - val_precision_m: 0.7070 - val_recall_m: 0.7066 - val_f1_m: 0.6763\n",
      "Epoch 21/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0451 - acc: 0.9846 - precision_m: 0.8698 - recall_m: 0.6906 - f1_m: 0.7466\n",
      "Epoch 21: val_acc did not improve from 0.97873\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0454 - acc: 0.9845 - precision_m: 0.8699 - recall_m: 0.6879 - f1_m: 0.7447 - val_loss: 0.0666 - val_acc: 0.9766 - val_precision_m: 0.7171 - val_recall_m: 0.7032 - val_f1_m: 0.6829\n",
      "Epoch 22/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0449 - acc: 0.9845 - precision_m: 0.8605 - recall_m: 0.6935 - f1_m: 0.7484\n",
      "Epoch 22: val_acc did not improve from 0.97873\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0450 - acc: 0.9846 - precision_m: 0.8608 - recall_m: 0.6921 - f1_m: 0.7472 - val_loss: 0.0784 - val_acc: 0.9764 - val_precision_m: 0.8882 - val_recall_m: 0.4712 - val_f1_m: 0.5934\n",
      "Epoch 23/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0477 - acc: 0.9840 - precision_m: 0.8629 - recall_m: 0.6889 - f1_m: 0.7430\n",
      "Epoch 23: val_acc improved from 0.97873 to 0.97897, saving model to models/best_model_4_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0475 - acc: 0.9840 - precision_m: 0.8626 - recall_m: 0.6911 - f1_m: 0.7448 - val_loss: 0.0689 - val_acc: 0.9790 - val_precision_m: 0.8699 - val_recall_m: 0.5839 - val_f1_m: 0.6720\n",
      "Epoch 24/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0435 - acc: 0.9848 - precision_m: 0.8713 - recall_m: 0.6908 - f1_m: 0.7512\n",
      "Epoch 24: val_acc did not improve from 0.97897\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0434 - acc: 0.9848 - precision_m: 0.8713 - recall_m: 0.6899 - f1_m: 0.7507 - val_loss: 0.0769 - val_acc: 0.9715 - val_precision_m: 0.6146 - val_recall_m: 0.7331 - val_f1_m: 0.6445\n",
      "Epoch 25/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0443 - acc: 0.9849 - precision_m: 0.8688 - recall_m: 0.7051 - f1_m: 0.7589\n",
      "Epoch 25: val_acc improved from 0.97897 to 0.97933, saving model to models/best_model_4_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0442 - acc: 0.9849 - precision_m: 0.8688 - recall_m: 0.7052 - f1_m: 0.7594 - val_loss: 0.0678 - val_acc: 0.9793 - val_precision_m: 0.8582 - val_recall_m: 0.6217 - val_f1_m: 0.6933\n",
      "Epoch 26/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.0395 - acc: 0.9863 - precision_m: 0.8733 - recall_m: 0.7246 - f1_m: 0.7782\n",
      "Epoch 26: val_acc did not improve from 0.97933\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0399 - acc: 0.9861 - precision_m: 0.8699 - recall_m: 0.7209 - f1_m: 0.7743 - val_loss: 0.0690 - val_acc: 0.9784 - val_precision_m: 0.8399 - val_recall_m: 0.5881 - val_f1_m: 0.6623\n",
      "Epoch 27/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0412 - acc: 0.9859 - precision_m: 0.8776 - recall_m: 0.7192 - f1_m: 0.7692\n",
      "Epoch 27: val_acc did not improve from 0.97933\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0407 - acc: 0.9861 - precision_m: 0.8799 - recall_m: 0.7217 - f1_m: 0.7721 - val_loss: 0.0852 - val_acc: 0.9762 - val_precision_m: 0.8730 - val_recall_m: 0.4790 - val_f1_m: 0.5922\n",
      "Epoch 28/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.0400 - acc: 0.9863 - precision_m: 0.8693 - recall_m: 0.7258 - f1_m: 0.7732\n",
      "Epoch 28: val_acc did not improve from 0.97933\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0400 - acc: 0.9863 - precision_m: 0.8693 - recall_m: 0.7258 - f1_m: 0.7732 - val_loss: 0.0754 - val_acc: 0.9768 - val_precision_m: 0.8556 - val_recall_m: 0.5377 - val_f1_m: 0.6316\n",
      "Epoch 29/30\n",
      "275/292 [===========================>..] - ETA: 0s - loss: 0.0403 - acc: 0.9861 - precision_m: 0.8842 - recall_m: 0.7184 - f1_m: 0.7727\n",
      "Epoch 29: val_acc did not improve from 0.97933\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0402 - acc: 0.9862 - precision_m: 0.8864 - recall_m: 0.7219 - f1_m: 0.7765 - val_loss: 0.0724 - val_acc: 0.9756 - val_precision_m: 0.7334 - val_recall_m: 0.6509 - val_f1_m: 0.6589\n",
      "Epoch 30/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0394 - acc: 0.9861 - precision_m: 0.8807 - recall_m: 0.7245 - f1_m: 0.7742\n",
      "Epoch 30: val_acc did not improve from 0.97933\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0394 - acc: 0.9862 - precision_m: 0.8804 - recall_m: 0.7276 - f1_m: 0.7760 - val_loss: 0.0779 - val_acc: 0.9758 - val_precision_m: 0.7089 - val_recall_m: 0.6963 - val_f1_m: 0.6765\n",
      "Score for fold 10: loss of 0.06775587052106857; acc of 97.93269038200378%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.056325290352106094; acc of 98.04546236991882%\n",
      "Test Precision: precision_m of 34.39181447029114%\n",
      "Test Recall: recall_m of 28.496935963630676%\n",
      "Test F1: f1_m of 29.540333151817322%\n",
      "------------------------------------------------------------------------\n",
      "Validation score per fold\n",
      "> Fold 1 - Loss: 0.07800406962633133 - Accuracy: 97.80246019363403%\n",
      "> Fold 2 - Loss: 0.0628446489572525 - Accuracy: 98.01221489906311%\n",
      "> Fold 3 - Loss: 0.06404568254947662 - Accuracy: 97.93962836265564%\n",
      "> Fold 4 - Loss: 0.06544382870197296 - Accuracy: 97.93432950973511%\n",
      "> Fold 5 - Loss: 0.06855207681655884 - Accuracy: 97.9203999042511%\n",
      "> Fold 6 - Loss: 0.07384378463029861 - Accuracy: 97.98722267150879%\n",
      "> Fold 7 - Loss: 0.06293405592441559 - Accuracy: 98.06451797485352%\n",
      "> Fold 8 - Loss: 0.06343943625688553 - Accuracy: 97.91566729545593%\n",
      "> Fold 9 - Loss: 0.06683529913425446 - Accuracy: 97.90276288986206%\n",
      "> Fold 10 - Loss: 0.06775587052106857 - Accuracy: 97.93269038200378%\n",
      "------------------------------------------------------------------------\n",
      "Testing score per fold\n",
      "> Fold 1 - Accuracy: 98.44816327095032 - Precision: 24.17840212583542 - Recall: 18.54557991027832 - F1: 20.06351500749588%\n",
      "> Fold 2 - Accuracy: 97.83331751823425 - Precision: 28.80992889404297 - Recall: 24.328114092350006 - F1: 25.60848295688629%\n",
      "> Fold 3 - Accuracy: 97.99509644508362 - Precision: 27.96485126018524 - Recall: 22.140425443649292 - F1: 23.42899888753891%\n",
      "> Fold 4 - Accuracy: 97.7388322353363 - Precision: 30.68050742149353 - Recall: 23.023825883865356 - F1: 25.06592571735382%\n",
      "> Fold 5 - Accuracy: 97.83258438110352 - Precision: 28.048917651176453 - Recall: 22.909292578697205 - F1: 24.304035305976868%\n",
      "> Fold 6 - Accuracy: 97.79083728790283 - Precision: 26.38888955116272 - Recall: 20.301753282546997 - F1: 21.80010676383972%\n",
      "> Fold 7 - Accuracy: 98.12124371528625 - Precision: 26.174989342689514 - Recall: 21.219511330127716 - F1: 22.293618321418762%\n",
      "> Fold 8 - Accuracy: 98.03075790405273 - Precision: 25.38280189037323 - Recall: 20.100751519203186 - F1: 21.601267158985138%\n",
      "> Fold 9 - Accuracy: 97.80184030532837 - Precision: 28.14302146434784 - Recall: 23.810896277427673 - F1: 25.03461241722107%\n",
      "> Fold 10 - Accuracy: 98.04546236991882 - Precision: 34.39181447029114 - Recall: 28.496935963630676 - F1: 29.540333151817322%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Validation Accuracy: 97.94118940830231 (+- 0.06655923643752625)\n",
      "> Validation Loss: 0.0673698753118515\n",
      "> Testing Accuracy: 97.9638135433197 (+- 0.20310800704241883)\n",
      "> Testing Precision: 28.016412407159805\n",
      "> Testing Recall: 22.487708628177643\n",
      "> Testing F1: 23.87408956885338\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Lists to hold cross-validation results\n",
    "acc_4_per_fold = []\n",
    "loss_4_per_fold = []\n",
    "precision_4_per_fold = []\n",
    "recall_4_per_fold = []\n",
    "f1_4_per_fold = []\n",
    "\n",
    "testing_acc_4_per_fold = []\n",
    "testing_precision_4_per_fold = []\n",
    "testing_recall_4_per_fold = []\n",
    "testing_f1_4_per_fold = []\n",
    "\n",
    "# Load data from .npz files\n",
    "for fold_no in range(1, 11):\n",
    "    with np.load(f'fold_{fold_no}.npz') as data:\n",
    "        x_train = data['x_train_fold.npy']\n",
    "        y_train = data['y_train_fold.npy']\n",
    "        x_val = data['x_val_fold.npy']\n",
    "        y_val = data['y_val_fold.npy']\n",
    "        x_test = data['x_test_fold.npy']\n",
    "        y_test = data['y_test_fold.npy']\n",
    "        \n",
    "        # Converting ground truth arrays to one wake word (1) and 'other' (0)\n",
    "        wake_word_index = all_targets.index(wake_word)\n",
    "        y_train = np.equal(y_train, wake_word_index).astype('float64')\n",
    "        y_val = np.equal(y_val, wake_word_index).astype('float64')\n",
    "        y_test = np.equal(y_test, wake_word_index).astype('float64')\n",
    "        \n",
    "        # CNN for TF expects (batch, height, width, channels)\n",
    "        x_train = x_train.reshape(x_train.shape[0], \n",
    "                          x_train.shape[1], \n",
    "                          x_train.shape[2], \n",
    "                          1)\n",
    "        x_val = x_val.reshape(x_val.shape[0], \n",
    "                          x_val.shape[1], \n",
    "                          x_val.shape[2], \n",
    "                          1)\n",
    "        x_test = x_test.reshape(x_test.shape[0], \n",
    "                          x_test.shape[1], \n",
    "                          x_test.shape[2], \n",
    "                          1)\n",
    "        sample_shape = x_test.shape[1:]\n",
    "\n",
    "    # CNN model\n",
    "    model_4 = models.Sequential()\n",
    "    model_4.add(layers.Conv2D(64,\n",
    "                              (5,5),\n",
    "                              activation=\"relu\",\n",
    "                              input_shape=sample_shape))\n",
    "    model_4.add(layers.MaxPooling2D(pool_size=(5, 5)))\n",
    "    \n",
    "    model_4.add(layers.Flatten())\n",
    "    model_4.add(layers.Dense(32, activation='relu'))\n",
    "    model_4.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "\n",
    "    model_4.compile(loss='binary_crossentropy', \n",
    "              optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "              metrics=['acc', precision_m, recall_m, f1_m])\n",
    "\n",
    "    checkpoint_filepath = f'models/best_model_4_fold_{fold_no}.h5'\n",
    "    model_checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=False,\n",
    "        monitor='val_acc',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "        save_freq='epoch'\n",
    "    )\n",
    "\n",
    "    # Instantiate the custom callback\n",
    "    metrics_history = MetricsHistory()\n",
    "\n",
    "    # Print fold number\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Train\n",
    "    history_4 = model_4.fit(x_train, \n",
    "                    y_train, \n",
    "                    epochs=30, \n",
    "                    batch_size=256, \n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[model_checkpoint_callback, metrics_history])\n",
    "\n",
    "    model_4.load_weights(checkpoint_filepath)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    scores = model_4.evaluate(x_val, y_val, verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model_4.metrics_names[0]} of {scores[0]}; {model_4.metrics_names[1]} of {scores[1] * 100}%')\n",
    "    acc_4_per_fold.append(scores[1] * 100)\n",
    "    loss_4_per_fold.append(scores[0])\n",
    "    precision_4_per_fold.append(metrics_history.best_metrics['precision_m'] * 100)\n",
    "    recall_4_per_fold.append(metrics_history.best_metrics['recall_m'] * 100)\n",
    "    f1_4_per_fold.append(metrics_history.best_metrics['f1_m'] * 100)\n",
    "\n",
    "    # Final evaluation on test set\n",
    "    final_scores = model_4.evaluate(x_test, y_test, verbose=0)\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Final test score: {model_4.metrics_names[0]} of {final_scores[0]}; {model_4.metrics_names[1]} of {final_scores[1] * 100}%')\n",
    "    print(f'Test Precision: {model_4.metrics_names[2]} of {final_scores[2] * 100}%')\n",
    "    print(f'Test Recall: {model_4.metrics_names[3]} of {final_scores[3] * 100}%')\n",
    "    print(f'Test F1: {model_4.metrics_names[4]} of {final_scores[4] * 100}%')\n",
    "\n",
    "    # Append test metrics to lists\n",
    "    testing_acc_4_per_fold.append(final_scores[1] * 100)\n",
    "    testing_precision_4_per_fold.append(final_scores[2] * 100)\n",
    "    testing_recall_4_per_fold.append(final_scores[3] * 100)\n",
    "    testing_f1_4_per_fold.append(final_scores[4] * 100)\n",
    "\n",
    "# Print the results\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Validation score per fold')\n",
    "for i in range(0, len(acc_4_per_fold)):\n",
    "    print(f'> Fold {i+1} - Loss: {loss_4_per_fold[i]} - Accuracy: {acc_4_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Testing score per fold')\n",
    "for i in range(0, len(testing_acc_4_per_fold)):\n",
    "    print(f'> Fold {i+1} - Accuracy: {testing_acc_4_per_fold[i]} - Precision: {testing_precision_4_per_fold[i]} - Recall: {testing_recall_4_per_fold[i]} - F1: {testing_f1_4_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Validation Accuracy: {np.mean(acc_4_per_fold)} (+- {np.std(acc_4_per_fold)})')\n",
    "print(f'> Validation Loss: {np.mean(loss_4_per_fold)}')\n",
    "print(f'> Testing Accuracy: {np.mean(testing_acc_4_per_fold)} (+- {np.std(testing_acc_4_per_fold)})')\n",
    "print(f'> Testing Precision: {np.mean(testing_precision_4_per_fold)}')\n",
    "print(f'> Testing Recall: {np.mean(testing_recall_4_per_fold)}')\n",
    "print(f'> Testing F1: {np.mean(testing_f1_4_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2012 - acc: 0.9400 - precision_m: 0.0179 - recall_m: 0.0242 - f1_m: 0.0140\n",
      "Epoch 1: val_acc improved from -inf to 0.96047, saving model to models/best_model_5_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 2s 3ms/step - loss: 0.2012 - acc: 0.9400 - precision_m: 0.0179 - recall_m: 0.0242 - f1_m: 0.0140 - val_loss: 0.1461 - val_acc: 0.9605 - val_precision_m: 0.0606 - val_recall_m: 0.0084 - val_f1_m: 0.0144\n",
      "Epoch 2/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.1330 - acc: 0.9631 - precision_m: 0.0848 - recall_m: 0.0106 - f1_m: 0.0185\n",
      "Epoch 2: val_acc did not improve from 0.96047\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1331 - acc: 0.9631 - precision_m: 0.0890 - recall_m: 0.0110 - f1_m: 0.0193 - val_loss: 0.1375 - val_acc: 0.9605 - val_precision_m: 0.0606 - val_recall_m: 0.0084 - val_f1_m: 0.0144\n",
      "Epoch 3/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.1266 - acc: 0.9631 - precision_m: 0.1593 - recall_m: 0.0216 - f1_m: 0.0370\n",
      "Epoch 3: val_acc did not improve from 0.96047\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1261 - acc: 0.9632 - precision_m: 0.1704 - recall_m: 0.0228 - f1_m: 0.0391 - val_loss: 0.1325 - val_acc: 0.9605 - val_precision_m: 0.0758 - val_recall_m: 0.0080 - val_f1_m: 0.0143\n",
      "Epoch 4/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.1224 - acc: 0.9632 - precision_m: 0.2381 - recall_m: 0.0348 - f1_m: 0.0590\n",
      "Epoch 4: val_acc improved from 0.96047 to 0.96071, saving model to models/best_model_5_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1219 - acc: 0.9634 - precision_m: 0.2334 - recall_m: 0.0341 - f1_m: 0.0578 - val_loss: 0.1291 - val_acc: 0.9607 - val_precision_m: 0.1667 - val_recall_m: 0.0157 - val_f1_m: 0.0283\n",
      "Epoch 5/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.1188 - acc: 0.9633 - precision_m: 0.3065 - recall_m: 0.0425 - f1_m: 0.0729\n",
      "Epoch 5: val_acc improved from 0.96071 to 0.96142, saving model to models/best_model_5_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1184 - acc: 0.9635 - precision_m: 0.3054 - recall_m: 0.0428 - f1_m: 0.0733 - val_loss: 0.1260 - val_acc: 0.9614 - val_precision_m: 0.2152 - val_recall_m: 0.0329 - val_f1_m: 0.0548\n",
      "Epoch 6/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.1157 - acc: 0.9636 - precision_m: 0.3501 - recall_m: 0.0565 - f1_m: 0.0933\n",
      "Epoch 6: val_acc improved from 0.96142 to 0.96154, saving model to models/best_model_5_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1152 - acc: 0.9637 - precision_m: 0.3406 - recall_m: 0.0558 - f1_m: 0.0920 - val_loss: 0.1223 - val_acc: 0.9615 - val_precision_m: 0.2626 - val_recall_m: 0.0399 - val_f1_m: 0.0677\n",
      "Epoch 7/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.1130 - acc: 0.9639 - precision_m: 0.4167 - recall_m: 0.0657 - f1_m: 0.1096\n",
      "Epoch 7: val_acc did not improve from 0.96154\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1125 - acc: 0.9641 - precision_m: 0.4187 - recall_m: 0.0661 - f1_m: 0.1102 - val_loss: 0.1194 - val_acc: 0.9607 - val_precision_m: 0.2677 - val_recall_m: 0.0450 - val_f1_m: 0.0753\n",
      "Epoch 8/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.1099 - acc: 0.9644 - precision_m: 0.4402 - recall_m: 0.0776 - f1_m: 0.1274\n",
      "Epoch 8: val_acc improved from 0.96154 to 0.96166, saving model to models/best_model_5_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1100 - acc: 0.9644 - precision_m: 0.4501 - recall_m: 0.0807 - f1_m: 0.1317 - val_loss: 0.1169 - val_acc: 0.9617 - val_precision_m: 0.3384 - val_recall_m: 0.0576 - val_f1_m: 0.0933\n",
      "Epoch 9/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.1080 - acc: 0.9645 - precision_m: 0.4831 - recall_m: 0.0881 - f1_m: 0.1438\n",
      "Epoch 9: val_acc improved from 0.96166 to 0.96190, saving model to models/best_model_5_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1075 - acc: 0.9647 - precision_m: 0.4930 - recall_m: 0.0913 - f1_m: 0.1488 - val_loss: 0.1145 - val_acc: 0.9619 - val_precision_m: 0.4121 - val_recall_m: 0.0740 - val_f1_m: 0.1189\n",
      "Epoch 10/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.1048 - acc: 0.9654 - precision_m: 0.5332 - recall_m: 0.1089 - f1_m: 0.1721\n",
      "Epoch 10: val_acc improved from 0.96190 to 0.96274, saving model to models/best_model_5_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1051 - acc: 0.9652 - precision_m: 0.5372 - recall_m: 0.1100 - f1_m: 0.1739 - val_loss: 0.1116 - val_acc: 0.9627 - val_precision_m: 0.4609 - val_recall_m: 0.1160 - val_f1_m: 0.1727\n",
      "Epoch 11/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.1031 - acc: 0.9656 - precision_m: 0.6007 - recall_m: 0.1280 - f1_m: 0.2003\n",
      "Epoch 11: val_acc did not improve from 0.96274\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1029 - acc: 0.9658 - precision_m: 0.5936 - recall_m: 0.1271 - f1_m: 0.1986 - val_loss: 0.1096 - val_acc: 0.9627 - val_precision_m: 0.4030 - val_recall_m: 0.0886 - val_f1_m: 0.1376\n",
      "Epoch 12/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.1007 - acc: 0.9660 - precision_m: 0.5858 - recall_m: 0.1374 - f1_m: 0.2126\n",
      "Epoch 12: val_acc improved from 0.96274 to 0.96310, saving model to models/best_model_5_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1005 - acc: 0.9661 - precision_m: 0.5909 - recall_m: 0.1399 - f1_m: 0.2158 - val_loss: 0.1075 - val_acc: 0.9631 - val_precision_m: 0.4061 - val_recall_m: 0.0992 - val_f1_m: 0.1529\n",
      "Epoch 13/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0983 - acc: 0.9667 - precision_m: 0.6356 - recall_m: 0.1656 - f1_m: 0.2512\n",
      "Epoch 13: val_acc improved from 0.96310 to 0.96381, saving model to models/best_model_5_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0979 - acc: 0.9667 - precision_m: 0.6344 - recall_m: 0.1649 - f1_m: 0.2504 - val_loss: 0.1051 - val_acc: 0.9638 - val_precision_m: 0.5029 - val_recall_m: 0.1289 - val_f1_m: 0.1932\n",
      "Epoch 14/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0964 - acc: 0.9672 - precision_m: 0.6580 - recall_m: 0.1939 - f1_m: 0.2863\n",
      "Epoch 14: val_acc improved from 0.96381 to 0.96417, saving model to models/best_model_5_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0961 - acc: 0.9672 - precision_m: 0.6647 - recall_m: 0.1948 - f1_m: 0.2880 - val_loss: 0.1036 - val_acc: 0.9642 - val_precision_m: 0.5498 - val_recall_m: 0.1612 - val_f1_m: 0.2311\n",
      "Epoch 15/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0945 - acc: 0.9674 - precision_m: 0.6690 - recall_m: 0.1975 - f1_m: 0.2917\n",
      "Epoch 15: val_acc improved from 0.96417 to 0.96465, saving model to models/best_model_5_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0945 - acc: 0.9674 - precision_m: 0.6768 - recall_m: 0.1985 - f1_m: 0.2935 - val_loss: 0.1028 - val_acc: 0.9646 - val_precision_m: 0.5732 - val_recall_m: 0.1753 - val_f1_m: 0.2446\n",
      "Epoch 16/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0935 - acc: 0.9676 - precision_m: 0.6820 - recall_m: 0.2196 - f1_m: 0.3169\n",
      "Epoch 16: val_acc did not improve from 0.96465\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0933 - acc: 0.9678 - precision_m: 0.6743 - recall_m: 0.2177 - f1_m: 0.3138 - val_loss: 0.1020 - val_acc: 0.9639 - val_precision_m: 0.5137 - val_recall_m: 0.1497 - val_f1_m: 0.2187\n",
      "Epoch 17/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0922 - acc: 0.9681 - precision_m: 0.6931 - recall_m: 0.2329 - f1_m: 0.3316\n",
      "Epoch 17: val_acc improved from 0.96465 to 0.96560, saving model to models/best_model_5_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0922 - acc: 0.9681 - precision_m: 0.6912 - recall_m: 0.2329 - f1_m: 0.3318 - val_loss: 0.0990 - val_acc: 0.9656 - val_precision_m: 0.6573 - val_recall_m: 0.2133 - val_f1_m: 0.2954\n",
      "Epoch 18/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0920 - acc: 0.9681 - precision_m: 0.6813 - recall_m: 0.2420 - f1_m: 0.3396\n",
      "Epoch 18: val_acc did not improve from 0.96560\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0914 - acc: 0.9683 - precision_m: 0.6846 - recall_m: 0.2479 - f1_m: 0.3452 - val_loss: 0.1010 - val_acc: 0.9645 - val_precision_m: 0.6076 - val_recall_m: 0.1685 - val_f1_m: 0.2463\n",
      "Epoch 19/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0902 - acc: 0.9685 - precision_m: 0.6849 - recall_m: 0.2568 - f1_m: 0.3560\n",
      "Epoch 19: val_acc improved from 0.96560 to 0.96656, saving model to models/best_model_5_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0901 - acc: 0.9685 - precision_m: 0.6830 - recall_m: 0.2554 - f1_m: 0.3543 - val_loss: 0.0970 - val_acc: 0.9666 - val_precision_m: 0.6399 - val_recall_m: 0.2657 - val_f1_m: 0.3393\n",
      "Epoch 20/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0891 - acc: 0.9691 - precision_m: 0.6954 - recall_m: 0.2720 - f1_m: 0.3690\n",
      "Epoch 20: val_acc did not improve from 0.96656\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0893 - acc: 0.9691 - precision_m: 0.6983 - recall_m: 0.2738 - f1_m: 0.3716 - val_loss: 0.0968 - val_acc: 0.9654 - val_precision_m: 0.6513 - val_recall_m: 0.2273 - val_f1_m: 0.3107\n",
      "Epoch 21/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0886 - acc: 0.9690 - precision_m: 0.6971 - recall_m: 0.2744 - f1_m: 0.3748\n",
      "Epoch 21: val_acc did not improve from 0.96656\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0885 - acc: 0.9691 - precision_m: 0.7031 - recall_m: 0.2779 - f1_m: 0.3789 - val_loss: 0.0967 - val_acc: 0.9657 - val_precision_m: 0.6470 - val_recall_m: 0.2168 - val_f1_m: 0.3010\n",
      "Epoch 22/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0879 - acc: 0.9693 - precision_m: 0.7259 - recall_m: 0.2900 - f1_m: 0.3937\n",
      "Epoch 22: val_acc did not improve from 0.96656\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0879 - acc: 0.9693 - precision_m: 0.7218 - recall_m: 0.2911 - f1_m: 0.3943 - val_loss: 0.0948 - val_acc: 0.9661 - val_precision_m: 0.6571 - val_recall_m: 0.2629 - val_f1_m: 0.3421\n",
      "Epoch 23/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.0875 - acc: 0.9692 - precision_m: 0.6996 - recall_m: 0.2934 - f1_m: 0.3940\n",
      "Epoch 23: val_acc did not improve from 0.96656\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0873 - acc: 0.9693 - precision_m: 0.6991 - recall_m: 0.2940 - f1_m: 0.3947 - val_loss: 0.0963 - val_acc: 0.9663 - val_precision_m: 0.6768 - val_recall_m: 0.1973 - val_f1_m: 0.2827\n",
      "Epoch 24/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.0864 - acc: 0.9697 - precision_m: 0.7016 - recall_m: 0.2961 - f1_m: 0.4001\n",
      "Epoch 24: val_acc improved from 0.96656 to 0.96775, saving model to models/best_model_5_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0864 - acc: 0.9697 - precision_m: 0.7016 - recall_m: 0.2961 - f1_m: 0.4001 - val_loss: 0.0927 - val_acc: 0.9678 - val_precision_m: 0.6897 - val_recall_m: 0.3083 - val_f1_m: 0.3904\n",
      "Epoch 25/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0863 - acc: 0.9699 - precision_m: 0.7101 - recall_m: 0.3128 - f1_m: 0.4142\n",
      "Epoch 25: val_acc did not improve from 0.96775\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0861 - acc: 0.9699 - precision_m: 0.7103 - recall_m: 0.3135 - f1_m: 0.4145 - val_loss: 0.0936 - val_acc: 0.9662 - val_precision_m: 0.6729 - val_recall_m: 0.2216 - val_f1_m: 0.3106\n",
      "Epoch 26/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0852 - acc: 0.9697 - precision_m: 0.6536 - recall_m: 0.3050 - f1_m: 0.3947\n",
      "Epoch 26: val_acc did not improve from 0.96775\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0855 - acc: 0.9695 - precision_m: 0.6549 - recall_m: 0.3042 - f1_m: 0.3943 - val_loss: 0.0919 - val_acc: 0.9678 - val_precision_m: 0.6772 - val_recall_m: 0.3183 - val_f1_m: 0.4066\n",
      "Epoch 27/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0845 - acc: 0.9701 - precision_m: 0.7231 - recall_m: 0.3232 - f1_m: 0.4271\n",
      "Epoch 27: val_acc did not improve from 0.96775\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0848 - acc: 0.9701 - precision_m: 0.7287 - recall_m: 0.3241 - f1_m: 0.4287 - val_loss: 0.0913 - val_acc: 0.9674 - val_precision_m: 0.6692 - val_recall_m: 0.2764 - val_f1_m: 0.3634\n",
      "Epoch 28/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0840 - acc: 0.9708 - precision_m: 0.7252 - recall_m: 0.3386 - f1_m: 0.4417\n",
      "Epoch 28: val_acc did not improve from 0.96775\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0842 - acc: 0.9706 - precision_m: 0.7234 - recall_m: 0.3383 - f1_m: 0.4409 - val_loss: 0.0923 - val_acc: 0.9667 - val_precision_m: 0.7288 - val_recall_m: 0.2553 - val_f1_m: 0.3543\n",
      "Epoch 29/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0832 - acc: 0.9706 - precision_m: 0.6984 - recall_m: 0.3347 - f1_m: 0.4355\n",
      "Epoch 29: val_acc improved from 0.96775 to 0.96823, saving model to models/best_model_5_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0836 - acc: 0.9704 - precision_m: 0.6957 - recall_m: 0.3356 - f1_m: 0.4358 - val_loss: 0.0901 - val_acc: 0.9682 - val_precision_m: 0.6517 - val_recall_m: 0.3545 - val_f1_m: 0.4344\n",
      "Epoch 30/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0836 - acc: 0.9703 - precision_m: 0.7205 - recall_m: 0.3481 - f1_m: 0.4465\n",
      "Epoch 30: val_acc did not improve from 0.96823\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0833 - acc: 0.9704 - precision_m: 0.7152 - recall_m: 0.3485 - f1_m: 0.4459 - val_loss: 0.0908 - val_acc: 0.9670 - val_precision_m: 0.6957 - val_recall_m: 0.2774 - val_f1_m: 0.3647\n",
      "Score for fold 1: loss of 0.09014429152011871; acc of 96.8231201171875%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.07345355302095413; acc of 97.68875241279602%\n",
      "Test Precision: precision_m of 17.370891571044922%\n",
      "Test Recall: recall_m of 10.886149853467941%\n",
      "Test F1: f1_m of 12.590061128139496%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.1886 - acc: 0.9464 - precision_m: 0.0227 - recall_m: 0.0171 - f1_m: 0.0128\n",
      "Epoch 1: val_acc improved from -inf to 0.96336, saving model to models/best_model_5_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 2s 3ms/step - loss: 0.1886 - acc: 0.9464 - precision_m: 0.0227 - recall_m: 0.0171 - f1_m: 0.0128 - val_loss: 0.1358 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.1269 - acc: 0.9646 - precision_m: 0.0523 - recall_m: 0.0068 - f1_m: 0.0118  \n",
      "Epoch 2: val_acc improved from 0.96336 to 0.96432, saving model to models/best_model_5_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1273 - acc: 0.9645 - precision_m: 0.0704 - recall_m: 0.0092 - f1_m: 0.0158 - val_loss: 0.1265 - val_acc: 0.9643 - val_precision_m: 0.1515 - val_recall_m: 0.0262 - val_f1_m: 0.0441\n",
      "Epoch 3/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.1213 - acc: 0.9648 - precision_m: 0.2291 - recall_m: 0.0324 - f1_m: 0.0551\n",
      "Epoch 3: val_acc did not improve from 0.96432\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1211 - acc: 0.9649 - precision_m: 0.2279 - recall_m: 0.0326 - f1_m: 0.0553 - val_loss: 0.1216 - val_acc: 0.9641 - val_precision_m: 0.1818 - val_recall_m: 0.0271 - val_f1_m: 0.0465\n",
      "Epoch 4/30\n",
      "275/291 [===========================>..] - ETA: 0s - loss: 0.1176 - acc: 0.9648 - precision_m: 0.2964 - recall_m: 0.0401 - f1_m: 0.0693\n",
      "Epoch 4: val_acc did not improve from 0.96432\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1171 - acc: 0.9649 - precision_m: 0.2976 - recall_m: 0.0424 - f1_m: 0.0721 - val_loss: 0.1192 - val_acc: 0.9640 - val_precision_m: 0.1818 - val_recall_m: 0.0271 - val_f1_m: 0.0465\n",
      "Epoch 5/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.1142 - acc: 0.9652 - precision_m: 0.4023 - recall_m: 0.0663 - f1_m: 0.1101\n",
      "Epoch 5: val_acc did not improve from 0.96432\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1137 - acc: 0.9654 - precision_m: 0.3878 - recall_m: 0.0637 - f1_m: 0.1058 - val_loss: 0.1147 - val_acc: 0.9641 - val_precision_m: 0.2273 - val_recall_m: 0.0292 - val_f1_m: 0.0514\n",
      "Epoch 6/30\n",
      "270/291 [==========================>...] - ETA: 0s - loss: 0.1103 - acc: 0.9656 - precision_m: 0.4223 - recall_m: 0.0741 - f1_m: 0.1211\n",
      "Epoch 6: val_acc improved from 0.96432 to 0.96467, saving model to models/best_model_5_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1105 - acc: 0.9655 - precision_m: 0.4187 - recall_m: 0.0744 - f1_m: 0.1214 - val_loss: 0.1116 - val_acc: 0.9647 - val_precision_m: 0.3283 - val_recall_m: 0.0591 - val_f1_m: 0.0927\n",
      "Epoch 7/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.1072 - acc: 0.9662 - precision_m: 0.4627 - recall_m: 0.0853 - f1_m: 0.1384\n",
      "Epoch 7: val_acc improved from 0.96467 to 0.96491, saving model to models/best_model_5_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1073 - acc: 0.9661 - precision_m: 0.4678 - recall_m: 0.0868 - f1_m: 0.1405 - val_loss: 0.1076 - val_acc: 0.9649 - val_precision_m: 0.3737 - val_recall_m: 0.0648 - val_f1_m: 0.1045\n",
      "Epoch 8/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.1046 - acc: 0.9662 - precision_m: 0.5162 - recall_m: 0.1070 - f1_m: 0.1687\n",
      "Epoch 8: val_acc did not improve from 0.96491\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1046 - acc: 0.9662 - precision_m: 0.5037 - recall_m: 0.1059 - f1_m: 0.1659 - val_loss: 0.1048 - val_acc: 0.9649 - val_precision_m: 0.3586 - val_recall_m: 0.0546 - val_f1_m: 0.0914\n",
      "Epoch 9/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.1024 - acc: 0.9668 - precision_m: 0.5467 - recall_m: 0.1263 - f1_m: 0.1952\n",
      "Epoch 9: val_acc improved from 0.96491 to 0.96575, saving model to models/best_model_5_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1023 - acc: 0.9669 - precision_m: 0.5440 - recall_m: 0.1278 - f1_m: 0.1960 - val_loss: 0.1023 - val_acc: 0.9658 - val_precision_m: 0.4444 - val_recall_m: 0.0872 - val_f1_m: 0.1349\n",
      "Epoch 10/30\n",
      "276/291 [===========================>..] - ETA: 0s - loss: 0.1004 - acc: 0.9669 - precision_m: 0.5497 - recall_m: 0.1388 - f1_m: 0.2114\n",
      "Epoch 10: val_acc improved from 0.96575 to 0.96635, saving model to models/best_model_5_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1002 - acc: 0.9670 - precision_m: 0.5509 - recall_m: 0.1388 - f1_m: 0.2112 - val_loss: 0.1003 - val_acc: 0.9664 - val_precision_m: 0.4495 - val_recall_m: 0.0933 - val_f1_m: 0.1480\n",
      "Epoch 11/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.0986 - acc: 0.9676 - precision_m: 0.6145 - recall_m: 0.1635 - f1_m: 0.2431\n",
      "Epoch 11: val_acc did not improve from 0.96635\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0984 - acc: 0.9676 - precision_m: 0.6133 - recall_m: 0.1649 - f1_m: 0.2448 - val_loss: 0.0991 - val_acc: 0.9656 - val_precision_m: 0.4040 - val_recall_m: 0.0700 - val_f1_m: 0.1143\n",
      "Epoch 12/30\n",
      "273/291 [===========================>..] - ETA: 0s - loss: 0.0958 - acc: 0.9683 - precision_m: 0.6281 - recall_m: 0.1698 - f1_m: 0.2530\n",
      "Epoch 12: val_acc improved from 0.96635 to 0.96731, saving model to models/best_model_5_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0965 - acc: 0.9680 - precision_m: 0.6325 - recall_m: 0.1705 - f1_m: 0.2545 - val_loss: 0.0980 - val_acc: 0.9673 - val_precision_m: 0.5337 - val_recall_m: 0.1463 - val_f1_m: 0.2156\n",
      "Epoch 13/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0954 - acc: 0.9688 - precision_m: 0.6749 - recall_m: 0.1973 - f1_m: 0.2888\n",
      "Epoch 13: val_acc improved from 0.96731 to 0.96755, saving model to models/best_model_5_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0953 - acc: 0.9687 - precision_m: 0.6714 - recall_m: 0.1946 - f1_m: 0.2854 - val_loss: 0.0953 - val_acc: 0.9675 - val_precision_m: 0.5505 - val_recall_m: 0.1319 - val_f1_m: 0.2028\n",
      "Epoch 14/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.0932 - acc: 0.9694 - precision_m: 0.7052 - recall_m: 0.2207 - f1_m: 0.3177\n",
      "Epoch 14: val_acc did not improve from 0.96755\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0930 - acc: 0.9694 - precision_m: 0.7006 - recall_m: 0.2211 - f1_m: 0.3174 - val_loss: 0.0964 - val_acc: 0.9655 - val_precision_m: 0.4343 - val_recall_m: 0.0790 - val_f1_m: 0.1272\n",
      "Epoch 15/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.0920 - acc: 0.9697 - precision_m: 0.7189 - recall_m: 0.2263 - f1_m: 0.3272\n",
      "Epoch 15: val_acc did not improve from 0.96755\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0919 - acc: 0.9697 - precision_m: 0.7176 - recall_m: 0.2265 - f1_m: 0.3277 - val_loss: 0.0925 - val_acc: 0.9674 - val_precision_m: 0.5264 - val_recall_m: 0.1436 - val_f1_m: 0.2158\n",
      "Epoch 16/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.0902 - acc: 0.9698 - precision_m: 0.6918 - recall_m: 0.2323 - f1_m: 0.3316\n",
      "Epoch 16: val_acc improved from 0.96755 to 0.96791, saving model to models/best_model_5_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0904 - acc: 0.9697 - precision_m: 0.6879 - recall_m: 0.2329 - f1_m: 0.3320 - val_loss: 0.0919 - val_acc: 0.9679 - val_precision_m: 0.5601 - val_recall_m: 0.1476 - val_f1_m: 0.2221\n",
      "Epoch 17/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0892 - acc: 0.9701 - precision_m: 0.7027 - recall_m: 0.2487 - f1_m: 0.3515\n",
      "Epoch 17: val_acc improved from 0.96791 to 0.96875, saving model to models/best_model_5_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0895 - acc: 0.9700 - precision_m: 0.6919 - recall_m: 0.2455 - f1_m: 0.3469 - val_loss: 0.0906 - val_acc: 0.9687 - val_precision_m: 0.6633 - val_recall_m: 0.2049 - val_f1_m: 0.2921\n",
      "Epoch 18/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0881 - acc: 0.9709 - precision_m: 0.7359 - recall_m: 0.2653 - f1_m: 0.3729\n",
      "Epoch 18: val_acc did not improve from 0.96875\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0884 - acc: 0.9707 - precision_m: 0.7328 - recall_m: 0.2650 - f1_m: 0.3725 - val_loss: 0.0901 - val_acc: 0.9683 - val_precision_m: 0.6584 - val_recall_m: 0.1805 - val_f1_m: 0.2682\n",
      "Epoch 19/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0873 - acc: 0.9708 - precision_m: 0.7346 - recall_m: 0.2683 - f1_m: 0.3751\n",
      "Epoch 19: val_acc improved from 0.96875 to 0.97006, saving model to models/best_model_5_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0878 - acc: 0.9706 - precision_m: 0.7300 - recall_m: 0.2704 - f1_m: 0.3768 - val_loss: 0.0897 - val_acc: 0.9701 - val_precision_m: 0.6819 - val_recall_m: 0.2716 - val_f1_m: 0.3659\n",
      "Epoch 20/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0875 - acc: 0.9705 - precision_m: 0.7176 - recall_m: 0.2700 - f1_m: 0.3732\n",
      "Epoch 20: val_acc did not improve from 0.97006\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0870 - acc: 0.9707 - precision_m: 0.7191 - recall_m: 0.2731 - f1_m: 0.3762 - val_loss: 0.0894 - val_acc: 0.9681 - val_precision_m: 0.6343 - val_recall_m: 0.1734 - val_f1_m: 0.2583\n",
      "Epoch 21/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0863 - acc: 0.9705 - precision_m: 0.7072 - recall_m: 0.2738 - f1_m: 0.3781\n",
      "Epoch 21: val_acc did not improve from 0.97006\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0863 - acc: 0.9706 - precision_m: 0.7148 - recall_m: 0.2767 - f1_m: 0.3822 - val_loss: 0.0885 - val_acc: 0.9692 - val_precision_m: 0.6623 - val_recall_m: 0.2657 - val_f1_m: 0.3604\n",
      "Epoch 22/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.0852 - acc: 0.9712 - precision_m: 0.7368 - recall_m: 0.2875 - f1_m: 0.3964\n",
      "Epoch 22: val_acc improved from 0.97006 to 0.97018, saving model to models/best_model_5_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0858 - acc: 0.9710 - precision_m: 0.7309 - recall_m: 0.2849 - f1_m: 0.3922 - val_loss: 0.0875 - val_acc: 0.9702 - val_precision_m: 0.6475 - val_recall_m: 0.3252 - val_f1_m: 0.4120\n",
      "Epoch 23/30\n",
      "271/291 [==========================>...] - ETA: 0s - loss: 0.0855 - acc: 0.9711 - precision_m: 0.7200 - recall_m: 0.2917 - f1_m: 0.3968\n",
      "Epoch 23: val_acc did not improve from 0.97018\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0850 - acc: 0.9712 - precision_m: 0.7265 - recall_m: 0.2911 - f1_m: 0.3974 - val_loss: 0.0881 - val_acc: 0.9698 - val_precision_m: 0.6647 - val_recall_m: 0.2769 - val_f1_m: 0.3653\n",
      "Epoch 24/30\n",
      "275/291 [===========================>..] - ETA: 0s - loss: 0.0849 - acc: 0.9714 - precision_m: 0.7528 - recall_m: 0.2986 - f1_m: 0.4080\n",
      "Epoch 24: val_acc did not improve from 0.97018\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0844 - acc: 0.9715 - precision_m: 0.7521 - recall_m: 0.2984 - f1_m: 0.4076 - val_loss: 0.0890 - val_acc: 0.9673 - val_precision_m: 0.6057 - val_recall_m: 0.1545 - val_f1_m: 0.2310\n",
      "Epoch 25/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.0840 - acc: 0.9712 - precision_m: 0.7218 - recall_m: 0.3026 - f1_m: 0.4075\n",
      "Epoch 25: val_acc did not improve from 0.97018\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0842 - acc: 0.9712 - precision_m: 0.7228 - recall_m: 0.3025 - f1_m: 0.4075 - val_loss: 0.0852 - val_acc: 0.9701 - val_precision_m: 0.6813 - val_recall_m: 0.3018 - val_f1_m: 0.3894\n",
      "Epoch 26/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0840 - acc: 0.9713 - precision_m: 0.7394 - recall_m: 0.3097 - f1_m: 0.4159\n",
      "Epoch 26: val_acc did not improve from 0.97018\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0837 - acc: 0.9714 - precision_m: 0.7351 - recall_m: 0.3117 - f1_m: 0.4170 - val_loss: 0.0857 - val_acc: 0.9702 - val_precision_m: 0.6661 - val_recall_m: 0.2683 - val_f1_m: 0.3600\n",
      "Epoch 27/30\n",
      "275/291 [===========================>..] - ETA: 0s - loss: 0.0836 - acc: 0.9716 - precision_m: 0.6894 - recall_m: 0.3087 - f1_m: 0.4095\n",
      "Epoch 27: val_acc improved from 0.97018 to 0.97210, saving model to models/best_model_5_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0836 - acc: 0.9716 - precision_m: 0.6885 - recall_m: 0.3071 - f1_m: 0.4078 - val_loss: 0.0846 - val_acc: 0.9721 - val_precision_m: 0.7171 - val_recall_m: 0.3656 - val_f1_m: 0.4575\n",
      "Epoch 28/30\n",
      "276/291 [===========================>..] - ETA: 0s - loss: 0.0822 - acc: 0.9720 - precision_m: 0.7198 - recall_m: 0.3252 - f1_m: 0.4261\n",
      "Epoch 28: val_acc did not improve from 0.97210\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0827 - acc: 0.9720 - precision_m: 0.7184 - recall_m: 0.3235 - f1_m: 0.4247 - val_loss: 0.0860 - val_acc: 0.9707 - val_precision_m: 0.7192 - val_recall_m: 0.2555 - val_f1_m: 0.3534\n",
      "Epoch 29/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.0825 - acc: 0.9720 - precision_m: 0.7472 - recall_m: 0.3310 - f1_m: 0.4359\n",
      "Epoch 29: val_acc did not improve from 0.97210\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0825 - acc: 0.9720 - precision_m: 0.7472 - recall_m: 0.3310 - f1_m: 0.4359 - val_loss: 0.0840 - val_acc: 0.9715 - val_precision_m: 0.7325 - val_recall_m: 0.3286 - val_f1_m: 0.4187\n",
      "Epoch 30/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.0813 - acc: 0.9725 - precision_m: 0.7384 - recall_m: 0.3340 - f1_m: 0.4388\n",
      "Epoch 30: val_acc did not improve from 0.97210\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0815 - acc: 0.9724 - precision_m: 0.7382 - recall_m: 0.3354 - f1_m: 0.4403 - val_loss: 0.0830 - val_acc: 0.9714 - val_precision_m: 0.6952 - val_recall_m: 0.3129 - val_f1_m: 0.4043\n",
      "Score for fold 2: loss of 0.08457425981760025; acc of 97.20991253852844%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.09291538596153259; acc of 96.8250572681427%\n",
      "Test Precision: precision_m of 21.372851729393005%\n",
      "Test Recall: recall_m of 14.11447823047638%\n",
      "Test F1: f1_m of 16.01133942604065%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.2075 - acc: 0.9347 - precision_m: 0.0128 - recall_m: 0.0241 - f1_m: 0.0115\n",
      "Epoch 1: val_acc improved from -inf to 0.96287, saving model to models/best_model_5_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 2s 3ms/step - loss: 0.2075 - acc: 0.9347 - precision_m: 0.0128 - recall_m: 0.0241 - f1_m: 0.0115 - val_loss: 0.1426 - val_acc: 0.9629 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "276/291 [===========================>..] - ETA: 0s - loss: 0.1319 - acc: 0.9636 - precision_m: 0.0954 - recall_m: 0.0103 - f1_m: 0.0183  \n",
      "Epoch 2: val_acc improved from 0.96287 to 0.96370, saving model to models/best_model_5_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1313 - acc: 0.9637 - precision_m: 0.1008 - recall_m: 0.0109 - f1_m: 0.0195 - val_loss: 0.1298 - val_acc: 0.9637 - val_precision_m: 0.0909 - val_recall_m: 0.0115 - val_f1_m: 0.0201\n",
      "Epoch 3/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.1242 - acc: 0.9641 - precision_m: 0.2362 - recall_m: 0.0304 - f1_m: 0.0527\n",
      "Epoch 3: val_acc improved from 0.96370 to 0.96382, saving model to models/best_model_5_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1242 - acc: 0.9640 - precision_m: 0.2291 - recall_m: 0.0296 - f1_m: 0.0513 - val_loss: 0.1257 - val_acc: 0.9638 - val_precision_m: 0.1212 - val_recall_m: 0.0239 - val_f1_m: 0.0381\n",
      "Epoch 4/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.1209 - acc: 0.9642 - precision_m: 0.3008 - recall_m: 0.0479 - f1_m: 0.0804\n",
      "Epoch 4: val_acc improved from 0.96382 to 0.96430, saving model to models/best_model_5_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1204 - acc: 0.9644 - precision_m: 0.3036 - recall_m: 0.0473 - f1_m: 0.0796 - val_loss: 0.1225 - val_acc: 0.9643 - val_precision_m: 0.1515 - val_recall_m: 0.0301 - val_f1_m: 0.0484\n",
      "Epoch 5/30\n",
      "276/291 [===========================>..] - ETA: 0s - loss: 0.1173 - acc: 0.9644 - precision_m: 0.3659 - recall_m: 0.0581 - f1_m: 0.0973\n",
      "Epoch 5: val_acc improved from 0.96430 to 0.96442, saving model to models/best_model_5_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1176 - acc: 0.9643 - precision_m: 0.3666 - recall_m: 0.0575 - f1_m: 0.0965 - val_loss: 0.1188 - val_acc: 0.9644 - val_precision_m: 0.1515 - val_recall_m: 0.0314 - val_f1_m: 0.0501\n",
      "Epoch 6/30\n",
      "276/291 [===========================>..] - ETA: 0s - loss: 0.1147 - acc: 0.9646 - precision_m: 0.4269 - recall_m: 0.0731 - f1_m: 0.1200\n",
      "Epoch 6: val_acc did not improve from 0.96442\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1146 - acc: 0.9646 - precision_m: 0.4307 - recall_m: 0.0727 - f1_m: 0.1197 - val_loss: 0.1149 - val_acc: 0.9642 - val_precision_m: 0.2121 - val_recall_m: 0.0392 - val_f1_m: 0.0635\n",
      "Epoch 7/30\n",
      "276/291 [===========================>..] - ETA: 0s - loss: 0.1121 - acc: 0.9648 - precision_m: 0.4671 - recall_m: 0.0830 - f1_m: 0.1355\n",
      "Epoch 7: val_acc improved from 0.96442 to 0.96466, saving model to models/best_model_5_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1120 - acc: 0.9649 - precision_m: 0.4739 - recall_m: 0.0854 - f1_m: 0.1390 - val_loss: 0.1117 - val_acc: 0.9647 - val_precision_m: 0.2273 - val_recall_m: 0.0425 - val_f1_m: 0.0688\n",
      "Epoch 8/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.1089 - acc: 0.9651 - precision_m: 0.4727 - recall_m: 0.0951 - f1_m: 0.1520\n",
      "Epoch 8: val_acc improved from 0.96466 to 0.96478, saving model to models/best_model_5_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1093 - acc: 0.9650 - precision_m: 0.4821 - recall_m: 0.0970 - f1_m: 0.1553 - val_loss: 0.1099 - val_acc: 0.9648 - val_precision_m: 0.2525 - val_recall_m: 0.0508 - val_f1_m: 0.0815\n",
      "Epoch 9/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.1070 - acc: 0.9657 - precision_m: 0.5533 - recall_m: 0.1174 - f1_m: 0.1845\n",
      "Epoch 9: val_acc improved from 0.96478 to 0.96562, saving model to models/best_model_5_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1071 - acc: 0.9657 - precision_m: 0.5559 - recall_m: 0.1170 - f1_m: 0.1841 - val_loss: 0.1075 - val_acc: 0.9656 - val_precision_m: 0.4239 - val_recall_m: 0.0831 - val_f1_m: 0.1325\n",
      "Epoch 10/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.1048 - acc: 0.9661 - precision_m: 0.5638 - recall_m: 0.1288 - f1_m: 0.1999\n",
      "Epoch 10: val_acc improved from 0.96562 to 0.96658, saving model to models/best_model_5_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1051 - acc: 0.9659 - precision_m: 0.5653 - recall_m: 0.1274 - f1_m: 0.1980 - val_loss: 0.1044 - val_acc: 0.9666 - val_precision_m: 0.4360 - val_recall_m: 0.1053 - val_f1_m: 0.1627\n",
      "Epoch 11/30\n",
      "275/291 [===========================>..] - ETA: 0s - loss: 0.1030 - acc: 0.9664 - precision_m: 0.6175 - recall_m: 0.1445 - f1_m: 0.2225\n",
      "Epoch 11: val_acc did not improve from 0.96658\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1033 - acc: 0.9664 - precision_m: 0.6162 - recall_m: 0.1460 - f1_m: 0.2240 - val_loss: 0.1031 - val_acc: 0.9666 - val_precision_m: 0.4419 - val_recall_m: 0.1225 - val_f1_m: 0.1821\n",
      "Epoch 12/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.1026 - acc: 0.9664 - precision_m: 0.6052 - recall_m: 0.1535 - f1_m: 0.2313\n",
      "Epoch 12: val_acc improved from 0.96658 to 0.96682, saving model to models/best_model_5_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1020 - acc: 0.9666 - precision_m: 0.6131 - recall_m: 0.1556 - f1_m: 0.2348 - val_loss: 0.1018 - val_acc: 0.9668 - val_precision_m: 0.4869 - val_recall_m: 0.1389 - val_f1_m: 0.2031\n",
      "Epoch 13/30\n",
      "275/291 [===========================>..] - ETA: 0s - loss: 0.1004 - acc: 0.9669 - precision_m: 0.6339 - recall_m: 0.1741 - f1_m: 0.2600\n",
      "Epoch 13: val_acc improved from 0.96682 to 0.96718, saving model to models/best_model_5_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1002 - acc: 0.9671 - precision_m: 0.6400 - recall_m: 0.1740 - f1_m: 0.2602 - val_loss: 0.1006 - val_acc: 0.9672 - val_precision_m: 0.4535 - val_recall_m: 0.1178 - val_f1_m: 0.1778\n",
      "Epoch 14/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0993 - acc: 0.9674 - precision_m: 0.6636 - recall_m: 0.1801 - f1_m: 0.2673\n",
      "Epoch 14: val_acc improved from 0.96718 to 0.96778, saving model to models/best_model_5_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0990 - acc: 0.9674 - precision_m: 0.6619 - recall_m: 0.1830 - f1_m: 0.2697 - val_loss: 0.0986 - val_acc: 0.9678 - val_precision_m: 0.5015 - val_recall_m: 0.1329 - val_f1_m: 0.2012\n",
      "Epoch 15/30\n",
      "275/291 [===========================>..] - ETA: 0s - loss: 0.0976 - acc: 0.9676 - precision_m: 0.6680 - recall_m: 0.1914 - f1_m: 0.2848\n",
      "Epoch 15: val_acc did not improve from 0.96778\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0979 - acc: 0.9675 - precision_m: 0.6682 - recall_m: 0.1947 - f1_m: 0.2881 - val_loss: 0.0980 - val_acc: 0.9678 - val_precision_m: 0.5146 - val_recall_m: 0.1553 - val_f1_m: 0.2268\n",
      "Epoch 16/30\n",
      "276/291 [===========================>..] - ETA: 0s - loss: 0.0968 - acc: 0.9674 - precision_m: 0.6499 - recall_m: 0.2060 - f1_m: 0.2957\n",
      "Epoch 16: val_acc improved from 0.96778 to 0.96802, saving model to models/best_model_5_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0965 - acc: 0.9676 - precision_m: 0.6484 - recall_m: 0.2070 - f1_m: 0.2960 - val_loss: 0.0991 - val_acc: 0.9680 - val_precision_m: 0.5106 - val_recall_m: 0.1295 - val_f1_m: 0.1946\n",
      "Epoch 17/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0955 - acc: 0.9679 - precision_m: 0.6525 - recall_m: 0.2175 - f1_m: 0.3082\n",
      "Epoch 17: val_acc improved from 0.96802 to 0.96921, saving model to models/best_model_5_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0955 - acc: 0.9679 - precision_m: 0.6489 - recall_m: 0.2182 - f1_m: 0.3082 - val_loss: 0.0957 - val_acc: 0.9692 - val_precision_m: 0.5449 - val_recall_m: 0.2264 - val_f1_m: 0.3021\n",
      "Epoch 18/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.0943 - acc: 0.9684 - precision_m: 0.6554 - recall_m: 0.2225 - f1_m: 0.3146\n",
      "Epoch 18: val_acc improved from 0.96921 to 0.97017, saving model to models/best_model_5_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0941 - acc: 0.9684 - precision_m: 0.6561 - recall_m: 0.2230 - f1_m: 0.3156 - val_loss: 0.0954 - val_acc: 0.9702 - val_precision_m: 0.5862 - val_recall_m: 0.2554 - val_f1_m: 0.3350\n",
      "Epoch 19/30\n",
      "273/291 [===========================>..] - ETA: 0s - loss: 0.0924 - acc: 0.9689 - precision_m: 0.6937 - recall_m: 0.2479 - f1_m: 0.3488\n",
      "Epoch 19: val_acc did not improve from 0.97017\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0928 - acc: 0.9688 - precision_m: 0.6866 - recall_m: 0.2462 - f1_m: 0.3458 - val_loss: 0.0933 - val_acc: 0.9701 - val_precision_m: 0.5238 - val_recall_m: 0.2246 - val_f1_m: 0.3018\n",
      "Epoch 20/30\n",
      "274/291 [===========================>..] - ETA: 0s - loss: 0.0912 - acc: 0.9688 - precision_m: 0.6841 - recall_m: 0.2508 - f1_m: 0.3475\n",
      "Epoch 20: val_acc did not improve from 0.97017\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0917 - acc: 0.9686 - precision_m: 0.6802 - recall_m: 0.2471 - f1_m: 0.3430 - val_loss: 0.0927 - val_acc: 0.9701 - val_precision_m: 0.5741 - val_recall_m: 0.2495 - val_f1_m: 0.3292\n",
      "Epoch 21/30\n",
      "276/291 [===========================>..] - ETA: 0s - loss: 0.0906 - acc: 0.9689 - precision_m: 0.6794 - recall_m: 0.2516 - f1_m: 0.3511\n",
      "Epoch 21: val_acc did not improve from 0.97017\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0902 - acc: 0.9691 - precision_m: 0.6847 - recall_m: 0.2510 - f1_m: 0.3509 - val_loss: 0.0925 - val_acc: 0.9691 - val_precision_m: 0.5364 - val_recall_m: 0.1975 - val_f1_m: 0.2790\n",
      "Epoch 22/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.0892 - acc: 0.9694 - precision_m: 0.6988 - recall_m: 0.2728 - f1_m: 0.3720\n",
      "Epoch 22: val_acc did not improve from 0.97017\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0892 - acc: 0.9694 - precision_m: 0.6988 - recall_m: 0.2728 - f1_m: 0.3720 - val_loss: 0.0940 - val_acc: 0.9680 - val_precision_m: 0.5283 - val_recall_m: 0.1378 - val_f1_m: 0.2093\n",
      "Epoch 23/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9696 - precision_m: 0.6869 - recall_m: 0.2727 - f1_m: 0.3733\n",
      "Epoch 23: val_acc did not improve from 0.97017\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0886 - acc: 0.9695 - precision_m: 0.6868 - recall_m: 0.2713 - f1_m: 0.3717 - val_loss: 0.0901 - val_acc: 0.9699 - val_precision_m: 0.6011 - val_recall_m: 0.2720 - val_f1_m: 0.3549\n",
      "Epoch 24/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.0879 - acc: 0.9698 - precision_m: 0.7127 - recall_m: 0.2830 - f1_m: 0.3860\n",
      "Epoch 24: val_acc did not improve from 0.97017\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0878 - acc: 0.9698 - precision_m: 0.7132 - recall_m: 0.2858 - f1_m: 0.3891 - val_loss: 0.0925 - val_acc: 0.9691 - val_precision_m: 0.5793 - val_recall_m: 0.1876 - val_f1_m: 0.2731\n",
      "Epoch 25/30\n",
      "274/291 [===========================>..] - ETA: 0s - loss: 0.0866 - acc: 0.9700 - precision_m: 0.7024 - recall_m: 0.2992 - f1_m: 0.3975\n",
      "Epoch 25: val_acc did not improve from 0.97017\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0867 - acc: 0.9700 - precision_m: 0.7050 - recall_m: 0.2981 - f1_m: 0.3971 - val_loss: 0.0895 - val_acc: 0.9699 - val_precision_m: 0.6429 - val_recall_m: 0.2533 - val_f1_m: 0.3452\n",
      "Epoch 26/30\n",
      "274/291 [===========================>..] - ETA: 0s - loss: 0.0856 - acc: 0.9699 - precision_m: 0.7046 - recall_m: 0.2918 - f1_m: 0.3949\n",
      "Epoch 26: val_acc did not improve from 0.97017\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0859 - acc: 0.9699 - precision_m: 0.7016 - recall_m: 0.2913 - f1_m: 0.3941 - val_loss: 0.0897 - val_acc: 0.9702 - val_precision_m: 0.6334 - val_recall_m: 0.2763 - val_f1_m: 0.3676\n",
      "Epoch 27/30\n",
      "275/291 [===========================>..] - ETA: 0s - loss: 0.0851 - acc: 0.9702 - precision_m: 0.7121 - recall_m: 0.3097 - f1_m: 0.4114\n",
      "Epoch 27: val_acc did not improve from 0.97017\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0851 - acc: 0.9703 - precision_m: 0.7107 - recall_m: 0.3127 - f1_m: 0.4141 - val_loss: 0.0896 - val_acc: 0.9697 - val_precision_m: 0.6092 - val_recall_m: 0.2157 - val_f1_m: 0.3033\n",
      "Epoch 28/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.0844 - acc: 0.9702 - precision_m: 0.7034 - recall_m: 0.3138 - f1_m: 0.4154\n",
      "Epoch 28: val_acc improved from 0.97017 to 0.97053, saving model to models/best_model_5_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0844 - acc: 0.9703 - precision_m: 0.7048 - recall_m: 0.3163 - f1_m: 0.4182 - val_loss: 0.0882 - val_acc: 0.9705 - val_precision_m: 0.6209 - val_recall_m: 0.2463 - val_f1_m: 0.3374\n",
      "Epoch 29/30\n",
      "272/291 [===========================>..] - ETA: 0s - loss: 0.0841 - acc: 0.9706 - precision_m: 0.7084 - recall_m: 0.3248 - f1_m: 0.4245\n",
      "Epoch 29: val_acc improved from 0.97053 to 0.97089, saving model to models/best_model_5_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0839 - acc: 0.9708 - precision_m: 0.7065 - recall_m: 0.3271 - f1_m: 0.4267 - val_loss: 0.0876 - val_acc: 0.9709 - val_precision_m: 0.6388 - val_recall_m: 0.2558 - val_f1_m: 0.3482\n",
      "Epoch 30/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0831 - acc: 0.9709 - precision_m: 0.7170 - recall_m: 0.3426 - f1_m: 0.4429\n",
      "Epoch 30: val_acc did not improve from 0.97089\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0831 - acc: 0.9708 - precision_m: 0.7132 - recall_m: 0.3405 - f1_m: 0.4397 - val_loss: 0.0874 - val_acc: 0.9691 - val_precision_m: 0.5786 - val_recall_m: 0.2990 - val_f1_m: 0.3761\n",
      "Score for fold 3: loss of 0.08758432418107986; acc of 97.08912372589111%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.08864285051822662; acc of 97.02463746070862%\n",
      "Test Precision: precision_m of 16.921769082546234%\n",
      "Test Recall: recall_m of 11.00461632013321%\n",
      "Test F1: f1_m of 12.42394894361496%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1983 - acc: 0.9439 - precision_m: 0.0158 - recall_m: 0.0167 - f1_m: 0.0115\n",
      "Epoch 1: val_acc improved from -inf to 0.96143, saving model to models/best_model_5_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 2s 3ms/step - loss: 0.1983 - acc: 0.9439 - precision_m: 0.0158 - recall_m: 0.0167 - f1_m: 0.0115 - val_loss: 0.1450 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.1317 - acc: 0.9645 - precision_m: 0.0461 - recall_m: 0.0056 - f1_m: 0.0096\n",
      "Epoch 2: val_acc improved from 0.96143 to 0.96179, saving model to models/best_model_5_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1311 - acc: 0.9647 - precision_m: 0.0479 - recall_m: 0.0057 - f1_m: 0.0100 - val_loss: 0.1358 - val_acc: 0.9618 - val_precision_m: 0.0909 - val_recall_m: 0.0124 - val_f1_m: 0.0217\n",
      "Epoch 3/30\n",
      "274/292 [===========================>..] - ETA: 0s - loss: 0.1254 - acc: 0.9649 - precision_m: 0.1429 - recall_m: 0.0187 - f1_m: 0.0324\n",
      "Epoch 3: val_acc improved from 0.96179 to 0.96203, saving model to models/best_model_5_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1253 - acc: 0.9649 - precision_m: 0.1513 - recall_m: 0.0193 - f1_m: 0.0335 - val_loss: 0.1317 - val_acc: 0.9620 - val_precision_m: 0.2424 - val_recall_m: 0.0338 - val_f1_m: 0.0587\n",
      "Epoch 4/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.1223 - acc: 0.9649 - precision_m: 0.2112 - recall_m: 0.0297 - f1_m: 0.0503\n",
      "Epoch 4: val_acc did not improve from 0.96203\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1222 - acc: 0.9649 - precision_m: 0.2100 - recall_m: 0.0297 - f1_m: 0.0503 - val_loss: 0.1307 - val_acc: 0.9617 - val_precision_m: 0.0909 - val_recall_m: 0.0106 - val_f1_m: 0.0188\n",
      "Epoch 5/30\n",
      "274/292 [===========================>..] - ETA: 0s - loss: 0.1202 - acc: 0.9650 - precision_m: 0.2619 - recall_m: 0.0375 - f1_m: 0.0636\n",
      "Epoch 5: val_acc improved from 0.96203 to 0.96310, saving model to models/best_model_5_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1195 - acc: 0.9652 - precision_m: 0.2594 - recall_m: 0.0375 - f1_m: 0.0636 - val_loss: 0.1264 - val_acc: 0.9631 - val_precision_m: 0.2626 - val_recall_m: 0.0483 - val_f1_m: 0.0795\n",
      "Epoch 6/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.1171 - acc: 0.9655 - precision_m: 0.3240 - recall_m: 0.0546 - f1_m: 0.0894\n",
      "Epoch 6: val_acc improved from 0.96310 to 0.96370, saving model to models/best_model_5_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1170 - acc: 0.9654 - precision_m: 0.3303 - recall_m: 0.0549 - f1_m: 0.0903 - val_loss: 0.1238 - val_acc: 0.9637 - val_precision_m: 0.3333 - val_recall_m: 0.0535 - val_f1_m: 0.0904\n",
      "Epoch 7/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.1146 - acc: 0.9657 - precision_m: 0.3517 - recall_m: 0.0622 - f1_m: 0.1018\n",
      "Epoch 7: val_acc did not improve from 0.96370\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1146 - acc: 0.9656 - precision_m: 0.3493 - recall_m: 0.0615 - f1_m: 0.1007 - val_loss: 0.1211 - val_acc: 0.9637 - val_precision_m: 0.3030 - val_recall_m: 0.0492 - val_f1_m: 0.0828\n",
      "Epoch 8/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.1127 - acc: 0.9657 - precision_m: 0.3646 - recall_m: 0.0631 - f1_m: 0.1036\n",
      "Epoch 8: val_acc did not improve from 0.96370\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1126 - acc: 0.9658 - precision_m: 0.3701 - recall_m: 0.0645 - f1_m: 0.1057 - val_loss: 0.1191 - val_acc: 0.9633 - val_precision_m: 0.2727 - val_recall_m: 0.0418 - val_f1_m: 0.0704\n",
      "Epoch 9/30\n",
      "273/292 [===========================>..] - ETA: 0s - loss: 0.1105 - acc: 0.9658 - precision_m: 0.4367 - recall_m: 0.0790 - f1_m: 0.1295\n",
      "Epoch 9: val_acc did not improve from 0.96370\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1102 - acc: 0.9659 - precision_m: 0.4402 - recall_m: 0.0808 - f1_m: 0.1320 - val_loss: 0.1184 - val_acc: 0.9627 - val_precision_m: 0.1818 - val_recall_m: 0.0234 - val_f1_m: 0.0409\n",
      "Epoch 10/30\n",
      "273/292 [===========================>..] - ETA: 0s - loss: 0.1076 - acc: 0.9663 - precision_m: 0.4600 - recall_m: 0.0861 - f1_m: 0.1388\n",
      "Epoch 10: val_acc improved from 0.96370 to 0.96418, saving model to models/best_model_5_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1080 - acc: 0.9662 - precision_m: 0.4611 - recall_m: 0.0862 - f1_m: 0.1390 - val_loss: 0.1139 - val_acc: 0.9642 - val_precision_m: 0.4485 - val_recall_m: 0.0910 - val_f1_m: 0.1457\n",
      "Epoch 11/30\n",
      "273/292 [===========================>..] - ETA: 0s - loss: 0.1056 - acc: 0.9668 - precision_m: 0.5079 - recall_m: 0.1046 - f1_m: 0.1661\n",
      "Epoch 11: val_acc did not improve from 0.96418\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1059 - acc: 0.9668 - precision_m: 0.5060 - recall_m: 0.1036 - f1_m: 0.1648 - val_loss: 0.1158 - val_acc: 0.9626 - val_precision_m: 0.2121 - val_recall_m: 0.0313 - val_f1_m: 0.0527\n",
      "Epoch 12/30\n",
      "275/292 [===========================>..] - ETA: 0s - loss: 0.1040 - acc: 0.9667 - precision_m: 0.5372 - recall_m: 0.1209 - f1_m: 0.1887\n",
      "Epoch 12: val_acc did not improve from 0.96418\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1041 - acc: 0.9667 - precision_m: 0.5168 - recall_m: 0.1157 - f1_m: 0.1808 - val_loss: 0.1097 - val_acc: 0.9642 - val_precision_m: 0.3838 - val_recall_m: 0.0680 - val_f1_m: 0.1105\n",
      "Epoch 13/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.1024 - acc: 0.9672 - precision_m: 0.5589 - recall_m: 0.1284 - f1_m: 0.1988\n",
      "Epoch 13: val_acc improved from 0.96418 to 0.96501, saving model to models/best_model_5_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1021 - acc: 0.9672 - precision_m: 0.5591 - recall_m: 0.1284 - f1_m: 0.1990 - val_loss: 0.1082 - val_acc: 0.9650 - val_precision_m: 0.4568 - val_recall_m: 0.1040 - val_f1_m: 0.1624\n",
      "Epoch 14/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.1000 - acc: 0.9675 - precision_m: 0.5577 - recall_m: 0.1364 - f1_m: 0.2108\n",
      "Epoch 14: val_acc did not improve from 0.96501\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1001 - acc: 0.9675 - precision_m: 0.5618 - recall_m: 0.1384 - f1_m: 0.2134 - val_loss: 0.1067 - val_acc: 0.9648 - val_precision_m: 0.4030 - val_recall_m: 0.0848 - val_f1_m: 0.1363\n",
      "Epoch 15/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0989 - acc: 0.9677 - precision_m: 0.6128 - recall_m: 0.1544 - f1_m: 0.2352\n",
      "Epoch 15: val_acc did not improve from 0.96501\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0985 - acc: 0.9679 - precision_m: 0.6195 - recall_m: 0.1559 - f1_m: 0.2376 - val_loss: 0.1046 - val_acc: 0.9644 - val_precision_m: 0.4131 - val_recall_m: 0.0992 - val_f1_m: 0.1546\n",
      "Epoch 16/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0963 - acc: 0.9681 - precision_m: 0.6176 - recall_m: 0.1652 - f1_m: 0.2479\n",
      "Epoch 16: val_acc did not improve from 0.96501\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0967 - acc: 0.9680 - precision_m: 0.6203 - recall_m: 0.1645 - f1_m: 0.2475 - val_loss: 0.1032 - val_acc: 0.9647 - val_precision_m: 0.4633 - val_recall_m: 0.1221 - val_f1_m: 0.1816\n",
      "Epoch 17/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.0945 - acc: 0.9688 - precision_m: 0.6422 - recall_m: 0.1813 - f1_m: 0.2700\n",
      "Epoch 17: val_acc improved from 0.96501 to 0.96513, saving model to models/best_model_5_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0951 - acc: 0.9685 - precision_m: 0.6394 - recall_m: 0.1786 - f1_m: 0.2664 - val_loss: 0.1026 - val_acc: 0.9651 - val_precision_m: 0.5093 - val_recall_m: 0.1687 - val_f1_m: 0.2373\n",
      "Epoch 18/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.0931 - acc: 0.9687 - precision_m: 0.6123 - recall_m: 0.1918 - f1_m: 0.2781\n",
      "Epoch 18: val_acc improved from 0.96513 to 0.96621, saving model to models/best_model_5_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0937 - acc: 0.9685 - precision_m: 0.6118 - recall_m: 0.1936 - f1_m: 0.2798 - val_loss: 0.1021 - val_acc: 0.9662 - val_precision_m: 0.5442 - val_recall_m: 0.2126 - val_f1_m: 0.2823\n",
      "Epoch 19/30\n",
      "275/292 [===========================>..] - ETA: 0s - loss: 0.0933 - acc: 0.9684 - precision_m: 0.6573 - recall_m: 0.2023 - f1_m: 0.2901\n",
      "Epoch 19: val_acc did not improve from 0.96621\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0932 - acc: 0.9685 - precision_m: 0.6636 - recall_m: 0.2018 - f1_m: 0.2903 - val_loss: 0.1011 - val_acc: 0.9653 - val_precision_m: 0.4763 - val_recall_m: 0.1527 - val_f1_m: 0.2188\n",
      "Epoch 20/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.0910 - acc: 0.9690 - precision_m: 0.6476 - recall_m: 0.2172 - f1_m: 0.3068\n",
      "Epoch 20: val_acc did not improve from 0.96621\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0908 - acc: 0.9690 - precision_m: 0.6472 - recall_m: 0.2165 - f1_m: 0.3066 - val_loss: 0.0991 - val_acc: 0.9660 - val_precision_m: 0.5766 - val_recall_m: 0.1739 - val_f1_m: 0.2474\n",
      "Epoch 21/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0897 - acc: 0.9692 - precision_m: 0.6663 - recall_m: 0.2180 - f1_m: 0.3123\n",
      "Epoch 21: val_acc improved from 0.96621 to 0.96693, saving model to models/best_model_5_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0896 - acc: 0.9692 - precision_m: 0.6640 - recall_m: 0.2172 - f1_m: 0.3113 - val_loss: 0.0979 - val_acc: 0.9669 - val_precision_m: 0.5786 - val_recall_m: 0.2027 - val_f1_m: 0.2779\n",
      "Epoch 22/30\n",
      "274/292 [===========================>..] - ETA: 0s - loss: 0.0888 - acc: 0.9693 - precision_m: 0.6482 - recall_m: 0.2338 - f1_m: 0.3254\n",
      "Epoch 22: val_acc did not improve from 0.96693\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0886 - acc: 0.9694 - precision_m: 0.6504 - recall_m: 0.2345 - f1_m: 0.3265 - val_loss: 0.0975 - val_acc: 0.9667 - val_precision_m: 0.5854 - val_recall_m: 0.1902 - val_f1_m: 0.2674\n",
      "Epoch 23/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.0876 - acc: 0.9698 - precision_m: 0.6871 - recall_m: 0.2473 - f1_m: 0.3471\n",
      "Epoch 23: val_acc improved from 0.96693 to 0.96764, saving model to models/best_model_5_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0875 - acc: 0.9698 - precision_m: 0.6941 - recall_m: 0.2479 - f1_m: 0.3486 - val_loss: 0.0978 - val_acc: 0.9676 - val_precision_m: 0.6311 - val_recall_m: 0.2373 - val_f1_m: 0.3177\n",
      "Epoch 24/30\n",
      "273/292 [===========================>..] - ETA: 0s - loss: 0.0867 - acc: 0.9699 - precision_m: 0.6802 - recall_m: 0.2646 - f1_m: 0.3621\n",
      "Epoch 24: val_acc improved from 0.96764 to 0.96836, saving model to models/best_model_5_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0871 - acc: 0.9698 - precision_m: 0.6755 - recall_m: 0.2581 - f1_m: 0.3549 - val_loss: 0.0963 - val_acc: 0.9684 - val_precision_m: 0.6708 - val_recall_m: 0.3099 - val_f1_m: 0.3938\n",
      "Epoch 25/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.0872 - acc: 0.9699 - precision_m: 0.6819 - recall_m: 0.2753 - f1_m: 0.3703\n",
      "Epoch 25: val_acc did not improve from 0.96836\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0869 - acc: 0.9700 - precision_m: 0.6746 - recall_m: 0.2723 - f1_m: 0.3668 - val_loss: 0.0997 - val_acc: 0.9660 - val_precision_m: 0.5601 - val_recall_m: 0.1378 - val_f1_m: 0.2050\n",
      "Epoch 26/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0858 - acc: 0.9705 - precision_m: 0.7167 - recall_m: 0.2706 - f1_m: 0.3737\n",
      "Epoch 26: val_acc did not improve from 0.96836\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0858 - acc: 0.9705 - precision_m: 0.7166 - recall_m: 0.2720 - f1_m: 0.3756 - val_loss: 0.0972 - val_acc: 0.9669 - val_precision_m: 0.6025 - val_recall_m: 0.1732 - val_f1_m: 0.2504\n",
      "Epoch 27/30\n",
      "275/292 [===========================>..] - ETA: 0s - loss: 0.0855 - acc: 0.9703 - precision_m: 0.6724 - recall_m: 0.2709 - f1_m: 0.3686\n",
      "Epoch 27: val_acc did not improve from 0.96836\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0852 - acc: 0.9704 - precision_m: 0.6788 - recall_m: 0.2726 - f1_m: 0.3716 - val_loss: 0.0947 - val_acc: 0.9676 - val_precision_m: 0.6227 - val_recall_m: 0.2811 - val_f1_m: 0.3567\n",
      "Epoch 28/30\n",
      "274/292 [===========================>..] - ETA: 0s - loss: 0.0851 - acc: 0.9709 - precision_m: 0.6985 - recall_m: 0.2985 - f1_m: 0.3981\n",
      "Epoch 28: val_acc did not improve from 0.96836\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0850 - acc: 0.9709 - precision_m: 0.6929 - recall_m: 0.2932 - f1_m: 0.3921 - val_loss: 0.0949 - val_acc: 0.9673 - val_precision_m: 0.6359 - val_recall_m: 0.2486 - val_f1_m: 0.3322\n",
      "Epoch 29/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0846 - acc: 0.9706 - precision_m: 0.6947 - recall_m: 0.2911 - f1_m: 0.3905\n",
      "Epoch 29: val_acc improved from 0.96836 to 0.96919, saving model to models/best_model_5_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0844 - acc: 0.9706 - precision_m: 0.6932 - recall_m: 0.2900 - f1_m: 0.3893 - val_loss: 0.0944 - val_acc: 0.9692 - val_precision_m: 0.7204 - val_recall_m: 0.2810 - val_f1_m: 0.3713\n",
      "Epoch 30/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0832 - acc: 0.9711 - precision_m: 0.7000 - recall_m: 0.2971 - f1_m: 0.3963\n",
      "Epoch 30: val_acc did not improve from 0.96919\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0835 - acc: 0.9708 - precision_m: 0.6966 - recall_m: 0.2954 - f1_m: 0.3948 - val_loss: 0.0941 - val_acc: 0.9678 - val_precision_m: 0.6563 - val_recall_m: 0.3016 - val_f1_m: 0.3782\n",
      "Score for fold 4: loss of 0.09442301094532013; acc of 96.91940546035767%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.09952224045991898; acc of 96.47300839424133%\n",
      "Test Precision: precision_m of 17.74180382490158%\n",
      "Test Recall: recall_m of 10.585501044988632%\n",
      "Test F1: f1_m of 12.150120735168457%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.1860 - acc: 0.9458 - precision_m: 0.0355 - recall_m: 0.0271 - f1_m: 0.0200\n",
      "Epoch 1: val_acc improved from -inf to 0.96211, saving model to models/best_model_5_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 2s 4ms/step - loss: 0.1860 - acc: 0.9458 - precision_m: 0.0355 - recall_m: 0.0271 - f1_m: 0.0200 - val_loss: 0.1386 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.1291 - acc: 0.9641 - precision_m: 0.1065 - recall_m: 0.0128 - f1_m: 0.0224\n",
      "Epoch 2: val_acc improved from 0.96211 to 0.96223, saving model to models/best_model_5_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1293 - acc: 0.9639 - precision_m: 0.1031 - recall_m: 0.0126 - f1_m: 0.0221 - val_loss: 0.1319 - val_acc: 0.9622 - val_precision_m: 0.0606 - val_recall_m: 0.0101 - val_f1_m: 0.0173\n",
      "Epoch 3/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.1245 - acc: 0.9641 - precision_m: 0.1784 - recall_m: 0.0248 - f1_m: 0.0421\n",
      "Epoch 3: val_acc did not improve from 0.96223\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1247 - acc: 0.9640 - precision_m: 0.1721 - recall_m: 0.0241 - f1_m: 0.0408 - val_loss: 0.1279 - val_acc: 0.9622 - val_precision_m: 0.0606 - val_recall_m: 0.0101 - val_f1_m: 0.0173\n",
      "Epoch 4/30\n",
      "270/291 [==========================>...] - ETA: 0s - loss: 0.1219 - acc: 0.9639 - precision_m: 0.2287 - recall_m: 0.0313 - f1_m: 0.0532\n",
      "Epoch 4: val_acc did not improve from 0.96223\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1212 - acc: 0.9642 - precision_m: 0.2385 - recall_m: 0.0327 - f1_m: 0.0556 - val_loss: 0.1248 - val_acc: 0.9622 - val_precision_m: 0.1364 - val_recall_m: 0.0163 - val_f1_m: 0.0283\n",
      "Epoch 5/30\n",
      "276/291 [===========================>..] - ETA: 0s - loss: 0.1178 - acc: 0.9643 - precision_m: 0.3013 - recall_m: 0.0446 - f1_m: 0.0752\n",
      "Epoch 5: val_acc improved from 0.96223 to 0.96247, saving model to models/best_model_5_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1182 - acc: 0.9643 - precision_m: 0.3047 - recall_m: 0.0446 - f1_m: 0.0754 - val_loss: 0.1217 - val_acc: 0.9625 - val_precision_m: 0.1414 - val_recall_m: 0.0252 - val_f1_m: 0.0420\n",
      "Epoch 6/30\n",
      "275/291 [===========================>..] - ETA: 0s - loss: 0.1158 - acc: 0.9644 - precision_m: 0.3358 - recall_m: 0.0532 - f1_m: 0.0892\n",
      "Epoch 6: val_acc improved from 0.96247 to 0.96259, saving model to models/best_model_5_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1151 - acc: 0.9646 - precision_m: 0.3431 - recall_m: 0.0537 - f1_m: 0.0902 - val_loss: 0.1204 - val_acc: 0.9626 - val_precision_m: 0.1061 - val_recall_m: 0.0230 - val_f1_m: 0.0375\n",
      "Epoch 7/30\n",
      "275/291 [===========================>..] - ETA: 0s - loss: 0.1122 - acc: 0.9649 - precision_m: 0.4285 - recall_m: 0.0722 - f1_m: 0.1183\n",
      "Epoch 7: val_acc improved from 0.96259 to 0.96414, saving model to models/best_model_5_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1126 - acc: 0.9648 - precision_m: 0.4261 - recall_m: 0.0727 - f1_m: 0.1190 - val_loss: 0.1163 - val_acc: 0.9641 - val_precision_m: 0.3258 - val_recall_m: 0.0588 - val_f1_m: 0.0959\n",
      "Epoch 8/30\n",
      "274/291 [===========================>..] - ETA: 0s - loss: 0.1101 - acc: 0.9652 - precision_m: 0.4140 - recall_m: 0.0803 - f1_m: 0.1283\n",
      "Epoch 8: val_acc did not improve from 0.96414\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1099 - acc: 0.9652 - precision_m: 0.4084 - recall_m: 0.0782 - f1_m: 0.1251 - val_loss: 0.1150 - val_acc: 0.9634 - val_precision_m: 0.2172 - val_recall_m: 0.0348 - val_f1_m: 0.0588\n",
      "Epoch 9/30\n",
      "271/291 [==========================>...] - ETA: 0s - loss: 0.1068 - acc: 0.9660 - precision_m: 0.4825 - recall_m: 0.0928 - f1_m: 0.1487\n",
      "Epoch 9: val_acc improved from 0.96414 to 0.96474, saving model to models/best_model_5_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1075 - acc: 0.9658 - precision_m: 0.4895 - recall_m: 0.0939 - f1_m: 0.1508 - val_loss: 0.1122 - val_acc: 0.9647 - val_precision_m: 0.2893 - val_recall_m: 0.0776 - val_f1_m: 0.1132\n",
      "Epoch 10/30\n",
      "276/291 [===========================>..] - ETA: 0s - loss: 0.1060 - acc: 0.9659 - precision_m: 0.5464 - recall_m: 0.1150 - f1_m: 0.1807\n",
      "Epoch 10: val_acc did not improve from 0.96474\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1054 - acc: 0.9662 - precision_m: 0.5486 - recall_m: 0.1144 - f1_m: 0.1803 - val_loss: 0.1112 - val_acc: 0.9647 - val_precision_m: 0.3253 - val_recall_m: 0.0744 - val_f1_m: 0.1131\n",
      "Epoch 11/30\n",
      "274/291 [===========================>..] - ETA: 0s - loss: 0.1043 - acc: 0.9661 - precision_m: 0.5515 - recall_m: 0.1189 - f1_m: 0.1881\n",
      "Epoch 11: val_acc did not improve from 0.96474\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1034 - acc: 0.9665 - precision_m: 0.5596 - recall_m: 0.1230 - f1_m: 0.1939 - val_loss: 0.1102 - val_acc: 0.9639 - val_precision_m: 0.2482 - val_recall_m: 0.0590 - val_f1_m: 0.0874\n",
      "Epoch 12/30\n",
      "276/291 [===========================>..] - ETA: 0s - loss: 0.1017 - acc: 0.9666 - precision_m: 0.5565 - recall_m: 0.1353 - f1_m: 0.2074\n",
      "Epoch 12: val_acc did not improve from 0.96474\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1018 - acc: 0.9666 - precision_m: 0.5576 - recall_m: 0.1353 - f1_m: 0.2076 - val_loss: 0.1072 - val_acc: 0.9647 - val_precision_m: 0.3878 - val_recall_m: 0.0876 - val_f1_m: 0.1334\n",
      "Epoch 13/30\n",
      "274/291 [===========================>..] - ETA: 0s - loss: 0.1004 - acc: 0.9668 - precision_m: 0.5894 - recall_m: 0.1541 - f1_m: 0.2319\n",
      "Epoch 13: val_acc improved from 0.96474 to 0.96534, saving model to models/best_model_5_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1001 - acc: 0.9670 - precision_m: 0.5833 - recall_m: 0.1539 - f1_m: 0.2313 - val_loss: 0.1068 - val_acc: 0.9653 - val_precision_m: 0.4015 - val_recall_m: 0.1182 - val_f1_m: 0.1683\n",
      "Epoch 14/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.0987 - acc: 0.9675 - precision_m: 0.6029 - recall_m: 0.1678 - f1_m: 0.2504\n",
      "Epoch 14: val_acc improved from 0.96534 to 0.96546, saving model to models/best_model_5_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0987 - acc: 0.9674 - precision_m: 0.6059 - recall_m: 0.1712 - f1_m: 0.2540 - val_loss: 0.1048 - val_acc: 0.9655 - val_precision_m: 0.4149 - val_recall_m: 0.1264 - val_f1_m: 0.1783\n",
      "Epoch 15/30\n",
      "276/291 [===========================>..] - ETA: 0s - loss: 0.0974 - acc: 0.9679 - precision_m: 0.6584 - recall_m: 0.1922 - f1_m: 0.2827\n",
      "Epoch 15: val_acc improved from 0.96546 to 0.96570, saving model to models/best_model_5_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0973 - acc: 0.9679 - precision_m: 0.6491 - recall_m: 0.1874 - f1_m: 0.2765 - val_loss: 0.1037 - val_acc: 0.9657 - val_precision_m: 0.4627 - val_recall_m: 0.1286 - val_f1_m: 0.1875\n",
      "Epoch 16/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.0950 - acc: 0.9683 - precision_m: 0.6423 - recall_m: 0.1928 - f1_m: 0.2823\n",
      "Epoch 16: val_acc improved from 0.96570 to 0.96689, saving model to models/best_model_5_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0958 - acc: 0.9681 - precision_m: 0.6438 - recall_m: 0.1942 - f1_m: 0.2844 - val_loss: 0.1028 - val_acc: 0.9669 - val_precision_m: 0.6474 - val_recall_m: 0.2351 - val_f1_m: 0.3116\n",
      "Epoch 17/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.0940 - acc: 0.9686 - precision_m: 0.6762 - recall_m: 0.2083 - f1_m: 0.3041\n",
      "Epoch 17: val_acc did not improve from 0.96689\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0940 - acc: 0.9687 - precision_m: 0.6773 - recall_m: 0.2099 - f1_m: 0.3058 - val_loss: 0.1015 - val_acc: 0.9667 - val_precision_m: 0.5928 - val_recall_m: 0.2258 - val_f1_m: 0.3005\n",
      "Epoch 18/30\n",
      "275/291 [===========================>..] - ETA: 0s - loss: 0.0931 - acc: 0.9690 - precision_m: 0.6946 - recall_m: 0.2281 - f1_m: 0.3278\n",
      "Epoch 18: val_acc did not improve from 0.96689\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0927 - acc: 0.9690 - precision_m: 0.6916 - recall_m: 0.2272 - f1_m: 0.3259 - val_loss: 0.1003 - val_acc: 0.9661 - val_precision_m: 0.5843 - val_recall_m: 0.2062 - val_f1_m: 0.2757\n",
      "Epoch 19/30\n",
      "275/291 [===========================>..] - ETA: 0s - loss: 0.0918 - acc: 0.9694 - precision_m: 0.7011 - recall_m: 0.2596 - f1_m: 0.3596\n",
      "Epoch 19: val_acc did not improve from 0.96689\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0916 - acc: 0.9695 - precision_m: 0.6854 - recall_m: 0.2566 - f1_m: 0.3545 - val_loss: 0.1023 - val_acc: 0.9655 - val_precision_m: 0.4834 - val_recall_m: 0.1481 - val_f1_m: 0.2102\n",
      "Epoch 20/30\n",
      "271/291 [==========================>...] - ETA: 0s - loss: 0.0908 - acc: 0.9692 - precision_m: 0.6932 - recall_m: 0.2468 - f1_m: 0.3458\n",
      "Epoch 20: val_acc did not improve from 0.96689\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0908 - acc: 0.9692 - precision_m: 0.6916 - recall_m: 0.2468 - f1_m: 0.3460 - val_loss: 0.0994 - val_acc: 0.9667 - val_precision_m: 0.6072 - val_recall_m: 0.1772 - val_f1_m: 0.2565\n",
      "Epoch 21/30\n",
      "274/291 [===========================>..] - ETA: 0s - loss: 0.0902 - acc: 0.9699 - precision_m: 0.7024 - recall_m: 0.2685 - f1_m: 0.3691\n",
      "Epoch 21: val_acc did not improve from 0.96689\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0900 - acc: 0.9699 - precision_m: 0.6960 - recall_m: 0.2676 - f1_m: 0.3670 - val_loss: 0.0993 - val_acc: 0.9669 - val_precision_m: 0.6025 - val_recall_m: 0.1977 - val_f1_m: 0.2779\n",
      "Epoch 22/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.0883 - acc: 0.9704 - precision_m: 0.7277 - recall_m: 0.2707 - f1_m: 0.3742\n",
      "Epoch 22: val_acc improved from 0.96689 to 0.96797, saving model to models/best_model_5_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0889 - acc: 0.9702 - precision_m: 0.7308 - recall_m: 0.2702 - f1_m: 0.3738 - val_loss: 0.0998 - val_acc: 0.9680 - val_precision_m: 0.6423 - val_recall_m: 0.3341 - val_f1_m: 0.4029\n",
      "Epoch 23/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.0886 - acc: 0.9700 - precision_m: 0.7102 - recall_m: 0.2832 - f1_m: 0.3885\n",
      "Epoch 23: val_acc did not improve from 0.96797\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0883 - acc: 0.9703 - precision_m: 0.7069 - recall_m: 0.2830 - f1_m: 0.3876 - val_loss: 0.0969 - val_acc: 0.9670 - val_precision_m: 0.6361 - val_recall_m: 0.2232 - val_f1_m: 0.3079\n",
      "Epoch 24/30\n",
      "273/291 [===========================>..] - ETA: 0s - loss: 0.0882 - acc: 0.9700 - precision_m: 0.6989 - recall_m: 0.2722 - f1_m: 0.3727\n",
      "Epoch 24: val_acc improved from 0.96797 to 0.96857, saving model to models/best_model_5_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0879 - acc: 0.9701 - precision_m: 0.6958 - recall_m: 0.2742 - f1_m: 0.3740 - val_loss: 0.0952 - val_acc: 0.9686 - val_precision_m: 0.7127 - val_recall_m: 0.3033 - val_f1_m: 0.3891\n",
      "Epoch 25/30\n",
      "275/291 [===========================>..] - ETA: 0s - loss: 0.0872 - acc: 0.9708 - precision_m: 0.7181 - recall_m: 0.2975 - f1_m: 0.4035\n",
      "Epoch 25: val_acc did not improve from 0.96857\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0868 - acc: 0.9709 - precision_m: 0.7146 - recall_m: 0.2936 - f1_m: 0.3991 - val_loss: 0.0961 - val_acc: 0.9677 - val_precision_m: 0.6507 - val_recall_m: 0.2357 - val_f1_m: 0.3199\n",
      "Epoch 26/30\n",
      "275/291 [===========================>..] - ETA: 0s - loss: 0.0857 - acc: 0.9713 - precision_m: 0.7438 - recall_m: 0.3095 - f1_m: 0.4197\n",
      "Epoch 26: val_acc did not improve from 0.96857\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0865 - acc: 0.9710 - precision_m: 0.7444 - recall_m: 0.3053 - f1_m: 0.4155 - val_loss: 0.0975 - val_acc: 0.9682 - val_precision_m: 0.6535 - val_recall_m: 0.3871 - val_f1_m: 0.4575\n",
      "Epoch 27/30\n",
      "274/291 [===========================>..] - ETA: 0s - loss: 0.0864 - acc: 0.9707 - precision_m: 0.7053 - recall_m: 0.3072 - f1_m: 0.4102\n",
      "Epoch 27: val_acc did not improve from 0.96857\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0858 - acc: 0.9710 - precision_m: 0.7087 - recall_m: 0.3098 - f1_m: 0.4128 - val_loss: 0.0970 - val_acc: 0.9669 - val_precision_m: 0.6194 - val_recall_m: 0.2082 - val_f1_m: 0.2904\n",
      "Epoch 28/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.0849 - acc: 0.9711 - precision_m: 0.7072 - recall_m: 0.3129 - f1_m: 0.4105\n",
      "Epoch 28: val_acc improved from 0.96857 to 0.96988, saving model to models/best_model_5_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0855 - acc: 0.9709 - precision_m: 0.7067 - recall_m: 0.3115 - f1_m: 0.4094 - val_loss: 0.0923 - val_acc: 0.9699 - val_precision_m: 0.6792 - val_recall_m: 0.3543 - val_f1_m: 0.4305\n",
      "Epoch 29/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.0851 - acc: 0.9711 - precision_m: 0.7268 - recall_m: 0.3145 - f1_m: 0.4196\n",
      "Epoch 29: val_acc did not improve from 0.96988\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0848 - acc: 0.9712 - precision_m: 0.7273 - recall_m: 0.3143 - f1_m: 0.4199 - val_loss: 0.0915 - val_acc: 0.9696 - val_precision_m: 0.6978 - val_recall_m: 0.3313 - val_f1_m: 0.4148\n",
      "Epoch 30/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0845 - acc: 0.9711 - precision_m: 0.7156 - recall_m: 0.3236 - f1_m: 0.4232\n",
      "Epoch 30: val_acc did not improve from 0.96988\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0846 - acc: 0.9711 - precision_m: 0.7131 - recall_m: 0.3228 - f1_m: 0.4220 - val_loss: 0.0927 - val_acc: 0.9683 - val_precision_m: 0.6230 - val_recall_m: 0.2789 - val_f1_m: 0.3540\n",
      "Score for fold 5: loss of 0.09228426963090897; acc of 96.98816537857056%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.08931871503591537; acc of 96.88234329223633%\n",
      "Test Precision: precision_m of 18.811149895191193%\n",
      "Test Recall: recall_m of 12.456674128770828%\n",
      "Test F1: f1_m of 14.164462685585022%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1847 - acc: 0.9488 - precision_m: 0.0113 - recall_m: 0.0128 - f1_m: 0.0094\n",
      "Epoch 1: val_acc improved from -inf to 0.96059, saving model to models/best_model_5_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 2s 3ms/step - loss: 0.1847 - acc: 0.9488 - precision_m: 0.0113 - recall_m: 0.0128 - f1_m: 0.0094 - val_loss: 0.1485 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.1323 - acc: 0.9640 - precision_m: 0.0487 - recall_m: 0.0052 - f1_m: 0.0092\n",
      "Epoch 2: val_acc improved from 0.96059 to 0.96083, saving model to models/best_model_5_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1323 - acc: 0.9639 - precision_m: 0.0497 - recall_m: 0.0052 - f1_m: 0.0093 - val_loss: 0.1386 - val_acc: 0.9608 - val_precision_m: 0.0606 - val_recall_m: 0.0084 - val_f1_m: 0.0144\n",
      "Epoch 3/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.1266 - acc: 0.9642 - precision_m: 0.1667 - recall_m: 0.0196 - f1_m: 0.0347\n",
      "Epoch 3: val_acc improved from 0.96083 to 0.96107, saving model to models/best_model_5_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1266 - acc: 0.9642 - precision_m: 0.1661 - recall_m: 0.0196 - f1_m: 0.0346 - val_loss: 0.1343 - val_acc: 0.9611 - val_precision_m: 0.0606 - val_recall_m: 0.0067 - val_f1_m: 0.0119\n",
      "Epoch 4/30\n",
      "272/292 [==========================>...] - ETA: 0s - loss: 0.1237 - acc: 0.9641 - precision_m: 0.1942 - recall_m: 0.0256 - f1_m: 0.0443\n",
      "Epoch 4: val_acc did not improve from 0.96107\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1235 - acc: 0.9642 - precision_m: 0.1963 - recall_m: 0.0258 - f1_m: 0.0447 - val_loss: 0.1314 - val_acc: 0.9607 - val_precision_m: 0.0303 - val_recall_m: 0.0011 - val_f1_m: 0.0021\n",
      "Epoch 5/30\n",
      "273/292 [===========================>..] - ETA: 0s - loss: 0.1211 - acc: 0.9642 - precision_m: 0.2524 - recall_m: 0.0359 - f1_m: 0.0612\n",
      "Epoch 5: val_acc did not improve from 0.96107\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1204 - acc: 0.9643 - precision_m: 0.2429 - recall_m: 0.0342 - f1_m: 0.0584 - val_loss: 0.1267 - val_acc: 0.9609 - val_precision_m: 0.1212 - val_recall_m: 0.0122 - val_f1_m: 0.0221\n",
      "Epoch 6/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.1161 - acc: 0.9648 - precision_m: 0.3128 - recall_m: 0.0442 - f1_m: 0.0754\n",
      "Epoch 6: val_acc did not improve from 0.96107\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1168 - acc: 0.9645 - precision_m: 0.3059 - recall_m: 0.0438 - f1_m: 0.0745 - val_loss: 0.1222 - val_acc: 0.9609 - val_precision_m: 0.1364 - val_recall_m: 0.0169 - val_f1_m: 0.0299\n",
      "Epoch 7/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.1137 - acc: 0.9647 - precision_m: 0.3102 - recall_m: 0.0482 - f1_m: 0.0800\n",
      "Epoch 7: val_acc improved from 0.96107 to 0.96179, saving model to models/best_model_5_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1136 - acc: 0.9647 - precision_m: 0.3111 - recall_m: 0.0487 - f1_m: 0.0808 - val_loss: 0.1181 - val_acc: 0.9618 - val_precision_m: 0.1919 - val_recall_m: 0.0275 - val_f1_m: 0.0467\n",
      "Epoch 8/30\n",
      "273/292 [===========================>..] - ETA: 0s - loss: 0.1110 - acc: 0.9647 - precision_m: 0.3489 - recall_m: 0.0585 - f1_m: 0.0973\n",
      "Epoch 8: val_acc did not improve from 0.96179\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1106 - acc: 0.9648 - precision_m: 0.3639 - recall_m: 0.0610 - f1_m: 0.1016 - val_loss: 0.1164 - val_acc: 0.9611 - val_precision_m: 0.1162 - val_recall_m: 0.0185 - val_f1_m: 0.0316\n",
      "Epoch 9/30\n",
      "275/292 [===========================>..] - ETA: 0s - loss: 0.1086 - acc: 0.9649 - precision_m: 0.4036 - recall_m: 0.0720 - f1_m: 0.1175\n",
      "Epoch 9: val_acc improved from 0.96179 to 0.96252, saving model to models/best_model_5_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1082 - acc: 0.9650 - precision_m: 0.4041 - recall_m: 0.0716 - f1_m: 0.1171 - val_loss: 0.1111 - val_acc: 0.9625 - val_precision_m: 0.2939 - val_recall_m: 0.0633 - val_f1_m: 0.1006\n",
      "Epoch 10/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.1062 - acc: 0.9650 - precision_m: 0.4216 - recall_m: 0.0850 - f1_m: 0.1361\n",
      "Epoch 10: val_acc did not improve from 0.96252\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1061 - acc: 0.9651 - precision_m: 0.4271 - recall_m: 0.0852 - f1_m: 0.1363 - val_loss: 0.1099 - val_acc: 0.9623 - val_precision_m: 0.2439 - val_recall_m: 0.0422 - val_f1_m: 0.0693\n",
      "Epoch 11/30\n",
      "274/292 [===========================>..] - ETA: 0s - loss: 0.1036 - acc: 0.9658 - precision_m: 0.5013 - recall_m: 0.1030 - f1_m: 0.1633\n",
      "Epoch 11: val_acc improved from 0.96252 to 0.96264, saving model to models/best_model_5_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1039 - acc: 0.9657 - precision_m: 0.5035 - recall_m: 0.1055 - f1_m: 0.1666 - val_loss: 0.1073 - val_acc: 0.9626 - val_precision_m: 0.3626 - val_recall_m: 0.0585 - val_f1_m: 0.0966\n",
      "Epoch 12/30\n",
      "273/292 [===========================>..] - ETA: 0s - loss: 0.1024 - acc: 0.9658 - precision_m: 0.5197 - recall_m: 0.1181 - f1_m: 0.1833\n",
      "Epoch 12: val_acc improved from 0.96264 to 0.96360, saving model to models/best_model_5_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1024 - acc: 0.9659 - precision_m: 0.5176 - recall_m: 0.1183 - f1_m: 0.1834 - val_loss: 0.1051 - val_acc: 0.9636 - val_precision_m: 0.4116 - val_recall_m: 0.0985 - val_f1_m: 0.1553\n",
      "Epoch 13/30\n",
      "275/292 [===========================>..] - ETA: 0s - loss: 0.1004 - acc: 0.9667 - precision_m: 0.5541 - recall_m: 0.1272 - f1_m: 0.1983\n",
      "Epoch 13: val_acc did not improve from 0.96360\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1006 - acc: 0.9666 - precision_m: 0.5620 - recall_m: 0.1316 - f1_m: 0.2044 - val_loss: 0.1049 - val_acc: 0.9635 - val_precision_m: 0.4812 - val_recall_m: 0.1296 - val_f1_m: 0.1965\n",
      "Epoch 14/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.0985 - acc: 0.9667 - precision_m: 0.5651 - recall_m: 0.1438 - f1_m: 0.2189\n",
      "Epoch 14: val_acc did not improve from 0.96360\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0989 - acc: 0.9667 - precision_m: 0.5711 - recall_m: 0.1449 - f1_m: 0.2209 - val_loss: 0.1026 - val_acc: 0.9630 - val_precision_m: 0.3980 - val_recall_m: 0.0794 - val_f1_m: 0.1267\n",
      "Epoch 15/30\n",
      "273/292 [===========================>..] - ETA: 0s - loss: 0.0975 - acc: 0.9670 - precision_m: 0.5727 - recall_m: 0.1549 - f1_m: 0.2291\n",
      "Epoch 15: val_acc improved from 0.96360 to 0.96493, saving model to models/best_model_5_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0975 - acc: 0.9669 - precision_m: 0.5778 - recall_m: 0.1577 - f1_m: 0.2334 - val_loss: 0.1012 - val_acc: 0.9649 - val_precision_m: 0.5941 - val_recall_m: 0.1705 - val_f1_m: 0.2505\n",
      "Epoch 16/30\n",
      "275/292 [===========================>..] - ETA: 0s - loss: 0.0960 - acc: 0.9676 - precision_m: 0.6154 - recall_m: 0.1749 - f1_m: 0.2598\n",
      "Epoch 16: val_acc improved from 0.96493 to 0.96565, saving model to models/best_model_5_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0959 - acc: 0.9676 - precision_m: 0.6192 - recall_m: 0.1769 - f1_m: 0.2620 - val_loss: 0.0999 - val_acc: 0.9657 - val_precision_m: 0.6131 - val_recall_m: 0.1906 - val_f1_m: 0.2736\n",
      "Epoch 17/30\n",
      "274/292 [===========================>..] - ETA: 0s - loss: 0.0946 - acc: 0.9675 - precision_m: 0.6194 - recall_m: 0.1892 - f1_m: 0.2745\n",
      "Epoch 17: val_acc did not improve from 0.96565\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0943 - acc: 0.9676 - precision_m: 0.6171 - recall_m: 0.1875 - f1_m: 0.2723 - val_loss: 0.0988 - val_acc: 0.9652 - val_precision_m: 0.5622 - val_recall_m: 0.1517 - val_f1_m: 0.2281\n",
      "Epoch 18/30\n",
      "274/292 [===========================>..] - ETA: 0s - loss: 0.0932 - acc: 0.9682 - precision_m: 0.6465 - recall_m: 0.2039 - f1_m: 0.2925\n",
      "Epoch 18: val_acc did not improve from 0.96565\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0928 - acc: 0.9684 - precision_m: 0.6474 - recall_m: 0.2057 - f1_m: 0.2951 - val_loss: 0.0990 - val_acc: 0.9652 - val_precision_m: 0.5604 - val_recall_m: 0.1832 - val_f1_m: 0.2619\n",
      "Epoch 19/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0915 - acc: 0.9683 - precision_m: 0.6638 - recall_m: 0.2208 - f1_m: 0.3143\n",
      "Epoch 19: val_acc did not improve from 0.96565\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0915 - acc: 0.9682 - precision_m: 0.6617 - recall_m: 0.2218 - f1_m: 0.3152 - val_loss: 0.0999 - val_acc: 0.9654 - val_precision_m: 0.6212 - val_recall_m: 0.1455 - val_f1_m: 0.2216\n",
      "Epoch 20/30\n",
      "273/292 [===========================>..] - ETA: 0s - loss: 0.0910 - acc: 0.9687 - precision_m: 0.6765 - recall_m: 0.2285 - f1_m: 0.3238\n",
      "Epoch 20: val_acc improved from 0.96565 to 0.96589, saving model to models/best_model_5_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0906 - acc: 0.9689 - precision_m: 0.6795 - recall_m: 0.2360 - f1_m: 0.3310 - val_loss: 0.0975 - val_acc: 0.9659 - val_precision_m: 0.6141 - val_recall_m: 0.1691 - val_f1_m: 0.2525\n",
      "Epoch 21/30\n",
      "275/292 [===========================>..] - ETA: 0s - loss: 0.0896 - acc: 0.9688 - precision_m: 0.6314 - recall_m: 0.2370 - f1_m: 0.3299\n",
      "Epoch 21: val_acc did not improve from 0.96589\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0896 - acc: 0.9688 - precision_m: 0.6361 - recall_m: 0.2356 - f1_m: 0.3292 - val_loss: 0.0952 - val_acc: 0.9657 - val_precision_m: 0.5914 - val_recall_m: 0.2070 - val_f1_m: 0.2898\n",
      "Epoch 22/30\n",
      "274/292 [===========================>..] - ETA: 0s - loss: 0.0885 - acc: 0.9692 - precision_m: 0.6956 - recall_m: 0.2580 - f1_m: 0.3585\n",
      "Epoch 22: val_acc did not improve from 0.96589\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0885 - acc: 0.9693 - precision_m: 0.6927 - recall_m: 0.2547 - f1_m: 0.3545 - val_loss: 0.0959 - val_acc: 0.9654 - val_precision_m: 0.5991 - val_recall_m: 0.1782 - val_f1_m: 0.2584\n",
      "Epoch 23/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.0880 - acc: 0.9695 - precision_m: 0.6813 - recall_m: 0.2650 - f1_m: 0.3624\n",
      "Epoch 23: val_acc did not improve from 0.96589\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0880 - acc: 0.9695 - precision_m: 0.6813 - recall_m: 0.2650 - f1_m: 0.3624 - val_loss: 0.0958 - val_acc: 0.9658 - val_precision_m: 0.6554 - val_recall_m: 0.2089 - val_f1_m: 0.2952\n",
      "Epoch 24/30\n",
      "275/292 [===========================>..] - ETA: 0s - loss: 0.0868 - acc: 0.9696 - precision_m: 0.6922 - recall_m: 0.2676 - f1_m: 0.3668\n",
      "Epoch 24: val_acc improved from 0.96589 to 0.96601, saving model to models/best_model_5_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0873 - acc: 0.9694 - precision_m: 0.6902 - recall_m: 0.2643 - f1_m: 0.3634 - val_loss: 0.0946 - val_acc: 0.9660 - val_precision_m: 0.6284 - val_recall_m: 0.2352 - val_f1_m: 0.3166\n",
      "Epoch 25/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.0865 - acc: 0.9699 - precision_m: 0.6753 - recall_m: 0.2812 - f1_m: 0.3779\n",
      "Epoch 25: val_acc improved from 0.96601 to 0.96686, saving model to models/best_model_5_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0866 - acc: 0.9699 - precision_m: 0.6765 - recall_m: 0.2815 - f1_m: 0.3786 - val_loss: 0.0943 - val_acc: 0.9669 - val_precision_m: 0.6693 - val_recall_m: 0.2586 - val_f1_m: 0.3465\n",
      "Epoch 26/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.0863 - acc: 0.9698 - precision_m: 0.6923 - recall_m: 0.2888 - f1_m: 0.3875\n",
      "Epoch 26: val_acc did not improve from 0.96686\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0860 - acc: 0.9700 - precision_m: 0.7013 - recall_m: 0.2889 - f1_m: 0.3893 - val_loss: 0.0937 - val_acc: 0.9659 - val_precision_m: 0.6372 - val_recall_m: 0.2316 - val_f1_m: 0.3078\n",
      "Epoch 27/30\n",
      "273/292 [===========================>..] - ETA: 0s - loss: 0.0854 - acc: 0.9700 - precision_m: 0.6827 - recall_m: 0.2912 - f1_m: 0.3903\n",
      "Epoch 27: val_acc improved from 0.96686 to 0.96770, saving model to models/best_model_5_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0858 - acc: 0.9700 - precision_m: 0.6847 - recall_m: 0.2911 - f1_m: 0.3912 - val_loss: 0.0938 - val_acc: 0.9677 - val_precision_m: 0.6585 - val_recall_m: 0.2898 - val_f1_m: 0.3683\n",
      "Epoch 28/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0848 - acc: 0.9703 - precision_m: 0.6869 - recall_m: 0.3007 - f1_m: 0.3993\n",
      "Epoch 28: val_acc did not improve from 0.96770\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0850 - acc: 0.9703 - precision_m: 0.6902 - recall_m: 0.3005 - f1_m: 0.4001 - val_loss: 0.0930 - val_acc: 0.9670 - val_precision_m: 0.6511 - val_recall_m: 0.2759 - val_f1_m: 0.3503\n",
      "Epoch 29/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.0848 - acc: 0.9703 - precision_m: 0.6822 - recall_m: 0.3004 - f1_m: 0.3992\n",
      "Epoch 29: val_acc did not improve from 0.96770\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0848 - acc: 0.9703 - precision_m: 0.6857 - recall_m: 0.3003 - f1_m: 0.4000 - val_loss: 0.0926 - val_acc: 0.9675 - val_precision_m: 0.7002 - val_recall_m: 0.2487 - val_f1_m: 0.3413\n",
      "Epoch 30/30\n",
      "273/292 [===========================>..] - ETA: 0s - loss: 0.0847 - acc: 0.9705 - precision_m: 0.6948 - recall_m: 0.3121 - f1_m: 0.4105\n",
      "Epoch 30: val_acc improved from 0.96770 to 0.96939, saving model to models/best_model_5_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0843 - acc: 0.9707 - precision_m: 0.7058 - recall_m: 0.3135 - f1_m: 0.4135 - val_loss: 0.0916 - val_acc: 0.9694 - val_precision_m: 0.7100 - val_recall_m: 0.3509 - val_f1_m: 0.4306\n",
      "Score for fold 6: loss of 0.09162186086177826; acc of 96.93865180015564%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.09857107698917389; acc of 96.81140780448914%\n",
      "Test Precision: precision_m of 17.505787312984467%\n",
      "Test Recall: recall_m of 13.265268504619598%\n",
      "Test F1: f1_m of 14.196151494979858%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2195 - acc: 0.9273 - precision_m: 0.0169 - recall_m: 0.0276 - f1_m: 0.0125\n",
      "Epoch 1: val_acc improved from -inf to 0.96249, saving model to models/best_model_5_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 2s 3ms/step - loss: 0.2195 - acc: 0.9273 - precision_m: 0.0169 - recall_m: 0.0276 - f1_m: 0.0125 - val_loss: 0.1438 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "274/292 [===========================>..] - ETA: 0s - loss: 0.1339 - acc: 0.9633 - precision_m: 0.0292 - recall_m: 0.0033 - f1_m: 0.0059   \n",
      "Epoch 2: val_acc improved from 0.96249 to 0.96260, saving model to models/best_model_5_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1343 - acc: 0.9631 - precision_m: 0.0308 - recall_m: 0.0035 - f1_m: 0.0062 - val_loss: 0.1319 - val_acc: 0.9626 - val_precision_m: 0.0606 - val_recall_m: 0.0069 - val_f1_m: 0.0122\n",
      "Epoch 3/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.1282 - acc: 0.9632 - precision_m: 0.1293 - recall_m: 0.0152 - f1_m: 0.0269\n",
      "Epoch 3: val_acc improved from 0.96260 to 0.96296, saving model to models/best_model_5_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1281 - acc: 0.9632 - precision_m: 0.1284 - recall_m: 0.0151 - f1_m: 0.0267 - val_loss: 0.1277 - val_acc: 0.9630 - val_precision_m: 0.1212 - val_recall_m: 0.0120 - val_f1_m: 0.0216\n",
      "Epoch 4/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1241 - acc: 0.9631 - precision_m: 0.1450 - recall_m: 0.0194 - f1_m: 0.0335\n",
      "Epoch 4: val_acc improved from 0.96296 to 0.96320, saving model to models/best_model_5_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1241 - acc: 0.9631 - precision_m: 0.1450 - recall_m: 0.0194 - f1_m: 0.0335 - val_loss: 0.1231 - val_acc: 0.9632 - val_precision_m: 0.1414 - val_recall_m: 0.0172 - val_f1_m: 0.0301\n",
      "Epoch 5/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.1194 - acc: 0.9632 - precision_m: 0.2300 - recall_m: 0.0304 - f1_m: 0.0523\n",
      "Epoch 5: val_acc improved from 0.96320 to 0.96356, saving model to models/best_model_5_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1196 - acc: 0.9632 - precision_m: 0.2197 - recall_m: 0.0290 - f1_m: 0.0500 - val_loss: 0.1187 - val_acc: 0.9636 - val_precision_m: 0.2020 - val_recall_m: 0.0275 - val_f1_m: 0.0477\n",
      "Epoch 6/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.1158 - acc: 0.9638 - precision_m: 0.3001 - recall_m: 0.0407 - f1_m: 0.0701\n",
      "Epoch 6: val_acc improved from 0.96356 to 0.96392, saving model to models/best_model_5_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1160 - acc: 0.9637 - precision_m: 0.3014 - recall_m: 0.0412 - f1_m: 0.0709 - val_loss: 0.1153 - val_acc: 0.9639 - val_precision_m: 0.2500 - val_recall_m: 0.0398 - val_f1_m: 0.0673\n",
      "Epoch 7/30\n",
      "273/292 [===========================>..] - ETA: 0s - loss: 0.1131 - acc: 0.9639 - precision_m: 0.3907 - recall_m: 0.0617 - f1_m: 0.1017\n",
      "Epoch 7: val_acc did not improve from 0.96392\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1128 - acc: 0.9642 - precision_m: 0.3938 - recall_m: 0.0634 - f1_m: 0.1040 - val_loss: 0.1129 - val_acc: 0.9639 - val_precision_m: 0.2424 - val_recall_m: 0.0319 - val_f1_m: 0.0557\n",
      "Epoch 8/30\n",
      "275/292 [===========================>..] - ETA: 0s - loss: 0.1097 - acc: 0.9641 - precision_m: 0.4177 - recall_m: 0.0718 - f1_m: 0.1172\n",
      "Epoch 8: val_acc improved from 0.96392 to 0.96440, saving model to models/best_model_5_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1096 - acc: 0.9642 - precision_m: 0.4157 - recall_m: 0.0716 - f1_m: 0.1166 - val_loss: 0.1085 - val_acc: 0.9644 - val_precision_m: 0.3460 - val_recall_m: 0.0692 - val_f1_m: 0.1084\n",
      "Epoch 9/30\n",
      "273/292 [===========================>..] - ETA: 0s - loss: 0.1067 - acc: 0.9652 - precision_m: 0.4568 - recall_m: 0.0930 - f1_m: 0.1473\n",
      "Epoch 9: val_acc improved from 0.96440 to 0.96583, saving model to models/best_model_5_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1068 - acc: 0.9650 - precision_m: 0.4611 - recall_m: 0.0929 - f1_m: 0.1474 - val_loss: 0.1053 - val_acc: 0.9658 - val_precision_m: 0.4823 - val_recall_m: 0.1085 - val_f1_m: 0.1648\n",
      "Epoch 10/30\n",
      "275/292 [===========================>..] - ETA: 0s - loss: 0.1038 - acc: 0.9654 - precision_m: 0.5496 - recall_m: 0.1149 - f1_m: 0.1811\n",
      "Epoch 10: val_acc improved from 0.96583 to 0.96726, saving model to models/best_model_5_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1041 - acc: 0.9654 - precision_m: 0.5525 - recall_m: 0.1143 - f1_m: 0.1808 - val_loss: 0.1031 - val_acc: 0.9673 - val_precision_m: 0.6214 - val_recall_m: 0.1777 - val_f1_m: 0.2589\n",
      "Epoch 11/30\n",
      "275/292 [===========================>..] - ETA: 0s - loss: 0.1011 - acc: 0.9660 - precision_m: 0.5954 - recall_m: 0.1318 - f1_m: 0.2064\n",
      "Epoch 11: val_acc did not improve from 0.96726\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1015 - acc: 0.9660 - precision_m: 0.6036 - recall_m: 0.1370 - f1_m: 0.2137 - val_loss: 0.1008 - val_acc: 0.9659 - val_precision_m: 0.4823 - val_recall_m: 0.1187 - val_f1_m: 0.1796\n",
      "Epoch 12/30\n",
      "273/292 [===========================>..] - ETA: 0s - loss: 0.0997 - acc: 0.9659 - precision_m: 0.5977 - recall_m: 0.1453 - f1_m: 0.2223\n",
      "Epoch 12: val_acc did not improve from 0.96726\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0997 - acc: 0.9660 - precision_m: 0.6056 - recall_m: 0.1496 - f1_m: 0.2278 - val_loss: 0.0990 - val_acc: 0.9673 - val_precision_m: 0.5867 - val_recall_m: 0.1748 - val_f1_m: 0.2519\n",
      "Epoch 13/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0972 - acc: 0.9669 - precision_m: 0.6355 - recall_m: 0.1681 - f1_m: 0.2544\n",
      "Epoch 13: val_acc did not improve from 0.96726\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0974 - acc: 0.9668 - precision_m: 0.6312 - recall_m: 0.1669 - f1_m: 0.2527 - val_loss: 0.0963 - val_acc: 0.9671 - val_precision_m: 0.5332 - val_recall_m: 0.1396 - val_f1_m: 0.2078\n",
      "Epoch 14/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0953 - acc: 0.9676 - precision_m: 0.6787 - recall_m: 0.1957 - f1_m: 0.2882\n",
      "Epoch 14: val_acc improved from 0.96726 to 0.96762, saving model to models/best_model_5_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0951 - acc: 0.9676 - precision_m: 0.6719 - recall_m: 0.1963 - f1_m: 0.2884 - val_loss: 0.0946 - val_acc: 0.9676 - val_precision_m: 0.5404 - val_recall_m: 0.1418 - val_f1_m: 0.2139\n",
      "Epoch 15/30\n",
      "272/292 [==========================>...] - ETA: 0s - loss: 0.0930 - acc: 0.9679 - precision_m: 0.6682 - recall_m: 0.2074 - f1_m: 0.3005\n",
      "Epoch 15: val_acc improved from 0.96762 to 0.96906, saving model to models/best_model_5_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0935 - acc: 0.9677 - precision_m: 0.6749 - recall_m: 0.2058 - f1_m: 0.2994 - val_loss: 0.0940 - val_acc: 0.9691 - val_precision_m: 0.5986 - val_recall_m: 0.2667 - val_f1_m: 0.3489\n",
      "Epoch 16/30\n",
      "275/292 [===========================>..] - ETA: 0s - loss: 0.0921 - acc: 0.9679 - precision_m: 0.6803 - recall_m: 0.2197 - f1_m: 0.3136\n",
      "Epoch 16: val_acc did not improve from 0.96906\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0922 - acc: 0.9679 - precision_m: 0.6787 - recall_m: 0.2215 - f1_m: 0.3159 - val_loss: 0.0915 - val_acc: 0.9691 - val_precision_m: 0.5966 - val_recall_m: 0.2547 - val_f1_m: 0.3352\n",
      "Epoch 17/30\n",
      "272/292 [==========================>...] - ETA: 0s - loss: 0.0912 - acc: 0.9684 - precision_m: 0.6811 - recall_m: 0.2379 - f1_m: 0.3360\n",
      "Epoch 17: val_acc did not improve from 0.96906\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0913 - acc: 0.9684 - precision_m: 0.6803 - recall_m: 0.2375 - f1_m: 0.3354 - val_loss: 0.0915 - val_acc: 0.9689 - val_precision_m: 0.5975 - val_recall_m: 0.1914 - val_f1_m: 0.2747\n",
      "Epoch 18/30\n",
      "272/292 [==========================>...] - ETA: 0s - loss: 0.0908 - acc: 0.9682 - precision_m: 0.6807 - recall_m: 0.2455 - f1_m: 0.3449\n",
      "Epoch 18: val_acc did not improve from 0.96906\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0901 - acc: 0.9686 - precision_m: 0.6891 - recall_m: 0.2491 - f1_m: 0.3494 - val_loss: 0.0919 - val_acc: 0.9682 - val_precision_m: 0.5680 - val_recall_m: 0.1944 - val_f1_m: 0.2741\n",
      "Epoch 19/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0897 - acc: 0.9686 - precision_m: 0.6789 - recall_m: 0.2532 - f1_m: 0.3525\n",
      "Epoch 19: val_acc improved from 0.96906 to 0.97013, saving model to models/best_model_5_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0896 - acc: 0.9686 - precision_m: 0.6798 - recall_m: 0.2540 - f1_m: 0.3537 - val_loss: 0.0899 - val_acc: 0.9701 - val_precision_m: 0.6478 - val_recall_m: 0.2724 - val_f1_m: 0.3670\n",
      "Epoch 20/30\n",
      "273/292 [===========================>..] - ETA: 0s - loss: 0.0887 - acc: 0.9687 - precision_m: 0.6761 - recall_m: 0.2687 - f1_m: 0.3655\n",
      "Epoch 20: val_acc did not improve from 0.97013\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0884 - acc: 0.9689 - precision_m: 0.6770 - recall_m: 0.2706 - f1_m: 0.3675 - val_loss: 0.0893 - val_acc: 0.9694 - val_precision_m: 0.6020 - val_recall_m: 0.2496 - val_f1_m: 0.3307\n",
      "Epoch 21/30\n",
      "274/292 [===========================>..] - ETA: 0s - loss: 0.0873 - acc: 0.9690 - precision_m: 0.6931 - recall_m: 0.2716 - f1_m: 0.3691\n",
      "Epoch 21: val_acc did not improve from 0.97013\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0877 - acc: 0.9689 - precision_m: 0.6834 - recall_m: 0.2712 - f1_m: 0.3676 - val_loss: 0.0894 - val_acc: 0.9691 - val_precision_m: 0.6697 - val_recall_m: 0.2107 - val_f1_m: 0.3070\n",
      "Epoch 22/30\n",
      "274/292 [===========================>..] - ETA: 0s - loss: 0.0874 - acc: 0.9691 - precision_m: 0.6716 - recall_m: 0.2772 - f1_m: 0.3705\n",
      "Epoch 22: val_acc did not improve from 0.97013\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0873 - acc: 0.9691 - precision_m: 0.6715 - recall_m: 0.2767 - f1_m: 0.3707 - val_loss: 0.0892 - val_acc: 0.9685 - val_precision_m: 0.6189 - val_recall_m: 0.2420 - val_f1_m: 0.3267\n",
      "Epoch 23/30\n",
      "274/292 [===========================>..] - ETA: 0s - loss: 0.0870 - acc: 0.9691 - precision_m: 0.7034 - recall_m: 0.2918 - f1_m: 0.3889\n",
      "Epoch 23: val_acc did not improve from 0.97013\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0865 - acc: 0.9693 - precision_m: 0.7009 - recall_m: 0.2908 - f1_m: 0.3880 - val_loss: 0.0881 - val_acc: 0.9698 - val_precision_m: 0.6090 - val_recall_m: 0.2823 - val_f1_m: 0.3628\n",
      "Epoch 24/30\n",
      "273/292 [===========================>..] - ETA: 0s - loss: 0.0858 - acc: 0.9697 - precision_m: 0.7068 - recall_m: 0.3072 - f1_m: 0.4078\n",
      "Epoch 24: val_acc did not improve from 0.97013\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0861 - acc: 0.9696 - precision_m: 0.7049 - recall_m: 0.3077 - f1_m: 0.4085 - val_loss: 0.0874 - val_acc: 0.9694 - val_precision_m: 0.5830 - val_recall_m: 0.3005 - val_f1_m: 0.3774\n",
      "Epoch 25/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.0855 - acc: 0.9698 - precision_m: 0.6954 - recall_m: 0.3022 - f1_m: 0.3996\n",
      "Epoch 25: val_acc did not improve from 0.97013\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0856 - acc: 0.9698 - precision_m: 0.6964 - recall_m: 0.3018 - f1_m: 0.3992 - val_loss: 0.0871 - val_acc: 0.9700 - val_precision_m: 0.6188 - val_recall_m: 0.2817 - val_f1_m: 0.3624\n",
      "Epoch 26/30\n",
      "274/292 [===========================>..] - ETA: 0s - loss: 0.0846 - acc: 0.9700 - precision_m: 0.7051 - recall_m: 0.3089 - f1_m: 0.4106\n",
      "Epoch 26: val_acc did not improve from 0.97013\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0849 - acc: 0.9699 - precision_m: 0.7030 - recall_m: 0.3083 - f1_m: 0.4100 - val_loss: 0.0868 - val_acc: 0.9694 - val_precision_m: 0.5618 - val_recall_m: 0.3010 - val_f1_m: 0.3686\n",
      "Epoch 27/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0844 - acc: 0.9699 - precision_m: 0.6906 - recall_m: 0.3131 - f1_m: 0.4155\n",
      "Epoch 27: val_acc did not improve from 0.97013\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0844 - acc: 0.9700 - precision_m: 0.6898 - recall_m: 0.3131 - f1_m: 0.4156 - val_loss: 0.0864 - val_acc: 0.9698 - val_precision_m: 0.6237 - val_recall_m: 0.2628 - val_f1_m: 0.3415\n",
      "Epoch 28/30\n",
      "272/292 [==========================>...] - ETA: 0s - loss: 0.0838 - acc: 0.9702 - precision_m: 0.6985 - recall_m: 0.3125 - f1_m: 0.4116\n",
      "Epoch 28: val_acc did not improve from 0.97013\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0842 - acc: 0.9699 - precision_m: 0.6937 - recall_m: 0.3115 - f1_m: 0.4104 - val_loss: 0.0868 - val_acc: 0.9698 - val_precision_m: 0.6090 - val_recall_m: 0.3452 - val_f1_m: 0.4142\n",
      "Epoch 29/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0835 - acc: 0.9703 - precision_m: 0.6970 - recall_m: 0.3301 - f1_m: 0.4290\n",
      "Epoch 29: val_acc improved from 0.97013 to 0.97025, saving model to models/best_model_5_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0836 - acc: 0.9702 - precision_m: 0.6964 - recall_m: 0.3308 - f1_m: 0.4296 - val_loss: 0.0874 - val_acc: 0.9703 - val_precision_m: 0.6113 - val_recall_m: 0.3858 - val_f1_m: 0.4418\n",
      "Epoch 30/30\n",
      "274/292 [===========================>..] - ETA: 0s - loss: 0.0830 - acc: 0.9704 - precision_m: 0.7222 - recall_m: 0.3349 - f1_m: 0.4371\n",
      "Epoch 30: val_acc improved from 0.97025 to 0.97049, saving model to models/best_model_5_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0835 - acc: 0.9702 - precision_m: 0.7200 - recall_m: 0.3325 - f1_m: 0.4347 - val_loss: 0.0851 - val_acc: 0.9705 - val_precision_m: 0.5811 - val_recall_m: 0.3513 - val_f1_m: 0.4175\n",
      "Score for fold 7: loss of 0.0850900262594223; acc of 97.04898595809937%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.07921290397644043; acc of 97.4003255367279%\n",
      "Test Precision: precision_m of 14.526300132274628%\n",
      "Test Recall: recall_m of 10.222333669662476%\n",
      "Test F1: f1_m of 11.365946382284164%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1901 - acc: 0.9476 - precision_m: 0.0259 - recall_m: 0.0191 - f1_m: 0.0147\n",
      "Epoch 1: val_acc improved from -inf to 0.96299, saving model to models/best_model_5_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 2s 3ms/step - loss: 0.1901 - acc: 0.9476 - precision_m: 0.0259 - recall_m: 0.0191 - f1_m: 0.0147 - val_loss: 0.1383 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "272/292 [==========================>...] - ETA: 0s - loss: 0.1329 - acc: 0.9632 - precision_m: 0.0821 - recall_m: 0.0088 - f1_m: 0.0158 \n",
      "Epoch 2: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1314 - acc: 0.9635 - precision_m: 0.0765 - recall_m: 0.0082 - f1_m: 0.0147 - val_loss: 0.1297 - val_acc: 0.9630 - val_precision_m: 0.0303 - val_recall_m: 0.0022 - val_f1_m: 0.0040\n",
      "Epoch 3/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1263 - acc: 0.9637 - precision_m: 0.1544 - recall_m: 0.0214 - f1_m: 0.0365\n",
      "Epoch 3: val_acc improved from 0.96299 to 0.96346, saving model to models/best_model_5_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1263 - acc: 0.9637 - precision_m: 0.1544 - recall_m: 0.0214 - f1_m: 0.0365 - val_loss: 0.1267 - val_acc: 0.9635 - val_precision_m: 0.0909 - val_recall_m: 0.0087 - val_f1_m: 0.0158\n",
      "Epoch 4/30\n",
      "275/292 [===========================>..] - ETA: 0s - loss: 0.1226 - acc: 0.9641 - precision_m: 0.2542 - recall_m: 0.0344 - f1_m: 0.0594\n",
      "Epoch 4: val_acc did not improve from 0.96346\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1232 - acc: 0.9639 - precision_m: 0.2566 - recall_m: 0.0353 - f1_m: 0.0606 - val_loss: 0.1236 - val_acc: 0.9632 - val_precision_m: 0.1667 - val_recall_m: 0.0213 - val_f1_m: 0.0367\n",
      "Epoch 5/30\n",
      "275/292 [===========================>..] - ETA: 0s - loss: 0.1212 - acc: 0.9638 - precision_m: 0.3048 - recall_m: 0.0483 - f1_m: 0.0798\n",
      "Epoch 5: val_acc did not improve from 0.96346\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1205 - acc: 0.9640 - precision_m: 0.2968 - recall_m: 0.0473 - f1_m: 0.0781 - val_loss: 0.1200 - val_acc: 0.9633 - val_precision_m: 0.1010 - val_recall_m: 0.0145 - val_f1_m: 0.0250\n",
      "Epoch 6/30\n",
      "273/292 [===========================>..] - ETA: 0s - loss: 0.1178 - acc: 0.9638 - precision_m: 0.3233 - recall_m: 0.0483 - f1_m: 0.0814\n",
      "Epoch 6: val_acc did not improve from 0.96346\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1169 - acc: 0.9641 - precision_m: 0.3245 - recall_m: 0.0480 - f1_m: 0.0811 - val_loss: 0.1172 - val_acc: 0.9633 - val_precision_m: 0.1162 - val_recall_m: 0.0170 - val_f1_m: 0.0293\n",
      "Epoch 7/30\n",
      "275/292 [===========================>..] - ETA: 0s - loss: 0.1151 - acc: 0.9640 - precision_m: 0.3945 - recall_m: 0.0607 - f1_m: 0.1021\n",
      "Epoch 7: val_acc did not improve from 0.96346\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1141 - acc: 0.9644 - precision_m: 0.3944 - recall_m: 0.0620 - f1_m: 0.1037 - val_loss: 0.1124 - val_acc: 0.9633 - val_precision_m: 0.1778 - val_recall_m: 0.0293 - val_f1_m: 0.0478\n",
      "Epoch 8/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.1111 - acc: 0.9651 - precision_m: 0.4613 - recall_m: 0.0829 - f1_m: 0.1335\n",
      "Epoch 8: val_acc improved from 0.96346 to 0.96382, saving model to models/best_model_5_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1111 - acc: 0.9651 - precision_m: 0.4572 - recall_m: 0.0822 - f1_m: 0.1325 - val_loss: 0.1090 - val_acc: 0.9638 - val_precision_m: 0.2081 - val_recall_m: 0.0471 - val_f1_m: 0.0710\n",
      "Epoch 9/30\n",
      "273/292 [===========================>..] - ETA: 0s - loss: 0.1085 - acc: 0.9654 - precision_m: 0.4763 - recall_m: 0.0949 - f1_m: 0.1513\n",
      "Epoch 9: val_acc improved from 0.96382 to 0.96466, saving model to models/best_model_5_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1085 - acc: 0.9653 - precision_m: 0.4784 - recall_m: 0.0941 - f1_m: 0.1504 - val_loss: 0.1066 - val_acc: 0.9647 - val_precision_m: 0.2861 - val_recall_m: 0.0744 - val_f1_m: 0.1102\n",
      "Epoch 10/30\n",
      "274/292 [===========================>..] - ETA: 0s - loss: 0.1065 - acc: 0.9656 - precision_m: 0.5249 - recall_m: 0.1103 - f1_m: 0.1747\n",
      "Epoch 10: val_acc did not improve from 0.96466\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1060 - acc: 0.9658 - precision_m: 0.5265 - recall_m: 0.1114 - f1_m: 0.1763 - val_loss: 0.1042 - val_acc: 0.9642 - val_precision_m: 0.2687 - val_recall_m: 0.0528 - val_f1_m: 0.0831\n",
      "Epoch 11/30\n",
      "272/292 [==========================>...] - ETA: 0s - loss: 0.1046 - acc: 0.9660 - precision_m: 0.5392 - recall_m: 0.1229 - f1_m: 0.1925\n",
      "Epoch 11: val_acc improved from 0.96466 to 0.96526, saving model to models/best_model_5_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1038 - acc: 0.9662 - precision_m: 0.5455 - recall_m: 0.1242 - f1_m: 0.1943 - val_loss: 0.1022 - val_acc: 0.9653 - val_precision_m: 0.2990 - val_recall_m: 0.0786 - val_f1_m: 0.1167\n",
      "Epoch 12/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1021 - acc: 0.9663 - precision_m: 0.5583 - recall_m: 0.1427 - f1_m: 0.2158\n",
      "Epoch 12: val_acc improved from 0.96526 to 0.96598, saving model to models/best_model_5_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1021 - acc: 0.9663 - precision_m: 0.5583 - recall_m: 0.1427 - f1_m: 0.2158 - val_loss: 0.1004 - val_acc: 0.9660 - val_precision_m: 0.3419 - val_recall_m: 0.0948 - val_f1_m: 0.1406\n",
      "Epoch 13/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.1000 - acc: 0.9668 - precision_m: 0.6132 - recall_m: 0.1596 - f1_m: 0.2381\n",
      "Epoch 13: val_acc did not improve from 0.96598\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1001 - acc: 0.9669 - precision_m: 0.6081 - recall_m: 0.1564 - f1_m: 0.2341 - val_loss: 0.0993 - val_acc: 0.9659 - val_precision_m: 0.3434 - val_recall_m: 0.0940 - val_f1_m: 0.1377\n",
      "Epoch 14/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0986 - acc: 0.9671 - precision_m: 0.6193 - recall_m: 0.1684 - f1_m: 0.2512\n",
      "Epoch 14: val_acc improved from 0.96598 to 0.96742, saving model to models/best_model_5_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0986 - acc: 0.9671 - precision_m: 0.6202 - recall_m: 0.1692 - f1_m: 0.2523 - val_loss: 0.0972 - val_acc: 0.9674 - val_precision_m: 0.4826 - val_recall_m: 0.1533 - val_f1_m: 0.2173\n",
      "Epoch 15/30\n",
      "273/292 [===========================>..] - ETA: 0s - loss: 0.0973 - acc: 0.9676 - precision_m: 0.6249 - recall_m: 0.1931 - f1_m: 0.2791\n",
      "Epoch 15: val_acc improved from 0.96742 to 0.96802, saving model to models/best_model_5_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0975 - acc: 0.9674 - precision_m: 0.6239 - recall_m: 0.1917 - f1_m: 0.2769 - val_loss: 0.0951 - val_acc: 0.9680 - val_precision_m: 0.5445 - val_recall_m: 0.1696 - val_f1_m: 0.2379\n",
      "Epoch 16/30\n",
      "273/292 [===========================>..] - ETA: 0s - loss: 0.0955 - acc: 0.9678 - precision_m: 0.6606 - recall_m: 0.1995 - f1_m: 0.2941\n",
      "Epoch 16: val_acc did not improve from 0.96802\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0962 - acc: 0.9676 - precision_m: 0.6564 - recall_m: 0.2008 - f1_m: 0.2950 - val_loss: 0.0973 - val_acc: 0.9661 - val_precision_m: 0.3182 - val_recall_m: 0.0874 - val_f1_m: 0.1301\n",
      "Epoch 17/30\n",
      "272/292 [==========================>...] - ETA: 0s - loss: 0.0946 - acc: 0.9678 - precision_m: 0.6465 - recall_m: 0.2007 - f1_m: 0.2908\n",
      "Epoch 17: val_acc improved from 0.96802 to 0.96921, saving model to models/best_model_5_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0949 - acc: 0.9676 - precision_m: 0.6460 - recall_m: 0.2002 - f1_m: 0.2901 - val_loss: 0.0961 - val_acc: 0.9692 - val_precision_m: 0.5926 - val_recall_m: 0.2813 - val_f1_m: 0.3549\n",
      "Epoch 18/30\n",
      "275/292 [===========================>..] - ETA: 0s - loss: 0.0946 - acc: 0.9679 - precision_m: 0.6531 - recall_m: 0.2223 - f1_m: 0.3160\n",
      "Epoch 18: val_acc did not improve from 0.96921\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0939 - acc: 0.9682 - precision_m: 0.6572 - recall_m: 0.2247 - f1_m: 0.3190 - val_loss: 0.0935 - val_acc: 0.9677 - val_precision_m: 0.5011 - val_recall_m: 0.1522 - val_f1_m: 0.2186\n",
      "Epoch 19/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.0926 - acc: 0.9683 - precision_m: 0.6681 - recall_m: 0.2341 - f1_m: 0.3283\n",
      "Epoch 19: val_acc did not improve from 0.96921\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0926 - acc: 0.9683 - precision_m: 0.6681 - recall_m: 0.2341 - f1_m: 0.3283 - val_loss: 0.0931 - val_acc: 0.9679 - val_precision_m: 0.5341 - val_recall_m: 0.1507 - val_f1_m: 0.2211\n",
      "Epoch 20/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.0917 - acc: 0.9685 - precision_m: 0.6785 - recall_m: 0.2350 - f1_m: 0.3311\n",
      "Epoch 20: val_acc did not improve from 0.96921\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0917 - acc: 0.9686 - precision_m: 0.6836 - recall_m: 0.2350 - f1_m: 0.3317 - val_loss: 0.0921 - val_acc: 0.9686 - val_precision_m: 0.5963 - val_recall_m: 0.2125 - val_f1_m: 0.2916\n",
      "Epoch 21/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0912 - acc: 0.9687 - precision_m: 0.6810 - recall_m: 0.2529 - f1_m: 0.3514\n",
      "Epoch 21: val_acc did not improve from 0.96921\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0909 - acc: 0.9688 - precision_m: 0.6775 - recall_m: 0.2513 - f1_m: 0.3493 - val_loss: 0.0905 - val_acc: 0.9686 - val_precision_m: 0.5618 - val_recall_m: 0.1833 - val_f1_m: 0.2550\n",
      "Epoch 22/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.0899 - acc: 0.9690 - precision_m: 0.7054 - recall_m: 0.2642 - f1_m: 0.3646\n",
      "Epoch 22: val_acc improved from 0.96921 to 0.97017, saving model to models/best_model_5_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0899 - acc: 0.9690 - precision_m: 0.7054 - recall_m: 0.2642 - f1_m: 0.3646 - val_loss: 0.0895 - val_acc: 0.9702 - val_precision_m: 0.6474 - val_recall_m: 0.2970 - val_f1_m: 0.3751\n",
      "Epoch 23/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.0886 - acc: 0.9694 - precision_m: 0.6811 - recall_m: 0.2702 - f1_m: 0.3673\n",
      "Epoch 23: val_acc improved from 0.97017 to 0.97029, saving model to models/best_model_5_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0886 - acc: 0.9694 - precision_m: 0.6811 - recall_m: 0.2702 - f1_m: 0.3673 - val_loss: 0.0898 - val_acc: 0.9703 - val_precision_m: 0.6364 - val_recall_m: 0.3063 - val_f1_m: 0.3885\n",
      "Epoch 24/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.0875 - acc: 0.9697 - precision_m: 0.7033 - recall_m: 0.2828 - f1_m: 0.3845\n",
      "Epoch 24: val_acc did not improve from 0.97029\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0874 - acc: 0.9697 - precision_m: 0.7026 - recall_m: 0.2830 - f1_m: 0.3845 - val_loss: 0.0894 - val_acc: 0.9697 - val_precision_m: 0.5857 - val_recall_m: 0.2717 - val_f1_m: 0.3487\n",
      "Epoch 25/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.0861 - acc: 0.9699 - precision_m: 0.7115 - recall_m: 0.2968 - f1_m: 0.3966\n",
      "Epoch 25: val_acc did not improve from 0.97029\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0861 - acc: 0.9700 - precision_m: 0.7125 - recall_m: 0.2966 - f1_m: 0.3966 - val_loss: 0.0886 - val_acc: 0.9691 - val_precision_m: 0.6129 - val_recall_m: 0.2365 - val_f1_m: 0.3159\n",
      "Epoch 26/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.0850 - acc: 0.9706 - precision_m: 0.7004 - recall_m: 0.3087 - f1_m: 0.4109\n",
      "Epoch 26: val_acc did not improve from 0.97029\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0853 - acc: 0.9705 - precision_m: 0.6997 - recall_m: 0.3078 - f1_m: 0.4100 - val_loss: 0.0883 - val_acc: 0.9699 - val_precision_m: 0.6465 - val_recall_m: 0.2451 - val_f1_m: 0.3343\n",
      "Epoch 27/30\n",
      "274/292 [===========================>..] - ETA: 0s - loss: 0.0836 - acc: 0.9708 - precision_m: 0.7174 - recall_m: 0.3184 - f1_m: 0.4188\n",
      "Epoch 27: val_acc did not improve from 0.97029\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0843 - acc: 0.9705 - precision_m: 0.7176 - recall_m: 0.3164 - f1_m: 0.4168 - val_loss: 0.0875 - val_acc: 0.9702 - val_precision_m: 0.6044 - val_recall_m: 0.2997 - val_f1_m: 0.3807\n",
      "Epoch 28/30\n",
      "274/292 [===========================>..] - ETA: 0s - loss: 0.0839 - acc: 0.9705 - precision_m: 0.7111 - recall_m: 0.3158 - f1_m: 0.4169\n",
      "Epoch 28: val_acc improved from 0.97029 to 0.97053, saving model to models/best_model_5_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0839 - acc: 0.9705 - precision_m: 0.7119 - recall_m: 0.3158 - f1_m: 0.4166 - val_loss: 0.0862 - val_acc: 0.9705 - val_precision_m: 0.6336 - val_recall_m: 0.2965 - val_f1_m: 0.3813\n",
      "Epoch 29/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.0835 - acc: 0.9707 - precision_m: 0.7316 - recall_m: 0.3300 - f1_m: 0.4307\n",
      "Epoch 29: val_acc improved from 0.97053 to 0.97077, saving model to models/best_model_5_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0835 - acc: 0.9707 - precision_m: 0.7316 - recall_m: 0.3300 - f1_m: 0.4307 - val_loss: 0.0859 - val_acc: 0.9708 - val_precision_m: 0.6569 - val_recall_m: 0.2833 - val_f1_m: 0.3716\n",
      "Epoch 30/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0827 - acc: 0.9709 - precision_m: 0.7254 - recall_m: 0.3280 - f1_m: 0.4312\n",
      "Epoch 30: val_acc improved from 0.97077 to 0.97113, saving model to models/best_model_5_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0827 - acc: 0.9709 - precision_m: 0.7248 - recall_m: 0.3282 - f1_m: 0.4313 - val_loss: 0.0848 - val_acc: 0.9711 - val_precision_m: 0.6514 - val_recall_m: 0.2997 - val_f1_m: 0.3873\n",
      "Score for fold 8: loss of 0.08476274460554123; acc of 97.11307883262634%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.08674927800893784; acc of 96.84699773788452%\n",
      "Test Precision: precision_m of 14.899882674217224%\n",
      "Test Recall: recall_m of 8.67929682135582%\n",
      "Test F1: f1_m of 10.246377438306808%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "Epoch 1/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.1845 - acc: 0.9503 - precision_m: 0.0118 - recall_m: 0.0169 - f1_m: 0.0102\n",
      "Epoch 1: val_acc improved from -inf to 0.96163, saving model to models/best_model_5_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 2s 4ms/step - loss: 0.1845 - acc: 0.9503 - precision_m: 0.0118 - recall_m: 0.0169 - f1_m: 0.0102 - val_loss: 0.1415 - val_acc: 0.9616 - val_precision_m: 0.0303 - val_recall_m: 0.0022 - val_f1_m: 0.0040\n",
      "Epoch 2/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1314 - acc: 0.9642 - precision_m: 0.0421 - recall_m: 0.0047 - f1_m: 0.0083\n",
      "Epoch 2: val_acc did not improve from 0.96163\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1313 - acc: 0.9643 - precision_m: 0.0418 - recall_m: 0.0047 - f1_m: 0.0083 - val_loss: 0.1336 - val_acc: 0.9616 - val_precision_m: 0.0303 - val_recall_m: 0.0022 - val_f1_m: 0.0040\n",
      "Epoch 3/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1262 - acc: 0.9644 - precision_m: 0.1211 - recall_m: 0.0143 - f1_m: 0.0253\n",
      "Epoch 3: val_acc improved from 0.96163 to 0.96211, saving model to models/best_model_5_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1264 - acc: 0.9643 - precision_m: 0.1203 - recall_m: 0.0142 - f1_m: 0.0251 - val_loss: 0.1294 - val_acc: 0.9621 - val_precision_m: 0.1212 - val_recall_m: 0.0136 - val_f1_m: 0.0240\n",
      "Epoch 4/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.1222 - acc: 0.9644 - precision_m: 0.1293 - recall_m: 0.0170 - f1_m: 0.0293\n",
      "Epoch 4: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1222 - acc: 0.9644 - precision_m: 0.1289 - recall_m: 0.0170 - f1_m: 0.0292 - val_loss: 0.1248 - val_acc: 0.9620 - val_precision_m: 0.1212 - val_recall_m: 0.0136 - val_f1_m: 0.0240\n",
      "Epoch 5/30\n",
      "272/291 [===========================>..] - ETA: 0s - loss: 0.1189 - acc: 0.9647 - precision_m: 0.1967 - recall_m: 0.0239 - f1_m: 0.0418\n",
      "Epoch 5: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1186 - acc: 0.9647 - precision_m: 0.2131 - recall_m: 0.0260 - f1_m: 0.0454 - val_loss: 0.1213 - val_acc: 0.9620 - val_precision_m: 0.1313 - val_recall_m: 0.0131 - val_f1_m: 0.0227\n",
      "Epoch 6/30\n",
      "273/291 [===========================>..] - ETA: 0s - loss: 0.1156 - acc: 0.9647 - precision_m: 0.2775 - recall_m: 0.0380 - f1_m: 0.0651\n",
      "Epoch 6: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1152 - acc: 0.9648 - precision_m: 0.2689 - recall_m: 0.0374 - f1_m: 0.0640 - val_loss: 0.1170 - val_acc: 0.9621 - val_precision_m: 0.1869 - val_recall_m: 0.0304 - val_f1_m: 0.0501\n",
      "Epoch 7/30\n",
      "271/291 [==========================>...] - ETA: 0s - loss: 0.1124 - acc: 0.9650 - precision_m: 0.3032 - recall_m: 0.0437 - f1_m: 0.0747\n",
      "Epoch 7: val_acc improved from 0.96211 to 0.96223, saving model to models/best_model_5_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1126 - acc: 0.9650 - precision_m: 0.3081 - recall_m: 0.0443 - f1_m: 0.0759 - val_loss: 0.1146 - val_acc: 0.9622 - val_precision_m: 0.1879 - val_recall_m: 0.0336 - val_f1_m: 0.0554\n",
      "Epoch 8/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.1096 - acc: 0.9652 - precision_m: 0.3597 - recall_m: 0.0574 - f1_m: 0.0954\n",
      "Epoch 8: val_acc improved from 0.96223 to 0.96330, saving model to models/best_model_5_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1096 - acc: 0.9651 - precision_m: 0.3628 - recall_m: 0.0580 - f1_m: 0.0965 - val_loss: 0.1115 - val_acc: 0.9633 - val_precision_m: 0.3525 - val_recall_m: 0.0715 - val_f1_m: 0.1093\n",
      "Epoch 9/30\n",
      "271/291 [==========================>...] - ETA: 0s - loss: 0.1072 - acc: 0.9651 - precision_m: 0.4050 - recall_m: 0.0701 - f1_m: 0.1148\n",
      "Epoch 9: val_acc did not improve from 0.96330\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1066 - acc: 0.9654 - precision_m: 0.4012 - recall_m: 0.0685 - f1_m: 0.1126 - val_loss: 0.1090 - val_acc: 0.9632 - val_precision_m: 0.3412 - val_recall_m: 0.0764 - val_f1_m: 0.1137\n",
      "Epoch 10/30\n",
      "273/291 [===========================>..] - ETA: 0s - loss: 0.1039 - acc: 0.9658 - precision_m: 0.4659 - recall_m: 0.0910 - f1_m: 0.1462\n",
      "Epoch 10: val_acc improved from 0.96330 to 0.96342, saving model to models/best_model_5_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1039 - acc: 0.9659 - precision_m: 0.4645 - recall_m: 0.0895 - f1_m: 0.1442 - val_loss: 0.1071 - val_acc: 0.9634 - val_precision_m: 0.3384 - val_recall_m: 0.0656 - val_f1_m: 0.1008\n",
      "Epoch 11/30\n",
      "272/291 [===========================>..] - ETA: 0s - loss: 0.1017 - acc: 0.9664 - precision_m: 0.5156 - recall_m: 0.1099 - f1_m: 0.1738\n",
      "Epoch 11: val_acc did not improve from 0.96342\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1016 - acc: 0.9664 - precision_m: 0.5114 - recall_m: 0.1097 - f1_m: 0.1730 - val_loss: 0.1070 - val_acc: 0.9631 - val_precision_m: 0.3182 - val_recall_m: 0.0570 - val_f1_m: 0.0899\n",
      "Epoch 12/30\n",
      "271/291 [==========================>...] - ETA: 0s - loss: 0.0986 - acc: 0.9667 - precision_m: 0.5846 - recall_m: 0.1229 - f1_m: 0.1938\n",
      "Epoch 12: val_acc improved from 0.96342 to 0.96425, saving model to models/best_model_5_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0986 - acc: 0.9668 - precision_m: 0.5753 - recall_m: 0.1222 - f1_m: 0.1926 - val_loss: 0.1020 - val_acc: 0.9643 - val_precision_m: 0.5098 - val_recall_m: 0.0958 - val_f1_m: 0.1502\n",
      "Epoch 13/30\n",
      "275/291 [===========================>..] - ETA: 0s - loss: 0.0959 - acc: 0.9678 - precision_m: 0.6029 - recall_m: 0.1568 - f1_m: 0.2359\n",
      "Epoch 13: val_acc improved from 0.96425 to 0.96509, saving model to models/best_model_5_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0963 - acc: 0.9677 - precision_m: 0.5978 - recall_m: 0.1557 - f1_m: 0.2345 - val_loss: 0.1005 - val_acc: 0.9651 - val_precision_m: 0.5952 - val_recall_m: 0.1551 - val_f1_m: 0.2183\n",
      "Epoch 14/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0937 - acc: 0.9682 - precision_m: 0.6232 - recall_m: 0.1741 - f1_m: 0.2579\n",
      "Epoch 14: val_acc improved from 0.96509 to 0.96640, saving model to models/best_model_5_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0941 - acc: 0.9681 - precision_m: 0.6157 - recall_m: 0.1726 - f1_m: 0.2555 - val_loss: 0.0998 - val_acc: 0.9664 - val_precision_m: 0.6564 - val_recall_m: 0.2049 - val_f1_m: 0.2815\n",
      "Epoch 15/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0927 - acc: 0.9684 - precision_m: 0.6667 - recall_m: 0.1833 - f1_m: 0.2738\n",
      "Epoch 15: val_acc did not improve from 0.96640\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0926 - acc: 0.9684 - precision_m: 0.6644 - recall_m: 0.1823 - f1_m: 0.2725 - val_loss: 0.1001 - val_acc: 0.9651 - val_precision_m: 0.5586 - val_recall_m: 0.1391 - val_f1_m: 0.2003\n",
      "Epoch 16/30\n",
      "273/291 [===========================>..] - ETA: 0s - loss: 0.0905 - acc: 0.9694 - precision_m: 0.7019 - recall_m: 0.2148 - f1_m: 0.3116\n",
      "Epoch 16: val_acc did not improve from 0.96640\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0910 - acc: 0.9692 - precision_m: 0.7028 - recall_m: 0.2146 - f1_m: 0.3116 - val_loss: 0.0974 - val_acc: 0.9663 - val_precision_m: 0.6659 - val_recall_m: 0.1901 - val_f1_m: 0.2704\n",
      "Epoch 17/30\n",
      "271/291 [==========================>...] - ETA: 0s - loss: 0.0897 - acc: 0.9696 - precision_m: 0.6795 - recall_m: 0.2281 - f1_m: 0.3282\n",
      "Epoch 17: val_acc did not improve from 0.96640\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0901 - acc: 0.9696 - precision_m: 0.6752 - recall_m: 0.2285 - f1_m: 0.3282 - val_loss: 0.0977 - val_acc: 0.9664 - val_precision_m: 0.7232 - val_recall_m: 0.1978 - val_f1_m: 0.2852\n",
      "Epoch 18/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.0888 - acc: 0.9695 - precision_m: 0.6910 - recall_m: 0.2387 - f1_m: 0.3357\n",
      "Epoch 18: val_acc improved from 0.96640 to 0.96699, saving model to models/best_model_5_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0889 - acc: 0.9695 - precision_m: 0.6912 - recall_m: 0.2388 - f1_m: 0.3360 - val_loss: 0.0952 - val_acc: 0.9670 - val_precision_m: 0.7356 - val_recall_m: 0.2181 - val_f1_m: 0.3057\n",
      "Epoch 19/30\n",
      "274/291 [===========================>..] - ETA: 0s - loss: 0.0876 - acc: 0.9698 - precision_m: 0.7071 - recall_m: 0.2458 - f1_m: 0.3486\n",
      "Epoch 19: val_acc improved from 0.96699 to 0.96783, saving model to models/best_model_5_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0881 - acc: 0.9695 - precision_m: 0.7030 - recall_m: 0.2464 - f1_m: 0.3485 - val_loss: 0.0933 - val_acc: 0.9678 - val_precision_m: 0.7478 - val_recall_m: 0.2625 - val_f1_m: 0.3409\n",
      "Epoch 20/30\n",
      "273/291 [===========================>..] - ETA: 0s - loss: 0.0874 - acc: 0.9702 - precision_m: 0.7113 - recall_m: 0.2679 - f1_m: 0.3695\n",
      "Epoch 20: val_acc improved from 0.96783 to 0.96854, saving model to models/best_model_5_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0872 - acc: 0.9703 - precision_m: 0.7050 - recall_m: 0.2628 - f1_m: 0.3630 - val_loss: 0.0931 - val_acc: 0.9685 - val_precision_m: 0.7576 - val_recall_m: 0.2943 - val_f1_m: 0.3726\n",
      "Epoch 21/30\n",
      "274/291 [===========================>..] - ETA: 0s - loss: 0.0862 - acc: 0.9705 - precision_m: 0.7040 - recall_m: 0.2793 - f1_m: 0.3786\n",
      "Epoch 21: val_acc did not improve from 0.96854\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0869 - acc: 0.9703 - precision_m: 0.7061 - recall_m: 0.2782 - f1_m: 0.3777 - val_loss: 0.0928 - val_acc: 0.9682 - val_precision_m: 0.7474 - val_recall_m: 0.2836 - val_f1_m: 0.3664\n",
      "Epoch 22/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0861 - acc: 0.9702 - precision_m: 0.6959 - recall_m: 0.2739 - f1_m: 0.3744\n",
      "Epoch 22: val_acc did not improve from 0.96854\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0862 - acc: 0.9702 - precision_m: 0.6980 - recall_m: 0.2737 - f1_m: 0.3746 - val_loss: 0.0946 - val_acc: 0.9682 - val_precision_m: 0.7496 - val_recall_m: 0.2626 - val_f1_m: 0.3474\n",
      "Epoch 23/30\n",
      "272/291 [===========================>..] - ETA: 0s - loss: 0.0847 - acc: 0.9710 - precision_m: 0.7134 - recall_m: 0.2896 - f1_m: 0.3945\n",
      "Epoch 23: val_acc did not improve from 0.96854\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0851 - acc: 0.9710 - precision_m: 0.7175 - recall_m: 0.2897 - f1_m: 0.3953 - val_loss: 0.0922 - val_acc: 0.9684 - val_precision_m: 0.7524 - val_recall_m: 0.2897 - val_f1_m: 0.3713\n",
      "Epoch 24/30\n",
      "273/291 [===========================>..] - ETA: 0s - loss: 0.0846 - acc: 0.9708 - precision_m: 0.7183 - recall_m: 0.2917 - f1_m: 0.3934\n",
      "Epoch 24: val_acc improved from 0.96854 to 0.96973, saving model to models/best_model_5_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0849 - acc: 0.9707 - precision_m: 0.7189 - recall_m: 0.2904 - f1_m: 0.3927 - val_loss: 0.0908 - val_acc: 0.9697 - val_precision_m: 0.7527 - val_recall_m: 0.3176 - val_f1_m: 0.3992\n",
      "Epoch 25/30\n",
      "273/291 [===========================>..] - ETA: 0s - loss: 0.0846 - acc: 0.9710 - precision_m: 0.7232 - recall_m: 0.2958 - f1_m: 0.4010\n",
      "Epoch 25: val_acc did not improve from 0.96973\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0844 - acc: 0.9710 - precision_m: 0.7257 - recall_m: 0.2945 - f1_m: 0.4000 - val_loss: 0.0913 - val_acc: 0.9687 - val_precision_m: 0.7169 - val_recall_m: 0.3213 - val_f1_m: 0.4011\n",
      "Epoch 26/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0839 - acc: 0.9711 - precision_m: 0.7142 - recall_m: 0.3064 - f1_m: 0.4119\n",
      "Epoch 26: val_acc did not improve from 0.96973\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0840 - acc: 0.9710 - precision_m: 0.7131 - recall_m: 0.3066 - f1_m: 0.4119 - val_loss: 0.0910 - val_acc: 0.9691 - val_precision_m: 0.7300 - val_recall_m: 0.2777 - val_f1_m: 0.3650\n",
      "Epoch 27/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0830 - acc: 0.9713 - precision_m: 0.7153 - recall_m: 0.3046 - f1_m: 0.4090\n",
      "Epoch 27: val_acc improved from 0.96973 to 0.97033, saving model to models/best_model_5_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0833 - acc: 0.9711 - precision_m: 0.7161 - recall_m: 0.3048 - f1_m: 0.4094 - val_loss: 0.0907 - val_acc: 0.9703 - val_precision_m: 0.7208 - val_recall_m: 0.3718 - val_f1_m: 0.4541\n",
      "Epoch 28/30\n",
      "273/291 [===========================>..] - ETA: 0s - loss: 0.0837 - acc: 0.9712 - precision_m: 0.6977 - recall_m: 0.3085 - f1_m: 0.4097\n",
      "Epoch 28: val_acc did not improve from 0.97033\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0831 - acc: 0.9714 - precision_m: 0.7022 - recall_m: 0.3132 - f1_m: 0.4149 - val_loss: 0.0896 - val_acc: 0.9703 - val_precision_m: 0.7368 - val_recall_m: 0.3426 - val_f1_m: 0.4261\n",
      "Epoch 29/30\n",
      "274/291 [===========================>..] - ETA: 0s - loss: 0.0825 - acc: 0.9717 - precision_m: 0.7292 - recall_m: 0.3171 - f1_m: 0.4248\n",
      "Epoch 29: val_acc did not improve from 0.97033\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0825 - acc: 0.9718 - precision_m: 0.7294 - recall_m: 0.3190 - f1_m: 0.4266 - val_loss: 0.0893 - val_acc: 0.9700 - val_precision_m: 0.7100 - val_recall_m: 0.3279 - val_f1_m: 0.4112\n",
      "Epoch 30/30\n",
      "272/291 [===========================>..] - ETA: 0s - loss: 0.0824 - acc: 0.9718 - precision_m: 0.7147 - recall_m: 0.3213 - f1_m: 0.4232\n",
      "Epoch 30: val_acc did not improve from 0.97033\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0824 - acc: 0.9716 - precision_m: 0.7132 - recall_m: 0.3204 - f1_m: 0.4225 - val_loss: 0.0884 - val_acc: 0.9701 - val_precision_m: 0.7318 - val_recall_m: 0.3349 - val_f1_m: 0.4168\n",
      "Score for fold 9: loss of 0.09068014472723007; acc of 97.03288674354553%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.0874176025390625; acc of 96.94640040397644%\n",
      "Test Precision: precision_m of 19.31949257850647%\n",
      "Test Recall: recall_m of 12.66106367111206%\n",
      "Test F1: f1_m of 14.332273602485657%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1807 - acc: 0.9501 - precision_m: 0.0235 - recall_m: 0.0262 - f1_m: 0.0186\n",
      "Epoch 1: val_acc improved from -inf to 0.96034, saving model to models/best_model_5_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 2s 4ms/step - loss: 0.1807 - acc: 0.9501 - precision_m: 0.0235 - recall_m: 0.0262 - f1_m: 0.0186 - val_loss: 0.1458 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.1269 - acc: 0.9645 - precision_m: 0.1134 - recall_m: 0.0123 - f1_m: 0.0220\n",
      "Epoch 2: val_acc improved from 0.96034 to 0.96094, saving model to models/best_model_5_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1270 - acc: 0.9645 - precision_m: 0.1130 - recall_m: 0.0123 - f1_m: 0.0219 - val_loss: 0.1358 - val_acc: 0.9609 - val_precision_m: 0.0909 - val_recall_m: 0.0156 - val_f1_m: 0.0265\n",
      "Epoch 3/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1220 - acc: 0.9648 - precision_m: 0.2123 - recall_m: 0.0283 - f1_m: 0.0491\n",
      "Epoch 3: val_acc did not improve from 0.96094\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1220 - acc: 0.9648 - precision_m: 0.2123 - recall_m: 0.0283 - f1_m: 0.0491 - val_loss: 0.1321 - val_acc: 0.9607 - val_precision_m: 0.1515 - val_recall_m: 0.0225 - val_f1_m: 0.0385\n",
      "Epoch 4/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1188 - acc: 0.9651 - precision_m: 0.3137 - recall_m: 0.0449 - f1_m: 0.0759\n",
      "Epoch 4: val_acc improved from 0.96094 to 0.96118, saving model to models/best_model_5_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1188 - acc: 0.9651 - precision_m: 0.3137 - recall_m: 0.0449 - f1_m: 0.0759 - val_loss: 0.1289 - val_acc: 0.9612 - val_precision_m: 0.1919 - val_recall_m: 0.0295 - val_f1_m: 0.0508\n",
      "Epoch 5/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.1162 - acc: 0.9650 - precision_m: 0.3325 - recall_m: 0.0504 - f1_m: 0.0852\n",
      "Epoch 5: val_acc improved from 0.96118 to 0.96190, saving model to models/best_model_5_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1159 - acc: 0.9651 - precision_m: 0.3382 - recall_m: 0.0511 - f1_m: 0.0864 - val_loss: 0.1255 - val_acc: 0.9619 - val_precision_m: 0.2374 - val_recall_m: 0.0388 - val_f1_m: 0.0661\n",
      "Epoch 6/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.1131 - acc: 0.9654 - precision_m: 0.4161 - recall_m: 0.0656 - f1_m: 0.1096\n",
      "Epoch 6: val_acc did not improve from 0.96190\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1133 - acc: 0.9654 - precision_m: 0.4144 - recall_m: 0.0659 - f1_m: 0.1100 - val_loss: 0.1246 - val_acc: 0.9615 - val_precision_m: 0.1919 - val_recall_m: 0.0278 - val_f1_m: 0.0479\n",
      "Epoch 7/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.1107 - acc: 0.9657 - precision_m: 0.4230 - recall_m: 0.0788 - f1_m: 0.1280\n",
      "Epoch 7: val_acc improved from 0.96190 to 0.96274, saving model to models/best_model_5_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1107 - acc: 0.9656 - precision_m: 0.4197 - recall_m: 0.0776 - f1_m: 0.1262 - val_loss: 0.1187 - val_acc: 0.9627 - val_precision_m: 0.2879 - val_recall_m: 0.0609 - val_f1_m: 0.0974\n",
      "Epoch 8/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1079 - acc: 0.9657 - precision_m: 0.4740 - recall_m: 0.0798 - f1_m: 0.1313\n",
      "Epoch 8: val_acc did not improve from 0.96274\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1079 - acc: 0.9658 - precision_m: 0.4760 - recall_m: 0.0801 - f1_m: 0.1318 - val_loss: 0.1155 - val_acc: 0.9627 - val_precision_m: 0.3283 - val_recall_m: 0.0660 - val_f1_m: 0.1065\n",
      "Epoch 9/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.1047 - acc: 0.9664 - precision_m: 0.5468 - recall_m: 0.1027 - f1_m: 0.1654\n",
      "Epoch 9: val_acc did not improve from 0.96274\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1045 - acc: 0.9665 - precision_m: 0.5449 - recall_m: 0.1024 - f1_m: 0.1648 - val_loss: 0.1131 - val_acc: 0.9621 - val_precision_m: 0.2677 - val_recall_m: 0.0497 - val_f1_m: 0.0811\n",
      "Epoch 10/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1021 - acc: 0.9670 - precision_m: 0.5649 - recall_m: 0.1162 - f1_m: 0.1845\n",
      "Epoch 10: val_acc improved from 0.96274 to 0.96358, saving model to models/best_model_5_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1021 - acc: 0.9670 - precision_m: 0.5649 - recall_m: 0.1162 - f1_m: 0.1845 - val_loss: 0.1092 - val_acc: 0.9636 - val_precision_m: 0.3808 - val_recall_m: 0.0986 - val_f1_m: 0.1497\n",
      "Epoch 11/30\n",
      "273/292 [===========================>..] - ETA: 0s - loss: 0.0998 - acc: 0.9674 - precision_m: 0.6421 - recall_m: 0.1436 - f1_m: 0.2258\n",
      "Epoch 11: val_acc improved from 0.96358 to 0.96370, saving model to models/best_model_5_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0996 - acc: 0.9675 - precision_m: 0.6443 - recall_m: 0.1454 - f1_m: 0.2282 - val_loss: 0.1076 - val_acc: 0.9637 - val_precision_m: 0.3939 - val_recall_m: 0.1054 - val_f1_m: 0.1573\n",
      "Epoch 12/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0973 - acc: 0.9681 - precision_m: 0.6196 - recall_m: 0.1556 - f1_m: 0.2390\n",
      "Epoch 12: val_acc improved from 0.96370 to 0.96442, saving model to models/best_model_5_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0975 - acc: 0.9680 - precision_m: 0.6158 - recall_m: 0.1540 - f1_m: 0.2367 - val_loss: 0.1055 - val_acc: 0.9644 - val_precision_m: 0.4697 - val_recall_m: 0.1211 - val_f1_m: 0.1795\n",
      "Epoch 13/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.0962 - acc: 0.9681 - precision_m: 0.6437 - recall_m: 0.1710 - f1_m: 0.2557\n",
      "Epoch 13: val_acc improved from 0.96442 to 0.96599, saving model to models/best_model_5_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0962 - acc: 0.9681 - precision_m: 0.6437 - recall_m: 0.1710 - f1_m: 0.2557 - val_loss: 0.1030 - val_acc: 0.9660 - val_precision_m: 0.5793 - val_recall_m: 0.1805 - val_f1_m: 0.2579\n",
      "Epoch 14/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.0944 - acc: 0.9687 - precision_m: 0.6627 - recall_m: 0.1900 - f1_m: 0.2796\n",
      "Epoch 14: val_acc did not improve from 0.96599\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0945 - acc: 0.9687 - precision_m: 0.6639 - recall_m: 0.1898 - f1_m: 0.2794 - val_loss: 0.1031 - val_acc: 0.9648 - val_precision_m: 0.5313 - val_recall_m: 0.1363 - val_f1_m: 0.2071\n",
      "Epoch 15/30\n",
      "271/292 [==========================>...] - ETA: 0s - loss: 0.0934 - acc: 0.9685 - precision_m: 0.7008 - recall_m: 0.2022 - f1_m: 0.2991\n",
      "Epoch 15: val_acc did not improve from 0.96599\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0928 - acc: 0.9688 - precision_m: 0.7011 - recall_m: 0.2027 - f1_m: 0.3001 - val_loss: 0.1021 - val_acc: 0.9650 - val_precision_m: 0.5202 - val_recall_m: 0.1454 - val_f1_m: 0.2168\n",
      "Epoch 16/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0913 - acc: 0.9693 - precision_m: 0.6890 - recall_m: 0.2217 - f1_m: 0.3168\n",
      "Epoch 16: val_acc improved from 0.96599 to 0.96611, saving model to models/best_model_5_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0918 - acc: 0.9692 - precision_m: 0.6936 - recall_m: 0.2204 - f1_m: 0.3159 - val_loss: 0.0995 - val_acc: 0.9661 - val_precision_m: 0.5889 - val_recall_m: 0.1845 - val_f1_m: 0.2640\n",
      "Epoch 17/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.0906 - acc: 0.9696 - precision_m: 0.6708 - recall_m: 0.2176 - f1_m: 0.3136\n",
      "Epoch 17: val_acc improved from 0.96611 to 0.96755, saving model to models/best_model_5_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0906 - acc: 0.9696 - precision_m: 0.6708 - recall_m: 0.2176 - f1_m: 0.3136 - val_loss: 0.0982 - val_acc: 0.9675 - val_precision_m: 0.6696 - val_recall_m: 0.2329 - val_f1_m: 0.3233\n",
      "Epoch 18/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.0900 - acc: 0.9695 - precision_m: 0.6900 - recall_m: 0.2344 - f1_m: 0.3320\n",
      "Epoch 18: val_acc did not improve from 0.96755\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0901 - acc: 0.9695 - precision_m: 0.6911 - recall_m: 0.2345 - f1_m: 0.3322 - val_loss: 0.0995 - val_acc: 0.9651 - val_precision_m: 0.5364 - val_recall_m: 0.1603 - val_f1_m: 0.2322\n",
      "Epoch 19/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0888 - acc: 0.9702 - precision_m: 0.7122 - recall_m: 0.2503 - f1_m: 0.3493\n",
      "Epoch 19: val_acc did not improve from 0.96755\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0887 - acc: 0.9702 - precision_m: 0.7119 - recall_m: 0.2501 - f1_m: 0.3490 - val_loss: 0.0981 - val_acc: 0.9661 - val_precision_m: 0.5720 - val_recall_m: 0.1740 - val_f1_m: 0.2510\n",
      "Epoch 20/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0888 - acc: 0.9697 - precision_m: 0.7110 - recall_m: 0.2490 - f1_m: 0.3481\n",
      "Epoch 20: val_acc did not improve from 0.96755\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0883 - acc: 0.9699 - precision_m: 0.7148 - recall_m: 0.2490 - f1_m: 0.3484 - val_loss: 0.1027 - val_acc: 0.9650 - val_precision_m: 0.4591 - val_recall_m: 0.1364 - val_f1_m: 0.2011\n",
      "Epoch 21/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.0874 - acc: 0.9703 - precision_m: 0.7020 - recall_m: 0.2592 - f1_m: 0.3585\n",
      "Epoch 21: val_acc improved from 0.96755 to 0.96815, saving model to models/best_model_5_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0875 - acc: 0.9702 - precision_m: 0.7013 - recall_m: 0.2586 - f1_m: 0.3578 - val_loss: 0.0952 - val_acc: 0.9681 - val_precision_m: 0.7454 - val_recall_m: 0.2845 - val_f1_m: 0.3869\n",
      "Epoch 22/30\n",
      "274/292 [===========================>..] - ETA: 0s - loss: 0.0868 - acc: 0.9704 - precision_m: 0.7107 - recall_m: 0.2721 - f1_m: 0.3735\n",
      "Epoch 22: val_acc did not improve from 0.96815\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0867 - acc: 0.9704 - precision_m: 0.7073 - recall_m: 0.2706 - f1_m: 0.3718 - val_loss: 0.0958 - val_acc: 0.9678 - val_precision_m: 0.7019 - val_recall_m: 0.2341 - val_f1_m: 0.3257\n",
      "Epoch 23/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0863 - acc: 0.9705 - precision_m: 0.7189 - recall_m: 0.2697 - f1_m: 0.3734\n",
      "Epoch 23: val_acc did not improve from 0.96815\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0862 - acc: 0.9705 - precision_m: 0.7152 - recall_m: 0.2678 - f1_m: 0.3711 - val_loss: 0.0954 - val_acc: 0.9678 - val_precision_m: 0.7071 - val_recall_m: 0.2280 - val_f1_m: 0.3233\n",
      "Epoch 24/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0857 - acc: 0.9706 - precision_m: 0.7259 - recall_m: 0.2761 - f1_m: 0.3796\n",
      "Epoch 24: val_acc improved from 0.96815 to 0.96839, saving model to models/best_model_5_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0858 - acc: 0.9705 - precision_m: 0.7245 - recall_m: 0.2747 - f1_m: 0.3778 - val_loss: 0.0945 - val_acc: 0.9684 - val_precision_m: 0.7833 - val_recall_m: 0.2667 - val_f1_m: 0.3754\n",
      "Epoch 25/30\n",
      "272/292 [==========================>...] - ETA: 0s - loss: 0.0848 - acc: 0.9708 - precision_m: 0.7183 - recall_m: 0.2899 - f1_m: 0.3886\n",
      "Epoch 25: val_acc improved from 0.96839 to 0.96887, saving model to models/best_model_5_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0851 - acc: 0.9706 - precision_m: 0.7188 - recall_m: 0.2883 - f1_m: 0.3874 - val_loss: 0.0935 - val_acc: 0.9689 - val_precision_m: 0.7733 - val_recall_m: 0.2972 - val_f1_m: 0.4035\n",
      "Epoch 26/30\n",
      "273/292 [===========================>..] - ETA: 0s - loss: 0.0845 - acc: 0.9709 - precision_m: 0.7421 - recall_m: 0.2969 - f1_m: 0.4027\n",
      "Epoch 26: val_acc improved from 0.96887 to 0.96911, saving model to models/best_model_5_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0847 - acc: 0.9709 - precision_m: 0.7355 - recall_m: 0.2969 - f1_m: 0.4015 - val_loss: 0.0933 - val_acc: 0.9691 - val_precision_m: 0.7709 - val_recall_m: 0.3111 - val_f1_m: 0.4144\n",
      "Epoch 27/30\n",
      "272/292 [==========================>...] - ETA: 0s - loss: 0.0838 - acc: 0.9711 - precision_m: 0.7177 - recall_m: 0.2927 - f1_m: 0.3945\n",
      "Epoch 27: val_acc improved from 0.96911 to 0.96959, saving model to models/best_model_5_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0842 - acc: 0.9709 - precision_m: 0.7172 - recall_m: 0.2945 - f1_m: 0.3965 - val_loss: 0.0922 - val_acc: 0.9696 - val_precision_m: 0.7814 - val_recall_m: 0.3048 - val_f1_m: 0.4109\n",
      "Epoch 28/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0840 - acc: 0.9713 - precision_m: 0.7457 - recall_m: 0.3016 - f1_m: 0.4104\n",
      "Epoch 28: val_acc improved from 0.96959 to 0.97043, saving model to models/best_model_5_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0840 - acc: 0.9713 - precision_m: 0.7443 - recall_m: 0.3020 - f1_m: 0.4108 - val_loss: 0.0919 - val_acc: 0.9704 - val_precision_m: 0.8002 - val_recall_m: 0.3348 - val_f1_m: 0.4466\n",
      "Epoch 29/30\n",
      "274/292 [===========================>..] - ETA: 0s - loss: 0.0843 - acc: 0.9711 - precision_m: 0.7307 - recall_m: 0.3103 - f1_m: 0.4136\n",
      "Epoch 29: val_acc did not improve from 0.97043\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0838 - acc: 0.9713 - precision_m: 0.7281 - recall_m: 0.3136 - f1_m: 0.4161 - val_loss: 0.1017 - val_acc: 0.9663 - val_precision_m: 0.6081 - val_recall_m: 0.1681 - val_f1_m: 0.2473\n",
      "Epoch 30/30\n",
      "272/292 [==========================>...] - ETA: 0s - loss: 0.0836 - acc: 0.9712 - precision_m: 0.7207 - recall_m: 0.2988 - f1_m: 0.4041\n",
      "Epoch 30: val_acc did not improve from 0.97043\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0830 - acc: 0.9715 - precision_m: 0.7227 - recall_m: 0.3047 - f1_m: 0.4102 - val_loss: 0.0930 - val_acc: 0.9688 - val_precision_m: 0.8260 - val_recall_m: 0.2578 - val_f1_m: 0.3662\n",
      "Score for fold 10: loss of 0.0919063538312912; acc of 97.0432698726654%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.08380404114723206; acc of 96.9693660736084%\n",
      "Test Precision: precision_m of 21.37426882982254%\n",
      "Test Recall: recall_m of 13.77248615026474%\n",
      "Test F1: f1_m of 15.730758011341095%\n",
      "------------------------------------------------------------------------\n",
      "Validation score per fold\n",
      "> Fold 1 - Loss: 0.09014429152011871 - Accuracy: 96.8231201171875%\n",
      "> Fold 2 - Loss: 0.08457425981760025 - Accuracy: 97.20991253852844%\n",
      "> Fold 3 - Loss: 0.08758432418107986 - Accuracy: 97.08912372589111%\n",
      "> Fold 4 - Loss: 0.09442301094532013 - Accuracy: 96.91940546035767%\n",
      "> Fold 5 - Loss: 0.09228426963090897 - Accuracy: 96.98816537857056%\n",
      "> Fold 6 - Loss: 0.09162186086177826 - Accuracy: 96.93865180015564%\n",
      "> Fold 7 - Loss: 0.0850900262594223 - Accuracy: 97.04898595809937%\n",
      "> Fold 8 - Loss: 0.08476274460554123 - Accuracy: 97.11307883262634%\n",
      "> Fold 9 - Loss: 0.09068014472723007 - Accuracy: 97.03288674354553%\n",
      "> Fold 10 - Loss: 0.0919063538312912 - Accuracy: 97.0432698726654%\n",
      "------------------------------------------------------------------------\n",
      "Testing score per fold\n",
      "> Fold 1 - Accuracy: 97.68875241279602 - Precision: 17.370891571044922 - Recall: 10.886149853467941 - F1: 12.590061128139496%\n",
      "> Fold 2 - Accuracy: 96.8250572681427 - Precision: 21.372851729393005 - Recall: 14.11447823047638 - F1: 16.01133942604065%\n",
      "> Fold 3 - Accuracy: 97.02463746070862 - Precision: 16.921769082546234 - Recall: 11.00461632013321 - F1: 12.42394894361496%\n",
      "> Fold 4 - Accuracy: 96.47300839424133 - Precision: 17.74180382490158 - Recall: 10.585501044988632 - F1: 12.150120735168457%\n",
      "> Fold 5 - Accuracy: 96.88234329223633 - Precision: 18.811149895191193 - Recall: 12.456674128770828 - F1: 14.164462685585022%\n",
      "> Fold 6 - Accuracy: 96.81140780448914 - Precision: 17.505787312984467 - Recall: 13.265268504619598 - F1: 14.196151494979858%\n",
      "> Fold 7 - Accuracy: 97.4003255367279 - Precision: 14.526300132274628 - Recall: 10.222333669662476 - F1: 11.365946382284164%\n",
      "> Fold 8 - Accuracy: 96.84699773788452 - Precision: 14.899882674217224 - Recall: 8.67929682135582 - F1: 10.246377438306808%\n",
      "> Fold 9 - Accuracy: 96.94640040397644 - Precision: 19.31949257850647 - Recall: 12.66106367111206 - F1: 14.332273602485657%\n",
      "> Fold 10 - Accuracy: 96.9693660736084 - Precision: 21.37426882982254 - Recall: 13.77248615026474 - F1: 15.730758011341095%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Validation Accuracy: 97.02066004276276 (+- 0.10371298741796246)\n",
      "> Validation Loss: 0.0893071286380291\n",
      "> Testing Accuracy: 96.98682963848114 (+- 0.31913462945053694)\n",
      "> Testing Precision: 17.984419763088226\n",
      "> Testing Recall: 11.764786839485168\n",
      "> Testing F1: 13.321143984794617\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Lists to hold cross-validation results\n",
    "acc_5_per_fold = []\n",
    "loss_5_per_fold = []\n",
    "precision_5_per_fold = []\n",
    "recall_5_per_fold = []\n",
    "f1_5_per_fold = []\n",
    "\n",
    "testing_acc_5_per_fold = []\n",
    "testing_precision_5_per_fold = []\n",
    "testing_recall_5_per_fold = []\n",
    "testing_f1_5_per_fold = []\n",
    "\n",
    "\n",
    "# Load data from .npz files\n",
    "for fold_no in range(1, 11):\n",
    "    with np.load(f'fold_{fold_no}.npz') as data:\n",
    "        x_train = data['x_train_fold.npy']\n",
    "        y_train = data['y_train_fold.npy']\n",
    "        x_val = data['x_val_fold.npy']\n",
    "        y_val = data['y_val_fold.npy']\n",
    "        x_test = data['x_test_fold.npy']\n",
    "        y_test = data['y_test_fold.npy']\n",
    "        \n",
    "        # Converting ground truth arrays to one wake word (1) and 'other' (0)\n",
    "        wake_word_index = all_targets.index(wake_word)\n",
    "        y_train = np.equal(y_train, wake_word_index).astype('float64')\n",
    "        y_val = np.equal(y_val, wake_word_index).astype('float64')\n",
    "        y_test = np.equal(y_test, wake_word_index).astype('float64')\n",
    "        \n",
    "        # CNN for TF expects (batch, height, width, channels)\n",
    "        x_train = x_train.reshape(x_train.shape[0], \n",
    "                          x_train.shape[1], \n",
    "                          x_train.shape[2], \n",
    "                          1)\n",
    "        x_val = x_val.reshape(x_val.shape[0], \n",
    "                          x_val.shape[1], \n",
    "                          x_val.shape[2], \n",
    "                          1)\n",
    "        x_test = x_test.reshape(x_test.shape[0], \n",
    "                          x_test.shape[1], \n",
    "                          x_test.shape[2], \n",
    "                          1)\n",
    "        sample_shape = x_test.shape[1:]\n",
    "\n",
    "    # CNN model\n",
    "    model_5 = models.Sequential()\n",
    "    model_5.add(layers.Conv2D(8,\n",
    "                              (4,4),\n",
    "                              activation=\"tanh\",\n",
    "                              input_shape=sample_shape))\n",
    "    model_5.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model_5.add(layers.Flatten())\n",
    "    model_5.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "\n",
    "    model_5.compile(loss='binary_crossentropy', \n",
    "              optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "              metrics=['acc', precision_m, recall_m, f1_m])\n",
    "\n",
    "    checkpoint_filepath = f'models/best_model_5_fold_{fold_no}.h5'\n",
    "    model_checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=False,\n",
    "        monitor='val_acc',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "        save_freq='epoch'\n",
    "    )\n",
    "\n",
    "    # Instantiate the custom callback\n",
    "    metrics_history = MetricsHistory()\n",
    "\n",
    "    # Print fold number\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Train\n",
    "    history_5 = model_5.fit(x_train, \n",
    "                    y_train, \n",
    "                    epochs=30, \n",
    "                    batch_size=256, \n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[model_checkpoint_callback, metrics_history])\n",
    "\n",
    "    model_5.load_weights(checkpoint_filepath)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    scores = model_5.evaluate(x_val, y_val, verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model_5.metrics_names[0]} of {scores[0]}; {model_5.metrics_names[1]} of {scores[1] * 100}%')\n",
    "    acc_5_per_fold.append(scores[1] * 100)\n",
    "    loss_5_per_fold.append(scores[0])\n",
    "    precision_5_per_fold.append(metrics_history.best_metrics['precision_m'] * 100)\n",
    "    recall_5_per_fold.append(metrics_history.best_metrics['recall_m'] * 100)\n",
    "    f1_5_per_fold.append(metrics_history.best_metrics['f1_m'] * 100)\n",
    "\n",
    "    # Final evaluation on test set\n",
    "    final_scores = model_5.evaluate(x_test, y_test, verbose=0)\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Final test score: {model_5.metrics_names[0]} of {final_scores[0]}; {model_5.metrics_names[1]} of {final_scores[1] * 100}%')\n",
    "    print(f'Test Precision: {model_5.metrics_names[2]} of {final_scores[2] * 100}%')\n",
    "    print(f'Test Recall: {model_5.metrics_names[3]} of {final_scores[3] * 100}%')\n",
    "    print(f'Test F1: {model_5.metrics_names[4]} of {final_scores[4] * 100}%')\n",
    "\n",
    "    # Append test metrics to lists\n",
    "    testing_acc_5_per_fold.append(final_scores[1] * 100)\n",
    "    testing_precision_5_per_fold.append(final_scores[2] * 100)\n",
    "    testing_recall_5_per_fold.append(final_scores[3] * 100)\n",
    "    testing_f1_5_per_fold.append(final_scores[4] * 100)\n",
    "\n",
    "# Print the results\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Validation score per fold')\n",
    "for i in range(0, len(acc_5_per_fold)):\n",
    "    print(f'> Fold {i+1} - Loss: {loss_5_per_fold[i]} - Accuracy: {acc_5_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Testing score per fold')\n",
    "for i in range(0, len(testing_acc_5_per_fold)):\n",
    "    print(f'> Fold {i+1} - Accuracy: {testing_acc_5_per_fold[i]} - Precision: {testing_precision_5_per_fold[i]} - Recall: {testing_recall_5_per_fold[i]} - F1: {testing_f1_5_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Validation Accuracy: {np.mean(acc_5_per_fold)} (+- {np.std(acc_5_per_fold)})')\n",
    "print(f'> Validation Loss: {np.mean(loss_5_per_fold)}')\n",
    "print(f'> Testing Accuracy: {np.mean(testing_acc_5_per_fold)} (+- {np.std(testing_acc_5_per_fold)})')\n",
    "print(f'> Testing Precision: {np.mean(testing_precision_5_per_fold)}')\n",
    "print(f'> Testing Recall: {np.mean(testing_recall_5_per_fold)}')\n",
    "print(f'> Testing F1: {np.mean(testing_f1_5_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1504 - acc: 0.9605 - precision_m: 0.0762 - recall_m: 0.0180 - f1_m: 0.0222\n",
      "Epoch 1: val_acc improved from -inf to 0.96226, saving model to models/best_model_6_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 3s 6ms/step - loss: 0.1504 - acc: 0.9605 - precision_m: 0.0762 - recall_m: 0.0180 - f1_m: 0.0222 - val_loss: 0.1078 - val_acc: 0.9623 - val_precision_m: 0.4419 - val_recall_m: 0.0964 - val_f1_m: 0.1457\n",
      "Epoch 2/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.0939 - acc: 0.9688 - precision_m: 0.6839 - recall_m: 0.2853 - f1_m: 0.3688\n",
      "Epoch 2: val_acc improved from 0.96226 to 0.96811, saving model to models/best_model_6_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0939 - acc: 0.9688 - precision_m: 0.6839 - recall_m: 0.2853 - f1_m: 0.3688 - val_loss: 0.0877 - val_acc: 0.9681 - val_precision_m: 0.7349 - val_recall_m: 0.3095 - val_f1_m: 0.3968\n",
      "Epoch 3/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0795 - acc: 0.9729 - precision_m: 0.7338 - recall_m: 0.4348 - f1_m: 0.5111\n",
      "Epoch 3: val_acc improved from 0.96811 to 0.96859, saving model to models/best_model_6_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0795 - acc: 0.9729 - precision_m: 0.7349 - recall_m: 0.4346 - f1_m: 0.5115 - val_loss: 0.0908 - val_acc: 0.9686 - val_precision_m: 0.7146 - val_recall_m: 0.2606 - val_f1_m: 0.3527\n",
      "Epoch 4/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0709 - acc: 0.9751 - precision_m: 0.7695 - recall_m: 0.4973 - f1_m: 0.5739\n",
      "Epoch 4: val_acc improved from 0.96859 to 0.97181, saving model to models/best_model_6_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0711 - acc: 0.9750 - precision_m: 0.7688 - recall_m: 0.4972 - f1_m: 0.5739 - val_loss: 0.0776 - val_acc: 0.9718 - val_precision_m: 0.6918 - val_recall_m: 0.4553 - val_f1_m: 0.5211\n",
      "Epoch 5/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0656 - acc: 0.9775 - precision_m: 0.8029 - recall_m: 0.5512 - f1_m: 0.6233\n",
      "Epoch 5: val_acc improved from 0.97181 to 0.97337, saving model to models/best_model_6_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0656 - acc: 0.9775 - precision_m: 0.8036 - recall_m: 0.5513 - f1_m: 0.6239 - val_loss: 0.0736 - val_acc: 0.9734 - val_precision_m: 0.6994 - val_recall_m: 0.5525 - val_f1_m: 0.5871\n",
      "Epoch 6/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9793 - precision_m: 0.8117 - recall_m: 0.5951 - f1_m: 0.6619\n",
      "Epoch 6: val_acc improved from 0.97337 to 0.97373, saving model to models/best_model_6_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0602 - acc: 0.9793 - precision_m: 0.8112 - recall_m: 0.5953 - f1_m: 0.6620 - val_loss: 0.0752 - val_acc: 0.9737 - val_precision_m: 0.7551 - val_recall_m: 0.4123 - val_f1_m: 0.5080\n",
      "Epoch 7/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0562 - acc: 0.9802 - precision_m: 0.8318 - recall_m: 0.6196 - f1_m: 0.6869\n",
      "Epoch 7: val_acc improved from 0.97373 to 0.97564, saving model to models/best_model_6_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0561 - acc: 0.9802 - precision_m: 0.8325 - recall_m: 0.6189 - f1_m: 0.6861 - val_loss: 0.0752 - val_acc: 0.9756 - val_precision_m: 0.7865 - val_recall_m: 0.4515 - val_f1_m: 0.5440\n",
      "Epoch 8/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0511 - acc: 0.9821 - precision_m: 0.8393 - recall_m: 0.6557 - f1_m: 0.7158\n",
      "Epoch 8: val_acc improved from 0.97564 to 0.97599, saving model to models/best_model_6_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0510 - acc: 0.9821 - precision_m: 0.8396 - recall_m: 0.6576 - f1_m: 0.7172 - val_loss: 0.0734 - val_acc: 0.9760 - val_precision_m: 0.7184 - val_recall_m: 0.5394 - val_f1_m: 0.5956\n",
      "Epoch 9/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9829 - precision_m: 0.8413 - recall_m: 0.6708 - f1_m: 0.7238\n",
      "Epoch 9: val_acc did not improve from 0.97599\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0479 - acc: 0.9829 - precision_m: 0.8413 - recall_m: 0.6719 - f1_m: 0.7246 - val_loss: 0.0745 - val_acc: 0.9737 - val_precision_m: 0.6236 - val_recall_m: 0.6302 - val_f1_m: 0.6082\n",
      "Epoch 10/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9842 - precision_m: 0.8530 - recall_m: 0.7068 - f1_m: 0.7552\n",
      "Epoch 10: val_acc did not improve from 0.97599\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0457 - acc: 0.9842 - precision_m: 0.8516 - recall_m: 0.7078 - f1_m: 0.7552 - val_loss: 0.0719 - val_acc: 0.9740 - val_precision_m: 0.6394 - val_recall_m: 0.6379 - val_f1_m: 0.6143\n",
      "Epoch 11/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9853 - precision_m: 0.8712 - recall_m: 0.7180 - f1_m: 0.7709\n",
      "Epoch 11: val_acc did not improve from 0.97599\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0418 - acc: 0.9853 - precision_m: 0.8712 - recall_m: 0.7187 - f1_m: 0.7713 - val_loss: 0.0750 - val_acc: 0.9760 - val_precision_m: 0.8216 - val_recall_m: 0.4711 - val_f1_m: 0.5660\n",
      "Epoch 12/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9861 - precision_m: 0.8678 - recall_m: 0.7438 - f1_m: 0.7865\n",
      "Epoch 12: val_acc improved from 0.97599 to 0.97767, saving model to models/best_model_6_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0392 - acc: 0.9861 - precision_m: 0.8677 - recall_m: 0.7442 - f1_m: 0.7867 - val_loss: 0.0784 - val_acc: 0.9777 - val_precision_m: 0.8336 - val_recall_m: 0.5089 - val_f1_m: 0.6014\n",
      "Epoch 13/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9863 - precision_m: 0.8774 - recall_m: 0.7477 - f1_m: 0.7910\n",
      "Epoch 13: val_acc did not improve from 0.97767\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0372 - acc: 0.9864 - precision_m: 0.8784 - recall_m: 0.7496 - f1_m: 0.7926 - val_loss: 0.0786 - val_acc: 0.9768 - val_precision_m: 0.7058 - val_recall_m: 0.5819 - val_f1_m: 0.6206\n",
      "Epoch 14/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0349 - acc: 0.9877 - precision_m: 0.8861 - recall_m: 0.7741 - f1_m: 0.8095\n",
      "Epoch 14: val_acc did not improve from 0.97767\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0348 - acc: 0.9877 - precision_m: 0.8855 - recall_m: 0.7755 - f1_m: 0.8101 - val_loss: 0.0870 - val_acc: 0.9765 - val_precision_m: 0.8638 - val_recall_m: 0.4593 - val_f1_m: 0.5609\n",
      "Epoch 15/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0323 - acc: 0.9882 - precision_m: 0.8945 - recall_m: 0.7805 - f1_m: 0.8180\n",
      "Epoch 15: val_acc did not improve from 0.97767\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0322 - acc: 0.9883 - precision_m: 0.8942 - recall_m: 0.7821 - f1_m: 0.8189 - val_loss: 0.0845 - val_acc: 0.9771 - val_precision_m: 0.7772 - val_recall_m: 0.5554 - val_f1_m: 0.6233\n",
      "Epoch 16/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0296 - acc: 0.9893 - precision_m: 0.9010 - recall_m: 0.8055 - f1_m: 0.8353\n",
      "Epoch 16: val_acc did not improve from 0.97767\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0297 - acc: 0.9892 - precision_m: 0.8995 - recall_m: 0.8068 - f1_m: 0.8353 - val_loss: 0.0804 - val_acc: 0.9759 - val_precision_m: 0.6889 - val_recall_m: 0.5819 - val_f1_m: 0.6049\n",
      "Epoch 17/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9894 - precision_m: 0.9045 - recall_m: 0.8154 - f1_m: 0.8440\n",
      "Epoch 17: val_acc did not improve from 0.97767\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0281 - acc: 0.9895 - precision_m: 0.9048 - recall_m: 0.8160 - f1_m: 0.8446 - val_loss: 0.0968 - val_acc: 0.9774 - val_precision_m: 0.7971 - val_recall_m: 0.5134 - val_f1_m: 0.5959\n",
      "Epoch 18/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0278 - acc: 0.9893 - precision_m: 0.9026 - recall_m: 0.8096 - f1_m: 0.8373\n",
      "Epoch 18: val_acc improved from 0.97767 to 0.97814, saving model to models/best_model_6_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0277 - acc: 0.9893 - precision_m: 0.9030 - recall_m: 0.8097 - f1_m: 0.8377 - val_loss: 0.0899 - val_acc: 0.9781 - val_precision_m: 0.7291 - val_recall_m: 0.6125 - val_f1_m: 0.6407\n",
      "Epoch 19/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9910 - precision_m: 0.9184 - recall_m: 0.8465 - f1_m: 0.8697\n",
      "Epoch 19: val_acc did not improve from 0.97814\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0247 - acc: 0.9910 - precision_m: 0.9179 - recall_m: 0.8465 - f1_m: 0.8694 - val_loss: 0.1002 - val_acc: 0.9737 - val_precision_m: 0.6512 - val_recall_m: 0.7147 - val_f1_m: 0.6541\n",
      "Epoch 20/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9918 - precision_m: 0.9161 - recall_m: 0.8649 - f1_m: 0.8806\n",
      "Epoch 20: val_acc did not improve from 0.97814\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0218 - acc: 0.9918 - precision_m: 0.9163 - recall_m: 0.8653 - f1_m: 0.8809 - val_loss: 0.0935 - val_acc: 0.9778 - val_precision_m: 0.7337 - val_recall_m: 0.5768 - val_f1_m: 0.6243\n",
      "Epoch 21/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9921 - precision_m: 0.9186 - recall_m: 0.8711 - f1_m: 0.8847\n",
      "Epoch 21: val_acc did not improve from 0.97814\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0208 - acc: 0.9921 - precision_m: 0.9190 - recall_m: 0.8716 - f1_m: 0.8852 - val_loss: 0.1035 - val_acc: 0.9755 - val_precision_m: 0.6892 - val_recall_m: 0.5799 - val_f1_m: 0.5946\n",
      "Epoch 22/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9934 - precision_m: 0.9348 - recall_m: 0.8887 - f1_m: 0.9031\n",
      "Epoch 22: val_acc did not improve from 0.97814\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0187 - acc: 0.9933 - precision_m: 0.9335 - recall_m: 0.8870 - f1_m: 0.9016 - val_loss: 0.1037 - val_acc: 0.9766 - val_precision_m: 0.7095 - val_recall_m: 0.5963 - val_f1_m: 0.6224\n",
      "Epoch 23/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9928 - precision_m: 0.9312 - recall_m: 0.8808 - f1_m: 0.8950\n",
      "Epoch 23: val_acc did not improve from 0.97814\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0193 - acc: 0.9928 - precision_m: 0.9315 - recall_m: 0.8813 - f1_m: 0.8953 - val_loss: 0.1004 - val_acc: 0.9765 - val_precision_m: 0.7030 - val_recall_m: 0.6257 - val_f1_m: 0.6369\n",
      "Epoch 24/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9935 - precision_m: 0.9352 - recall_m: 0.8967 - f1_m: 0.9069\n",
      "Epoch 24: val_acc did not improve from 0.97814\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0167 - acc: 0.9936 - precision_m: 0.9351 - recall_m: 0.8978 - f1_m: 0.9075 - val_loss: 0.1055 - val_acc: 0.9772 - val_precision_m: 0.6928 - val_recall_m: 0.6301 - val_f1_m: 0.6385\n",
      "Epoch 25/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0167 - acc: 0.9940 - precision_m: 0.9391 - recall_m: 0.9011 - f1_m: 0.9121\n",
      "Epoch 25: val_acc did not improve from 0.97814\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0167 - acc: 0.9939 - precision_m: 0.9384 - recall_m: 0.8999 - f1_m: 0.9110 - val_loss: 0.1109 - val_acc: 0.9780 - val_precision_m: 0.7160 - val_recall_m: 0.6004 - val_f1_m: 0.6312\n",
      "Epoch 26/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9948 - precision_m: 0.9416 - recall_m: 0.9054 - f1_m: 0.9177\n",
      "Epoch 26: val_acc did not improve from 0.97814\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0143 - acc: 0.9948 - precision_m: 0.9416 - recall_m: 0.9058 - f1_m: 0.9180 - val_loss: 0.1141 - val_acc: 0.9779 - val_precision_m: 0.7162 - val_recall_m: 0.6255 - val_f1_m: 0.6476\n",
      "Epoch 27/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9948 - precision_m: 0.9420 - recall_m: 0.9182 - f1_m: 0.9252\n",
      "Epoch 27: val_acc did not improve from 0.97814\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0137 - acc: 0.9948 - precision_m: 0.9425 - recall_m: 0.9166 - f1_m: 0.9245 - val_loss: 0.1436 - val_acc: 0.9760 - val_precision_m: 0.7256 - val_recall_m: 0.5234 - val_f1_m: 0.5788\n",
      "Epoch 28/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9952 - precision_m: 0.9553 - recall_m: 0.9197 - f1_m: 0.9318\n",
      "Epoch 28: val_acc did not improve from 0.97814\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0132 - acc: 0.9953 - precision_m: 0.9554 - recall_m: 0.9203 - f1_m: 0.9323 - val_loss: 0.1257 - val_acc: 0.9758 - val_precision_m: 0.6539 - val_recall_m: 0.6176 - val_f1_m: 0.6151\n",
      "Epoch 29/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9956 - precision_m: 0.9541 - recall_m: 0.9255 - f1_m: 0.9344\n",
      "Epoch 29: val_acc did not improve from 0.97814\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0117 - acc: 0.9956 - precision_m: 0.9545 - recall_m: 0.9261 - f1_m: 0.9350 - val_loss: 0.1235 - val_acc: 0.9736 - val_precision_m: 0.6039 - val_recall_m: 0.6938 - val_f1_m: 0.6288\n",
      "Epoch 30/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9953 - precision_m: 0.9503 - recall_m: 0.9233 - f1_m: 0.9313\n",
      "Epoch 30: val_acc did not improve from 0.97814\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0126 - acc: 0.9953 - precision_m: 0.9506 - recall_m: 0.9240 - f1_m: 0.9319 - val_loss: 0.1451 - val_acc: 0.9761 - val_precision_m: 0.7262 - val_recall_m: 0.5306 - val_f1_m: 0.5908\n",
      "Score for fold 1: loss of 0.08989149332046509; acc of 97.81440496444702%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.05692922696471214; acc of 98.32709431648254%\n",
      "Test Precision: precision_m of 25.545772910118103%\n",
      "Test Recall: recall_m of 21.330203115940094%\n",
      "Test F1: f1_m of 22.41954803466797%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.1217 - acc: 0.9666 - precision_m: 0.3574 - recall_m: 0.1092 - f1_m: 0.1530\n",
      "Epoch 1: val_acc improved from -inf to 0.97174, saving model to models/best_model_6_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 3s 6ms/step - loss: 0.1217 - acc: 0.9666 - precision_m: 0.3574 - recall_m: 0.1092 - f1_m: 0.1530 - val_loss: 0.0879 - val_acc: 0.9717 - val_precision_m: 0.7135 - val_recall_m: 0.2978 - val_f1_m: 0.3930\n",
      "Epoch 2/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0820 - acc: 0.9721 - precision_m: 0.7269 - recall_m: 0.3771 - f1_m: 0.4624\n",
      "Epoch 2: val_acc improved from 0.97174 to 0.97402, saving model to models/best_model_6_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0818 - acc: 0.9721 - precision_m: 0.7269 - recall_m: 0.3784 - f1_m: 0.4639 - val_loss: 0.0763 - val_acc: 0.9740 - val_precision_m: 0.7289 - val_recall_m: 0.3821 - val_f1_m: 0.4778\n",
      "Epoch 3/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0708 - acc: 0.9759 - precision_m: 0.7564 - recall_m: 0.4796 - f1_m: 0.5563\n",
      "Epoch 3: val_acc improved from 0.97402 to 0.97521, saving model to models/best_model_6_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0705 - acc: 0.9759 - precision_m: 0.7590 - recall_m: 0.4795 - f1_m: 0.5571 - val_loss: 0.0736 - val_acc: 0.9752 - val_precision_m: 0.7321 - val_recall_m: 0.4645 - val_f1_m: 0.5435\n",
      "Epoch 4/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0611 - acc: 0.9789 - precision_m: 0.7852 - recall_m: 0.5686 - f1_m: 0.6376\n",
      "Epoch 4: val_acc improved from 0.97521 to 0.97641, saving model to models/best_model_6_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0610 - acc: 0.9789 - precision_m: 0.7847 - recall_m: 0.5665 - f1_m: 0.6361 - val_loss: 0.0769 - val_acc: 0.9764 - val_precision_m: 0.7585 - val_recall_m: 0.4293 - val_f1_m: 0.5224\n",
      "Epoch 5/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0582 - acc: 0.9797 - precision_m: 0.8125 - recall_m: 0.5860 - f1_m: 0.6528\n",
      "Epoch 5: val_acc improved from 0.97641 to 0.97904, saving model to models/best_model_6_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0581 - acc: 0.9797 - precision_m: 0.8118 - recall_m: 0.5866 - f1_m: 0.6531 - val_loss: 0.0650 - val_acc: 0.9790 - val_precision_m: 0.7725 - val_recall_m: 0.5573 - val_f1_m: 0.6243\n",
      "Epoch 6/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0523 - acc: 0.9814 - precision_m: 0.8213 - recall_m: 0.6325 - f1_m: 0.6950\n",
      "Epoch 6: val_acc did not improve from 0.97904\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0521 - acc: 0.9815 - precision_m: 0.8214 - recall_m: 0.6341 - f1_m: 0.6961 - val_loss: 0.0774 - val_acc: 0.9780 - val_precision_m: 0.7841 - val_recall_m: 0.4971 - val_f1_m: 0.5803\n",
      "Epoch 7/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0485 - acc: 0.9835 - precision_m: 0.8528 - recall_m: 0.6688 - f1_m: 0.7299\n",
      "Epoch 7: val_acc improved from 0.97904 to 0.98084, saving model to models/best_model_6_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0486 - acc: 0.9834 - precision_m: 0.8518 - recall_m: 0.6686 - f1_m: 0.7292 - val_loss: 0.0602 - val_acc: 0.9808 - val_precision_m: 0.7580 - val_recall_m: 0.6670 - val_f1_m: 0.6813\n",
      "Epoch 8/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9840 - precision_m: 0.8509 - recall_m: 0.6834 - f1_m: 0.7360\n",
      "Epoch 8: val_acc did not improve from 0.98084\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0450 - acc: 0.9839 - precision_m: 0.8509 - recall_m: 0.6832 - f1_m: 0.7359 - val_loss: 0.0679 - val_acc: 0.9774 - val_precision_m: 0.6568 - val_recall_m: 0.6912 - val_f1_m: 0.6533\n",
      "Epoch 9/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9854 - precision_m: 0.8703 - recall_m: 0.7044 - f1_m: 0.7611\n",
      "Epoch 9: val_acc improved from 0.98084 to 0.98108, saving model to models/best_model_6_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0412 - acc: 0.9853 - precision_m: 0.8685 - recall_m: 0.7044 - f1_m: 0.7605 - val_loss: 0.0658 - val_acc: 0.9811 - val_precision_m: 0.7697 - val_recall_m: 0.6369 - val_f1_m: 0.6708\n",
      "Epoch 10/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9867 - precision_m: 0.8707 - recall_m: 0.7428 - f1_m: 0.7876\n",
      "Epoch 10: val_acc improved from 0.98108 to 0.98180, saving model to models/best_model_6_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0374 - acc: 0.9866 - precision_m: 0.8712 - recall_m: 0.7422 - f1_m: 0.7875 - val_loss: 0.0694 - val_acc: 0.9818 - val_precision_m: 0.8384 - val_recall_m: 0.6238 - val_f1_m: 0.6829\n",
      "Epoch 11/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9881 - precision_m: 0.8890 - recall_m: 0.7673 - f1_m: 0.8074\n",
      "Epoch 11: val_acc did not improve from 0.98180\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0345 - acc: 0.9881 - precision_m: 0.8894 - recall_m: 0.7671 - f1_m: 0.8075 - val_loss: 0.0694 - val_acc: 0.9807 - val_precision_m: 0.8219 - val_recall_m: 0.5888 - val_f1_m: 0.6627\n",
      "Epoch 12/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9885 - precision_m: 0.8898 - recall_m: 0.7875 - f1_m: 0.8229\n",
      "Epoch 12: val_acc did not improve from 0.98180\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0318 - acc: 0.9886 - precision_m: 0.8906 - recall_m: 0.7879 - f1_m: 0.8234 - val_loss: 0.0812 - val_acc: 0.9793 - val_precision_m: 0.8370 - val_recall_m: 0.5432 - val_f1_m: 0.6316\n",
      "Epoch 13/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9889 - precision_m: 0.8984 - recall_m: 0.7937 - f1_m: 0.8256\n",
      "Epoch 13: val_acc improved from 0.98180 to 0.98204, saving model to models/best_model_6_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0311 - acc: 0.9889 - precision_m: 0.8960 - recall_m: 0.7939 - f1_m: 0.8245 - val_loss: 0.0692 - val_acc: 0.9820 - val_precision_m: 0.8008 - val_recall_m: 0.6286 - val_f1_m: 0.6740\n",
      "Epoch 14/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0268 - acc: 0.9903 - precision_m: 0.9036 - recall_m: 0.8210 - f1_m: 0.8489\n",
      "Epoch 14: val_acc did not improve from 0.98204\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0268 - acc: 0.9903 - precision_m: 0.9032 - recall_m: 0.8213 - f1_m: 0.8489 - val_loss: 0.0730 - val_acc: 0.9811 - val_precision_m: 0.7452 - val_recall_m: 0.6674 - val_f1_m: 0.6823\n",
      "Epoch 15/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.9909 - precision_m: 0.9171 - recall_m: 0.8301 - f1_m: 0.8578\n",
      "Epoch 15: val_acc did not improve from 0.98204\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0251 - acc: 0.9909 - precision_m: 0.9180 - recall_m: 0.8298 - f1_m: 0.8581 - val_loss: 0.0673 - val_acc: 0.9807 - val_precision_m: 0.7409 - val_recall_m: 0.6903 - val_f1_m: 0.6852\n",
      "Epoch 16/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9915 - precision_m: 0.9139 - recall_m: 0.8399 - f1_m: 0.8612\n",
      "Epoch 16: val_acc did not improve from 0.98204\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0235 - acc: 0.9915 - precision_m: 0.9144 - recall_m: 0.8403 - f1_m: 0.8617 - val_loss: 0.0740 - val_acc: 0.9817 - val_precision_m: 0.8038 - val_recall_m: 0.6260 - val_f1_m: 0.6778\n",
      "Epoch 17/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9917 - precision_m: 0.9204 - recall_m: 0.8466 - f1_m: 0.8705\n",
      "Epoch 17: val_acc did not improve from 0.98204\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0229 - acc: 0.9917 - precision_m: 0.9210 - recall_m: 0.8462 - f1_m: 0.8705 - val_loss: 0.0802 - val_acc: 0.9810 - val_precision_m: 0.7488 - val_recall_m: 0.6414 - val_f1_m: 0.6666\n",
      "Epoch 18/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9934 - precision_m: 0.9336 - recall_m: 0.8807 - f1_m: 0.8993\n",
      "Epoch 18: val_acc did not improve from 0.98204\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0183 - acc: 0.9934 - precision_m: 0.9318 - recall_m: 0.8811 - f1_m: 0.8984 - val_loss: 0.0757 - val_acc: 0.9808 - val_precision_m: 0.7229 - val_recall_m: 0.6957 - val_f1_m: 0.6843\n",
      "Epoch 19/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9935 - precision_m: 0.9355 - recall_m: 0.8773 - f1_m: 0.8958\n",
      "Epoch 19: val_acc did not improve from 0.98204\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0180 - acc: 0.9934 - precision_m: 0.9343 - recall_m: 0.8772 - f1_m: 0.8950 - val_loss: 0.1005 - val_acc: 0.9816 - val_precision_m: 0.7872 - val_recall_m: 0.6145 - val_f1_m: 0.6670\n",
      "Epoch 20/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9937 - precision_m: 0.9330 - recall_m: 0.8887 - f1_m: 0.9020\n",
      "Epoch 20: val_acc did not improve from 0.98204\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0175 - acc: 0.9936 - precision_m: 0.9334 - recall_m: 0.8882 - f1_m: 0.9019 - val_loss: 0.1033 - val_acc: 0.9690 - val_precision_m: 0.5384 - val_recall_m: 0.7397 - val_f1_m: 0.6026\n",
      "Epoch 21/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9940 - precision_m: 0.9382 - recall_m: 0.8956 - f1_m: 0.9069\n",
      "Epoch 21: val_acc did not improve from 0.98204\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0163 - acc: 0.9940 - precision_m: 0.9387 - recall_m: 0.8958 - f1_m: 0.9073 - val_loss: 0.0777 - val_acc: 0.9806 - val_precision_m: 0.7331 - val_recall_m: 0.6659 - val_f1_m: 0.6771\n",
      "Epoch 22/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9955 - precision_m: 0.9557 - recall_m: 0.9141 - f1_m: 0.9288\n",
      "Epoch 22: val_acc did not improve from 0.98204\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0127 - acc: 0.9955 - precision_m: 0.9549 - recall_m: 0.9138 - f1_m: 0.9282 - val_loss: 0.1049 - val_acc: 0.9810 - val_precision_m: 0.7339 - val_recall_m: 0.6797 - val_f1_m: 0.6865\n",
      "Epoch 23/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9952 - precision_m: 0.9485 - recall_m: 0.9145 - f1_m: 0.9255\n",
      "Epoch 23: val_acc did not improve from 0.98204\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0127 - acc: 0.9952 - precision_m: 0.9481 - recall_m: 0.9139 - f1_m: 0.9250 - val_loss: 0.0923 - val_acc: 0.9807 - val_precision_m: 0.7245 - val_recall_m: 0.6999 - val_f1_m: 0.6907\n",
      "Epoch 24/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9955 - precision_m: 0.9524 - recall_m: 0.9223 - f1_m: 0.9310\n",
      "Epoch 24: val_acc improved from 0.98204 to 0.98252, saving model to models/best_model_6_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0122 - acc: 0.9955 - precision_m: 0.9527 - recall_m: 0.9228 - f1_m: 0.9314 - val_loss: 0.1101 - val_acc: 0.9825 - val_precision_m: 0.7835 - val_recall_m: 0.6547 - val_f1_m: 0.6913\n",
      "Epoch 25/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0114 - acc: 0.9960 - precision_m: 0.9596 - recall_m: 0.9325 - f1_m: 0.9413\n",
      "Epoch 25: val_acc did not improve from 0.98252\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0114 - acc: 0.9960 - precision_m: 0.9597 - recall_m: 0.9330 - f1_m: 0.9415 - val_loss: 0.0963 - val_acc: 0.9786 - val_precision_m: 0.6658 - val_recall_m: 0.7043 - val_f1_m: 0.6600\n",
      "Epoch 26/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9962 - precision_m: 0.9588 - recall_m: 0.9381 - f1_m: 0.9442\n",
      "Epoch 26: val_acc did not improve from 0.98252\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0114 - acc: 0.9962 - precision_m: 0.9596 - recall_m: 0.9364 - f1_m: 0.9434 - val_loss: 0.1032 - val_acc: 0.9819 - val_precision_m: 0.7759 - val_recall_m: 0.6508 - val_f1_m: 0.6818\n",
      "Epoch 27/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0116 - acc: 0.9958 - precision_m: 0.9548 - recall_m: 0.9288 - f1_m: 0.9351\n",
      "Epoch 27: val_acc did not improve from 0.98252\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0115 - acc: 0.9958 - precision_m: 0.9549 - recall_m: 0.9296 - f1_m: 0.9356 - val_loss: 0.0991 - val_acc: 0.9820 - val_precision_m: 0.7580 - val_recall_m: 0.6920 - val_f1_m: 0.6954\n",
      "Epoch 28/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9969 - precision_m: 0.9686 - recall_m: 0.9470 - f1_m: 0.9541\n",
      "Epoch 28: val_acc did not improve from 0.98252\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0087 - acc: 0.9969 - precision_m: 0.9689 - recall_m: 0.9469 - f1_m: 0.9543 - val_loss: 0.1092 - val_acc: 0.9812 - val_precision_m: 0.7483 - val_recall_m: 0.6494 - val_f1_m: 0.6712\n",
      "Epoch 29/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9975 - precision_m: 0.9742 - recall_m: 0.9582 - f1_m: 0.9641\n",
      "Epoch 29: val_acc did not improve from 0.98252\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0072 - acc: 0.9975 - precision_m: 0.9745 - recall_m: 0.9578 - f1_m: 0.9640 - val_loss: 0.1415 - val_acc: 0.9814 - val_precision_m: 0.7725 - val_recall_m: 0.6402 - val_f1_m: 0.6757\n",
      "Epoch 30/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9960 - precision_m: 0.9589 - recall_m: 0.9357 - f1_m: 0.9408\n",
      "Epoch 30: val_acc did not improve from 0.98252\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0115 - acc: 0.9961 - precision_m: 0.9592 - recall_m: 0.9362 - f1_m: 0.9412 - val_loss: 0.1345 - val_acc: 0.9819 - val_precision_m: 0.8064 - val_recall_m: 0.6186 - val_f1_m: 0.6780\n",
      "Score for fold 2: loss of 0.11013027280569077; acc of 98.25170636177063%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.10150610655546188; acc of 98.05856347084045%\n",
      "Test Precision: precision_m of 32.10616111755371%\n",
      "Test Recall: recall_m of 25.80167055130005%\n",
      "Test F1: f1_m of 27.336999773979187%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.1345 - acc: 0.9638 - precision_m: 0.2244 - recall_m: 0.0659 - f1_m: 0.0937\n",
      "Epoch 1: val_acc improved from -inf to 0.97005, saving model to models/best_model_6_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 3s 6ms/step - loss: 0.1345 - acc: 0.9638 - precision_m: 0.2244 - recall_m: 0.0659 - f1_m: 0.0937 - val_loss: 0.0979 - val_acc: 0.9701 - val_precision_m: 0.6251 - val_recall_m: 0.2976 - val_f1_m: 0.3777\n",
      "Epoch 2/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0863 - acc: 0.9706 - precision_m: 0.7090 - recall_m: 0.3556 - f1_m: 0.4393\n",
      "Epoch 2: val_acc improved from 0.97005 to 0.97077, saving model to models/best_model_6_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0867 - acc: 0.9705 - precision_m: 0.7065 - recall_m: 0.3578 - f1_m: 0.4401 - val_loss: 0.0849 - val_acc: 0.9708 - val_precision_m: 0.7058 - val_recall_m: 0.1981 - val_f1_m: 0.2911\n",
      "Epoch 3/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0766 - acc: 0.9729 - precision_m: 0.7360 - recall_m: 0.4296 - f1_m: 0.5069\n",
      "Epoch 3: val_acc improved from 0.97077 to 0.97568, saving model to models/best_model_6_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0767 - acc: 0.9730 - precision_m: 0.7347 - recall_m: 0.4332 - f1_m: 0.5092 - val_loss: 0.0750 - val_acc: 0.9757 - val_precision_m: 0.7195 - val_recall_m: 0.4206 - val_f1_m: 0.5076\n",
      "Epoch 4/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0671 - acc: 0.9766 - precision_m: 0.7773 - recall_m: 0.5226 - f1_m: 0.5943\n",
      "Epoch 4: val_acc improved from 0.97568 to 0.97628, saving model to models/best_model_6_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0672 - acc: 0.9765 - precision_m: 0.7758 - recall_m: 0.5216 - f1_m: 0.5929 - val_loss: 0.0712 - val_acc: 0.9763 - val_precision_m: 0.6504 - val_recall_m: 0.5208 - val_f1_m: 0.5584\n",
      "Epoch 5/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9783 - precision_m: 0.8105 - recall_m: 0.5679 - f1_m: 0.6388\n",
      "Epoch 5: val_acc improved from 0.97628 to 0.97772, saving model to models/best_model_6_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0618 - acc: 0.9783 - precision_m: 0.8096 - recall_m: 0.5683 - f1_m: 0.6388 - val_loss: 0.0645 - val_acc: 0.9777 - val_precision_m: 0.6817 - val_recall_m: 0.4949 - val_f1_m: 0.5548\n",
      "Epoch 6/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0560 - acc: 0.9804 - precision_m: 0.8084 - recall_m: 0.6223 - f1_m: 0.6810\n",
      "Epoch 6: val_acc improved from 0.97772 to 0.97832, saving model to models/best_model_6_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0560 - acc: 0.9805 - precision_m: 0.8106 - recall_m: 0.6237 - f1_m: 0.6829 - val_loss: 0.0635 - val_acc: 0.9783 - val_precision_m: 0.7233 - val_recall_m: 0.5975 - val_f1_m: 0.6267\n",
      "Epoch 7/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0517 - acc: 0.9819 - precision_m: 0.8415 - recall_m: 0.6455 - f1_m: 0.7059\n",
      "Epoch 7: val_acc did not improve from 0.97832\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0517 - acc: 0.9819 - precision_m: 0.8419 - recall_m: 0.6459 - f1_m: 0.7061 - val_loss: 0.0714 - val_acc: 0.9777 - val_precision_m: 0.7835 - val_recall_m: 0.4380 - val_f1_m: 0.5404\n",
      "Epoch 8/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9833 - precision_m: 0.8500 - recall_m: 0.6901 - f1_m: 0.7394\n",
      "Epoch 8: val_acc did not improve from 0.97832\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0483 - acc: 0.9833 - precision_m: 0.8483 - recall_m: 0.6906 - f1_m: 0.7391 - val_loss: 0.0645 - val_acc: 0.9783 - val_precision_m: 0.7809 - val_recall_m: 0.4766 - val_f1_m: 0.5660\n",
      "Epoch 9/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9841 - precision_m: 0.8571 - recall_m: 0.7011 - f1_m: 0.7523\n",
      "Epoch 9: val_acc improved from 0.97832 to 0.97940, saving model to models/best_model_6_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0446 - acc: 0.9842 - precision_m: 0.8569 - recall_m: 0.7017 - f1_m: 0.7524 - val_loss: 0.0644 - val_acc: 0.9794 - val_precision_m: 0.8015 - val_recall_m: 0.5641 - val_f1_m: 0.6369\n",
      "Epoch 10/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0396 - acc: 0.9859 - precision_m: 0.8643 - recall_m: 0.7380 - f1_m: 0.7809\n",
      "Epoch 10: val_acc improved from 0.97940 to 0.98071, saving model to models/best_model_6_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0397 - acc: 0.9859 - precision_m: 0.8641 - recall_m: 0.7369 - f1_m: 0.7802 - val_loss: 0.0600 - val_acc: 0.9807 - val_precision_m: 0.7553 - val_recall_m: 0.6079 - val_f1_m: 0.6532\n",
      "Epoch 11/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9864 - precision_m: 0.8678 - recall_m: 0.7551 - f1_m: 0.7918\n",
      "Epoch 11: val_acc improved from 0.98071 to 0.98119, saving model to models/best_model_6_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0377 - acc: 0.9865 - precision_m: 0.8658 - recall_m: 0.7555 - f1_m: 0.7910 - val_loss: 0.0585 - val_acc: 0.9812 - val_precision_m: 0.7559 - val_recall_m: 0.5888 - val_f1_m: 0.6372\n",
      "Epoch 12/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9879 - precision_m: 0.8834 - recall_m: 0.7835 - f1_m: 0.8160\n",
      "Epoch 12: val_acc did not improve from 0.98119\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0340 - acc: 0.9879 - precision_m: 0.8829 - recall_m: 0.7835 - f1_m: 0.8157 - val_loss: 0.0662 - val_acc: 0.9802 - val_precision_m: 0.7403 - val_recall_m: 0.6201 - val_f1_m: 0.6516\n",
      "Epoch 13/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9884 - precision_m: 0.8919 - recall_m: 0.7886 - f1_m: 0.8237\n",
      "Epoch 13: val_acc did not improve from 0.98119\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0326 - acc: 0.9883 - precision_m: 0.8919 - recall_m: 0.7850 - f1_m: 0.8212 - val_loss: 0.0747 - val_acc: 0.9790 - val_precision_m: 0.8378 - val_recall_m: 0.4527 - val_f1_m: 0.5662\n",
      "Epoch 14/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9890 - precision_m: 0.8978 - recall_m: 0.7948 - f1_m: 0.8284\n",
      "Epoch 14: val_acc improved from 0.98119 to 0.98131, saving model to models/best_model_6_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0307 - acc: 0.9890 - precision_m: 0.8971 - recall_m: 0.7954 - f1_m: 0.8285 - val_loss: 0.0618 - val_acc: 0.9813 - val_precision_m: 0.7855 - val_recall_m: 0.5663 - val_f1_m: 0.6357\n",
      "Epoch 15/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9902 - precision_m: 0.9084 - recall_m: 0.8158 - f1_m: 0.8463\n",
      "Epoch 15: val_acc improved from 0.98131 to 0.98179, saving model to models/best_model_6_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0275 - acc: 0.9902 - precision_m: 0.9094 - recall_m: 0.8145 - f1_m: 0.8459 - val_loss: 0.0654 - val_acc: 0.9818 - val_precision_m: 0.7413 - val_recall_m: 0.6625 - val_f1_m: 0.6826\n",
      "Epoch 16/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9906 - precision_m: 0.9067 - recall_m: 0.8366 - f1_m: 0.8580\n",
      "Epoch 16: val_acc improved from 0.98179 to 0.98419, saving model to models/best_model_6_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0258 - acc: 0.9906 - precision_m: 0.9067 - recall_m: 0.8351 - f1_m: 0.8573 - val_loss: 0.0645 - val_acc: 0.9842 - val_precision_m: 0.8295 - val_recall_m: 0.6617 - val_f1_m: 0.7129\n",
      "Epoch 17/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9918 - precision_m: 0.9195 - recall_m: 0.8537 - f1_m: 0.8757\n",
      "Epoch 17: val_acc did not improve from 0.98419\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0224 - acc: 0.9917 - precision_m: 0.9177 - recall_m: 0.8535 - f1_m: 0.8745 - val_loss: 0.0700 - val_acc: 0.9781 - val_precision_m: 0.6713 - val_recall_m: 0.7183 - val_f1_m: 0.6659\n",
      "Epoch 18/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0209 - acc: 0.9923 - precision_m: 0.9255 - recall_m: 0.8621 - f1_m: 0.8853\n",
      "Epoch 18: val_acc did not improve from 0.98419\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0210 - acc: 0.9923 - precision_m: 0.9243 - recall_m: 0.8624 - f1_m: 0.8846 - val_loss: 0.0690 - val_acc: 0.9811 - val_precision_m: 0.7522 - val_recall_m: 0.6576 - val_f1_m: 0.6683\n",
      "Epoch 19/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0200 - acc: 0.9924 - precision_m: 0.9259 - recall_m: 0.8705 - f1_m: 0.8881\n",
      "Epoch 19: val_acc did not improve from 0.98419\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0199 - acc: 0.9924 - precision_m: 0.9258 - recall_m: 0.8699 - f1_m: 0.8878 - val_loss: 0.0691 - val_acc: 0.9807 - val_precision_m: 0.6934 - val_recall_m: 0.6841 - val_f1_m: 0.6763\n",
      "Epoch 20/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9939 - precision_m: 0.9387 - recall_m: 0.8912 - f1_m: 0.9083\n",
      "Epoch 20: val_acc did not improve from 0.98419\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0165 - acc: 0.9940 - precision_m: 0.9387 - recall_m: 0.8927 - f1_m: 0.9091 - val_loss: 0.0803 - val_acc: 0.9829 - val_precision_m: 0.8066 - val_recall_m: 0.6467 - val_f1_m: 0.6900\n",
      "Epoch 21/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.0155 - acc: 0.9941 - precision_m: 0.9407 - recall_m: 0.9010 - f1_m: 0.9140\n",
      "Epoch 21: val_acc did not improve from 0.98419\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0156 - acc: 0.9941 - precision_m: 0.9398 - recall_m: 0.9006 - f1_m: 0.9134 - val_loss: 0.0855 - val_acc: 0.9799 - val_precision_m: 0.7141 - val_recall_m: 0.6729 - val_f1_m: 0.6772\n",
      "Epoch 22/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9942 - precision_m: 0.9375 - recall_m: 0.9030 - f1_m: 0.9124\n",
      "Epoch 22: val_acc did not improve from 0.98419\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0159 - acc: 0.9942 - precision_m: 0.9365 - recall_m: 0.9020 - f1_m: 0.9114 - val_loss: 0.0837 - val_acc: 0.9810 - val_precision_m: 0.7124 - val_recall_m: 0.7189 - val_f1_m: 0.6938\n",
      "Epoch 23/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9948 - precision_m: 0.9475 - recall_m: 0.9180 - f1_m: 0.9253\n",
      "Epoch 23: val_acc did not improve from 0.98419\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0141 - acc: 0.9947 - precision_m: 0.9467 - recall_m: 0.9141 - f1_m: 0.9227 - val_loss: 0.0952 - val_acc: 0.9750 - val_precision_m: 0.6048 - val_recall_m: 0.7324 - val_f1_m: 0.6418\n",
      "Epoch 24/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0142 - acc: 0.9947 - precision_m: 0.9454 - recall_m: 0.9124 - f1_m: 0.9213\n",
      "Epoch 24: val_acc did not improve from 0.98419\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0141 - acc: 0.9948 - precision_m: 0.9456 - recall_m: 0.9136 - f1_m: 0.9220 - val_loss: 0.0875 - val_acc: 0.9825 - val_precision_m: 0.7594 - val_recall_m: 0.6359 - val_f1_m: 0.6762\n",
      "Epoch 25/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9959 - precision_m: 0.9554 - recall_m: 0.9359 - f1_m: 0.9418\n",
      "Epoch 25: val_acc did not improve from 0.98419\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0112 - acc: 0.9960 - precision_m: 0.9557 - recall_m: 0.9368 - f1_m: 0.9424 - val_loss: 0.1150 - val_acc: 0.9805 - val_precision_m: 0.7329 - val_recall_m: 0.6558 - val_f1_m: 0.6736\n",
      "Epoch 26/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 0.9956 - precision_m: 0.9527 - recall_m: 0.9303 - f1_m: 0.9352\n",
      "Epoch 26: val_acc did not improve from 0.98419\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0120 - acc: 0.9956 - precision_m: 0.9528 - recall_m: 0.9305 - f1_m: 0.9354 - val_loss: 0.1194 - val_acc: 0.9828 - val_precision_m: 0.8363 - val_recall_m: 0.5785 - val_f1_m: 0.6568\n",
      "Epoch 27/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9952 - precision_m: 0.9437 - recall_m: 0.9184 - f1_m: 0.9253\n",
      "Epoch 27: val_acc did not improve from 0.98419\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0130 - acc: 0.9952 - precision_m: 0.9430 - recall_m: 0.9188 - f1_m: 0.9252 - val_loss: 0.1153 - val_acc: 0.9833 - val_precision_m: 0.7989 - val_recall_m: 0.6691 - val_f1_m: 0.7059\n",
      "Epoch 28/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9962 - precision_m: 0.9562 - recall_m: 0.9427 - f1_m: 0.9448\n",
      "Epoch 28: val_acc did not improve from 0.98419\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0100 - acc: 0.9962 - precision_m: 0.9561 - recall_m: 0.9433 - f1_m: 0.9451 - val_loss: 0.1103 - val_acc: 0.9829 - val_precision_m: 0.7912 - val_recall_m: 0.6652 - val_f1_m: 0.6898\n",
      "Epoch 29/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9961 - precision_m: 0.9624 - recall_m: 0.9399 - f1_m: 0.9456\n",
      "Epoch 29: val_acc did not improve from 0.98419\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0105 - acc: 0.9961 - precision_m: 0.9624 - recall_m: 0.9397 - f1_m: 0.9455 - val_loss: 0.0974 - val_acc: 0.9826 - val_precision_m: 0.7599 - val_recall_m: 0.6951 - val_f1_m: 0.7078\n",
      "Epoch 30/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9965 - precision_m: 0.9607 - recall_m: 0.9448 - f1_m: 0.9487\n",
      "Epoch 30: val_acc did not improve from 0.98419\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0100 - acc: 0.9965 - precision_m: 0.9597 - recall_m: 0.9457 - f1_m: 0.9486 - val_loss: 0.1197 - val_acc: 0.9837 - val_precision_m: 0.8223 - val_recall_m: 0.6140 - val_f1_m: 0.6750\n",
      "Score for fold 3: loss of 0.06453768163919449; acc of 98.41878414154053%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.07426474243402481; acc of 98.05908203125%\n",
      "Test Precision: precision_m of 29.39341962337494%\n",
      "Test Recall: recall_m of 23.741497099399567%\n",
      "Test F1: f1_m of 25.340357422828674%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1259 - acc: 0.9654 - precision_m: 0.2504 - recall_m: 0.0728 - f1_m: 0.1036\n",
      "Epoch 1: val_acc improved from -inf to 0.96143, saving model to models/best_model_6_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 3s 6ms/step - loss: 0.1259 - acc: 0.9654 - precision_m: 0.2504 - recall_m: 0.0728 - f1_m: 0.1036 - val_loss: 0.1476 - val_acc: 0.9614 - val_precision_m: 0.0152 - val_recall_m: 0.0025 - val_f1_m: 0.0043\n",
      "Epoch 2/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0865 - acc: 0.9711 - precision_m: 0.6433 - recall_m: 0.3194 - f1_m: 0.3995\n",
      "Epoch 2: val_acc improved from 0.96143 to 0.96693, saving model to models/best_model_6_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0863 - acc: 0.9711 - precision_m: 0.6411 - recall_m: 0.3222 - f1_m: 0.4011 - val_loss: 0.1142 - val_acc: 0.9669 - val_precision_m: 0.5556 - val_recall_m: 0.1581 - val_f1_m: 0.2224\n",
      "Epoch 3/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0732 - acc: 0.9747 - precision_m: 0.7485 - recall_m: 0.4519 - f1_m: 0.5292\n",
      "Epoch 3: val_acc did not improve from 0.96693\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0731 - acc: 0.9747 - precision_m: 0.7490 - recall_m: 0.4542 - f1_m: 0.5312 - val_loss: 0.1046 - val_acc: 0.9594 - val_precision_m: 0.4685 - val_recall_m: 0.6767 - val_f1_m: 0.5237\n",
      "Epoch 4/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0712 - acc: 0.9760 - precision_m: 0.7655 - recall_m: 0.4869 - f1_m: 0.5607\n",
      "Epoch 4: val_acc improved from 0.96693 to 0.97469, saving model to models/best_model_6_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0711 - acc: 0.9760 - precision_m: 0.7630 - recall_m: 0.4855 - f1_m: 0.5592 - val_loss: 0.0770 - val_acc: 0.9747 - val_precision_m: 0.6755 - val_recall_m: 0.5503 - val_f1_m: 0.5814\n",
      "Epoch 5/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0594 - acc: 0.9797 - precision_m: 0.8042 - recall_m: 0.5652 - f1_m: 0.6363\n",
      "Epoch 5: val_acc did not improve from 0.97469\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0593 - acc: 0.9797 - precision_m: 0.8017 - recall_m: 0.5662 - f1_m: 0.6363 - val_loss: 0.1380 - val_acc: 0.9448 - val_precision_m: 0.3742 - val_recall_m: 0.7643 - val_f1_m: 0.4796\n",
      "Epoch 6/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0613 - acc: 0.9791 - precision_m: 0.7949 - recall_m: 0.5669 - f1_m: 0.6386\n",
      "Epoch 6: val_acc did not improve from 0.97469\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0613 - acc: 0.9792 - precision_m: 0.7924 - recall_m: 0.5660 - f1_m: 0.6372 - val_loss: 0.0795 - val_acc: 0.9747 - val_precision_m: 0.7698 - val_recall_m: 0.4133 - val_f1_m: 0.5062\n",
      "Epoch 7/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0545 - acc: 0.9813 - precision_m: 0.8325 - recall_m: 0.6221 - f1_m: 0.6837\n",
      "Epoch 7: val_acc improved from 0.97469 to 0.97481, saving model to models/best_model_6_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0546 - acc: 0.9813 - precision_m: 0.8302 - recall_m: 0.6190 - f1_m: 0.6806 - val_loss: 0.0826 - val_acc: 0.9748 - val_precision_m: 0.8475 - val_recall_m: 0.3683 - val_f1_m: 0.4762\n",
      "Epoch 8/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9835 - precision_m: 0.8443 - recall_m: 0.6563 - f1_m: 0.7167\n",
      "Epoch 8: val_acc did not improve from 0.97481\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0478 - acc: 0.9835 - precision_m: 0.8407 - recall_m: 0.6540 - f1_m: 0.7141 - val_loss: 0.0742 - val_acc: 0.9736 - val_precision_m: 0.6558 - val_recall_m: 0.6155 - val_f1_m: 0.6095\n",
      "Epoch 9/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9841 - precision_m: 0.8481 - recall_m: 0.6919 - f1_m: 0.7414\n",
      "Epoch 9: val_acc improved from 0.97481 to 0.97887, saving model to models/best_model_6_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0456 - acc: 0.9840 - precision_m: 0.8435 - recall_m: 0.6887 - f1_m: 0.7378 - val_loss: 0.0708 - val_acc: 0.9789 - val_precision_m: 0.8414 - val_recall_m: 0.4837 - val_f1_m: 0.5759\n",
      "Epoch 10/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9847 - precision_m: 0.8584 - recall_m: 0.6967 - f1_m: 0.7487\n",
      "Epoch 10: val_acc did not improve from 0.97887\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0434 - acc: 0.9848 - precision_m: 0.8542 - recall_m: 0.6940 - f1_m: 0.7457 - val_loss: 0.0788 - val_acc: 0.9789 - val_precision_m: 0.8253 - val_recall_m: 0.4944 - val_f1_m: 0.5862\n",
      "Epoch 11/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9864 - precision_m: 0.8761 - recall_m: 0.7342 - f1_m: 0.7817\n",
      "Epoch 11: val_acc improved from 0.97887 to 0.97934, saving model to models/best_model_6_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0391 - acc: 0.9864 - precision_m: 0.8731 - recall_m: 0.7323 - f1_m: 0.7795 - val_loss: 0.0670 - val_acc: 0.9793 - val_precision_m: 0.7711 - val_recall_m: 0.5648 - val_f1_m: 0.6210\n",
      "Epoch 12/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0369 - acc: 0.9868 - precision_m: 0.8700 - recall_m: 0.7470 - f1_m: 0.7900\n",
      "Epoch 12: val_acc did not improve from 0.97934\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0369 - acc: 0.9868 - precision_m: 0.8669 - recall_m: 0.7445 - f1_m: 0.7872 - val_loss: 0.0627 - val_acc: 0.9785 - val_precision_m: 0.7073 - val_recall_m: 0.6468 - val_f1_m: 0.6387\n",
      "Epoch 13/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9877 - precision_m: 0.8871 - recall_m: 0.7631 - f1_m: 0.8050\n",
      "Epoch 13: val_acc did not improve from 0.97934\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0341 - acc: 0.9878 - precision_m: 0.8836 - recall_m: 0.7630 - f1_m: 0.8036 - val_loss: 0.0904 - val_acc: 0.9791 - val_precision_m: 0.8573 - val_recall_m: 0.4995 - val_f1_m: 0.5931\n",
      "Epoch 14/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0308 - acc: 0.9890 - precision_m: 0.9013 - recall_m: 0.7923 - f1_m: 0.8300\n",
      "Epoch 14: val_acc did not improve from 0.97934\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0308 - acc: 0.9890 - precision_m: 0.8981 - recall_m: 0.7900 - f1_m: 0.8273 - val_loss: 0.0834 - val_acc: 0.9778 - val_precision_m: 0.8247 - val_recall_m: 0.4839 - val_f1_m: 0.5753\n",
      "Epoch 15/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0288 - acc: 0.9893 - precision_m: 0.8971 - recall_m: 0.8000 - f1_m: 0.8350\n",
      "Epoch 15: val_acc improved from 0.97934 to 0.98090, saving model to models/best_model_6_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0289 - acc: 0.9893 - precision_m: 0.8940 - recall_m: 0.7957 - f1_m: 0.8311 - val_loss: 0.0741 - val_acc: 0.9809 - val_precision_m: 0.8037 - val_recall_m: 0.6149 - val_f1_m: 0.6700\n",
      "Epoch 16/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9908 - precision_m: 0.9010 - recall_m: 0.8211 - f1_m: 0.8476\n",
      "Epoch 16: val_acc did not improve from 0.98090\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0257 - acc: 0.9908 - precision_m: 0.8993 - recall_m: 0.8187 - f1_m: 0.8457 - val_loss: 0.0707 - val_acc: 0.9777 - val_precision_m: 0.6764 - val_recall_m: 0.6802 - val_f1_m: 0.6515\n",
      "Epoch 17/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9909 - precision_m: 0.9111 - recall_m: 0.8321 - f1_m: 0.8578\n",
      "Epoch 17: val_acc did not improve from 0.98090\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0250 - acc: 0.9909 - precision_m: 0.9084 - recall_m: 0.8287 - f1_m: 0.8547 - val_loss: 0.0891 - val_acc: 0.9803 - val_precision_m: 0.8018 - val_recall_m: 0.5882 - val_f1_m: 0.6501\n",
      "Epoch 18/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0214 - acc: 0.9924 - precision_m: 0.9254 - recall_m: 0.8602 - f1_m: 0.8815\n",
      "Epoch 18: val_acc did not improve from 0.98090\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0215 - acc: 0.9923 - precision_m: 0.9213 - recall_m: 0.8574 - f1_m: 0.8781 - val_loss: 0.0981 - val_acc: 0.9785 - val_precision_m: 0.8218 - val_recall_m: 0.4864 - val_f1_m: 0.5774\n",
      "Epoch 19/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9920 - precision_m: 0.9249 - recall_m: 0.8541 - f1_m: 0.8768\n",
      "Epoch 19: val_acc did not improve from 0.98090\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0211 - acc: 0.9921 - precision_m: 0.9206 - recall_m: 0.8528 - f1_m: 0.8739 - val_loss: 0.1038 - val_acc: 0.9796 - val_precision_m: 0.8598 - val_recall_m: 0.5286 - val_f1_m: 0.6216\n",
      "Epoch 20/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9933 - precision_m: 0.9348 - recall_m: 0.8801 - f1_m: 0.8987\n",
      "Epoch 20: val_acc did not improve from 0.98090\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0191 - acc: 0.9932 - precision_m: 0.9319 - recall_m: 0.8748 - f1_m: 0.8940 - val_loss: 0.1011 - val_acc: 0.9768 - val_precision_m: 0.7763 - val_recall_m: 0.4879 - val_f1_m: 0.5611\n",
      "Epoch 21/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9935 - precision_m: 0.9379 - recall_m: 0.8820 - f1_m: 0.8984\n",
      "Epoch 21: val_acc did not improve from 0.98090\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0183 - acc: 0.9935 - precision_m: 0.9350 - recall_m: 0.8791 - f1_m: 0.8957 - val_loss: 0.0887 - val_acc: 0.9731 - val_precision_m: 0.6055 - val_recall_m: 0.7199 - val_f1_m: 0.6250\n",
      "Epoch 22/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9943 - precision_m: 0.9462 - recall_m: 0.8944 - f1_m: 0.9119\n",
      "Epoch 22: val_acc did not improve from 0.98090\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0157 - acc: 0.9943 - precision_m: 0.9425 - recall_m: 0.8914 - f1_m: 0.9086 - val_loss: 0.0982 - val_acc: 0.9778 - val_precision_m: 0.7044 - val_recall_m: 0.6693 - val_f1_m: 0.6504\n",
      "Epoch 23/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9951 - precision_m: 0.9509 - recall_m: 0.9114 - f1_m: 0.9241\n",
      "Epoch 23: val_acc did not improve from 0.98090\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0139 - acc: 0.9951 - precision_m: 0.9467 - recall_m: 0.9085 - f1_m: 0.9206 - val_loss: 0.1376 - val_acc: 0.9756 - val_precision_m: 0.8485 - val_recall_m: 0.3876 - val_f1_m: 0.5032\n",
      "Epoch 24/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9940 - precision_m: 0.9373 - recall_m: 0.8947 - f1_m: 0.9068\n",
      "Epoch 24: val_acc did not improve from 0.98090\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0161 - acc: 0.9940 - precision_m: 0.9342 - recall_m: 0.8917 - f1_m: 0.9039 - val_loss: 0.0927 - val_acc: 0.9783 - val_precision_m: 0.7095 - val_recall_m: 0.6570 - val_f1_m: 0.6497\n",
      "Epoch 25/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0128 - acc: 0.9953 - precision_m: 0.9559 - recall_m: 0.9144 - f1_m: 0.9279\n",
      "Epoch 25: val_acc did not improve from 0.98090\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0131 - acc: 0.9952 - precision_m: 0.9550 - recall_m: 0.9145 - f1_m: 0.9274 - val_loss: 0.0931 - val_acc: 0.9752 - val_precision_m: 0.6367 - val_recall_m: 0.6824 - val_f1_m: 0.6270\n",
      "Epoch 26/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9951 - precision_m: 0.9512 - recall_m: 0.9146 - f1_m: 0.9268\n",
      "Epoch 26: val_acc did not improve from 0.98090\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0135 - acc: 0.9951 - precision_m: 0.9472 - recall_m: 0.9119 - f1_m: 0.9235 - val_loss: 0.1125 - val_acc: 0.9789 - val_precision_m: 0.7833 - val_recall_m: 0.5591 - val_f1_m: 0.6259\n",
      "Epoch 27/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0116 - acc: 0.9959 - precision_m: 0.9598 - recall_m: 0.9231 - f1_m: 0.9361\n",
      "Epoch 27: val_acc did not improve from 0.98090\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0118 - acc: 0.9958 - precision_m: 0.9561 - recall_m: 0.9191 - f1_m: 0.9320 - val_loss: 0.1363 - val_acc: 0.9801 - val_precision_m: 0.8278 - val_recall_m: 0.5533 - val_f1_m: 0.6385\n",
      "Epoch 28/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9965 - precision_m: 0.9638 - recall_m: 0.9364 - f1_m: 0.9452\n",
      "Epoch 28: val_acc did not improve from 0.98090\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0101 - acc: 0.9965 - precision_m: 0.9606 - recall_m: 0.9328 - f1_m: 0.9419 - val_loss: 0.1637 - val_acc: 0.9789 - val_precision_m: 0.8318 - val_recall_m: 0.5028 - val_f1_m: 0.5935\n",
      "Epoch 29/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9955 - precision_m: 0.9487 - recall_m: 0.9218 - f1_m: 0.9290\n",
      "Epoch 29: val_acc did not improve from 0.98090\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0121 - acc: 0.9954 - precision_m: 0.9445 - recall_m: 0.9187 - f1_m: 0.9254 - val_loss: 0.1193 - val_acc: 0.9767 - val_precision_m: 0.6924 - val_recall_m: 0.6349 - val_f1_m: 0.6277\n",
      "Epoch 30/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9972 - precision_m: 0.9708 - recall_m: 0.9540 - f1_m: 0.9595\n",
      "Epoch 30: val_acc did not improve from 0.98090\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0079 - acc: 0.9972 - precision_m: 0.9677 - recall_m: 0.9501 - f1_m: 0.9560 - val_loss: 0.1463 - val_acc: 0.9789 - val_precision_m: 0.8126 - val_recall_m: 0.5491 - val_f1_m: 0.6289\n",
      "Score for fold 4: loss of 0.07412908226251602; acc of 98.08955192565918%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.08605797588825226; acc of 97.68473505973816%\n",
      "Test Precision: precision_m of 30.827152729034424%\n",
      "Test Recall: recall_m of 26.290535926818848%\n",
      "Test F1: f1_m of 27.38366425037384%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.1376 - acc: 0.9637 - precision_m: 0.2346 - recall_m: 0.0682 - f1_m: 0.0982\n",
      "Epoch 1: val_acc improved from -inf to 0.96558, saving model to models/best_model_6_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 3s 6ms/step - loss: 0.1376 - acc: 0.9637 - precision_m: 0.2346 - recall_m: 0.0682 - f1_m: 0.0982 - val_loss: 0.1006 - val_acc: 0.9656 - val_precision_m: 0.4848 - val_recall_m: 0.1035 - val_f1_m: 0.1638\n",
      "Epoch 2/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0889 - acc: 0.9706 - precision_m: 0.6933 - recall_m: 0.3311 - f1_m: 0.4199\n",
      "Epoch 2: val_acc improved from 0.96558 to 0.97108, saving model to models/best_model_6_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0886 - acc: 0.9707 - precision_m: 0.6925 - recall_m: 0.3311 - f1_m: 0.4197 - val_loss: 0.0819 - val_acc: 0.9711 - val_precision_m: 0.6743 - val_recall_m: 0.4822 - val_f1_m: 0.5306\n",
      "Epoch 3/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0785 - acc: 0.9732 - precision_m: 0.7440 - recall_m: 0.4425 - f1_m: 0.5174\n",
      "Epoch 3: val_acc did not improve from 0.97108\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0784 - acc: 0.9733 - precision_m: 0.7406 - recall_m: 0.4427 - f1_m: 0.5166 - val_loss: 0.0815 - val_acc: 0.9710 - val_precision_m: 0.7229 - val_recall_m: 0.2746 - val_f1_m: 0.3707\n",
      "Epoch 4/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0693 - acc: 0.9763 - precision_m: 0.7786 - recall_m: 0.5075 - f1_m: 0.5850\n",
      "Epoch 4: val_acc improved from 0.97108 to 0.97406, saving model to models/best_model_6_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0692 - acc: 0.9763 - precision_m: 0.7785 - recall_m: 0.5088 - f1_m: 0.5858 - val_loss: 0.0753 - val_acc: 0.9741 - val_precision_m: 0.7711 - val_recall_m: 0.5035 - val_f1_m: 0.5756\n",
      "Epoch 5/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0640 - acc: 0.9780 - precision_m: 0.8042 - recall_m: 0.5464 - f1_m: 0.6205\n",
      "Epoch 5: val_acc improved from 0.97406 to 0.97574, saving model to models/best_model_6_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0639 - acc: 0.9780 - precision_m: 0.8038 - recall_m: 0.5474 - f1_m: 0.6212 - val_loss: 0.0778 - val_acc: 0.9757 - val_precision_m: 0.8461 - val_recall_m: 0.4321 - val_f1_m: 0.5412\n",
      "Epoch 6/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0603 - acc: 0.9793 - precision_m: 0.8020 - recall_m: 0.5932 - f1_m: 0.6531\n",
      "Epoch 6: val_acc improved from 0.97574 to 0.97717, saving model to models/best_model_6_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0602 - acc: 0.9793 - precision_m: 0.8017 - recall_m: 0.5924 - f1_m: 0.6526 - val_loss: 0.0700 - val_acc: 0.9772 - val_precision_m: 0.7842 - val_recall_m: 0.4864 - val_f1_m: 0.5744\n",
      "Epoch 7/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0555 - acc: 0.9804 - precision_m: 0.8142 - recall_m: 0.6123 - f1_m: 0.6708\n",
      "Epoch 7: val_acc did not improve from 0.97717\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0556 - acc: 0.9804 - precision_m: 0.8168 - recall_m: 0.6104 - f1_m: 0.6701 - val_loss: 0.0721 - val_acc: 0.9766 - val_precision_m: 0.8107 - val_recall_m: 0.5065 - val_f1_m: 0.5876\n",
      "Epoch 8/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9818 - precision_m: 0.8338 - recall_m: 0.6486 - f1_m: 0.7071\n",
      "Epoch 8: val_acc did not improve from 0.97717\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0516 - acc: 0.9817 - precision_m: 0.8316 - recall_m: 0.6485 - f1_m: 0.7063 - val_loss: 0.0670 - val_acc: 0.9762 - val_precision_m: 0.7323 - val_recall_m: 0.5606 - val_f1_m: 0.6012\n",
      "Epoch 9/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9835 - precision_m: 0.8420 - recall_m: 0.6766 - f1_m: 0.7336\n",
      "Epoch 9: val_acc improved from 0.97717 to 0.97968, saving model to models/best_model_6_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0476 - acc: 0.9834 - precision_m: 0.8404 - recall_m: 0.6758 - f1_m: 0.7325 - val_loss: 0.0617 - val_acc: 0.9797 - val_precision_m: 0.7565 - val_recall_m: 0.6385 - val_f1_m: 0.6702\n",
      "Epoch 10/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0444 - acc: 0.9845 - precision_m: 0.8579 - recall_m: 0.7013 - f1_m: 0.7485\n",
      "Epoch 10: val_acc did not improve from 0.97968\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0443 - acc: 0.9846 - precision_m: 0.8587 - recall_m: 0.7021 - f1_m: 0.7495 - val_loss: 0.0646 - val_acc: 0.9787 - val_precision_m: 0.7129 - val_recall_m: 0.7268 - val_f1_m: 0.6992\n",
      "Epoch 11/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9860 - precision_m: 0.8699 - recall_m: 0.7444 - f1_m: 0.7849\n",
      "Epoch 11: val_acc did not improve from 0.97968\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0400 - acc: 0.9860 - precision_m: 0.8692 - recall_m: 0.7453 - f1_m: 0.7850 - val_loss: 0.0651 - val_acc: 0.9794 - val_precision_m: 0.7877 - val_recall_m: 0.6385 - val_f1_m: 0.6788\n",
      "Epoch 12/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0386 - acc: 0.9862 - precision_m: 0.8732 - recall_m: 0.7433 - f1_m: 0.7838\n",
      "Epoch 12: val_acc improved from 0.97968 to 0.98136, saving model to models/best_model_6_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0384 - acc: 0.9862 - precision_m: 0.8726 - recall_m: 0.7427 - f1_m: 0.7833 - val_loss: 0.0704 - val_acc: 0.9814 - val_precision_m: 0.9075 - val_recall_m: 0.5790 - val_f1_m: 0.6828\n",
      "Epoch 13/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9875 - precision_m: 0.8798 - recall_m: 0.7708 - f1_m: 0.8053\n",
      "Epoch 13: val_acc did not improve from 0.98136\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0344 - acc: 0.9875 - precision_m: 0.8796 - recall_m: 0.7729 - f1_m: 0.8063 - val_loss: 0.0715 - val_acc: 0.9793 - val_precision_m: 0.7319 - val_recall_m: 0.6554 - val_f1_m: 0.6649\n",
      "Epoch 14/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9882 - precision_m: 0.8809 - recall_m: 0.7827 - f1_m: 0.8153\n",
      "Epoch 14: val_acc did not improve from 0.98136\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0319 - acc: 0.9882 - precision_m: 0.8818 - recall_m: 0.7837 - f1_m: 0.8165 - val_loss: 0.0710 - val_acc: 0.9784 - val_precision_m: 0.7553 - val_recall_m: 0.6387 - val_f1_m: 0.6638\n",
      "Epoch 15/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0298 - acc: 0.9895 - precision_m: 0.8987 - recall_m: 0.8104 - f1_m: 0.8394\n",
      "Epoch 15: val_acc did not improve from 0.98136\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0298 - acc: 0.9895 - precision_m: 0.8994 - recall_m: 0.8097 - f1_m: 0.8393 - val_loss: 0.0695 - val_acc: 0.9766 - val_precision_m: 0.7013 - val_recall_m: 0.6739 - val_f1_m: 0.6583\n",
      "Epoch 16/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0301 - acc: 0.9891 - precision_m: 0.8977 - recall_m: 0.8061 - f1_m: 0.8330\n",
      "Epoch 16: val_acc did not improve from 0.98136\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0302 - acc: 0.9892 - precision_m: 0.8978 - recall_m: 0.8078 - f1_m: 0.8341 - val_loss: 0.0707 - val_acc: 0.9796 - val_precision_m: 0.8187 - val_recall_m: 0.6050 - val_f1_m: 0.6646\n",
      "Epoch 17/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0254 - acc: 0.9907 - precision_m: 0.9093 - recall_m: 0.8378 - f1_m: 0.8603\n",
      "Epoch 17: val_acc did not improve from 0.98136\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0253 - acc: 0.9907 - precision_m: 0.9098 - recall_m: 0.8377 - f1_m: 0.8606 - val_loss: 0.0890 - val_acc: 0.9792 - val_precision_m: 0.8713 - val_recall_m: 0.5341 - val_f1_m: 0.6327\n",
      "Epoch 18/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9914 - precision_m: 0.9119 - recall_m: 0.8447 - f1_m: 0.8664\n",
      "Epoch 18: val_acc did not improve from 0.98136\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0233 - acc: 0.9914 - precision_m: 0.9091 - recall_m: 0.8448 - f1_m: 0.8651 - val_loss: 0.1065 - val_acc: 0.9782 - val_precision_m: 0.8656 - val_recall_m: 0.5189 - val_f1_m: 0.6126\n",
      "Epoch 19/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0217 - acc: 0.9924 - precision_m: 0.9223 - recall_m: 0.8699 - f1_m: 0.8860\n",
      "Epoch 19: val_acc did not improve from 0.98136\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0217 - acc: 0.9924 - precision_m: 0.9229 - recall_m: 0.8698 - f1_m: 0.8861 - val_loss: 0.1107 - val_acc: 0.9786 - val_precision_m: 0.9107 - val_recall_m: 0.5128 - val_f1_m: 0.6201\n",
      "Epoch 20/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9928 - precision_m: 0.9295 - recall_m: 0.8766 - f1_m: 0.8931\n",
      "Epoch 20: val_acc did not improve from 0.98136\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0189 - acc: 0.9928 - precision_m: 0.9295 - recall_m: 0.8744 - f1_m: 0.8913 - val_loss: 0.0937 - val_acc: 0.9788 - val_precision_m: 0.7633 - val_recall_m: 0.6509 - val_f1_m: 0.6733\n",
      "Epoch 21/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9930 - precision_m: 0.9301 - recall_m: 0.8784 - f1_m: 0.8965\n",
      "Epoch 21: val_acc did not improve from 0.98136\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0188 - acc: 0.9931 - precision_m: 0.9311 - recall_m: 0.8793 - f1_m: 0.8975 - val_loss: 0.1022 - val_acc: 0.9808 - val_precision_m: 0.8730 - val_recall_m: 0.5936 - val_f1_m: 0.6755\n",
      "Epoch 22/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.9939 - precision_m: 0.9302 - recall_m: 0.8953 - f1_m: 0.9046\n",
      "Epoch 22: val_acc did not improve from 0.98136\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0172 - acc: 0.9939 - precision_m: 0.9307 - recall_m: 0.8958 - f1_m: 0.9052 - val_loss: 0.0952 - val_acc: 0.9794 - val_precision_m: 0.7541 - val_recall_m: 0.6880 - val_f1_m: 0.6920\n",
      "Epoch 23/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9932 - precision_m: 0.9310 - recall_m: 0.8811 - f1_m: 0.8966\n",
      "Epoch 23: val_acc did not improve from 0.98136\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0186 - acc: 0.9932 - precision_m: 0.9310 - recall_m: 0.8826 - f1_m: 0.8975 - val_loss: 0.1079 - val_acc: 0.9803 - val_precision_m: 0.8686 - val_recall_m: 0.6039 - val_f1_m: 0.6824\n",
      "Epoch 24/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9942 - precision_m: 0.9407 - recall_m: 0.8976 - f1_m: 0.9114\n",
      "Epoch 24: val_acc did not improve from 0.98136\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0158 - acc: 0.9941 - precision_m: 0.9396 - recall_m: 0.8955 - f1_m: 0.9097 - val_loss: 0.0918 - val_acc: 0.9767 - val_precision_m: 0.6678 - val_recall_m: 0.7040 - val_f1_m: 0.6574\n",
      "Epoch 25/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9949 - precision_m: 0.9457 - recall_m: 0.9085 - f1_m: 0.9213\n",
      "Epoch 25: val_acc did not improve from 0.98136\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0141 - acc: 0.9949 - precision_m: 0.9460 - recall_m: 0.9067 - f1_m: 0.9202 - val_loss: 0.0912 - val_acc: 0.9812 - val_precision_m: 0.8264 - val_recall_m: 0.6748 - val_f1_m: 0.7103\n",
      "Epoch 26/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9951 - precision_m: 0.9462 - recall_m: 0.9184 - f1_m: 0.9258\n",
      "Epoch 26: val_acc did not improve from 0.98136\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0132 - acc: 0.9951 - precision_m: 0.9461 - recall_m: 0.9173 - f1_m: 0.9251 - val_loss: 0.1341 - val_acc: 0.9808 - val_precision_m: 0.8893 - val_recall_m: 0.5949 - val_f1_m: 0.6860\n",
      "Epoch 27/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0128 - acc: 0.9953 - precision_m: 0.9468 - recall_m: 0.9203 - f1_m: 0.9278\n",
      "Epoch 27: val_acc did not improve from 0.98136\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0128 - acc: 0.9953 - precision_m: 0.9472 - recall_m: 0.9208 - f1_m: 0.9283 - val_loss: 0.1372 - val_acc: 0.9808 - val_precision_m: 0.9341 - val_recall_m: 0.5693 - val_f1_m: 0.6776\n",
      "Epoch 28/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 0.9955 - precision_m: 0.9551 - recall_m: 0.9197 - f1_m: 0.9298\n",
      "Epoch 28: val_acc did not improve from 0.98136\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0120 - acc: 0.9955 - precision_m: 0.9551 - recall_m: 0.9208 - f1_m: 0.9305 - val_loss: 0.1267 - val_acc: 0.9791 - val_precision_m: 0.7738 - val_recall_m: 0.6223 - val_f1_m: 0.6623\n",
      "Epoch 29/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0114 - acc: 0.9960 - precision_m: 0.9587 - recall_m: 0.9365 - f1_m: 0.9438\n",
      "Epoch 29: val_acc did not improve from 0.98136\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0114 - acc: 0.9960 - precision_m: 0.9586 - recall_m: 0.9361 - f1_m: 0.9435 - val_loss: 0.1214 - val_acc: 0.9803 - val_precision_m: 0.8353 - val_recall_m: 0.6078 - val_f1_m: 0.6751\n",
      "Epoch 30/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9958 - precision_m: 0.9539 - recall_m: 0.9319 - f1_m: 0.9373\n",
      "Epoch 30: val_acc improved from 0.98136 to 0.98147, saving model to models/best_model_6_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0116 - acc: 0.9958 - precision_m: 0.9526 - recall_m: 0.9326 - f1_m: 0.9368 - val_loss: 0.1216 - val_acc: 0.9815 - val_precision_m: 0.8277 - val_recall_m: 0.6434 - val_f1_m: 0.6915\n",
      "Score for fold 5: loss of 0.1215633749961853; acc of 98.14748167991638%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.12115104496479034; acc of 98.01409244537354%\n",
      "Test Precision: precision_m of 30.80204427242279%\n",
      "Test Recall: recall_m of 24.502570927143097%\n",
      "Test F1: f1_m of 26.31005346775055%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1449 - acc: 0.9612 - precision_m: 0.1268 - recall_m: 0.0324 - f1_m: 0.0455\n",
      "Epoch 1: val_acc improved from -inf to 0.96722, saving model to models/best_model_6_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 3s 6ms/step - loss: 0.1449 - acc: 0.9612 - precision_m: 0.1268 - recall_m: 0.0324 - f1_m: 0.0455 - val_loss: 0.1042 - val_acc: 0.9672 - val_precision_m: 0.6781 - val_recall_m: 0.2363 - val_f1_m: 0.3348\n",
      "Epoch 2/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0884 - acc: 0.9696 - precision_m: 0.6898 - recall_m: 0.2912 - f1_m: 0.3754\n",
      "Epoch 2: val_acc improved from 0.96722 to 0.97204, saving model to models/best_model_6_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0882 - acc: 0.9697 - precision_m: 0.6895 - recall_m: 0.2910 - f1_m: 0.3754 - val_loss: 0.0863 - val_acc: 0.9720 - val_precision_m: 0.6727 - val_recall_m: 0.5405 - val_f1_m: 0.5729\n",
      "Epoch 3/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0771 - acc: 0.9741 - precision_m: 0.7448 - recall_m: 0.4450 - f1_m: 0.5221\n",
      "Epoch 3: val_acc improved from 0.97204 to 0.97397, saving model to models/best_model_6_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0774 - acc: 0.9740 - precision_m: 0.7466 - recall_m: 0.4430 - f1_m: 0.5213 - val_loss: 0.0801 - val_acc: 0.9740 - val_precision_m: 0.8396 - val_recall_m: 0.3853 - val_f1_m: 0.5035\n",
      "Epoch 4/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0687 - acc: 0.9762 - precision_m: 0.7729 - recall_m: 0.5004 - f1_m: 0.5795\n",
      "Epoch 4: val_acc improved from 0.97397 to 0.97505, saving model to models/best_model_6_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0686 - acc: 0.9762 - precision_m: 0.7730 - recall_m: 0.4990 - f1_m: 0.5788 - val_loss: 0.0818 - val_acc: 0.9751 - val_precision_m: 0.8515 - val_recall_m: 0.4527 - val_f1_m: 0.5429\n",
      "Epoch 5/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0623 - acc: 0.9781 - precision_m: 0.7927 - recall_m: 0.5600 - f1_m: 0.6289\n",
      "Epoch 5: val_acc improved from 0.97505 to 0.97638, saving model to models/best_model_6_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0622 - acc: 0.9781 - precision_m: 0.7931 - recall_m: 0.5610 - f1_m: 0.6298 - val_loss: 0.0711 - val_acc: 0.9764 - val_precision_m: 0.8362 - val_recall_m: 0.5098 - val_f1_m: 0.5941\n",
      "Epoch 6/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0578 - acc: 0.9801 - precision_m: 0.8136 - recall_m: 0.5919 - f1_m: 0.6602\n",
      "Epoch 6: val_acc did not improve from 0.97638\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0578 - acc: 0.9801 - precision_m: 0.8147 - recall_m: 0.5923 - f1_m: 0.6610 - val_loss: 0.0714 - val_acc: 0.9752 - val_precision_m: 0.6952 - val_recall_m: 0.7177 - val_f1_m: 0.6677\n",
      "Epoch 7/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0558 - acc: 0.9808 - precision_m: 0.8317 - recall_m: 0.6079 - f1_m: 0.6737\n",
      "Epoch 7: val_acc improved from 0.97638 to 0.97734, saving model to models/best_model_6_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0556 - acc: 0.9809 - precision_m: 0.8328 - recall_m: 0.6094 - f1_m: 0.6754 - val_loss: 0.0684 - val_acc: 0.9773 - val_precision_m: 0.7652 - val_recall_m: 0.6256 - val_f1_m: 0.6481\n",
      "Epoch 8/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9819 - precision_m: 0.8332 - recall_m: 0.6436 - f1_m: 0.7007\n",
      "Epoch 8: val_acc did not improve from 0.97734\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0523 - acc: 0.9818 - precision_m: 0.8329 - recall_m: 0.6425 - f1_m: 0.6999 - val_loss: 0.0737 - val_acc: 0.9738 - val_precision_m: 0.6559 - val_recall_m: 0.7112 - val_f1_m: 0.6475\n",
      "Epoch 9/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0465 - acc: 0.9830 - precision_m: 0.8417 - recall_m: 0.6786 - f1_m: 0.7302\n",
      "Epoch 9: val_acc improved from 0.97734 to 0.97891, saving model to models/best_model_6_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0467 - acc: 0.9830 - precision_m: 0.8405 - recall_m: 0.6798 - f1_m: 0.7305 - val_loss: 0.0638 - val_acc: 0.9789 - val_precision_m: 0.8134 - val_recall_m: 0.6328 - val_f1_m: 0.6665\n",
      "Epoch 10/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9839 - precision_m: 0.8529 - recall_m: 0.6881 - f1_m: 0.7363\n",
      "Epoch 10: val_acc improved from 0.97891 to 0.97903, saving model to models/best_model_6_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0453 - acc: 0.9839 - precision_m: 0.8486 - recall_m: 0.6870 - f1_m: 0.7338 - val_loss: 0.0707 - val_acc: 0.9790 - val_precision_m: 0.8779 - val_recall_m: 0.5509 - val_f1_m: 0.6316\n",
      "Epoch 11/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9860 - precision_m: 0.8638 - recall_m: 0.7324 - f1_m: 0.7792\n",
      "Epoch 11: val_acc did not improve from 0.97903\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0400 - acc: 0.9860 - precision_m: 0.8628 - recall_m: 0.7321 - f1_m: 0.7786 - val_loss: 0.0760 - val_acc: 0.9776 - val_precision_m: 0.8169 - val_recall_m: 0.5171 - val_f1_m: 0.5979\n",
      "Epoch 12/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9856 - precision_m: 0.8662 - recall_m: 0.7315 - f1_m: 0.7724\n",
      "Epoch 12: val_acc improved from 0.97903 to 0.98084, saving model to models/best_model_6_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0394 - acc: 0.9856 - precision_m: 0.8653 - recall_m: 0.7325 - f1_m: 0.7726 - val_loss: 0.0684 - val_acc: 0.9808 - val_precision_m: 0.8559 - val_recall_m: 0.6092 - val_f1_m: 0.6734\n",
      "Epoch 13/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0354 - acc: 0.9875 - precision_m: 0.8770 - recall_m: 0.7752 - f1_m: 0.8104\n",
      "Epoch 13: val_acc did not improve from 0.98084\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0355 - acc: 0.9875 - precision_m: 0.8751 - recall_m: 0.7748 - f1_m: 0.8094 - val_loss: 0.0669 - val_acc: 0.9801 - val_precision_m: 0.7735 - val_recall_m: 0.6708 - val_f1_m: 0.6838\n",
      "Epoch 14/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0349 - acc: 0.9872 - precision_m: 0.8722 - recall_m: 0.7590 - f1_m: 0.7954\n",
      "Epoch 14: val_acc did not improve from 0.98084\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0348 - acc: 0.9873 - precision_m: 0.8719 - recall_m: 0.7593 - f1_m: 0.7952 - val_loss: 0.0657 - val_acc: 0.9796 - val_precision_m: 0.7452 - val_recall_m: 0.7444 - val_f1_m: 0.7122\n",
      "Epoch 15/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9887 - precision_m: 0.8952 - recall_m: 0.7985 - f1_m: 0.8293\n",
      "Epoch 15: val_acc did not improve from 0.98084\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0318 - acc: 0.9887 - precision_m: 0.8962 - recall_m: 0.7961 - f1_m: 0.8277 - val_loss: 0.0765 - val_acc: 0.9790 - val_precision_m: 0.8744 - val_recall_m: 0.5379 - val_f1_m: 0.6254\n",
      "Epoch 16/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0293 - acc: 0.9893 - precision_m: 0.8922 - recall_m: 0.8107 - f1_m: 0.8349\n",
      "Epoch 16: val_acc did not improve from 0.98084\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0293 - acc: 0.9892 - precision_m: 0.8920 - recall_m: 0.8075 - f1_m: 0.8329 - val_loss: 0.0680 - val_acc: 0.9791 - val_precision_m: 0.7324 - val_recall_m: 0.6944 - val_f1_m: 0.6799\n",
      "Epoch 17/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0276 - acc: 0.9900 - precision_m: 0.9016 - recall_m: 0.8220 - f1_m: 0.8461\n",
      "Epoch 17: val_acc did not improve from 0.98084\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0275 - acc: 0.9901 - precision_m: 0.9012 - recall_m: 0.8225 - f1_m: 0.8461 - val_loss: 0.0729 - val_acc: 0.9805 - val_precision_m: 0.7868 - val_recall_m: 0.6772 - val_f1_m: 0.6959\n",
      "Epoch 18/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9907 - precision_m: 0.9098 - recall_m: 0.8381 - f1_m: 0.8600\n",
      "Epoch 18: val_acc did not improve from 0.98084\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0265 - acc: 0.9906 - precision_m: 0.9099 - recall_m: 0.8341 - f1_m: 0.8574 - val_loss: 0.0779 - val_acc: 0.9788 - val_precision_m: 0.7798 - val_recall_m: 0.6398 - val_f1_m: 0.6690\n",
      "Epoch 19/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9911 - precision_m: 0.9149 - recall_m: 0.8387 - f1_m: 0.8619\n",
      "Epoch 19: val_acc did not improve from 0.98084\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0248 - acc: 0.9910 - precision_m: 0.9149 - recall_m: 0.8386 - f1_m: 0.8620 - val_loss: 0.0726 - val_acc: 0.9788 - val_precision_m: 0.7033 - val_recall_m: 0.7555 - val_f1_m: 0.7014\n",
      "Epoch 20/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9924 - precision_m: 0.9262 - recall_m: 0.8632 - f1_m: 0.8844\n",
      "Epoch 20: val_acc improved from 0.98084 to 0.98144, saving model to models/best_model_6_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0210 - acc: 0.9924 - precision_m: 0.9257 - recall_m: 0.8639 - f1_m: 0.8846 - val_loss: 0.0831 - val_acc: 0.9814 - val_precision_m: 0.8192 - val_recall_m: 0.6307 - val_f1_m: 0.6862\n",
      "Epoch 21/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9925 - precision_m: 0.9291 - recall_m: 0.8661 - f1_m: 0.8882\n",
      "Epoch 21: val_acc did not improve from 0.98144\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0206 - acc: 0.9924 - precision_m: 0.9276 - recall_m: 0.8659 - f1_m: 0.8874 - val_loss: 0.0923 - val_acc: 0.9810 - val_precision_m: 0.8520 - val_recall_m: 0.6205 - val_f1_m: 0.6779\n",
      "Epoch 22/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9935 - precision_m: 0.9334 - recall_m: 0.8833 - f1_m: 0.8998\n",
      "Epoch 22: val_acc did not improve from 0.98144\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0174 - acc: 0.9935 - precision_m: 0.9326 - recall_m: 0.8841 - f1_m: 0.8998 - val_loss: 0.0986 - val_acc: 0.9801 - val_precision_m: 0.7848 - val_recall_m: 0.6530 - val_f1_m: 0.6750\n",
      "Epoch 23/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9930 - precision_m: 0.9255 - recall_m: 0.8814 - f1_m: 0.8910\n",
      "Epoch 23: val_acc did not improve from 0.98144\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0182 - acc: 0.9930 - precision_m: 0.9255 - recall_m: 0.8808 - f1_m: 0.8908 - val_loss: 0.1023 - val_acc: 0.9802 - val_precision_m: 0.8280 - val_recall_m: 0.6132 - val_f1_m: 0.6721\n",
      "Epoch 24/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9944 - precision_m: 0.9461 - recall_m: 0.9028 - f1_m: 0.9170\n",
      "Epoch 24: val_acc did not improve from 0.98144\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0154 - acc: 0.9945 - precision_m: 0.9464 - recall_m: 0.9038 - f1_m: 0.9177 - val_loss: 0.0859 - val_acc: 0.9783 - val_precision_m: 0.7112 - val_recall_m: 0.7205 - val_f1_m: 0.6876\n",
      "Epoch 25/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9950 - precision_m: 0.9493 - recall_m: 0.9157 - f1_m: 0.9247\n",
      "Epoch 25: val_acc did not improve from 0.98144\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0147 - acc: 0.9949 - precision_m: 0.9470 - recall_m: 0.9158 - f1_m: 0.9235 - val_loss: 0.0969 - val_acc: 0.9731 - val_precision_m: 0.6112 - val_recall_m: 0.7400 - val_f1_m: 0.6472\n",
      "Epoch 26/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9949 - precision_m: 0.9421 - recall_m: 0.9123 - f1_m: 0.9202\n",
      "Epoch 26: val_acc did not improve from 0.98144\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0134 - acc: 0.9949 - precision_m: 0.9424 - recall_m: 0.9131 - f1_m: 0.9208 - val_loss: 0.1194 - val_acc: 0.9795 - val_precision_m: 0.8135 - val_recall_m: 0.5937 - val_f1_m: 0.6514\n",
      "Epoch 27/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9947 - precision_m: 0.9471 - recall_m: 0.9143 - f1_m: 0.9233\n",
      "Epoch 27: val_acc did not improve from 0.98144\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0148 - acc: 0.9947 - precision_m: 0.9478 - recall_m: 0.9107 - f1_m: 0.9210 - val_loss: 0.1088 - val_acc: 0.9787 - val_precision_m: 0.8120 - val_recall_m: 0.6464 - val_f1_m: 0.6867\n",
      "Epoch 28/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9952 - precision_m: 0.9496 - recall_m: 0.9267 - f1_m: 0.9320\n",
      "Epoch 28: val_acc did not improve from 0.98144\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0129 - acc: 0.9953 - precision_m: 0.9505 - recall_m: 0.9270 - f1_m: 0.9326 - val_loss: 0.1088 - val_acc: 0.9732 - val_precision_m: 0.6659 - val_recall_m: 0.7457 - val_f1_m: 0.6743\n",
      "Epoch 29/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9953 - precision_m: 0.9478 - recall_m: 0.9280 - f1_m: 0.9321\n",
      "Epoch 29: val_acc did not improve from 0.98144\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0127 - acc: 0.9953 - precision_m: 0.9478 - recall_m: 0.9282 - f1_m: 0.9323 - val_loss: 0.1389 - val_acc: 0.9793 - val_precision_m: 0.8279 - val_recall_m: 0.5422 - val_f1_m: 0.6181\n",
      "Epoch 30/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9959 - precision_m: 0.9613 - recall_m: 0.9356 - f1_m: 0.9428\n",
      "Epoch 30: val_acc did not improve from 0.98144\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0108 - acc: 0.9959 - precision_m: 0.9609 - recall_m: 0.9352 - f1_m: 0.9425 - val_loss: 0.1267 - val_acc: 0.9799 - val_precision_m: 0.8467 - val_recall_m: 0.6033 - val_f1_m: 0.6677\n",
      "Score for fold 6: loss of 0.08310282975435257; acc of 98.14390540122986%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.08640777319669724; acc of 97.76906967163086%\n",
      "Test Precision: precision_m of 26.456257700920105%\n",
      "Test Recall: recall_m of 22.351329028606415%\n",
      "Test F1: f1_m of 23.221492767333984%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1424 - acc: 0.9628 - precision_m: 0.1731 - recall_m: 0.0463 - f1_m: 0.0660\n",
      "Epoch 1: val_acc improved from -inf to 0.96774, saving model to models/best_model_6_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 3s 6ms/step - loss: 0.1424 - acc: 0.9628 - precision_m: 0.1731 - recall_m: 0.0463 - f1_m: 0.0660 - val_loss: 0.0983 - val_acc: 0.9677 - val_precision_m: 0.5421 - val_recall_m: 0.2795 - val_f1_m: 0.3437\n",
      "Epoch 2/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0906 - acc: 0.9698 - precision_m: 0.6806 - recall_m: 0.3287 - f1_m: 0.4098\n",
      "Epoch 2: val_acc did not improve from 0.96774\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0905 - acc: 0.9698 - precision_m: 0.6827 - recall_m: 0.3276 - f1_m: 0.4092 - val_loss: 0.1070 - val_acc: 0.9675 - val_precision_m: 0.4527 - val_recall_m: 0.1406 - val_f1_m: 0.1994\n",
      "Epoch 3/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0772 - acc: 0.9738 - precision_m: 0.7448 - recall_m: 0.4517 - f1_m: 0.5320\n",
      "Epoch 3: val_acc improved from 0.96774 to 0.97407, saving model to models/best_model_6_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0773 - acc: 0.9738 - precision_m: 0.7444 - recall_m: 0.4532 - f1_m: 0.5331 - val_loss: 0.0766 - val_acc: 0.9741 - val_precision_m: 0.8359 - val_recall_m: 0.3823 - val_f1_m: 0.4882\n",
      "Epoch 4/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0684 - acc: 0.9768 - precision_m: 0.7920 - recall_m: 0.5297 - f1_m: 0.6073\n",
      "Epoch 4: val_acc improved from 0.97407 to 0.97527, saving model to models/best_model_6_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0686 - acc: 0.9767 - precision_m: 0.7907 - recall_m: 0.5261 - f1_m: 0.6040 - val_loss: 0.0752 - val_acc: 0.9753 - val_precision_m: 0.8251 - val_recall_m: 0.3913 - val_f1_m: 0.5039\n",
      "Epoch 5/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0633 - acc: 0.9784 - precision_m: 0.8088 - recall_m: 0.5635 - f1_m: 0.6367\n",
      "Epoch 5: val_acc improved from 0.97527 to 0.97742, saving model to models/best_model_6_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0634 - acc: 0.9784 - precision_m: 0.8065 - recall_m: 0.5626 - f1_m: 0.6357 - val_loss: 0.0714 - val_acc: 0.9774 - val_precision_m: 0.8221 - val_recall_m: 0.4726 - val_f1_m: 0.5643\n",
      "Epoch 6/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9801 - precision_m: 0.8278 - recall_m: 0.6106 - f1_m: 0.6784\n",
      "Epoch 6: val_acc did not improve from 0.97742\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0573 - acc: 0.9802 - precision_m: 0.8274 - recall_m: 0.6114 - f1_m: 0.6787 - val_loss: 0.0737 - val_acc: 0.9772 - val_precision_m: 0.7987 - val_recall_m: 0.4778 - val_f1_m: 0.5776\n",
      "Epoch 7/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0537 - acc: 0.9814 - precision_m: 0.8361 - recall_m: 0.6312 - f1_m: 0.6954\n",
      "Epoch 7: val_acc improved from 0.97742 to 0.97754, saving model to models/best_model_6_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0535 - acc: 0.9814 - precision_m: 0.8325 - recall_m: 0.6296 - f1_m: 0.6932 - val_loss: 0.0709 - val_acc: 0.9775 - val_precision_m: 0.8494 - val_recall_m: 0.4634 - val_f1_m: 0.5564\n",
      "Epoch 8/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0509 - acc: 0.9821 - precision_m: 0.8465 - recall_m: 0.6419 - f1_m: 0.7055\n",
      "Epoch 8: val_acc improved from 0.97754 to 0.97861, saving model to models/best_model_6_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0507 - acc: 0.9822 - precision_m: 0.8474 - recall_m: 0.6436 - f1_m: 0.7069 - val_loss: 0.0637 - val_acc: 0.9786 - val_precision_m: 0.7375 - val_recall_m: 0.5772 - val_f1_m: 0.6205\n",
      "Epoch 9/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.9837 - precision_m: 0.8584 - recall_m: 0.6941 - f1_m: 0.7468\n",
      "Epoch 9: val_acc improved from 0.97861 to 0.97909, saving model to models/best_model_6_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0473 - acc: 0.9837 - precision_m: 0.8584 - recall_m: 0.6945 - f1_m: 0.7469 - val_loss: 0.0633 - val_acc: 0.9791 - val_precision_m: 0.7143 - val_recall_m: 0.6366 - val_f1_m: 0.6532\n",
      "Epoch 10/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0422 - acc: 0.9851 - precision_m: 0.8620 - recall_m: 0.7119 - f1_m: 0.7648\n",
      "Epoch 10: val_acc improved from 0.97909 to 0.97981, saving model to models/best_model_6_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0421 - acc: 0.9850 - precision_m: 0.8591 - recall_m: 0.7095 - f1_m: 0.7621 - val_loss: 0.0708 - val_acc: 0.9798 - val_precision_m: 0.8072 - val_recall_m: 0.5529 - val_f1_m: 0.6276\n",
      "Epoch 11/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9853 - precision_m: 0.8739 - recall_m: 0.7293 - f1_m: 0.7746\n",
      "Epoch 11: val_acc did not improve from 0.97981\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0420 - acc: 0.9853 - precision_m: 0.8739 - recall_m: 0.7274 - f1_m: 0.7732 - val_loss: 0.0626 - val_acc: 0.9792 - val_precision_m: 0.7244 - val_recall_m: 0.6465 - val_f1_m: 0.6595\n",
      "Epoch 12/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0388 - acc: 0.9860 - precision_m: 0.8730 - recall_m: 0.7359 - f1_m: 0.7827\n",
      "Epoch 12: val_acc did not improve from 0.97981\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0389 - acc: 0.9860 - precision_m: 0.8722 - recall_m: 0.7377 - f1_m: 0.7833 - val_loss: 0.0616 - val_acc: 0.9793 - val_precision_m: 0.7103 - val_recall_m: 0.6816 - val_f1_m: 0.6716\n",
      "Epoch 13/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9881 - precision_m: 0.8978 - recall_m: 0.7758 - f1_m: 0.8186\n",
      "Epoch 13: val_acc did not improve from 0.97981\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0340 - acc: 0.9880 - precision_m: 0.8981 - recall_m: 0.7747 - f1_m: 0.8179 - val_loss: 0.0627 - val_acc: 0.9797 - val_precision_m: 0.7086 - val_recall_m: 0.6656 - val_f1_m: 0.6600\n",
      "Epoch 14/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0315 - acc: 0.9887 - precision_m: 0.8951 - recall_m: 0.7918 - f1_m: 0.8288\n",
      "Epoch 14: val_acc improved from 0.97981 to 0.98017, saving model to models/best_model_6_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0315 - acc: 0.9887 - precision_m: 0.8953 - recall_m: 0.7927 - f1_m: 0.8294 - val_loss: 0.0744 - val_acc: 0.9802 - val_precision_m: 0.7685 - val_recall_m: 0.6142 - val_f1_m: 0.6555\n",
      "Epoch 15/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9889 - precision_m: 0.8976 - recall_m: 0.7942 - f1_m: 0.8300\n",
      "Epoch 15: val_acc did not improve from 0.98017\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0310 - acc: 0.9888 - precision_m: 0.8969 - recall_m: 0.7939 - f1_m: 0.8297 - val_loss: 0.0702 - val_acc: 0.9756 - val_precision_m: 0.6330 - val_recall_m: 0.6990 - val_f1_m: 0.6448\n",
      "Epoch 16/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9896 - precision_m: 0.9000 - recall_m: 0.8191 - f1_m: 0.8444\n",
      "Epoch 16: val_acc did not improve from 0.98017\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0277 - acc: 0.9895 - precision_m: 0.8965 - recall_m: 0.8187 - f1_m: 0.8424 - val_loss: 0.0965 - val_acc: 0.9790 - val_precision_m: 0.8097 - val_recall_m: 0.4990 - val_f1_m: 0.5883\n",
      "Epoch 17/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9904 - precision_m: 0.9129 - recall_m: 0.8301 - f1_m: 0.8577\n",
      "Epoch 17: val_acc did not improve from 0.98017\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0256 - acc: 0.9904 - precision_m: 0.9128 - recall_m: 0.8306 - f1_m: 0.8580 - val_loss: 0.0739 - val_acc: 0.9787 - val_precision_m: 0.7558 - val_recall_m: 0.6148 - val_f1_m: 0.6564\n",
      "Epoch 18/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9910 - precision_m: 0.9173 - recall_m: 0.8397 - f1_m: 0.8649\n",
      "Epoch 18: val_acc did not improve from 0.98017\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0253 - acc: 0.9909 - precision_m: 0.9173 - recall_m: 0.8397 - f1_m: 0.8646 - val_loss: 0.0706 - val_acc: 0.9774 - val_precision_m: 0.7129 - val_recall_m: 0.5984 - val_f1_m: 0.6200\n",
      "Epoch 19/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9915 - precision_m: 0.9225 - recall_m: 0.8479 - f1_m: 0.8734\n",
      "Epoch 19: val_acc did not improve from 0.98017\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0232 - acc: 0.9915 - precision_m: 0.9223 - recall_m: 0.8458 - f1_m: 0.8713 - val_loss: 0.0699 - val_acc: 0.9792 - val_precision_m: 0.7082 - val_recall_m: 0.6395 - val_f1_m: 0.6505\n",
      "Epoch 20/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0209 - acc: 0.9923 - precision_m: 0.9268 - recall_m: 0.8629 - f1_m: 0.8855\n",
      "Epoch 20: val_acc did not improve from 0.98017\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0210 - acc: 0.9922 - precision_m: 0.9265 - recall_m: 0.8634 - f1_m: 0.8856 - val_loss: 0.0873 - val_acc: 0.9792 - val_precision_m: 0.7692 - val_recall_m: 0.6047 - val_f1_m: 0.6544\n",
      "Epoch 21/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9929 - precision_m: 0.9300 - recall_m: 0.8794 - f1_m: 0.8946\n",
      "Epoch 21: val_acc improved from 0.98017 to 0.98053, saving model to models/best_model_6_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0197 - acc: 0.9930 - precision_m: 0.9305 - recall_m: 0.8798 - f1_m: 0.8951 - val_loss: 0.0821 - val_acc: 0.9805 - val_precision_m: 0.7701 - val_recall_m: 0.6184 - val_f1_m: 0.6598\n",
      "Epoch 22/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0167 - acc: 0.9939 - precision_m: 0.9325 - recall_m: 0.9019 - f1_m: 0.9105\n",
      "Epoch 22: val_acc did not improve from 0.98053\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0167 - acc: 0.9939 - precision_m: 0.9327 - recall_m: 0.9021 - f1_m: 0.9108 - val_loss: 0.0806 - val_acc: 0.9797 - val_precision_m: 0.7688 - val_recall_m: 0.5742 - val_f1_m: 0.6348\n",
      "Epoch 23/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9932 - precision_m: 0.9270 - recall_m: 0.8877 - f1_m: 0.8979\n",
      "Epoch 23: val_acc did not improve from 0.98053\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0192 - acc: 0.9932 - precision_m: 0.9276 - recall_m: 0.8865 - f1_m: 0.8976 - val_loss: 0.0788 - val_acc: 0.9791 - val_precision_m: 0.7378 - val_recall_m: 0.6460 - val_f1_m: 0.6642\n",
      "Epoch 24/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9941 - precision_m: 0.9436 - recall_m: 0.9014 - f1_m: 0.9139\n",
      "Epoch 24: val_acc did not improve from 0.98053\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0154 - acc: 0.9940 - precision_m: 0.9435 - recall_m: 0.8995 - f1_m: 0.9128 - val_loss: 0.0958 - val_acc: 0.9785 - val_precision_m: 0.7485 - val_recall_m: 0.5674 - val_f1_m: 0.6217\n",
      "Epoch 25/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.9942 - precision_m: 0.9387 - recall_m: 0.9088 - f1_m: 0.9153\n",
      "Epoch 25: val_acc did not improve from 0.98053\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0157 - acc: 0.9943 - precision_m: 0.9392 - recall_m: 0.9097 - f1_m: 0.9161 - val_loss: 0.1251 - val_acc: 0.9793 - val_precision_m: 0.8671 - val_recall_m: 0.5022 - val_f1_m: 0.5979\n",
      "Epoch 26/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9955 - precision_m: 0.9514 - recall_m: 0.9254 - f1_m: 0.9325\n",
      "Epoch 26: val_acc did not improve from 0.98053\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0132 - acc: 0.9955 - precision_m: 0.9514 - recall_m: 0.9265 - f1_m: 0.9331 - val_loss: 0.1375 - val_acc: 0.9789 - val_precision_m: 0.8202 - val_recall_m: 0.5013 - val_f1_m: 0.5903\n",
      "Epoch 27/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9953 - precision_m: 0.9527 - recall_m: 0.9247 - f1_m: 0.9328\n",
      "Epoch 27: val_acc did not improve from 0.98053\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0127 - acc: 0.9953 - precision_m: 0.9508 - recall_m: 0.9258 - f1_m: 0.9321 - val_loss: 0.1091 - val_acc: 0.9786 - val_precision_m: 0.7527 - val_recall_m: 0.6083 - val_f1_m: 0.6440\n",
      "Epoch 28/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9947 - precision_m: 0.9465 - recall_m: 0.9154 - f1_m: 0.9243\n",
      "Epoch 28: val_acc did not improve from 0.98053\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0148 - acc: 0.9947 - precision_m: 0.9453 - recall_m: 0.9171 - f1_m: 0.9246 - val_loss: 0.1078 - val_acc: 0.9795 - val_precision_m: 0.7748 - val_recall_m: 0.5933 - val_f1_m: 0.6354\n",
      "Epoch 29/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0114 - acc: 0.9958 - precision_m: 0.9555 - recall_m: 0.9276 - f1_m: 0.9364\n",
      "Epoch 29: val_acc did not improve from 0.98053\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0116 - acc: 0.9958 - precision_m: 0.9552 - recall_m: 0.9271 - f1_m: 0.9360 - val_loss: 0.1484 - val_acc: 0.9533 - val_precision_m: 0.4179 - val_recall_m: 0.7913 - val_f1_m: 0.5251\n",
      "Epoch 30/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 0.9957 - precision_m: 0.9553 - recall_m: 0.9324 - f1_m: 0.9381\n",
      "Epoch 30: val_acc did not improve from 0.98053\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0119 - acc: 0.9958 - precision_m: 0.9557 - recall_m: 0.9316 - f1_m: 0.9378 - val_loss: 0.1136 - val_acc: 0.9785 - val_precision_m: 0.7236 - val_recall_m: 0.5927 - val_f1_m: 0.6214\n",
      "Score for fold 7: loss of 0.08212610334157944; acc of 98.05256724357605%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.08674290031194687; acc of 98.09939861297607%\n",
      "Test Precision: precision_m of 23.844367265701294%\n",
      "Test Recall: recall_m of 19.190308451652527%\n",
      "Test F1: f1_m of 20.26924043893814%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1413 - acc: 0.9627 - precision_m: 0.1865 - recall_m: 0.0517 - f1_m: 0.0735\n",
      "Epoch 1: val_acc improved from -inf to 0.96622, saving model to models/best_model_6_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 3s 6ms/step - loss: 0.1413 - acc: 0.9627 - precision_m: 0.1865 - recall_m: 0.0517 - f1_m: 0.0735 - val_loss: 0.0985 - val_acc: 0.9662 - val_precision_m: 0.4162 - val_recall_m: 0.1110 - val_f1_m: 0.1663\n",
      "Epoch 2/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0903 - acc: 0.9691 - precision_m: 0.6548 - recall_m: 0.2926 - f1_m: 0.3718\n",
      "Epoch 2: val_acc improved from 0.96622 to 0.97233, saving model to models/best_model_6_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0903 - acc: 0.9692 - precision_m: 0.6564 - recall_m: 0.2978 - f1_m: 0.3767 - val_loss: 0.0828 - val_acc: 0.9723 - val_precision_m: 0.6596 - val_recall_m: 0.3979 - val_f1_m: 0.4596\n",
      "Epoch 3/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0778 - acc: 0.9733 - precision_m: 0.7365 - recall_m: 0.4380 - f1_m: 0.5161\n",
      "Epoch 3: val_acc did not improve from 0.97233\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0778 - acc: 0.9733 - precision_m: 0.7373 - recall_m: 0.4407 - f1_m: 0.5181 - val_loss: 0.0898 - val_acc: 0.9709 - val_precision_m: 0.6995 - val_recall_m: 0.2542 - val_f1_m: 0.3440\n",
      "Epoch 4/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0689 - acc: 0.9764 - precision_m: 0.7793 - recall_m: 0.5220 - f1_m: 0.5967\n",
      "Epoch 4: val_acc improved from 0.97233 to 0.97532, saving model to models/best_model_6_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0690 - acc: 0.9763 - precision_m: 0.7796 - recall_m: 0.5214 - f1_m: 0.5966 - val_loss: 0.0733 - val_acc: 0.9753 - val_precision_m: 0.7053 - val_recall_m: 0.4380 - val_f1_m: 0.5037\n",
      "Epoch 5/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9786 - precision_m: 0.7857 - recall_m: 0.5637 - f1_m: 0.6347\n",
      "Epoch 5: val_acc did not improve from 0.97532\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0620 - acc: 0.9785 - precision_m: 0.7848 - recall_m: 0.5628 - f1_m: 0.6339 - val_loss: 0.0748 - val_acc: 0.9708 - val_precision_m: 0.5847 - val_recall_m: 0.4961 - val_f1_m: 0.4967\n",
      "Epoch 6/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9799 - precision_m: 0.8075 - recall_m: 0.6081 - f1_m: 0.6714\n",
      "Epoch 6: val_acc did not improve from 0.97532\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0582 - acc: 0.9798 - precision_m: 0.8078 - recall_m: 0.6035 - f1_m: 0.6676 - val_loss: 0.0777 - val_acc: 0.9736 - val_precision_m: 0.6092 - val_recall_m: 0.5609 - val_f1_m: 0.5553\n",
      "Epoch 7/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0554 - acc: 0.9804 - precision_m: 0.8120 - recall_m: 0.6217 - f1_m: 0.6791\n",
      "Epoch 7: val_acc improved from 0.97532 to 0.97664, saving model to models/best_model_6_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0553 - acc: 0.9804 - precision_m: 0.8102 - recall_m: 0.6242 - f1_m: 0.6797 - val_loss: 0.0821 - val_acc: 0.9766 - val_precision_m: 0.7253 - val_recall_m: 0.4181 - val_f1_m: 0.4914\n",
      "Epoch 8/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0498 - acc: 0.9827 - precision_m: 0.8409 - recall_m: 0.6675 - f1_m: 0.7250\n",
      "Epoch 8: val_acc did not improve from 0.97664\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0501 - acc: 0.9827 - precision_m: 0.8418 - recall_m: 0.6638 - f1_m: 0.7224 - val_loss: 0.0814 - val_acc: 0.9707 - val_precision_m: 0.5430 - val_recall_m: 0.7086 - val_f1_m: 0.5930\n",
      "Epoch 9/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9831 - precision_m: 0.8403 - recall_m: 0.6852 - f1_m: 0.7321\n",
      "Epoch 9: val_acc improved from 0.97664 to 0.97784, saving model to models/best_model_6_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0478 - acc: 0.9832 - precision_m: 0.8412 - recall_m: 0.6860 - f1_m: 0.7331 - val_loss: 0.0729 - val_acc: 0.9778 - val_precision_m: 0.6433 - val_recall_m: 0.6087 - val_f1_m: 0.6043\n",
      "Epoch 10/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9850 - precision_m: 0.8594 - recall_m: 0.7142 - f1_m: 0.7666\n",
      "Epoch 10: val_acc did not improve from 0.97784\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0426 - acc: 0.9849 - precision_m: 0.8573 - recall_m: 0.7168 - f1_m: 0.7668 - val_loss: 0.0747 - val_acc: 0.9776 - val_precision_m: 0.7841 - val_recall_m: 0.4403 - val_f1_m: 0.5327\n",
      "Epoch 11/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9856 - precision_m: 0.8692 - recall_m: 0.7298 - f1_m: 0.7736\n",
      "Epoch 11: val_acc improved from 0.97784 to 0.97964, saving model to models/best_model_6_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0406 - acc: 0.9856 - precision_m: 0.8683 - recall_m: 0.7308 - f1_m: 0.7741 - val_loss: 0.0721 - val_acc: 0.9796 - val_precision_m: 0.7469 - val_recall_m: 0.5354 - val_f1_m: 0.5952\n",
      "Epoch 12/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9867 - precision_m: 0.8808 - recall_m: 0.7544 - f1_m: 0.7968\n",
      "Epoch 12: val_acc did not improve from 0.97964\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0379 - acc: 0.9867 - precision_m: 0.8804 - recall_m: 0.7558 - f1_m: 0.7974 - val_loss: 0.0690 - val_acc: 0.9772 - val_precision_m: 0.6826 - val_recall_m: 0.6343 - val_f1_m: 0.6157\n",
      "Epoch 13/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0349 - acc: 0.9877 - precision_m: 0.8911 - recall_m: 0.7687 - f1_m: 0.8103\n",
      "Epoch 13: val_acc did not improve from 0.97964\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0350 - acc: 0.9877 - precision_m: 0.8900 - recall_m: 0.7664 - f1_m: 0.8084 - val_loss: 0.0734 - val_acc: 0.9770 - val_precision_m: 0.6421 - val_recall_m: 0.6311 - val_f1_m: 0.6146\n",
      "Epoch 14/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0333 - acc: 0.9882 - precision_m: 0.8887 - recall_m: 0.7903 - f1_m: 0.8213\n",
      "Epoch 14: val_acc did not improve from 0.97964\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0333 - acc: 0.9882 - precision_m: 0.8874 - recall_m: 0.7900 - f1_m: 0.8206 - val_loss: 0.0711 - val_acc: 0.9795 - val_precision_m: 0.6871 - val_recall_m: 0.6329 - val_f1_m: 0.6309\n",
      "Epoch 15/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9890 - precision_m: 0.8868 - recall_m: 0.8056 - f1_m: 0.8293\n",
      "Epoch 15: val_acc did not improve from 0.97964\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0307 - acc: 0.9890 - precision_m: 0.8863 - recall_m: 0.8061 - f1_m: 0.8295 - val_loss: 0.0694 - val_acc: 0.9772 - val_precision_m: 0.6657 - val_recall_m: 0.6476 - val_f1_m: 0.6257\n",
      "Epoch 16/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0280 - acc: 0.9899 - precision_m: 0.9043 - recall_m: 0.8137 - f1_m: 0.8462\n",
      "Epoch 16: val_acc did not improve from 0.97964\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0281 - acc: 0.9899 - precision_m: 0.9042 - recall_m: 0.8134 - f1_m: 0.8458 - val_loss: 0.0785 - val_acc: 0.9746 - val_precision_m: 0.5899 - val_recall_m: 0.7157 - val_f1_m: 0.6259\n",
      "Epoch 17/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9903 - precision_m: 0.9081 - recall_m: 0.8255 - f1_m: 0.8505\n",
      "Epoch 17: val_acc did not improve from 0.97964\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0269 - acc: 0.9902 - precision_m: 0.9066 - recall_m: 0.8257 - f1_m: 0.8498 - val_loss: 0.0738 - val_acc: 0.9793 - val_precision_m: 0.6951 - val_recall_m: 0.6201 - val_f1_m: 0.6276\n",
      "Epoch 18/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9916 - precision_m: 0.9268 - recall_m: 0.8467 - f1_m: 0.8760\n",
      "Epoch 18: val_acc did not improve from 0.97964\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0234 - acc: 0.9916 - precision_m: 0.9266 - recall_m: 0.8473 - f1_m: 0.8763 - val_loss: 0.0806 - val_acc: 0.9781 - val_precision_m: 0.6750 - val_recall_m: 0.6397 - val_f1_m: 0.6370\n",
      "Epoch 19/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9919 - precision_m: 0.9195 - recall_m: 0.8527 - f1_m: 0.8730\n",
      "Epoch 19: val_acc did not improve from 0.97964\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0228 - acc: 0.9918 - precision_m: 0.9187 - recall_m: 0.8521 - f1_m: 0.8723 - val_loss: 0.0776 - val_acc: 0.9757 - val_precision_m: 0.6192 - val_recall_m: 0.6754 - val_f1_m: 0.6177\n",
      "Epoch 20/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9924 - precision_m: 0.9304 - recall_m: 0.8659 - f1_m: 0.8895\n",
      "Epoch 20: val_acc did not improve from 0.97964\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0203 - acc: 0.9924 - precision_m: 0.9304 - recall_m: 0.8647 - f1_m: 0.8888 - val_loss: 0.1044 - val_acc: 0.9790 - val_precision_m: 0.7957 - val_recall_m: 0.4962 - val_f1_m: 0.5757\n",
      "Epoch 21/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0200 - acc: 0.9928 - precision_m: 0.9330 - recall_m: 0.8723 - f1_m: 0.8925\n",
      "Epoch 21: val_acc improved from 0.97964 to 0.98059, saving model to models/best_model_6_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0202 - acc: 0.9927 - precision_m: 0.9339 - recall_m: 0.8710 - f1_m: 0.8922 - val_loss: 0.0859 - val_acc: 0.9806 - val_precision_m: 0.7400 - val_recall_m: 0.5773 - val_f1_m: 0.6241\n",
      "Epoch 22/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9937 - precision_m: 0.9376 - recall_m: 0.8929 - f1_m: 0.9076\n",
      "Epoch 22: val_acc did not improve from 0.98059\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0176 - acc: 0.9937 - precision_m: 0.9370 - recall_m: 0.8925 - f1_m: 0.9070 - val_loss: 0.0867 - val_acc: 0.9780 - val_precision_m: 0.6499 - val_recall_m: 0.6887 - val_f1_m: 0.6368\n",
      "Epoch 23/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9939 - precision_m: 0.9410 - recall_m: 0.8958 - f1_m: 0.9118\n",
      "Epoch 23: val_acc did not improve from 0.98059\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0165 - acc: 0.9940 - precision_m: 0.9419 - recall_m: 0.8968 - f1_m: 0.9128 - val_loss: 0.1105 - val_acc: 0.9788 - val_precision_m: 0.7781 - val_recall_m: 0.4805 - val_f1_m: 0.5600\n",
      "Epoch 24/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9946 - precision_m: 0.9462 - recall_m: 0.9042 - f1_m: 0.9181\n",
      "Epoch 24: val_acc did not improve from 0.98059\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0148 - acc: 0.9945 - precision_m: 0.9456 - recall_m: 0.9037 - f1_m: 0.9176 - val_loss: 0.0903 - val_acc: 0.9762 - val_precision_m: 0.6183 - val_recall_m: 0.6835 - val_f1_m: 0.6213\n",
      "Epoch 25/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9947 - precision_m: 0.9443 - recall_m: 0.9069 - f1_m: 0.9176\n",
      "Epoch 25: val_acc did not improve from 0.98059\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0148 - acc: 0.9946 - precision_m: 0.9440 - recall_m: 0.9051 - f1_m: 0.9165 - val_loss: 0.1051 - val_acc: 0.9804 - val_precision_m: 0.7356 - val_recall_m: 0.5715 - val_f1_m: 0.6227\n",
      "Epoch 26/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9940 - precision_m: 0.9463 - recall_m: 0.8932 - f1_m: 0.9093\n",
      "Epoch 26: val_acc did not improve from 0.98059\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0158 - acc: 0.9940 - precision_m: 0.9468 - recall_m: 0.8929 - f1_m: 0.9095 - val_loss: 0.1069 - val_acc: 0.9745 - val_precision_m: 0.6047 - val_recall_m: 0.6907 - val_f1_m: 0.6131\n",
      "Epoch 27/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0133 - acc: 0.9952 - precision_m: 0.9521 - recall_m: 0.9201 - f1_m: 0.9314\n",
      "Epoch 27: val_acc did not improve from 0.98059\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0132 - acc: 0.9952 - precision_m: 0.9526 - recall_m: 0.9215 - f1_m: 0.9324 - val_loss: 0.1262 - val_acc: 0.9784 - val_precision_m: 0.7249 - val_recall_m: 0.5338 - val_f1_m: 0.5833\n",
      "Epoch 28/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9954 - precision_m: 0.9528 - recall_m: 0.9225 - f1_m: 0.9311\n",
      "Epoch 28: val_acc did not improve from 0.98059\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0126 - acc: 0.9954 - precision_m: 0.9530 - recall_m: 0.9232 - f1_m: 0.9317 - val_loss: 0.1302 - val_acc: 0.9790 - val_precision_m: 0.6808 - val_recall_m: 0.5769 - val_f1_m: 0.6032\n",
      "Epoch 29/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9960 - precision_m: 0.9587 - recall_m: 0.9328 - f1_m: 0.9407\n",
      "Epoch 29: val_acc did not improve from 0.98059\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0112 - acc: 0.9960 - precision_m: 0.9585 - recall_m: 0.9339 - f1_m: 0.9413 - val_loss: 0.1219 - val_acc: 0.9792 - val_precision_m: 0.6987 - val_recall_m: 0.6030 - val_f1_m: 0.6217\n",
      "Epoch 30/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9962 - precision_m: 0.9640 - recall_m: 0.9355 - f1_m: 0.9451\n",
      "Epoch 30: val_acc did not improve from 0.98059\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0104 - acc: 0.9962 - precision_m: 0.9644 - recall_m: 0.9357 - f1_m: 0.9454 - val_loss: 0.1226 - val_acc: 0.9806 - val_precision_m: 0.7380 - val_recall_m: 0.5648 - val_f1_m: 0.6124\n",
      "Score for fold 8: loss of 0.08589111268520355; acc of 98.05941581726074%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.07719250023365021; acc of 98.1967031955719%\n",
      "Test Precision: precision_m of 27.789556980133057%\n",
      "Test Recall: recall_m of 23.19181263446808%\n",
      "Test F1: f1_m of 24.3171826004982%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "Epoch 1/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.1508 - acc: 0.9611 - precision_m: 0.0704 - recall_m: 0.0169 - f1_m: 0.0207\n",
      "Epoch 1: val_acc improved from -inf to 0.96270, saving model to models/best_model_6_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 3s 6ms/step - loss: 0.1508 - acc: 0.9611 - precision_m: 0.0704 - recall_m: 0.0169 - f1_m: 0.0207 - val_loss: 0.1120 - val_acc: 0.9627 - val_precision_m: 0.1515 - val_recall_m: 0.0208 - val_f1_m: 0.0364\n",
      "Epoch 2/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0953 - acc: 0.9683 - precision_m: 0.6254 - recall_m: 0.2464 - f1_m: 0.3204\n",
      "Epoch 2: val_acc improved from 0.96270 to 0.97164, saving model to models/best_model_6_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0953 - acc: 0.9683 - precision_m: 0.6265 - recall_m: 0.2486 - f1_m: 0.3232 - val_loss: 0.0870 - val_acc: 0.9716 - val_precision_m: 0.7477 - val_recall_m: 0.3265 - val_f1_m: 0.4204\n",
      "Epoch 3/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0799 - acc: 0.9729 - precision_m: 0.7349 - recall_m: 0.3963 - f1_m: 0.4842\n",
      "Epoch 3: val_acc did not improve from 0.97164\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0800 - acc: 0.9730 - precision_m: 0.7357 - recall_m: 0.3968 - f1_m: 0.4851 - val_loss: 0.0897 - val_acc: 0.9709 - val_precision_m: 0.6128 - val_recall_m: 0.2353 - val_f1_m: 0.3194\n",
      "Epoch 4/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0730 - acc: 0.9751 - precision_m: 0.7489 - recall_m: 0.4597 - f1_m: 0.5402\n",
      "Epoch 4: val_acc improved from 0.97164 to 0.97569, saving model to models/best_model_6_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0729 - acc: 0.9751 - precision_m: 0.7484 - recall_m: 0.4617 - f1_m: 0.5415 - val_loss: 0.0823 - val_acc: 0.9757 - val_precision_m: 0.7954 - val_recall_m: 0.4477 - val_f1_m: 0.5425\n",
      "Epoch 5/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0673 - acc: 0.9769 - precision_m: 0.8014 - recall_m: 0.5104 - f1_m: 0.5899\n",
      "Epoch 5: val_acc did not improve from 0.97569\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0673 - acc: 0.9769 - precision_m: 0.8006 - recall_m: 0.5099 - f1_m: 0.5894 - val_loss: 0.0857 - val_acc: 0.9737 - val_precision_m: 0.6741 - val_recall_m: 0.5686 - val_f1_m: 0.5977\n",
      "Epoch 6/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9782 - precision_m: 0.7991 - recall_m: 0.5435 - f1_m: 0.6169\n",
      "Epoch 6: val_acc did not improve from 0.97569\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0634 - acc: 0.9782 - precision_m: 0.7986 - recall_m: 0.5450 - f1_m: 0.6179 - val_loss: 0.0818 - val_acc: 0.9722 - val_precision_m: 0.6361 - val_recall_m: 0.6321 - val_f1_m: 0.6126\n",
      "Epoch 7/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0600 - acc: 0.9796 - precision_m: 0.8112 - recall_m: 0.5763 - f1_m: 0.6466\n",
      "Epoch 7: val_acc did not improve from 0.97569\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0600 - acc: 0.9797 - precision_m: 0.8140 - recall_m: 0.5763 - f1_m: 0.6477 - val_loss: 0.0756 - val_acc: 0.9733 - val_precision_m: 0.6301 - val_recall_m: 0.6079 - val_f1_m: 0.5936\n",
      "Epoch 8/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0555 - acc: 0.9807 - precision_m: 0.8221 - recall_m: 0.6087 - f1_m: 0.6737\n",
      "Epoch 8: val_acc improved from 0.97569 to 0.97891, saving model to models/best_model_6_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0557 - acc: 0.9805 - precision_m: 0.8175 - recall_m: 0.6066 - f1_m: 0.6705 - val_loss: 0.0716 - val_acc: 0.9789 - val_precision_m: 0.7736 - val_recall_m: 0.5823 - val_f1_m: 0.6367\n",
      "Epoch 9/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0520 - acc: 0.9822 - precision_m: 0.8374 - recall_m: 0.6335 - f1_m: 0.6989\n",
      "Epoch 9: val_acc did not improve from 0.97891\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0521 - acc: 0.9822 - precision_m: 0.8375 - recall_m: 0.6334 - f1_m: 0.6991 - val_loss: 0.0738 - val_acc: 0.9763 - val_precision_m: 0.6535 - val_recall_m: 0.6687 - val_f1_m: 0.6413\n",
      "Epoch 10/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0498 - acc: 0.9829 - precision_m: 0.8408 - recall_m: 0.6568 - f1_m: 0.7134\n",
      "Epoch 10: val_acc improved from 0.97891 to 0.97939, saving model to models/best_model_6_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0497 - acc: 0.9829 - precision_m: 0.8407 - recall_m: 0.6569 - f1_m: 0.7136 - val_loss: 0.0695 - val_acc: 0.9794 - val_precision_m: 0.8438 - val_recall_m: 0.5643 - val_f1_m: 0.6409\n",
      "Epoch 11/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9836 - precision_m: 0.8509 - recall_m: 0.6766 - f1_m: 0.7308\n",
      "Epoch 11: val_acc did not improve from 0.97939\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0460 - acc: 0.9836 - precision_m: 0.8522 - recall_m: 0.6757 - f1_m: 0.7305 - val_loss: 0.0747 - val_acc: 0.9789 - val_precision_m: 0.7809 - val_recall_m: 0.5512 - val_f1_m: 0.6181\n",
      "Epoch 12/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9849 - precision_m: 0.8618 - recall_m: 0.6975 - f1_m: 0.7537\n",
      "Epoch 12: val_acc did not improve from 0.97939\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0420 - acc: 0.9848 - precision_m: 0.8593 - recall_m: 0.6978 - f1_m: 0.7525 - val_loss: 0.0994 - val_acc: 0.9760 - val_precision_m: 0.8906 - val_recall_m: 0.3838 - val_f1_m: 0.5076\n",
      "Epoch 13/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9847 - precision_m: 0.8598 - recall_m: 0.7042 - f1_m: 0.7505\n",
      "Epoch 13: val_acc improved from 0.97939 to 0.98117, saving model to models/best_model_6_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0420 - acc: 0.9848 - precision_m: 0.8612 - recall_m: 0.7040 - f1_m: 0.7512 - val_loss: 0.0766 - val_acc: 0.9812 - val_precision_m: 0.8512 - val_recall_m: 0.5805 - val_f1_m: 0.6581\n",
      "Epoch 14/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0372 - acc: 0.9870 - precision_m: 0.8845 - recall_m: 0.7475 - f1_m: 0.7947\n",
      "Epoch 14: val_acc did not improve from 0.98117\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0373 - acc: 0.9870 - precision_m: 0.8850 - recall_m: 0.7459 - f1_m: 0.7935 - val_loss: 0.0838 - val_acc: 0.9776 - val_precision_m: 0.8495 - val_recall_m: 0.4725 - val_f1_m: 0.5816\n",
      "Epoch 15/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9875 - precision_m: 0.8796 - recall_m: 0.7664 - f1_m: 0.8031\n",
      "Epoch 15: val_acc did not improve from 0.98117\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0343 - acc: 0.9875 - precision_m: 0.8801 - recall_m: 0.7668 - f1_m: 0.8037 - val_loss: 0.0838 - val_acc: 0.9800 - val_precision_m: 0.8276 - val_recall_m: 0.5270 - val_f1_m: 0.6206\n",
      "Epoch 16/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9887 - precision_m: 0.8907 - recall_m: 0.7761 - f1_m: 0.8153\n",
      "Epoch 16: val_acc did not improve from 0.98117\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0320 - acc: 0.9886 - precision_m: 0.8910 - recall_m: 0.7733 - f1_m: 0.8138 - val_loss: 0.0775 - val_acc: 0.9751 - val_precision_m: 0.6539 - val_recall_m: 0.6445 - val_f1_m: 0.6235\n",
      "Epoch 17/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0308 - acc: 0.9891 - precision_m: 0.8987 - recall_m: 0.7956 - f1_m: 0.8293\n",
      "Epoch 17: val_acc did not improve from 0.98117\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0309 - acc: 0.9891 - precision_m: 0.8977 - recall_m: 0.7958 - f1_m: 0.8291 - val_loss: 0.0784 - val_acc: 0.9769 - val_precision_m: 0.6452 - val_recall_m: 0.6670 - val_f1_m: 0.6315\n",
      "Epoch 18/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0286 - acc: 0.9894 - precision_m: 0.9035 - recall_m: 0.8039 - f1_m: 0.8380\n",
      "Epoch 18: val_acc did not improve from 0.98117\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0287 - acc: 0.9895 - precision_m: 0.9034 - recall_m: 0.8055 - f1_m: 0.8388 - val_loss: 0.0755 - val_acc: 0.9797 - val_precision_m: 0.7677 - val_recall_m: 0.6306 - val_f1_m: 0.6665\n",
      "Epoch 19/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9904 - precision_m: 0.9039 - recall_m: 0.8232 - f1_m: 0.8506\n",
      "Epoch 19: val_acc did not improve from 0.98117\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0267 - acc: 0.9904 - precision_m: 0.9039 - recall_m: 0.8238 - f1_m: 0.8510 - val_loss: 0.0872 - val_acc: 0.9805 - val_precision_m: 0.7748 - val_recall_m: 0.6328 - val_f1_m: 0.6658\n",
      "Epoch 20/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9916 - precision_m: 0.9224 - recall_m: 0.8401 - f1_m: 0.8690\n",
      "Epoch 20: val_acc did not improve from 0.98117\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0237 - acc: 0.9916 - precision_m: 0.9234 - recall_m: 0.8388 - f1_m: 0.8687 - val_loss: 0.0761 - val_acc: 0.9799 - val_precision_m: 0.7633 - val_recall_m: 0.6301 - val_f1_m: 0.6635\n",
      "Epoch 21/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0226 - acc: 0.9918 - precision_m: 0.9168 - recall_m: 0.8536 - f1_m: 0.8722\n",
      "Epoch 21: val_acc did not improve from 0.98117\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0226 - acc: 0.9918 - precision_m: 0.9165 - recall_m: 0.8538 - f1_m: 0.8722 - val_loss: 0.0924 - val_acc: 0.9800 - val_precision_m: 0.7824 - val_recall_m: 0.6146 - val_f1_m: 0.6588\n",
      "Epoch 22/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9921 - precision_m: 0.9241 - recall_m: 0.8594 - f1_m: 0.8813\n",
      "Epoch 22: val_acc did not improve from 0.98117\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0216 - acc: 0.9921 - precision_m: 0.9231 - recall_m: 0.8592 - f1_m: 0.8808 - val_loss: 0.0858 - val_acc: 0.9770 - val_precision_m: 0.6814 - val_recall_m: 0.6696 - val_f1_m: 0.6376\n",
      "Epoch 23/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9925 - precision_m: 0.9296 - recall_m: 0.8661 - f1_m: 0.8856\n",
      "Epoch 23: val_acc did not improve from 0.98117\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0205 - acc: 0.9926 - precision_m: 0.9300 - recall_m: 0.8667 - f1_m: 0.8863 - val_loss: 0.0950 - val_acc: 0.9788 - val_precision_m: 0.7192 - val_recall_m: 0.6426 - val_f1_m: 0.6529\n",
      "Epoch 24/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9934 - precision_m: 0.9335 - recall_m: 0.8849 - f1_m: 0.8998\n",
      "Epoch 24: val_acc did not improve from 0.98117\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0183 - acc: 0.9934 - precision_m: 0.9339 - recall_m: 0.8855 - f1_m: 0.9004 - val_loss: 0.1200 - val_acc: 0.9807 - val_precision_m: 0.7906 - val_recall_m: 0.5424 - val_f1_m: 0.6278\n",
      "Epoch 25/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9938 - precision_m: 0.9390 - recall_m: 0.8899 - f1_m: 0.9064\n",
      "Epoch 25: val_acc did not improve from 0.98117\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0168 - acc: 0.9938 - precision_m: 0.9403 - recall_m: 0.8894 - f1_m: 0.9068 - val_loss: 0.1046 - val_acc: 0.9752 - val_precision_m: 0.6376 - val_recall_m: 0.7331 - val_f1_m: 0.6575\n",
      "Epoch 26/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.9938 - precision_m: 0.9365 - recall_m: 0.8900 - f1_m: 0.9048\n",
      "Epoch 26: val_acc did not improve from 0.98117\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0172 - acc: 0.9938 - precision_m: 0.9367 - recall_m: 0.8903 - f1_m: 0.9051 - val_loss: 0.1124 - val_acc: 0.9811 - val_precision_m: 0.7790 - val_recall_m: 0.6039 - val_f1_m: 0.6557\n",
      "Epoch 27/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9941 - precision_m: 0.9388 - recall_m: 0.9006 - f1_m: 0.9111\n",
      "Epoch 27: val_acc did not improve from 0.98117\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0154 - acc: 0.9941 - precision_m: 0.9395 - recall_m: 0.8990 - f1_m: 0.9104 - val_loss: 0.1192 - val_acc: 0.9766 - val_precision_m: 0.6614 - val_recall_m: 0.6565 - val_f1_m: 0.6352\n",
      "Epoch 28/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9952 - precision_m: 0.9495 - recall_m: 0.9197 - f1_m: 0.9282\n",
      "Epoch 28: val_acc did not improve from 0.98117\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0132 - acc: 0.9952 - precision_m: 0.9498 - recall_m: 0.9178 - f1_m: 0.9274 - val_loss: 0.1240 - val_acc: 0.9664 - val_precision_m: 0.5252 - val_recall_m: 0.7525 - val_f1_m: 0.5962\n",
      "Epoch 29/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0114 - acc: 0.9960 - precision_m: 0.9557 - recall_m: 0.9340 - f1_m: 0.9396\n",
      "Epoch 29: val_acc did not improve from 0.98117\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0114 - acc: 0.9960 - precision_m: 0.9556 - recall_m: 0.9335 - f1_m: 0.9394 - val_loss: 0.1239 - val_acc: 0.9799 - val_precision_m: 0.7498 - val_recall_m: 0.6225 - val_f1_m: 0.6562\n",
      "Epoch 30/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9949 - precision_m: 0.9472 - recall_m: 0.9117 - f1_m: 0.9219\n",
      "Epoch 30: val_acc did not improve from 0.98117\n",
      "291/291 [==============================] - 1s 5ms/step - loss: 0.0134 - acc: 0.9949 - precision_m: 0.9467 - recall_m: 0.9118 - f1_m: 0.9218 - val_loss: 0.1444 - val_acc: 0.9807 - val_precision_m: 0.7640 - val_recall_m: 0.5835 - val_f1_m: 0.6343\n",
      "Score for fold 9: loss of 0.07656946778297424; acc of 98.11725616455078%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.06869389861822128; acc of 97.96426892280579%\n",
      "Test Precision: precision_m of 28.696659207344055%\n",
      "Test Recall: recall_m of 22.646096348762512%\n",
      "Test F1: f1_m of 24.481137096881866%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1631 - acc: 0.9593 - precision_m: 0.0941 - recall_m: 0.0244 - f1_m: 0.0280\n",
      "Epoch 1: val_acc improved from -inf to 0.96034, saving model to models/best_model_6_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 3s 6ms/step - loss: 0.1631 - acc: 0.9593 - precision_m: 0.0941 - recall_m: 0.0244 - f1_m: 0.0280 - val_loss: 0.1258 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0932 - acc: 0.9692 - precision_m: 0.6419 - recall_m: 0.2689 - f1_m: 0.3469\n",
      "Epoch 2: val_acc improved from 0.96034 to 0.96430, saving model to models/best_model_6_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0930 - acc: 0.9692 - precision_m: 0.6416 - recall_m: 0.2666 - f1_m: 0.3445 - val_loss: 0.1001 - val_acc: 0.9643 - val_precision_m: 0.4747 - val_recall_m: 0.1152 - val_f1_m: 0.1761\n",
      "Epoch 3/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0822 - acc: 0.9722 - precision_m: 0.7135 - recall_m: 0.3818 - f1_m: 0.4599\n",
      "Epoch 3: val_acc improved from 0.96430 to 0.97091, saving model to models/best_model_6_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0822 - acc: 0.9722 - precision_m: 0.7155 - recall_m: 0.3813 - f1_m: 0.4605 - val_loss: 0.0874 - val_acc: 0.9709 - val_precision_m: 0.7401 - val_recall_m: 0.4156 - val_f1_m: 0.5053\n",
      "Epoch 4/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0734 - acc: 0.9747 - precision_m: 0.7552 - recall_m: 0.4604 - f1_m: 0.5402\n",
      "Epoch 4: val_acc did not improve from 0.97091\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0736 - acc: 0.9747 - precision_m: 0.7544 - recall_m: 0.4610 - f1_m: 0.5408 - val_loss: 0.0858 - val_acc: 0.9706 - val_precision_m: 0.6338 - val_recall_m: 0.6119 - val_f1_m: 0.5892\n",
      "Epoch 5/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9766 - precision_m: 0.7679 - recall_m: 0.5045 - f1_m: 0.5816\n",
      "Epoch 5: val_acc improved from 0.97091 to 0.97308, saving model to models/best_model_6_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0682 - acc: 0.9765 - precision_m: 0.7611 - recall_m: 0.5004 - f1_m: 0.5767 - val_loss: 0.0782 - val_acc: 0.9731 - val_precision_m: 0.7985 - val_recall_m: 0.4565 - val_f1_m: 0.5601\n",
      "Epoch 6/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0644 - acc: 0.9778 - precision_m: 0.7811 - recall_m: 0.5464 - f1_m: 0.6120\n",
      "Epoch 6: val_acc improved from 0.97308 to 0.97572, saving model to models/best_model_6_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0647 - acc: 0.9777 - precision_m: 0.7814 - recall_m: 0.5472 - f1_m: 0.6130 - val_loss: 0.0769 - val_acc: 0.9757 - val_precision_m: 0.7456 - val_recall_m: 0.5925 - val_f1_m: 0.6321\n",
      "Epoch 7/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0585 - acc: 0.9799 - precision_m: 0.8092 - recall_m: 0.5837 - f1_m: 0.6549\n",
      "Epoch 7: val_acc did not improve from 0.97572\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0586 - acc: 0.9799 - precision_m: 0.8115 - recall_m: 0.5836 - f1_m: 0.6561 - val_loss: 0.0734 - val_acc: 0.9755 - val_precision_m: 0.7333 - val_recall_m: 0.5939 - val_f1_m: 0.6271\n",
      "Epoch 8/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0557 - acc: 0.9810 - precision_m: 0.8188 - recall_m: 0.6050 - f1_m: 0.6698\n",
      "Epoch 8: val_acc did not improve from 0.97572\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0557 - acc: 0.9811 - precision_m: 0.8208 - recall_m: 0.6080 - f1_m: 0.6728 - val_loss: 0.0841 - val_acc: 0.9703 - val_precision_m: 0.5919 - val_recall_m: 0.7280 - val_f1_m: 0.6302\n",
      "Epoch 9/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0539 - acc: 0.9810 - precision_m: 0.8313 - recall_m: 0.6231 - f1_m: 0.6832\n",
      "Epoch 9: val_acc did not improve from 0.97572\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0540 - acc: 0.9809 - precision_m: 0.8314 - recall_m: 0.6196 - f1_m: 0.6810 - val_loss: 0.0734 - val_acc: 0.9751 - val_precision_m: 0.6868 - val_recall_m: 0.6798 - val_f1_m: 0.6528\n",
      "Epoch 10/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9823 - precision_m: 0.8331 - recall_m: 0.6557 - f1_m: 0.7076\n",
      "Epoch 10: val_acc improved from 0.97572 to 0.97776, saving model to models/best_model_6_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0502 - acc: 0.9823 - precision_m: 0.8334 - recall_m: 0.6553 - f1_m: 0.7078 - val_loss: 0.0720 - val_acc: 0.9778 - val_precision_m: 0.7559 - val_recall_m: 0.6393 - val_f1_m: 0.6676\n",
      "Epoch 11/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0463 - acc: 0.9837 - precision_m: 0.8454 - recall_m: 0.6860 - f1_m: 0.7354\n",
      "Epoch 11: val_acc did not improve from 0.97776\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0463 - acc: 0.9837 - precision_m: 0.8435 - recall_m: 0.6836 - f1_m: 0.7334 - val_loss: 0.0801 - val_acc: 0.9764 - val_precision_m: 0.8995 - val_recall_m: 0.4780 - val_f1_m: 0.6032\n",
      "Epoch 12/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0440 - acc: 0.9846 - precision_m: 0.8606 - recall_m: 0.7053 - f1_m: 0.7531\n",
      "Epoch 12: val_acc did not improve from 0.97776\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0438 - acc: 0.9847 - precision_m: 0.8607 - recall_m: 0.7053 - f1_m: 0.7534 - val_loss: 0.0786 - val_acc: 0.9773 - val_precision_m: 0.7969 - val_recall_m: 0.5915 - val_f1_m: 0.6451\n",
      "Epoch 13/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9854 - precision_m: 0.8520 - recall_m: 0.7267 - f1_m: 0.7701\n",
      "Epoch 13: val_acc improved from 0.97776 to 0.97812, saving model to models/best_model_6_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0406 - acc: 0.9853 - precision_m: 0.8515 - recall_m: 0.7256 - f1_m: 0.7690 - val_loss: 0.0779 - val_acc: 0.9781 - val_precision_m: 0.8051 - val_recall_m: 0.6124 - val_f1_m: 0.6718\n",
      "Epoch 14/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0385 - acc: 0.9866 - precision_m: 0.8724 - recall_m: 0.7338 - f1_m: 0.7810\n",
      "Epoch 14: val_acc did not improve from 0.97812\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0387 - acc: 0.9865 - precision_m: 0.8710 - recall_m: 0.7318 - f1_m: 0.7791 - val_loss: 0.0824 - val_acc: 0.9781 - val_precision_m: 0.8464 - val_recall_m: 0.5605 - val_f1_m: 0.6467\n",
      "Epoch 15/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0377 - acc: 0.9865 - precision_m: 0.8730 - recall_m: 0.7459 - f1_m: 0.7858\n",
      "Epoch 15: val_acc improved from 0.97812 to 0.97873, saving model to models/best_model_6_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0375 - acc: 0.9866 - precision_m: 0.8739 - recall_m: 0.7464 - f1_m: 0.7866 - val_loss: 0.0751 - val_acc: 0.9787 - val_precision_m: 0.8086 - val_recall_m: 0.6279 - val_f1_m: 0.6766\n",
      "Epoch 16/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0346 - acc: 0.9874 - precision_m: 0.8796 - recall_m: 0.7588 - f1_m: 0.7976\n",
      "Epoch 16: val_acc improved from 0.97873 to 0.97897, saving model to models/best_model_6_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0346 - acc: 0.9874 - precision_m: 0.8805 - recall_m: 0.7569 - f1_m: 0.7964 - val_loss: 0.0781 - val_acc: 0.9790 - val_precision_m: 0.7838 - val_recall_m: 0.6302 - val_f1_m: 0.6784\n",
      "Epoch 17/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9880 - precision_m: 0.8873 - recall_m: 0.7772 - f1_m: 0.8132\n",
      "Epoch 17: val_acc did not improve from 0.97897\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0339 - acc: 0.9881 - precision_m: 0.8879 - recall_m: 0.7780 - f1_m: 0.8139 - val_loss: 0.0728 - val_acc: 0.9780 - val_precision_m: 0.7508 - val_recall_m: 0.6576 - val_f1_m: 0.6735\n",
      "Epoch 18/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.9893 - precision_m: 0.8927 - recall_m: 0.8048 - f1_m: 0.8333\n",
      "Epoch 18: val_acc did not improve from 0.97897\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0301 - acc: 0.9891 - precision_m: 0.8933 - recall_m: 0.7980 - f1_m: 0.8286 - val_loss: 0.0751 - val_acc: 0.9788 - val_precision_m: 0.7925 - val_recall_m: 0.6316 - val_f1_m: 0.6830\n",
      "Epoch 19/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9892 - precision_m: 0.8936 - recall_m: 0.8104 - f1_m: 0.8367\n",
      "Epoch 19: val_acc did not improve from 0.97897\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0296 - acc: 0.9892 - precision_m: 0.8942 - recall_m: 0.8099 - f1_m: 0.8368 - val_loss: 0.0808 - val_acc: 0.9762 - val_precision_m: 0.7045 - val_recall_m: 0.6653 - val_f1_m: 0.6614\n",
      "Epoch 20/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9900 - precision_m: 0.9100 - recall_m: 0.8156 - f1_m: 0.8465\n",
      "Epoch 20: val_acc did not improve from 0.97897\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0265 - acc: 0.9900 - precision_m: 0.9093 - recall_m: 0.8145 - f1_m: 0.8454 - val_loss: 0.0897 - val_acc: 0.9746 - val_precision_m: 0.6857 - val_recall_m: 0.6718 - val_f1_m: 0.6429\n",
      "Epoch 21/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0253 - acc: 0.9910 - precision_m: 0.9146 - recall_m: 0.8330 - f1_m: 0.8590\n",
      "Epoch 21: val_acc did not improve from 0.97897\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0253 - acc: 0.9910 - precision_m: 0.9151 - recall_m: 0.8328 - f1_m: 0.8593 - val_loss: 0.0898 - val_acc: 0.9755 - val_precision_m: 0.6878 - val_recall_m: 0.6967 - val_f1_m: 0.6647\n",
      "Epoch 22/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9916 - precision_m: 0.9139 - recall_m: 0.8471 - f1_m: 0.8695\n",
      "Epoch 22: val_acc did not improve from 0.97897\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0224 - acc: 0.9916 - precision_m: 0.9140 - recall_m: 0.8468 - f1_m: 0.8695 - val_loss: 0.0908 - val_acc: 0.9760 - val_precision_m: 0.6949 - val_recall_m: 0.6813 - val_f1_m: 0.6623\n",
      "Epoch 23/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9922 - precision_m: 0.9200 - recall_m: 0.8653 - f1_m: 0.8815\n",
      "Epoch 23: val_acc did not improve from 0.97897\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0218 - acc: 0.9921 - precision_m: 0.9185 - recall_m: 0.8637 - f1_m: 0.8799 - val_loss: 0.1113 - val_acc: 0.9779 - val_precision_m: 0.8040 - val_recall_m: 0.5612 - val_f1_m: 0.6370\n",
      "Epoch 24/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9924 - precision_m: 0.9275 - recall_m: 0.8582 - f1_m: 0.8830\n",
      "Epoch 24: val_acc did not improve from 0.97897\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0206 - acc: 0.9923 - precision_m: 0.9267 - recall_m: 0.8589 - f1_m: 0.8831 - val_loss: 0.0945 - val_acc: 0.9767 - val_precision_m: 0.6928 - val_recall_m: 0.6990 - val_f1_m: 0.6750\n",
      "Epoch 25/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0200 - acc: 0.9925 - precision_m: 0.9158 - recall_m: 0.8669 - f1_m: 0.8822\n",
      "Epoch 25: val_acc did not improve from 0.97897\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0198 - acc: 0.9926 - precision_m: 0.9167 - recall_m: 0.8679 - f1_m: 0.8833 - val_loss: 0.1090 - val_acc: 0.9772 - val_precision_m: 0.7444 - val_recall_m: 0.6260 - val_f1_m: 0.6596\n",
      "Epoch 26/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0188 - acc: 0.9931 - precision_m: 0.9330 - recall_m: 0.8784 - f1_m: 0.8950\n",
      "Epoch 26: val_acc did not improve from 0.97897\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0188 - acc: 0.9932 - precision_m: 0.9324 - recall_m: 0.8796 - f1_m: 0.8951 - val_loss: 0.0916 - val_acc: 0.9770 - val_precision_m: 0.7350 - val_recall_m: 0.6580 - val_f1_m: 0.6666\n",
      "Epoch 27/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9947 - precision_m: 0.9458 - recall_m: 0.9027 - f1_m: 0.9164\n",
      "Epoch 27: val_acc did not improve from 0.97897\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0153 - acc: 0.9947 - precision_m: 0.9460 - recall_m: 0.9027 - f1_m: 0.9166 - val_loss: 0.1121 - val_acc: 0.9761 - val_precision_m: 0.7337 - val_recall_m: 0.6471 - val_f1_m: 0.6573\n",
      "Epoch 28/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9935 - precision_m: 0.9301 - recall_m: 0.8885 - f1_m: 0.8995\n",
      "Epoch 28: val_acc did not improve from 0.97897\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0173 - acc: 0.9935 - precision_m: 0.9308 - recall_m: 0.8892 - f1_m: 0.9003 - val_loss: 0.1091 - val_acc: 0.9762 - val_precision_m: 0.6948 - val_recall_m: 0.6508 - val_f1_m: 0.6525\n",
      "Epoch 29/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0147 - acc: 0.9944 - precision_m: 0.9414 - recall_m: 0.9042 - f1_m: 0.9164\n",
      "Epoch 29: val_acc did not improve from 0.97897\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0147 - acc: 0.9944 - precision_m: 0.9412 - recall_m: 0.9044 - f1_m: 0.9164 - val_loss: 0.1159 - val_acc: 0.9772 - val_precision_m: 0.7492 - val_recall_m: 0.6445 - val_f1_m: 0.6661\n",
      "Epoch 30/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9948 - precision_m: 0.9459 - recall_m: 0.9119 - f1_m: 0.9212\n",
      "Epoch 30: val_acc did not improve from 0.97897\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0141 - acc: 0.9948 - precision_m: 0.9463 - recall_m: 0.9114 - f1_m: 0.9212 - val_loss: 0.1305 - val_acc: 0.9775 - val_precision_m: 0.7722 - val_recall_m: 0.6313 - val_f1_m: 0.6693\n",
      "Score for fold 10: loss of 0.07805041968822479; acc of 97.89663553237915%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.0603441521525383; acc of 98.04546236991882%\n",
      "Test Precision: precision_m of 33.783626556396484%\n",
      "Test Recall: recall_m of 28.89682948589325%\n",
      "Test F1: f1_m of 29.91560399532318%\n",
      "------------------------------------------------------------------------\n",
      "Validation score per fold\n",
      "> Fold 1 - Loss: 0.08989149332046509 - Accuracy: 97.81440496444702%\n",
      "> Fold 2 - Loss: 0.11013027280569077 - Accuracy: 98.25170636177063%\n",
      "> Fold 3 - Loss: 0.06453768163919449 - Accuracy: 98.41878414154053%\n",
      "> Fold 4 - Loss: 0.07412908226251602 - Accuracy: 98.08955192565918%\n",
      "> Fold 5 - Loss: 0.1215633749961853 - Accuracy: 98.14748167991638%\n",
      "> Fold 6 - Loss: 0.08310282975435257 - Accuracy: 98.14390540122986%\n",
      "> Fold 7 - Loss: 0.08212610334157944 - Accuracy: 98.05256724357605%\n",
      "> Fold 8 - Loss: 0.08589111268520355 - Accuracy: 98.05941581726074%\n",
      "> Fold 9 - Loss: 0.07656946778297424 - Accuracy: 98.11725616455078%\n",
      "> Fold 10 - Loss: 0.07805041968822479 - Accuracy: 97.89663553237915%\n",
      "------------------------------------------------------------------------\n",
      "Testing score per fold\n",
      "> Fold 1 - Accuracy: 98.32709431648254 - Precision: 25.545772910118103 - Recall: 21.330203115940094 - F1: 22.41954803466797%\n",
      "> Fold 2 - Accuracy: 98.05856347084045 - Precision: 32.10616111755371 - Recall: 25.80167055130005 - F1: 27.336999773979187%\n",
      "> Fold 3 - Accuracy: 98.05908203125 - Precision: 29.39341962337494 - Recall: 23.741497099399567 - F1: 25.340357422828674%\n",
      "> Fold 4 - Accuracy: 97.68473505973816 - Precision: 30.827152729034424 - Recall: 26.290535926818848 - F1: 27.38366425037384%\n",
      "> Fold 5 - Accuracy: 98.01409244537354 - Precision: 30.80204427242279 - Recall: 24.502570927143097 - F1: 26.31005346775055%\n",
      "> Fold 6 - Accuracy: 97.76906967163086 - Precision: 26.456257700920105 - Recall: 22.351329028606415 - F1: 23.221492767333984%\n",
      "> Fold 7 - Accuracy: 98.09939861297607 - Precision: 23.844367265701294 - Recall: 19.190308451652527 - F1: 20.26924043893814%\n",
      "> Fold 8 - Accuracy: 98.1967031955719 - Precision: 27.789556980133057 - Recall: 23.19181263446808 - F1: 24.3171826004982%\n",
      "> Fold 9 - Accuracy: 97.96426892280579 - Precision: 28.696659207344055 - Recall: 22.646096348762512 - F1: 24.481137096881866%\n",
      "> Fold 10 - Accuracy: 98.04546236991882 - Precision: 33.783626556396484 - Recall: 28.89682948589325 - F1: 29.91560399532318%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Validation Accuracy: 98.09917092323303 (+- 0.16001218090121588)\n",
      "> Validation Loss: 0.08659918382763862\n",
      "> Testing Accuracy: 98.02184700965881 (+- 0.17719291876364945)\n",
      "> Testing Precision: 28.924501836299896\n",
      "> Testing Recall: 23.794285356998444\n",
      "> Testing F1: 25.09952798485756\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Lists to hold cross-validation results\n",
    "acc_6_per_fold = []\n",
    "loss_6_per_fold = []\n",
    "precision_6_per_fold = []\n",
    "recall_6_per_fold = []\n",
    "f1_6_per_fold = []\n",
    "\n",
    "testing_acc_6_per_fold = []\n",
    "testing_precision_6_per_fold = []\n",
    "testing_recall_6_per_fold = []\n",
    "testing_f1_6_per_fold = []\n",
    "\n",
    "# Load data from .npz files\n",
    "for fold_no in range(1, 11):\n",
    "    with np.load(f'fold_{fold_no}.npz') as data:\n",
    "        x_train = data['x_train_fold.npy']\n",
    "        y_train = data['y_train_fold.npy']\n",
    "        x_val = data['x_val_fold.npy']\n",
    "        y_val = data['y_val_fold.npy']\n",
    "        x_test = data['x_test_fold.npy']\n",
    "        y_test = data['y_test_fold.npy']\n",
    "        \n",
    "        # Converting ground truth arrays to one wake word (1) and 'other' (0)\n",
    "        wake_word_index = all_targets.index(wake_word)\n",
    "        y_train = np.equal(y_train, wake_word_index).astype('float64')\n",
    "        y_val = np.equal(y_val, wake_word_index).astype('float64')\n",
    "        y_test = np.equal(y_test, wake_word_index).astype('float64')\n",
    "        \n",
    "        # CNN for TF expects (batch, height, width, channels)\n",
    "        x_train = x_train.reshape(x_train.shape[0], \n",
    "                          x_train.shape[1], \n",
    "                          x_train.shape[2], \n",
    "                          1)\n",
    "        x_val = x_val.reshape(x_val.shape[0], \n",
    "                          x_val.shape[1], \n",
    "                          x_val.shape[2], \n",
    "                          1)\n",
    "        x_test = x_test.reshape(x_test.shape[0], \n",
    "                          x_test.shape[1], \n",
    "                          x_test.shape[2], \n",
    "                          1)\n",
    "        sample_shape = x_test.shape[1:]\n",
    "\n",
    "    # CNN model\n",
    "    model_6 = models.Sequential()\n",
    "    model_6.add(layers.Conv2D(64, \n",
    "                            (2, 2), \n",
    "                            activation='relu',\n",
    "                            input_shape=sample_shape))\n",
    "    model_6.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model_6.add(layers.Conv2D(64, (2, 2), activation='relu'))\n",
    "    model_6.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model_6.add(layers.Conv2D(128, (2, 2), activation='relu'))\n",
    "    model_6.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Classifier\n",
    "    model_6.add(layers.Flatten())\n",
    "    model_6.add(layers.Dense(128, activation='relu'))\n",
    "    model_6.add(layers.Dropout(0.5))\n",
    "    model_6.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "\n",
    "    model_6.compile(loss='binary_crossentropy', \n",
    "              optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "              metrics=['acc', precision_m, recall_m, f1_m])\n",
    "\n",
    "    checkpoint_filepath = f'models/best_model_6_fold_{fold_no}.h5'\n",
    "    model_checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=False,\n",
    "        monitor='val_acc',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "        save_freq='epoch'\n",
    "    )\n",
    "\n",
    "    # Instantiate the custom callback\n",
    "    metrics_history = MetricsHistory()\n",
    "\n",
    "    # Print fold number\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Train\n",
    "    history_6 = model_6.fit(x_train, \n",
    "                    y_train, \n",
    "                    epochs=30, \n",
    "                    batch_size=256, \n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[model_checkpoint_callback, metrics_history])\n",
    "\n",
    "    model_6.load_weights(checkpoint_filepath)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    scores = model_6.evaluate(x_val, y_val, verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model_6.metrics_names[0]} of {scores[0]}; {model_6.metrics_names[1]} of {scores[1] * 100}%')\n",
    "    acc_6_per_fold.append(scores[1] * 100)\n",
    "    loss_6_per_fold.append(scores[0])\n",
    "    precision_6_per_fold.append(metrics_history.best_metrics['precision_m'] * 100)\n",
    "    recall_6_per_fold.append(metrics_history.best_metrics['recall_m'] * 100)\n",
    "    f1_6_per_fold.append(metrics_history.best_metrics['f1_m'] * 100)\n",
    "\n",
    "    # Final evaluation on test set\n",
    "    final_scores = model_6.evaluate(x_test, y_test, verbose=0)\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Final test score: {model_6.metrics_names[0]} of {final_scores[0]}; {model_6.metrics_names[1]} of {final_scores[1] * 100}%')\n",
    "    print(f'Test Precision: {model_6.metrics_names[2]} of {final_scores[2] * 100}%')\n",
    "    print(f'Test Recall: {model_6.metrics_names[3]} of {final_scores[3] * 100}%')\n",
    "    print(f'Test F1: {model_6.metrics_names[4]} of {final_scores[4] * 100}%')\n",
    "\n",
    "    # Append test metrics to lists\n",
    "    testing_acc_6_per_fold.append(final_scores[1] * 100)\n",
    "    testing_precision_6_per_fold.append(final_scores[2] * 100)\n",
    "    testing_recall_6_per_fold.append(final_scores[3] * 100)\n",
    "    testing_f1_6_per_fold.append(final_scores[4] * 100)\n",
    "\n",
    "# Print the results\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Validation score per fold')\n",
    "for i in range(0, len(acc_6_per_fold)):\n",
    "    print(f'> Fold {i+1} - Loss: {loss_6_per_fold[i]} - Accuracy: {acc_6_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Testing score per fold')\n",
    "for i in range(0, len(testing_acc_6_per_fold)):\n",
    "    print(f'> Fold {i+1} - Accuracy: {testing_acc_6_per_fold[i]} - Precision: {testing_precision_6_per_fold[i]} - Recall: {testing_recall_6_per_fold[i]} - F1: {testing_f1_6_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Validation Accuracy: {np.mean(acc_6_per_fold)} (+- {np.std(acc_6_per_fold)})')\n",
    "print(f'> Validation Loss: {np.mean(loss_6_per_fold)}')\n",
    "print(f'> Testing Accuracy: {np.mean(testing_acc_6_per_fold)} (+- {np.std(testing_acc_6_per_fold)})')\n",
    "print(f'> Testing Precision: {np.mean(testing_precision_6_per_fold)}')\n",
    "print(f'> Testing Recall: {np.mean(testing_recall_6_per_fold)}')\n",
    "print(f'> Testing F1: {np.mean(testing_f1_6_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1685 - acc: 0.9597 - precision_m: 1.6053e-04 - recall_m: 0.0034 - f1_m: 3.0669e-04\n",
      "Epoch 1: val_acc improved from -inf to 0.96023, saving model to models/best_model_7_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 10s 21ms/step - loss: 0.1685 - acc: 0.9597 - precision_m: 1.6053e-04 - recall_m: 0.0034 - f1_m: 3.0669e-04 - val_loss: 0.1649 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1513 - acc: 0.9626 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 2: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1505 - acc: 0.9628 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1731 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 3/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.1464 - acc: 0.9629 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 3: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 5s 16ms/step - loss: 0.1464 - acc: 0.9628 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1528 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 4/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1447 - acc: 0.9629 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 4: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 5s 16ms/step - loss: 0.1450 - acc: 0.9628 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1481 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 5/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1438 - acc: 0.9628 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 5: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1438 - acc: 0.9628 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1522 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 6/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.1410 - acc: 0.9629 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 6: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 5s 16ms/step - loss: 0.1412 - acc: 0.9628 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1491 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 7/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1393 - acc: 0.9628 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 7: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 5s 16ms/step - loss: 0.1393 - acc: 0.9628 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1546 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 8/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1385 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 8: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 5s 16ms/step - loss: 0.1393 - acc: 0.9628 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1467 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 9/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1379 - acc: 0.9629 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 9: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 5s 15ms/step - loss: 0.1378 - acc: 0.9628 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1458 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 10/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.1360 - acc: 0.9628 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 10: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1360 - acc: 0.9628 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1436 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 11/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1346 - acc: 0.9628 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 11: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1345 - acc: 0.9628 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1409 - val_acc: 0.9601 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 12/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1323 - acc: 0.9628 - precision_m: 0.0098 - recall_m: 0.0014 - f1_m: 0.0025\n",
      "Epoch 12: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1322 - acc: 0.9628 - precision_m: 0.0097 - recall_m: 0.0014 - f1_m: 0.0024 - val_loss: 0.1386 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 13/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1316 - acc: 0.9628 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 13: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 5s 16ms/step - loss: 0.1316 - acc: 0.9628 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1414 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 14/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1302 - acc: 0.9628 - precision_m: 0.0363 - recall_m: 0.0052 - f1_m: 0.0089\n",
      "Epoch 14: val_acc improved from 0.96023 to 0.96035, saving model to models/best_model_7_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 5s 16ms/step - loss: 0.1302 - acc: 0.9628 - precision_m: 0.0360 - recall_m: 0.0052 - f1_m: 0.0088 - val_loss: 0.1407 - val_acc: 0.9603 - val_precision_m: 0.0303 - val_recall_m: 0.0023 - val_f1_m: 0.0043\n",
      "Epoch 15/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1282 - acc: 0.9630 - precision_m: 0.0952 - recall_m: 0.0143 - f1_m: 0.0236\n",
      "Epoch 15: val_acc did not improve from 0.96035\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1284 - acc: 0.9629 - precision_m: 0.0970 - recall_m: 0.0151 - f1_m: 0.0248 - val_loss: 0.1400 - val_acc: 0.9599 - val_precision_m: 0.0152 - val_recall_m: 0.0013 - val_f1_m: 0.0023\n",
      "Epoch 16/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1271 - acc: 0.9627 - precision_m: 0.1171 - recall_m: 0.0172 - f1_m: 0.0291\n",
      "Epoch 16: val_acc did not improve from 0.96035\n",
      "292/292 [==============================] - 5s 16ms/step - loss: 0.1270 - acc: 0.9628 - precision_m: 0.1159 - recall_m: 0.0171 - f1_m: 0.0288 - val_loss: 0.1453 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 17/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.1258 - acc: 0.9630 - precision_m: 0.1153 - recall_m: 0.0186 - f1_m: 0.0302\n",
      "Epoch 17: val_acc did not improve from 0.96035\n",
      "292/292 [==============================] - 5s 16ms/step - loss: 0.1259 - acc: 0.9629 - precision_m: 0.1149 - recall_m: 0.0186 - f1_m: 0.0301 - val_loss: 0.1387 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 18/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1237 - acc: 0.9633 - precision_m: 0.2707 - recall_m: 0.0443 - f1_m: 0.0728\n",
      "Epoch 18: val_acc did not improve from 0.96035\n",
      "292/292 [==============================] - 5s 16ms/step - loss: 0.1237 - acc: 0.9633 - precision_m: 0.2707 - recall_m: 0.0443 - f1_m: 0.0728 - val_loss: 0.1393 - val_acc: 0.9602 - val_precision_m: 0.0606 - val_recall_m: 0.0029 - val_f1_m: 0.0055\n",
      "Epoch 19/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1219 - acc: 0.9638 - precision_m: 0.3337 - recall_m: 0.0672 - f1_m: 0.1062\n",
      "Epoch 19: val_acc did not improve from 0.96035\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1220 - acc: 0.9638 - precision_m: 0.3337 - recall_m: 0.0670 - f1_m: 0.1059 - val_loss: 0.1351 - val_acc: 0.9601 - val_precision_m: 0.0606 - val_recall_m: 0.0167 - val_f1_m: 0.0232\n",
      "Epoch 20/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1201 - acc: 0.9637 - precision_m: 0.3859 - recall_m: 0.0799 - f1_m: 0.1226\n",
      "Epoch 20: val_acc improved from 0.96035 to 0.96059, saving model to models/best_model_7_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 5s 16ms/step - loss: 0.1200 - acc: 0.9637 - precision_m: 0.3819 - recall_m: 0.0791 - f1_m: 0.1213 - val_loss: 0.1389 - val_acc: 0.9606 - val_precision_m: 0.0606 - val_recall_m: 0.0059 - val_f1_m: 0.0108\n",
      "Epoch 21/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1186 - acc: 0.9638 - precision_m: 0.4050 - recall_m: 0.0842 - f1_m: 0.1323\n",
      "Epoch 21: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 5s 16ms/step - loss: 0.1186 - acc: 0.9639 - precision_m: 0.4060 - recall_m: 0.0841 - f1_m: 0.1321 - val_loss: 0.1339 - val_acc: 0.9605 - val_precision_m: 0.1818 - val_recall_m: 0.0313 - val_f1_m: 0.0487\n",
      "Epoch 22/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1164 - acc: 0.9644 - precision_m: 0.4318 - recall_m: 0.0997 - f1_m: 0.1531\n",
      "Epoch 22: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1164 - acc: 0.9644 - precision_m: 0.4318 - recall_m: 0.0997 - f1_m: 0.1531 - val_loss: 0.1394 - val_acc: 0.9605 - val_precision_m: 0.0303 - val_recall_m: 0.0032 - val_f1_m: 0.0058\n",
      "Epoch 23/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.1162 - acc: 0.9646 - precision_m: 0.4693 - recall_m: 0.1034 - f1_m: 0.1601\n",
      "Epoch 23: val_acc improved from 0.96059 to 0.96095, saving model to models/best_model_7_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 5s 16ms/step - loss: 0.1161 - acc: 0.9646 - precision_m: 0.4718 - recall_m: 0.1051 - f1_m: 0.1622 - val_loss: 0.1312 - val_acc: 0.9609 - val_precision_m: 0.3636 - val_recall_m: 0.0548 - val_f1_m: 0.0890\n",
      "Epoch 24/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1126 - acc: 0.9655 - precision_m: 0.5345 - recall_m: 0.1382 - f1_m: 0.2048\n",
      "Epoch 24: val_acc did not improve from 0.96095\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1127 - acc: 0.9655 - precision_m: 0.5359 - recall_m: 0.1382 - f1_m: 0.2050 - val_loss: 0.1332 - val_acc: 0.9606 - val_precision_m: 0.1894 - val_recall_m: 0.0510 - val_f1_m: 0.0659\n",
      "Epoch 25/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1117 - acc: 0.9651 - precision_m: 0.5402 - recall_m: 0.1322 - f1_m: 0.1999\n",
      "Epoch 25: val_acc improved from 0.96095 to 0.96190, saving model to models/best_model_7_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 5s 16ms/step - loss: 0.1116 - acc: 0.9652 - precision_m: 0.5346 - recall_m: 0.1308 - f1_m: 0.1978 - val_loss: 0.1342 - val_acc: 0.9619 - val_precision_m: 0.2879 - val_recall_m: 0.0503 - val_f1_m: 0.0807\n",
      "Epoch 26/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1085 - acc: 0.9658 - precision_m: 0.5772 - recall_m: 0.1603 - f1_m: 0.2349\n",
      "Epoch 26: val_acc did not improve from 0.96190\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1085 - acc: 0.9657 - precision_m: 0.5759 - recall_m: 0.1604 - f1_m: 0.2350 - val_loss: 0.1356 - val_acc: 0.9613 - val_precision_m: 0.3182 - val_recall_m: 0.0492 - val_f1_m: 0.0799\n",
      "Epoch 27/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.1070 - acc: 0.9659 - precision_m: 0.6009 - recall_m: 0.1823 - f1_m: 0.2618\n",
      "Epoch 27: val_acc did not improve from 0.96190\n",
      "292/292 [==============================] - 5s 16ms/step - loss: 0.1069 - acc: 0.9659 - precision_m: 0.6022 - recall_m: 0.1831 - f1_m: 0.2629 - val_loss: 0.1355 - val_acc: 0.9571 - val_precision_m: 0.3802 - val_recall_m: 0.2644 - val_f1_m: 0.2962\n",
      "Epoch 28/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1039 - acc: 0.9669 - precision_m: 0.6267 - recall_m: 0.2059 - f1_m: 0.2882\n",
      "Epoch 28: val_acc did not improve from 0.96190\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1037 - acc: 0.9670 - precision_m: 0.6245 - recall_m: 0.2068 - f1_m: 0.2884 - val_loss: 0.1285 - val_acc: 0.9615 - val_precision_m: 0.4258 - val_recall_m: 0.1962 - val_f1_m: 0.2503\n",
      "Epoch 29/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1024 - acc: 0.9673 - precision_m: 0.6506 - recall_m: 0.2233 - f1_m: 0.3110\n",
      "Epoch 29: val_acc did not improve from 0.96190\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1023 - acc: 0.9673 - precision_m: 0.6517 - recall_m: 0.2244 - f1_m: 0.3120 - val_loss: 0.1287 - val_acc: 0.9614 - val_precision_m: 0.3867 - val_recall_m: 0.1567 - val_f1_m: 0.2120\n",
      "Epoch 30/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1004 - acc: 0.9675 - precision_m: 0.6530 - recall_m: 0.2292 - f1_m: 0.3195\n",
      "Epoch 30: val_acc did not improve from 0.96190\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1002 - acc: 0.9675 - precision_m: 0.6515 - recall_m: 0.2283 - f1_m: 0.3184 - val_loss: 0.1360 - val_acc: 0.9612 - val_precision_m: 0.4040 - val_recall_m: 0.0753 - val_f1_m: 0.1214\n",
      "Score for fold 1: loss of 0.13419558107852936; acc of 96.19013667106628%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.09927315264940262; acc of 97.31454849243164%\n",
      "Test Precision: precision_m of 2.464788593351841%\n",
      "Test Recall: recall_m of 1.2676055543124676%\n",
      "Test F1: f1_m of 1.60211231559515%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.1606 - acc: 0.9611 - precision_m: 6.8729e-05 - recall_m: 0.0034 - f1_m: 1.3476e-04\n",
      "Epoch 1: val_acc improved from -inf to 0.96336, saving model to models/best_model_7_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 9s 22ms/step - loss: 0.1606 - acc: 0.9611 - precision_m: 6.8729e-05 - recall_m: 0.0034 - f1_m: 1.3476e-04 - val_loss: 0.1526 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1449 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 2: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1449 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1414 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 3/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1423 - acc: 0.9643 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 3: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 5s 16ms/step - loss: 0.1421 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1419 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 4/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1403 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 4: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1403 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1422 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 5/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1396 - acc: 0.9643 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 5: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 5s 16ms/step - loss: 0.1396 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1436 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 6/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1386 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 6: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1385 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1392 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 7/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1368 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 7: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1367 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1384 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 8/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1362 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 8: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1364 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1365 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 9/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1361 - acc: 0.9643 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 9: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1359 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1379 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 10/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1343 - acc: 0.9643 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 10: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1342 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1395 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 11/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1343 - acc: 0.9643 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 11: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1342 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1419 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 12/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1318 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 12: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1318 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1360 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 13/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1309 - acc: 0.9643 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 13: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1308 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1354 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 14/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1284 - acc: 0.9644 - precision_m: 0.0035 - recall_m: 4.3253e-04 - f1_m: 7.6893e-04 \n",
      "Epoch 14: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1285 - acc: 0.9644 - precision_m: 0.0034 - recall_m: 4.2955e-04 - f1_m: 7.6365e-04 - val_loss: 0.1342 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 15/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1287 - acc: 0.9643 - precision_m: 0.0087 - recall_m: 0.0014 - f1_m: 0.0024\n",
      "Epoch 15: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1285 - acc: 0.9644 - precision_m: 0.0086 - recall_m: 0.0014 - f1_m: 0.0024 - val_loss: 0.1356 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 16/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1259 - acc: 0.9643 - precision_m: 0.0035 - recall_m: 3.1456e-04 - f1_m: 5.7670e-04\n",
      "Epoch 16: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1258 - acc: 0.9643 - precision_m: 0.0034 - recall_m: 3.1240e-04 - f1_m: 5.7274e-04 - val_loss: 0.1396 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 17/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1232 - acc: 0.9646 - precision_m: 0.0640 - recall_m: 0.0100 - f1_m: 0.0168\n",
      "Epoch 17: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1233 - acc: 0.9645 - precision_m: 0.0636 - recall_m: 0.0099 - f1_m: 0.0166 - val_loss: 0.1356 - val_acc: 0.9624 - val_precision_m: 0.0379 - val_recall_m: 0.0078 - val_f1_m: 0.0127\n",
      "Epoch 18/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1222 - acc: 0.9646 - precision_m: 0.1497 - recall_m: 0.0222 - f1_m: 0.0373\n",
      "Epoch 18: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1225 - acc: 0.9645 - precision_m: 0.1486 - recall_m: 0.0221 - f1_m: 0.0371 - val_loss: 0.1323 - val_acc: 0.9632 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 19/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1198 - acc: 0.9648 - precision_m: 0.1843 - recall_m: 0.0279 - f1_m: 0.0466\n",
      "Epoch 19: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1197 - acc: 0.9648 - precision_m: 0.1830 - recall_m: 0.0277 - f1_m: 0.0463 - val_loss: 0.1258 - val_acc: 0.9629 - val_precision_m: 0.0833 - val_recall_m: 0.0135 - val_f1_m: 0.0221\n",
      "Epoch 20/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1169 - acc: 0.9651 - precision_m: 0.2931 - recall_m: 0.0550 - f1_m: 0.0867\n",
      "Epoch 20: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1167 - acc: 0.9651 - precision_m: 0.2911 - recall_m: 0.0546 - f1_m: 0.0861 - val_loss: 0.1384 - val_acc: 0.9634 - val_precision_m: 0.0303 - val_recall_m: 0.0038 - val_f1_m: 0.0067\n",
      "Epoch 21/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1149 - acc: 0.9657 - precision_m: 0.3808 - recall_m: 0.0721 - f1_m: 0.1155\n",
      "Epoch 21: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 5s 16ms/step - loss: 0.1150 - acc: 0.9656 - precision_m: 0.3782 - recall_m: 0.0716 - f1_m: 0.1147 - val_loss: 0.1274 - val_acc: 0.9632 - val_precision_m: 0.0606 - val_recall_m: 0.0047 - val_f1_m: 0.0087\n",
      "Epoch 22/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1121 - acc: 0.9660 - precision_m: 0.4271 - recall_m: 0.0918 - f1_m: 0.1406\n",
      "Epoch 22: val_acc improved from 0.96336 to 0.96491, saving model to models/best_model_7_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 5s 16ms/step - loss: 0.1121 - acc: 0.9660 - precision_m: 0.4290 - recall_m: 0.0924 - f1_m: 0.1414 - val_loss: 0.1271 - val_acc: 0.9649 - val_precision_m: 0.4715 - val_recall_m: 0.1290 - val_f1_m: 0.1830\n",
      "Epoch 23/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1097 - acc: 0.9663 - precision_m: 0.4685 - recall_m: 0.1036 - f1_m: 0.1590\n",
      "Epoch 23: val_acc did not improve from 0.96491\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1098 - acc: 0.9662 - precision_m: 0.4687 - recall_m: 0.1031 - f1_m: 0.1584 - val_loss: 0.1225 - val_acc: 0.9642 - val_precision_m: 0.2727 - val_recall_m: 0.0397 - val_f1_m: 0.0666\n",
      "Epoch 24/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1071 - acc: 0.9668 - precision_m: 0.5206 - recall_m: 0.1280 - f1_m: 0.1934\n",
      "Epoch 24: val_acc did not improve from 0.96491\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1072 - acc: 0.9668 - precision_m: 0.5227 - recall_m: 0.1287 - f1_m: 0.1946 - val_loss: 0.1247 - val_acc: 0.9638 - val_precision_m: 0.4123 - val_recall_m: 0.1653 - val_f1_m: 0.2224\n",
      "Epoch 25/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1059 - acc: 0.9670 - precision_m: 0.5462 - recall_m: 0.1466 - f1_m: 0.2168\n",
      "Epoch 25: val_acc did not improve from 0.96491\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1060 - acc: 0.9669 - precision_m: 0.5442 - recall_m: 0.1459 - f1_m: 0.2159 - val_loss: 0.1212 - val_acc: 0.9648 - val_precision_m: 0.4318 - val_recall_m: 0.0986 - val_f1_m: 0.1434\n",
      "Epoch 26/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1033 - acc: 0.9673 - precision_m: 0.5702 - recall_m: 0.1511 - f1_m: 0.2257\n",
      "Epoch 26: val_acc did not improve from 0.96491\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1036 - acc: 0.9672 - precision_m: 0.5680 - recall_m: 0.1503 - f1_m: 0.2245 - val_loss: 0.1269 - val_acc: 0.9637 - val_precision_m: 0.4524 - val_recall_m: 0.1166 - val_f1_m: 0.1702\n",
      "Epoch 27/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1004 - acc: 0.9677 - precision_m: 0.6070 - recall_m: 0.1878 - f1_m: 0.2670\n",
      "Epoch 27: val_acc did not improve from 0.96491\n",
      "291/291 [==============================] - 5s 15ms/step - loss: 0.1003 - acc: 0.9678 - precision_m: 0.6069 - recall_m: 0.1888 - f1_m: 0.2680 - val_loss: 0.1308 - val_acc: 0.9649 - val_precision_m: 0.4171 - val_recall_m: 0.1200 - val_f1_m: 0.1749\n",
      "Epoch 28/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0986 - acc: 0.9685 - precision_m: 0.6294 - recall_m: 0.2183 - f1_m: 0.3040\n",
      "Epoch 28: val_acc did not improve from 0.96491\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.0986 - acc: 0.9685 - precision_m: 0.6308 - recall_m: 0.2189 - f1_m: 0.3050 - val_loss: 0.1271 - val_acc: 0.9636 - val_precision_m: 0.4174 - val_recall_m: 0.1774 - val_f1_m: 0.2336\n",
      "Epoch 29/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0956 - acc: 0.9694 - precision_m: 0.6689 - recall_m: 0.2458 - f1_m: 0.3365\n",
      "Epoch 29: val_acc did not improve from 0.96491\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.0955 - acc: 0.9694 - precision_m: 0.6711 - recall_m: 0.2455 - f1_m: 0.3365 - val_loss: 0.1241 - val_acc: 0.9641 - val_precision_m: 0.3976 - val_recall_m: 0.1481 - val_f1_m: 0.1979\n",
      "Epoch 30/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0934 - acc: 0.9689 - precision_m: 0.6340 - recall_m: 0.2615 - f1_m: 0.3460\n",
      "Epoch 30: val_acc did not improve from 0.96491\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.0934 - acc: 0.9689 - precision_m: 0.6347 - recall_m: 0.2619 - f1_m: 0.3467 - val_loss: 0.1221 - val_acc: 0.9646 - val_precision_m: 0.4212 - val_recall_m: 0.1518 - val_f1_m: 0.2106\n",
      "Score for fold 2: loss of 0.1271340399980545; acc of 96.49143815040588%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.13616371154785156; acc of 95.81679701805115%\n",
      "Test Precision: precision_m of 8.036530017852783%\n",
      "Test Recall: recall_m of 3.3378180116415024%\n",
      "Test F1: f1_m of 4.263202100992203%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.1649 - acc: 0.9602 - precision_m: 1.3424e-04 - recall_m: 0.0034 - f1_m: 2.5838e-04\n",
      "Epoch 1: val_acc improved from -inf to 0.96299, saving model to models/best_model_7_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 9s 21ms/step - loss: 0.1649 - acc: 0.9602 - precision_m: 1.3424e-04 - recall_m: 0.0034 - f1_m: 2.5838e-04 - val_loss: 0.1496 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1489 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 2: val_acc did not improve from 0.96299\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1488 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1438 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 3/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1433 - acc: 0.9635 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 3: val_acc did not improve from 0.96299\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1435 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1421 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 4/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1423 - acc: 0.9633 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 4: val_acc did not improve from 0.96299\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1421 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1428 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 5/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1416 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 5: val_acc did not improve from 0.96299\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1416 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1431 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 6/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1406 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 6: val_acc did not improve from 0.96299\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1406 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1408 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 7/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1394 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 7: val_acc did not improve from 0.96299\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1396 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1571 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 8/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1401 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 8: val_acc did not improve from 0.96299\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1399 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1480 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 9/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1377 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 9: val_acc did not improve from 0.96299\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1378 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1394 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 10/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1359 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 10: val_acc did not improve from 0.96299\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1359 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1385 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 11/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1350 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 11: val_acc did not improve from 0.96299\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1348 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1347 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 12/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1333 - acc: 0.9635 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 12: val_acc did not improve from 0.96299\n",
      "291/291 [==============================] - 5s 15ms/step - loss: 0.1335 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1347 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 13/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1311 - acc: 0.9633 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 13: val_acc did not improve from 0.96299\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1310 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1330 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 14/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1302 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 14: val_acc did not improve from 0.96299\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1302 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1321 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 15/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1276 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 15: val_acc did not improve from 0.96299\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1275 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1282 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 16/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1260 - acc: 0.9636 - precision_m: 0.1194 - recall_m: 0.0204 - f1_m: 0.0335\n",
      "Epoch 16: val_acc did not improve from 0.96299\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1260 - acc: 0.9636 - precision_m: 0.1186 - recall_m: 0.0203 - f1_m: 0.0333 - val_loss: 0.1317 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 17/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1238 - acc: 0.9636 - precision_m: 0.1312 - recall_m: 0.0201 - f1_m: 0.0336\n",
      "Epoch 17: val_acc improved from 0.96299 to 0.96322, saving model to models/best_model_7_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 5s 16ms/step - loss: 0.1239 - acc: 0.9636 - precision_m: 0.1360 - recall_m: 0.0212 - f1_m: 0.0353 - val_loss: 0.1277 - val_acc: 0.9632 - val_precision_m: 0.1212 - val_recall_m: 0.0139 - val_f1_m: 0.0246\n",
      "Epoch 18/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1215 - acc: 0.9637 - precision_m: 0.2469 - recall_m: 0.0447 - f1_m: 0.0721\n",
      "Epoch 18: val_acc did not improve from 0.96322\n",
      "291/291 [==============================] - 5s 15ms/step - loss: 0.1214 - acc: 0.9638 - precision_m: 0.2487 - recall_m: 0.0450 - f1_m: 0.0726 - val_loss: 0.1282 - val_acc: 0.9632 - val_precision_m: 0.2475 - val_recall_m: 0.0361 - val_f1_m: 0.0596\n",
      "Epoch 19/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1193 - acc: 0.9640 - precision_m: 0.3013 - recall_m: 0.0620 - f1_m: 0.0961\n",
      "Epoch 19: val_acc did not improve from 0.96322\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1196 - acc: 0.9639 - precision_m: 0.2992 - recall_m: 0.0615 - f1_m: 0.0954 - val_loss: 0.1290 - val_acc: 0.9632 - val_precision_m: 0.1212 - val_recall_m: 0.0126 - val_f1_m: 0.0226\n",
      "Epoch 20/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1172 - acc: 0.9643 - precision_m: 0.3672 - recall_m: 0.0810 - f1_m: 0.1228\n",
      "Epoch 20: val_acc did not improve from 0.96322\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1172 - acc: 0.9643 - precision_m: 0.3681 - recall_m: 0.0808 - f1_m: 0.1225 - val_loss: 0.1339 - val_acc: 0.9629 - val_precision_m: 0.0606 - val_recall_m: 0.0086 - val_f1_m: 0.0148\n",
      "Epoch 21/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1139 - acc: 0.9645 - precision_m: 0.4098 - recall_m: 0.0831 - f1_m: 0.1305\n",
      "Epoch 21: val_acc improved from 0.96322 to 0.96334, saving model to models/best_model_7_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 5s 16ms/step - loss: 0.1138 - acc: 0.9645 - precision_m: 0.4104 - recall_m: 0.0828 - f1_m: 0.1302 - val_loss: 0.1245 - val_acc: 0.9633 - val_precision_m: 0.1818 - val_recall_m: 0.0273 - val_f1_m: 0.0472\n",
      "Epoch 22/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1124 - acc: 0.9654 - precision_m: 0.4782 - recall_m: 0.1124 - f1_m: 0.1701\n",
      "Epoch 22: val_acc improved from 0.96334 to 0.96358, saving model to models/best_model_7_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 5s 16ms/step - loss: 0.1127 - acc: 0.9652 - precision_m: 0.4749 - recall_m: 0.1116 - f1_m: 0.1689 - val_loss: 0.1267 - val_acc: 0.9636 - val_precision_m: 0.2455 - val_recall_m: 0.0660 - val_f1_m: 0.0961\n",
      "Epoch 23/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1103 - acc: 0.9654 - precision_m: 0.5422 - recall_m: 0.1296 - f1_m: 0.1947\n",
      "Epoch 23: val_acc improved from 0.96358 to 0.96454, saving model to models/best_model_7_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 5s 16ms/step - loss: 0.1105 - acc: 0.9653 - precision_m: 0.5410 - recall_m: 0.1294 - f1_m: 0.1944 - val_loss: 0.1221 - val_acc: 0.9645 - val_precision_m: 0.2828 - val_recall_m: 0.0661 - val_f1_m: 0.1025\n",
      "Epoch 24/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1080 - acc: 0.9660 - precision_m: 0.5596 - recall_m: 0.1556 - f1_m: 0.2294\n",
      "Epoch 24: val_acc did not improve from 0.96454\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1079 - acc: 0.9661 - precision_m: 0.5557 - recall_m: 0.1545 - f1_m: 0.2278 - val_loss: 0.1363 - val_acc: 0.9642 - val_precision_m: 0.2121 - val_recall_m: 0.0538 - val_f1_m: 0.0831\n",
      "Epoch 25/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1064 - acc: 0.9666 - precision_m: 0.5948 - recall_m: 0.1856 - f1_m: 0.2660\n",
      "Epoch 25: val_acc did not improve from 0.96454\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1062 - acc: 0.9667 - precision_m: 0.5942 - recall_m: 0.1849 - f1_m: 0.2652 - val_loss: 0.1285 - val_acc: 0.9631 - val_precision_m: 0.3889 - val_recall_m: 0.0837 - val_f1_m: 0.1264\n",
      "Epoch 26/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1037 - acc: 0.9666 - precision_m: 0.6084 - recall_m: 0.1835 - f1_m: 0.2665\n",
      "Epoch 26: val_acc improved from 0.96454 to 0.96466, saving model to models/best_model_7_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 5s 16ms/step - loss: 0.1037 - acc: 0.9666 - precision_m: 0.6077 - recall_m: 0.1826 - f1_m: 0.2654 - val_loss: 0.1189 - val_acc: 0.9647 - val_precision_m: 0.4636 - val_recall_m: 0.1697 - val_f1_m: 0.2314\n",
      "Epoch 27/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1020 - acc: 0.9670 - precision_m: 0.6403 - recall_m: 0.1992 - f1_m: 0.2845\n",
      "Epoch 27: val_acc did not improve from 0.96466\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1019 - acc: 0.9670 - precision_m: 0.6394 - recall_m: 0.1988 - f1_m: 0.2841 - val_loss: 0.1252 - val_acc: 0.9621 - val_precision_m: 0.3628 - val_recall_m: 0.1632 - val_f1_m: 0.2106\n",
      "Epoch 28/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0985 - acc: 0.9680 - precision_m: 0.6353 - recall_m: 0.2380 - f1_m: 0.3257\n",
      "Epoch 28: val_acc did not improve from 0.96466\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.0988 - acc: 0.9679 - precision_m: 0.6309 - recall_m: 0.2364 - f1_m: 0.3235 - val_loss: 0.1224 - val_acc: 0.9647 - val_precision_m: 0.3955 - val_recall_m: 0.0848 - val_f1_m: 0.1298\n",
      "Epoch 29/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0962 - acc: 0.9685 - precision_m: 0.6608 - recall_m: 0.2517 - f1_m: 0.3413\n",
      "Epoch 29: val_acc improved from 0.96466 to 0.96502, saving model to models/best_model_7_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 5s 16ms/step - loss: 0.0962 - acc: 0.9685 - precision_m: 0.6574 - recall_m: 0.2504 - f1_m: 0.3395 - val_loss: 0.1213 - val_acc: 0.9650 - val_precision_m: 0.4568 - val_recall_m: 0.1497 - val_f1_m: 0.2126\n",
      "Epoch 30/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0943 - acc: 0.9686 - precision_m: 0.6998 - recall_m: 0.2569 - f1_m: 0.3496\n",
      "Epoch 30: val_acc improved from 0.96502 to 0.96550, saving model to models/best_model_7_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 5s 16ms/step - loss: 0.0941 - acc: 0.9686 - precision_m: 0.6984 - recall_m: 0.2568 - f1_m: 0.3495 - val_loss: 0.1208 - val_acc: 0.9655 - val_precision_m: 0.5000 - val_recall_m: 0.1236 - val_f1_m: 0.1853\n",
      "Score for fold 3: loss of 0.12082887440919876; acc of 96.55007123947144%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.12190759927034378; acc of 96.6833770275116%\n",
      "Test Precision: precision_m of 8.673469722270966%\n",
      "Test Recall: recall_m of 5.096776410937309%\n",
      "Test F1: f1_m of 5.821455642580986%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1624 - acc: 0.9646 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 1: val_acc improved from -inf to 0.96143, saving model to models/best_model_7_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 8s 20ms/step - loss: 0.1624 - acc: 0.9646 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1593 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1455 - acc: 0.9647 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 2: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1458 - acc: 0.9646 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1499 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 3/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1428 - acc: 0.9646 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 3: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 5s 15ms/step - loss: 0.1427 - acc: 0.9646 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1546 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 4/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1404 - acc: 0.9646 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 4: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 5s 15ms/step - loss: 0.1406 - acc: 0.9646 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1534 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 5/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1389 - acc: 0.9647 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 5: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1392 - acc: 0.9646 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1526 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 6/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1387 - acc: 0.9645 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 6: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 5s 15ms/step - loss: 0.1385 - acc: 0.9646 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1436 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 7/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1373 - acc: 0.9645 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 7: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1371 - acc: 0.9646 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1478 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 8/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1367 - acc: 0.9646 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 8: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1367 - acc: 0.9646 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1592 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 9/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1349 - acc: 0.9646 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 9: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1351 - acc: 0.9646 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1428 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 10/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1335 - acc: 0.9646 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 10: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1338 - acc: 0.9646 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1510 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 11/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1324 - acc: 0.9647 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 11: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1326 - acc: 0.9646 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1437 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 12/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1309 - acc: 0.9646 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 12: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1310 - acc: 0.9646 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1467 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 13/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1289 - acc: 0.9647 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 13: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1291 - acc: 0.9646 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1434 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 14/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1276 - acc: 0.9646 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 14: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1277 - acc: 0.9646 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1387 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 15/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1267 - acc: 0.9646 - precision_m: 0.0035 - recall_m: 6.0292e-04 - f1_m: 0.0010\n",
      "Epoch 15: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1269 - acc: 0.9646 - precision_m: 0.0034 - recall_m: 5.9672e-04 - f1_m: 0.0010 - val_loss: 0.1357 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 16/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1236 - acc: 0.9645 - precision_m: 0.0035 - recall_m: 3.1456e-04 - f1_m: 5.7670e-04    \n",
      "Epoch 16: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1234 - acc: 0.9646 - precision_m: 0.0034 - recall_m: 3.1133e-04 - f1_m: 5.7078e-04 - val_loss: 0.1521 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 17/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1226 - acc: 0.9647 - precision_m: 0.1169 - recall_m: 0.0188 - f1_m: 0.0310\n",
      "Epoch 17: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1224 - acc: 0.9647 - precision_m: 0.1157 - recall_m: 0.0186 - f1_m: 0.0307 - val_loss: 0.1360 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 18/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1194 - acc: 0.9651 - precision_m: 0.1764 - recall_m: 0.0294 - f1_m: 0.0477\n",
      "Epoch 18: val_acc improved from 0.96143 to 0.96155, saving model to models/best_model_7_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 5s 16ms/step - loss: 0.1194 - acc: 0.9651 - precision_m: 0.1814 - recall_m: 0.0335 - f1_m: 0.0522 - val_loss: 0.1322 - val_acc: 0.9616 - val_precision_m: 0.3747 - val_recall_m: 0.1009 - val_f1_m: 0.1531\n",
      "Epoch 19/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1187 - acc: 0.9651 - precision_m: 0.2530 - recall_m: 0.0572 - f1_m: 0.0874\n",
      "Epoch 19: val_acc did not improve from 0.96155\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1188 - acc: 0.9650 - precision_m: 0.2538 - recall_m: 0.0578 - f1_m: 0.0881 - val_loss: 0.1305 - val_acc: 0.9611 - val_precision_m: 0.3283 - val_recall_m: 0.0552 - val_f1_m: 0.0919\n",
      "Epoch 20/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1149 - acc: 0.9656 - precision_m: 0.3706 - recall_m: 0.0692 - f1_m: 0.1105\n",
      "Epoch 20: val_acc improved from 0.96155 to 0.96167, saving model to models/best_model_7_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 5s 16ms/step - loss: 0.1150 - acc: 0.9656 - precision_m: 0.3702 - recall_m: 0.0688 - f1_m: 0.1098 - val_loss: 0.1348 - val_acc: 0.9617 - val_precision_m: 0.0909 - val_recall_m: 0.0139 - val_f1_m: 0.0241\n",
      "Epoch 21/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1133 - acc: 0.9658 - precision_m: 0.4374 - recall_m: 0.0875 - f1_m: 0.1389\n",
      "Epoch 21: val_acc improved from 0.96167 to 0.96334, saving model to models/best_model_7_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 5s 16ms/step - loss: 0.1134 - acc: 0.9657 - precision_m: 0.4363 - recall_m: 0.0871 - f1_m: 0.1383 - val_loss: 0.1314 - val_acc: 0.9633 - val_precision_m: 0.4242 - val_recall_m: 0.0616 - val_f1_m: 0.1049\n",
      "Epoch 22/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1121 - acc: 0.9659 - precision_m: 0.4778 - recall_m: 0.1041 - f1_m: 0.1610\n",
      "Epoch 22: val_acc did not improve from 0.96334\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1118 - acc: 0.9660 - precision_m: 0.4763 - recall_m: 0.1035 - f1_m: 0.1602 - val_loss: 0.1436 - val_acc: 0.9625 - val_precision_m: 0.2626 - val_recall_m: 0.0369 - val_f1_m: 0.0624\n",
      "Epoch 23/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1091 - acc: 0.9667 - precision_m: 0.5114 - recall_m: 0.1154 - f1_m: 0.1796\n",
      "Epoch 23: val_acc did not improve from 0.96334\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1093 - acc: 0.9667 - precision_m: 0.5062 - recall_m: 0.1142 - f1_m: 0.1777 - val_loss: 0.1289 - val_acc: 0.9627 - val_precision_m: 0.3566 - val_recall_m: 0.0596 - val_f1_m: 0.1002\n",
      "Epoch 24/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1066 - acc: 0.9670 - precision_m: 0.5702 - recall_m: 0.1498 - f1_m: 0.2242\n",
      "Epoch 24: val_acc did not improve from 0.96334\n",
      "292/292 [==============================] - 5s 15ms/step - loss: 0.1067 - acc: 0.9670 - precision_m: 0.5678 - recall_m: 0.1487 - f1_m: 0.2227 - val_loss: 0.1260 - val_acc: 0.9627 - val_precision_m: 0.2424 - val_recall_m: 0.0429 - val_f1_m: 0.0693\n",
      "Epoch 25/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1062 - acc: 0.9674 - precision_m: 0.5346 - recall_m: 0.1471 - f1_m: 0.2120\n",
      "Epoch 25: val_acc did not improve from 0.96334\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1062 - acc: 0.9673 - precision_m: 0.5375 - recall_m: 0.1511 - f1_m: 0.2158 - val_loss: 0.1297 - val_acc: 0.9620 - val_precision_m: 0.4619 - val_recall_m: 0.2014 - val_f1_m: 0.2520\n",
      "Epoch 26/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1048 - acc: 0.9673 - precision_m: 0.5711 - recall_m: 0.1634 - f1_m: 0.2375\n",
      "Epoch 26: val_acc did not improve from 0.96334\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1046 - acc: 0.9674 - precision_m: 0.5704 - recall_m: 0.1630 - f1_m: 0.2371 - val_loss: 0.1261 - val_acc: 0.9632 - val_precision_m: 0.5303 - val_recall_m: 0.1164 - val_f1_m: 0.1713\n",
      "Epoch 27/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1029 - acc: 0.9680 - precision_m: 0.6022 - recall_m: 0.1681 - f1_m: 0.2461\n",
      "Epoch 27: val_acc did not improve from 0.96334\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1029 - acc: 0.9680 - precision_m: 0.6057 - recall_m: 0.1703 - f1_m: 0.2490 - val_loss: 0.1423 - val_acc: 0.9576 - val_precision_m: 0.4267 - val_recall_m: 0.2840 - val_f1_m: 0.3174\n",
      "Epoch 28/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1011 - acc: 0.9677 - precision_m: 0.6073 - recall_m: 0.1978 - f1_m: 0.2771\n",
      "Epoch 28: val_acc did not improve from 0.96334\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1010 - acc: 0.9678 - precision_m: 0.6011 - recall_m: 0.1958 - f1_m: 0.2743 - val_loss: 0.1318 - val_acc: 0.9611 - val_precision_m: 0.4008 - val_recall_m: 0.1524 - val_f1_m: 0.2030\n",
      "Epoch 29/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0996 - acc: 0.9681 - precision_m: 0.6081 - recall_m: 0.2116 - f1_m: 0.2942\n",
      "Epoch 29: val_acc did not improve from 0.96334\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.0998 - acc: 0.9681 - precision_m: 0.6110 - recall_m: 0.2140 - f1_m: 0.2963 - val_loss: 0.1293 - val_acc: 0.9610 - val_precision_m: 0.4140 - val_recall_m: 0.2313 - val_f1_m: 0.2810\n",
      "Epoch 30/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0954 - acc: 0.9692 - precision_m: 0.6539 - recall_m: 0.2321 - f1_m: 0.3209\n",
      "Epoch 30: val_acc did not improve from 0.96334\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.0954 - acc: 0.9692 - precision_m: 0.6523 - recall_m: 0.2310 - f1_m: 0.3196 - val_loss: 0.1321 - val_acc: 0.9627 - val_precision_m: 0.3914 - val_recall_m: 0.0701 - val_f1_m: 0.1161\n",
      "Score for fold 4: loss of 0.13136957585811615; acc of 96.33432626724243%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.14474309980869293; acc of 95.7156777381897%\n",
      "Test Precision: precision_m of 4.267589375376701%\n",
      "Test Recall: recall_m of 1.6839675605297089%\n",
      "Test F1: f1_m of 2.1810539066791534%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.1620 - acc: 0.9606 - precision_m: 9.3965e-05 - recall_m: 0.0034 - f1_m: 1.8293e-04\n",
      "Epoch 1: val_acc improved from -inf to 0.96211, saving model to models/best_model_7_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 9s 21ms/step - loss: 0.1620 - acc: 0.9606 - precision_m: 9.3965e-05 - recall_m: 0.0034 - f1_m: 1.8293e-04 - val_loss: 0.1535 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1493 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 2: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1496 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1471 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 3/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1439 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 3: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1441 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1455 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 4/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1420 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 4: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1422 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1525 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 5/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1417 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 5: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1416 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1421 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 6/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1400 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 6: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1399 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1466 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 7/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1387 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 7: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1386 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1421 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 8/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1381 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 8: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1383 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1435 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 9/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1363 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 9: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1361 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1451 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 10/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1353 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 10: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1353 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1405 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 11/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1329 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 11: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1329 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1371 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 12/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1320 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 12: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1320 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1387 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 13/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1306 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 13: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1307 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1384 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 14/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1292 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 14: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1293 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1401 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 15/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1272 - acc: 0.9639 - precision_m: 0.0211 - recall_m: 0.0033 - f1_m: 0.0055\n",
      "Epoch 15: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1274 - acc: 0.9638 - precision_m: 0.0210 - recall_m: 0.0032 - f1_m: 0.0055 - val_loss: 0.1466 - val_acc: 0.9620 - val_precision_m: 0.1212 - val_recall_m: 0.0125 - val_f1_m: 0.0221\n",
      "Epoch 16/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1254 - acc: 0.9640 - precision_m: 0.0845 - recall_m: 0.0151 - f1_m: 0.0245\n",
      "Epoch 16: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1253 - acc: 0.9641 - precision_m: 0.0840 - recall_m: 0.0150 - f1_m: 0.0243 - val_loss: 0.1485 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 17/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1246 - acc: 0.9639 - precision_m: 0.0725 - recall_m: 0.0114 - f1_m: 0.0190\n",
      "Epoch 17: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1245 - acc: 0.9640 - precision_m: 0.0721 - recall_m: 0.0113 - f1_m: 0.0189 - val_loss: 0.1327 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 18/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1221 - acc: 0.9643 - precision_m: 0.1875 - recall_m: 0.0266 - f1_m: 0.0452\n",
      "Epoch 18: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1222 - acc: 0.9643 - precision_m: 0.1863 - recall_m: 0.0265 - f1_m: 0.0448 - val_loss: 0.1315 - val_acc: 0.9621 - val_precision_m: 0.1515 - val_recall_m: 0.0163 - val_f1_m: 0.0290\n",
      "Epoch 19/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1203 - acc: 0.9639 - precision_m: 0.1645 - recall_m: 0.0256 - f1_m: 0.0423\n",
      "Epoch 19: val_acc improved from 0.96211 to 0.96235, saving model to models/best_model_7_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 5s 16ms/step - loss: 0.1201 - acc: 0.9640 - precision_m: 0.1634 - recall_m: 0.0255 - f1_m: 0.0420 - val_loss: 0.1398 - val_acc: 0.9624 - val_precision_m: 0.0303 - val_recall_m: 0.0032 - val_f1_m: 0.0058\n",
      "Epoch 20/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1190 - acc: 0.9643 - precision_m: 0.2563 - recall_m: 0.0435 - f1_m: 0.0718\n",
      "Epoch 20: val_acc did not improve from 0.96235\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1188 - acc: 0.9643 - precision_m: 0.2546 - recall_m: 0.0432 - f1_m: 0.0713 - val_loss: 0.1315 - val_acc: 0.9622 - val_precision_m: 0.1515 - val_recall_m: 0.0181 - val_f1_m: 0.0316\n",
      "Epoch 21/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1165 - acc: 0.9647 - precision_m: 0.3340 - recall_m: 0.0742 - f1_m: 0.1146\n",
      "Epoch 21: val_acc improved from 0.96235 to 0.96259, saving model to models/best_model_7_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 5s 16ms/step - loss: 0.1165 - acc: 0.9647 - precision_m: 0.3328 - recall_m: 0.0741 - f1_m: 0.1144 - val_loss: 0.1324 - val_acc: 0.9626 - val_precision_m: 0.2828 - val_recall_m: 0.0374 - val_f1_m: 0.0651\n",
      "Epoch 22/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1144 - acc: 0.9650 - precision_m: 0.3829 - recall_m: 0.0789 - f1_m: 0.1235\n",
      "Epoch 22: val_acc did not improve from 0.96259\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1144 - acc: 0.9649 - precision_m: 0.3820 - recall_m: 0.0788 - f1_m: 0.1232 - val_loss: 0.1367 - val_acc: 0.9572 - val_precision_m: 0.3069 - val_recall_m: 0.1545 - val_f1_m: 0.1867\n",
      "Epoch 23/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1132 - acc: 0.9654 - precision_m: 0.4391 - recall_m: 0.0912 - f1_m: 0.1430\n",
      "Epoch 23: val_acc did not improve from 0.96259\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1130 - acc: 0.9654 - precision_m: 0.4396 - recall_m: 0.0913 - f1_m: 0.1433 - val_loss: 0.1295 - val_acc: 0.9621 - val_precision_m: 0.3712 - val_recall_m: 0.0862 - val_f1_m: 0.1279\n",
      "Epoch 24/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1108 - acc: 0.9657 - precision_m: 0.5227 - recall_m: 0.1337 - f1_m: 0.1994\n",
      "Epoch 24: val_acc did not improve from 0.96259\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1108 - acc: 0.9658 - precision_m: 0.5225 - recall_m: 0.1336 - f1_m: 0.1994 - val_loss: 0.1276 - val_acc: 0.9625 - val_precision_m: 0.2121 - val_recall_m: 0.0310 - val_f1_m: 0.0534\n",
      "Epoch 25/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1086 - acc: 0.9663 - precision_m: 0.5572 - recall_m: 0.1416 - f1_m: 0.2107\n",
      "Epoch 25: val_acc did not improve from 0.96259\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1085 - acc: 0.9663 - precision_m: 0.5568 - recall_m: 0.1422 - f1_m: 0.2112 - val_loss: 0.1328 - val_acc: 0.9592 - val_precision_m: 0.3634 - val_recall_m: 0.1656 - val_f1_m: 0.2054\n",
      "Epoch 26/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1070 - acc: 0.9665 - precision_m: 0.5434 - recall_m: 0.1537 - f1_m: 0.2251\n",
      "Epoch 26: val_acc did not improve from 0.96259\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1069 - acc: 0.9665 - precision_m: 0.5442 - recall_m: 0.1537 - f1_m: 0.2252 - val_loss: 0.1403 - val_acc: 0.9603 - val_precision_m: 0.3637 - val_recall_m: 0.1220 - val_f1_m: 0.1678\n",
      "Epoch 27/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1046 - acc: 0.9669 - precision_m: 0.5942 - recall_m: 0.1757 - f1_m: 0.2529\n",
      "Epoch 27: val_acc improved from 0.96259 to 0.96355, saving model to models/best_model_7_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 5s 16ms/step - loss: 0.1046 - acc: 0.9669 - precision_m: 0.5962 - recall_m: 0.1762 - f1_m: 0.2539 - val_loss: 0.1297 - val_acc: 0.9635 - val_precision_m: 0.3712 - val_recall_m: 0.0706 - val_f1_m: 0.1155\n",
      "Epoch 28/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1034 - acc: 0.9676 - precision_m: 0.6367 - recall_m: 0.1971 - f1_m: 0.2814\n",
      "Epoch 28: val_acc did not improve from 0.96355\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1032 - acc: 0.9677 - precision_m: 0.6392 - recall_m: 0.1978 - f1_m: 0.2825 - val_loss: 0.1312 - val_acc: 0.9626 - val_precision_m: 0.4195 - val_recall_m: 0.1110 - val_f1_m: 0.1576\n",
      "Epoch 29/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0997 - acc: 0.9676 - precision_m: 0.6409 - recall_m: 0.2161 - f1_m: 0.3035\n",
      "Epoch 29: val_acc did not improve from 0.96355\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.0997 - acc: 0.9676 - precision_m: 0.6434 - recall_m: 0.2155 - f1_m: 0.3029 - val_loss: 0.1318 - val_acc: 0.9604 - val_precision_m: 0.3724 - val_recall_m: 0.1276 - val_f1_m: 0.1802\n",
      "Epoch 30/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0976 - acc: 0.9682 - precision_m: 0.6439 - recall_m: 0.2284 - f1_m: 0.3184\n",
      "Epoch 30: val_acc did not improve from 0.96355\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.0976 - acc: 0.9683 - precision_m: 0.6452 - recall_m: 0.2286 - f1_m: 0.3186 - val_loss: 0.1319 - val_acc: 0.9628 - val_precision_m: 0.3333 - val_recall_m: 0.0568 - val_f1_m: 0.0936\n",
      "Score for fold 5: loss of 0.12969060242176056; acc of 96.35472893714905%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.12723901867866516; acc of 96.4552640914917%\n",
      "Test Precision: precision_m of 6.1433445662260056%\n",
      "Test Recall: recall_m of 2.549569495022297%\n",
      "Test F1: f1_m of 3.3794131129980087%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1653 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 1: val_acc improved from -inf to 0.96059, saving model to models/best_model_7_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 9s 21ms/step - loss: 0.1653 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1567 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1464 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 2: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1463 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1530 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 3/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1429 - acc: 0.9640 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 3: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1431 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1483 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 4/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1428 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 4: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1426 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1635 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 5/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1415 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 5: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1415 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1497 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 6/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1416 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 6: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 5s 15ms/step - loss: 0.1415 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1481 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 7/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1400 - acc: 0.9640 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 7: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1402 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1509 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 8/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1396 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 8: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1396 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1499 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 9/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1390 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 9: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1387 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1468 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 10/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1375 - acc: 0.9640 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 10: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1379 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1478 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 11/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1367 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 11: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1368 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1457 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 12/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1349 - acc: 0.9638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 12: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1346 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1450 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 13/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1337 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 13: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1339 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1412 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 14/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1323 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 14: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 5s 15ms/step - loss: 0.1323 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1468 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 15/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1310 - acc: 0.9640 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 15: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1311 - acc: 0.9639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1479 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 16/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1305 - acc: 0.9638 - precision_m: 0.0069 - recall_m: 6.5064e-04 - f1_m: 0.0012\n",
      "Epoch 16: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1303 - acc: 0.9639 - precision_m: 0.0068 - recall_m: 6.4395e-04 - f1_m: 0.0012 - val_loss: 0.1483 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 17/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1278 - acc: 0.9639 - precision_m: 0.0138 - recall_m: 0.0015 - f1_m: 0.0026\n",
      "Epoch 17: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1277 - acc: 0.9639 - precision_m: 0.0171 - recall_m: 0.0023 - f1_m: 0.0040 - val_loss: 0.1398 - val_acc: 0.9605 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 18/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1252 - acc: 0.9642 - precision_m: 0.1351 - recall_m: 0.0194 - f1_m: 0.0330\n",
      "Epoch 18: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1256 - acc: 0.9641 - precision_m: 0.1371 - recall_m: 0.0197 - f1_m: 0.0334 - val_loss: 0.1399 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 19/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1221 - acc: 0.9643 - precision_m: 0.2061 - recall_m: 0.0346 - f1_m: 0.0569\n",
      "Epoch 19: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1221 - acc: 0.9643 - precision_m: 0.2074 - recall_m: 0.0347 - f1_m: 0.0572 - val_loss: 0.1390 - val_acc: 0.9606 - val_precision_m: 0.2955 - val_recall_m: 0.0393 - val_f1_m: 0.0677\n",
      "Epoch 20/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1208 - acc: 0.9646 - precision_m: 0.2990 - recall_m: 0.0498 - f1_m: 0.0819\n",
      "Epoch 20: val_acc improved from 0.96059 to 0.96288, saving model to models/best_model_7_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 5s 16ms/step - loss: 0.1207 - acc: 0.9646 - precision_m: 0.3045 - recall_m: 0.0516 - f1_m: 0.0846 - val_loss: 0.1356 - val_acc: 0.9629 - val_precision_m: 0.3889 - val_recall_m: 0.0642 - val_f1_m: 0.1080\n",
      "Epoch 21/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1178 - acc: 0.9650 - precision_m: 0.3943 - recall_m: 0.0861 - f1_m: 0.1325\n",
      "Epoch 21: val_acc did not improve from 0.96288\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1178 - acc: 0.9651 - precision_m: 0.3936 - recall_m: 0.0857 - f1_m: 0.1320 - val_loss: 0.1309 - val_acc: 0.9611 - val_precision_m: 0.0909 - val_recall_m: 0.0116 - val_f1_m: 0.0204\n",
      "Epoch 22/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1163 - acc: 0.9650 - precision_m: 0.3695 - recall_m: 0.0727 - f1_m: 0.1153\n",
      "Epoch 22: val_acc did not improve from 0.96288\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1164 - acc: 0.9649 - precision_m: 0.3692 - recall_m: 0.0722 - f1_m: 0.1145 - val_loss: 0.1298 - val_acc: 0.9612 - val_precision_m: 0.1798 - val_recall_m: 0.0317 - val_f1_m: 0.0522\n",
      "Epoch 23/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1134 - acc: 0.9657 - precision_m: 0.4466 - recall_m: 0.1014 - f1_m: 0.1553\n",
      "Epoch 23: val_acc did not improve from 0.96288\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1134 - acc: 0.9657 - precision_m: 0.4455 - recall_m: 0.1009 - f1_m: 0.1545 - val_loss: 0.1350 - val_acc: 0.9616 - val_precision_m: 0.1667 - val_recall_m: 0.0266 - val_f1_m: 0.0441\n",
      "Epoch 24/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1113 - acc: 0.9662 - precision_m: 0.5169 - recall_m: 0.1195 - f1_m: 0.1845\n",
      "Epoch 24: val_acc did not improve from 0.96288\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1115 - acc: 0.9662 - precision_m: 0.5185 - recall_m: 0.1196 - f1_m: 0.1848 - val_loss: 0.1284 - val_acc: 0.9623 - val_precision_m: 0.3485 - val_recall_m: 0.0975 - val_f1_m: 0.1432\n",
      "Epoch 25/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1095 - acc: 0.9665 - precision_m: 0.5922 - recall_m: 0.1552 - f1_m: 0.2313\n",
      "Epoch 25: val_acc did not improve from 0.96288\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1093 - acc: 0.9666 - precision_m: 0.5895 - recall_m: 0.1544 - f1_m: 0.2303 - val_loss: 0.1310 - val_acc: 0.9623 - val_precision_m: 0.3636 - val_recall_m: 0.0820 - val_f1_m: 0.1296\n",
      "Epoch 26/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1084 - acc: 0.9660 - precision_m: 0.5253 - recall_m: 0.1330 - f1_m: 0.1969\n",
      "Epoch 26: val_acc did not improve from 0.96288\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1084 - acc: 0.9660 - precision_m: 0.5267 - recall_m: 0.1344 - f1_m: 0.1987 - val_loss: 0.1286 - val_acc: 0.9609 - val_precision_m: 0.4564 - val_recall_m: 0.1203 - val_f1_m: 0.1761\n",
      "Epoch 27/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1065 - acc: 0.9670 - precision_m: 0.5815 - recall_m: 0.1641 - f1_m: 0.2342\n",
      "Epoch 27: val_acc did not improve from 0.96288\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1066 - acc: 0.9669 - precision_m: 0.5818 - recall_m: 0.1644 - f1_m: 0.2348 - val_loss: 0.1346 - val_acc: 0.9616 - val_precision_m: 0.4968 - val_recall_m: 0.1127 - val_f1_m: 0.1703\n",
      "Epoch 28/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1042 - acc: 0.9672 - precision_m: 0.6103 - recall_m: 0.1793 - f1_m: 0.2583\n",
      "Epoch 28: val_acc did not improve from 0.96288\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1043 - acc: 0.9673 - precision_m: 0.6109 - recall_m: 0.1797 - f1_m: 0.2590 - val_loss: 0.1279 - val_acc: 0.9625 - val_precision_m: 0.4843 - val_recall_m: 0.1156 - val_f1_m: 0.1798\n",
      "Epoch 29/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1021 - acc: 0.9679 - precision_m: 0.6549 - recall_m: 0.1919 - f1_m: 0.2775\n",
      "Epoch 29: val_acc did not improve from 0.96288\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1026 - acc: 0.9678 - precision_m: 0.6498 - recall_m: 0.1903 - f1_m: 0.2753 - val_loss: 0.1322 - val_acc: 0.9620 - val_precision_m: 0.2667 - val_recall_m: 0.0464 - val_f1_m: 0.0760\n",
      "Epoch 30/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0999 - acc: 0.9684 - precision_m: 0.6739 - recall_m: 0.2051 - f1_m: 0.2930\n",
      "Epoch 30: val_acc did not improve from 0.96288\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.0998 - acc: 0.9684 - precision_m: 0.6773 - recall_m: 0.2054 - f1_m: 0.2938 - val_loss: 0.1300 - val_acc: 0.9614 - val_precision_m: 0.3631 - val_recall_m: 0.0694 - val_f1_m: 0.1099\n",
      "Score for fold 6: loss of 0.13555467128753662; acc of 96.2878167629242%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.1215130165219307; acc of 96.53934240341187%\n",
      "Test Precision: precision_m of 5.55555522441864%\n",
      "Test Recall: recall_m of 2.3383762687444687%\n",
      "Test F1: f1_m of 3.005676530301571%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1661 - acc: 0.9598 - precision_m: 1.2040e-04 - recall_m: 0.0034 - f1_m: 2.3262e-04\n",
      "Epoch 1: val_acc improved from -inf to 0.96249, saving model to models/best_model_7_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 9s 21ms/step - loss: 0.1661 - acc: 0.9598 - precision_m: 1.2040e-04 - recall_m: 0.0034 - f1_m: 2.3262e-04 - val_loss: 0.1505 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1496 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 2: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1497 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1456 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 3/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1462 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 3: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1461 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1462 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 4/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1444 - acc: 0.9629 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 4: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1443 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1452 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 5/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1440 - acc: 0.9629 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 5: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 5s 15ms/step - loss: 0.1438 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1413 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 6/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1419 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 6: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1418 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1418 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 7/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1403 - acc: 0.9632 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 7: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1406 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1408 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 8/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1404 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 8: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 5s 15ms/step - loss: 0.1404 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1405 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 9/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1372 - acc: 0.9631 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 9: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1375 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1395 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 10/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1389 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 10: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1389 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1401 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 11/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1372 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 11: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1372 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1487 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 12/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1358 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 12: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 5s 16ms/step - loss: 0.1358 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1388 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 13/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1330 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 13: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1330 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1416 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 14/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1329 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 14: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1328 - acc: 0.9630 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1360 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 15/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1312 - acc: 0.9629 - precision_m: 0.0110 - recall_m: 0.0014 - f1_m: 0.0024\n",
      "Epoch 15: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1311 - acc: 0.9630 - precision_m: 0.0108 - recall_m: 0.0014 - f1_m: 0.0024 - val_loss: 0.1393 - val_acc: 0.9624 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 16/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1288 - acc: 0.9630 - precision_m: 0.0879 - recall_m: 0.0130 - f1_m: 0.0218\n",
      "Epoch 16: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1286 - acc: 0.9632 - precision_m: 0.0870 - recall_m: 0.0129 - f1_m: 0.0216 - val_loss: 0.1420 - val_acc: 0.9622 - val_precision_m: 0.0303 - val_recall_m: 0.0028 - val_f1_m: 0.0051\n",
      "Epoch 17/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1283 - acc: 0.9629 - precision_m: 0.0963 - recall_m: 0.0119 - f1_m: 0.0207\n",
      "Epoch 17: val_acc improved from 0.96249 to 0.96260, saving model to models/best_model_7_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 5s 16ms/step - loss: 0.1283 - acc: 0.9630 - precision_m: 0.0987 - recall_m: 0.0121 - f1_m: 0.0211 - val_loss: 0.1355 - val_acc: 0.9626 - val_precision_m: 0.0303 - val_recall_m: 0.0022 - val_f1_m: 0.0040\n",
      "Epoch 18/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1258 - acc: 0.9632 - precision_m: 0.1588 - recall_m: 0.0306 - f1_m: 0.0480\n",
      "Epoch 18: val_acc did not improve from 0.96260\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1256 - acc: 0.9632 - precision_m: 0.1640 - recall_m: 0.0313 - f1_m: 0.0493 - val_loss: 0.1309 - val_acc: 0.9616 - val_precision_m: 0.2323 - val_recall_m: 0.0383 - val_f1_m: 0.0641\n",
      "Epoch 19/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1245 - acc: 0.9633 - precision_m: 0.2663 - recall_m: 0.0442 - f1_m: 0.0716\n",
      "Epoch 19: val_acc did not improve from 0.96260\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1243 - acc: 0.9634 - precision_m: 0.2636 - recall_m: 0.0438 - f1_m: 0.0709 - val_loss: 0.1327 - val_acc: 0.9625 - val_precision_m: 0.0303 - val_recall_m: 0.0022 - val_f1_m: 0.0040\n",
      "Epoch 20/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1208 - acc: 0.9636 - precision_m: 0.2798 - recall_m: 0.0559 - f1_m: 0.0882\n",
      "Epoch 20: val_acc did not improve from 0.96260\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1209 - acc: 0.9636 - precision_m: 0.2829 - recall_m: 0.0572 - f1_m: 0.0901 - val_loss: 0.1322 - val_acc: 0.9603 - val_precision_m: 0.3146 - val_recall_m: 0.1128 - val_f1_m: 0.1604\n",
      "Epoch 21/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1200 - acc: 0.9640 - precision_m: 0.4226 - recall_m: 0.0816 - f1_m: 0.1280\n",
      "Epoch 21: val_acc did not improve from 0.96260\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1199 - acc: 0.9641 - precision_m: 0.4210 - recall_m: 0.0818 - f1_m: 0.1281 - val_loss: 0.1317 - val_acc: 0.9624 - val_precision_m: 0.1818 - val_recall_m: 0.0228 - val_f1_m: 0.0398\n",
      "Epoch 22/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1172 - acc: 0.9644 - precision_m: 0.4698 - recall_m: 0.1058 - f1_m: 0.1614\n",
      "Epoch 22: val_acc improved from 0.96260 to 0.96416, saving model to models/best_model_7_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 5s 16ms/step - loss: 0.1169 - acc: 0.9645 - precision_m: 0.4667 - recall_m: 0.1050 - f1_m: 0.1603 - val_loss: 0.1248 - val_acc: 0.9642 - val_precision_m: 0.3434 - val_recall_m: 0.0800 - val_f1_m: 0.1240\n",
      "Epoch 23/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1140 - acc: 0.9644 - precision_m: 0.4934 - recall_m: 0.1093 - f1_m: 0.1675\n",
      "Epoch 23: val_acc did not improve from 0.96416\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1142 - acc: 0.9643 - precision_m: 0.4917 - recall_m: 0.1087 - f1_m: 0.1667 - val_loss: 0.1287 - val_acc: 0.9634 - val_precision_m: 0.2702 - val_recall_m: 0.0778 - val_f1_m: 0.1071\n",
      "Epoch 24/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1125 - acc: 0.9649 - precision_m: 0.5047 - recall_m: 0.1285 - f1_m: 0.1910\n",
      "Epoch 24: val_acc did not improve from 0.96416\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1125 - acc: 0.9650 - precision_m: 0.5018 - recall_m: 0.1281 - f1_m: 0.1903 - val_loss: 0.1239 - val_acc: 0.9627 - val_precision_m: 0.3242 - val_recall_m: 0.0548 - val_f1_m: 0.0884\n",
      "Epoch 25/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1102 - acc: 0.9654 - precision_m: 0.5467 - recall_m: 0.1421 - f1_m: 0.2116\n",
      "Epoch 25: val_acc did not improve from 0.96416\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1102 - acc: 0.9654 - precision_m: 0.5411 - recall_m: 0.1407 - f1_m: 0.2094 - val_loss: 0.1306 - val_acc: 0.9628 - val_precision_m: 0.1742 - val_recall_m: 0.0225 - val_f1_m: 0.0384\n",
      "Epoch 26/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1079 - acc: 0.9655 - precision_m: 0.5403 - recall_m: 0.1497 - f1_m: 0.2206\n",
      "Epoch 26: val_acc did not improve from 0.96416\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1078 - acc: 0.9655 - precision_m: 0.5382 - recall_m: 0.1489 - f1_m: 0.2196 - val_loss: 0.1239 - val_acc: 0.9614 - val_precision_m: 0.3886 - val_recall_m: 0.1420 - val_f1_m: 0.1953\n",
      "Epoch 27/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1049 - acc: 0.9664 - precision_m: 0.5859 - recall_m: 0.1896 - f1_m: 0.2674\n",
      "Epoch 27: val_acc did not improve from 0.96416\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1050 - acc: 0.9664 - precision_m: 0.5844 - recall_m: 0.1907 - f1_m: 0.2683 - val_loss: 0.1330 - val_acc: 0.9625 - val_precision_m: 0.3272 - val_recall_m: 0.1071 - val_f1_m: 0.1532\n",
      "Epoch 28/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1032 - acc: 0.9667 - precision_m: 0.6338 - recall_m: 0.2076 - f1_m: 0.2918\n",
      "Epoch 28: val_acc did not improve from 0.96416\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1030 - acc: 0.9666 - precision_m: 0.6299 - recall_m: 0.2068 - f1_m: 0.2905 - val_loss: 0.1202 - val_acc: 0.9627 - val_precision_m: 0.4233 - val_recall_m: 0.1615 - val_f1_m: 0.2137\n",
      "Epoch 29/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1013 - acc: 0.9670 - precision_m: 0.6194 - recall_m: 0.2060 - f1_m: 0.2894\n",
      "Epoch 29: val_acc did not improve from 0.96416\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1011 - acc: 0.9671 - precision_m: 0.6233 - recall_m: 0.2068 - f1_m: 0.2907 - val_loss: 0.1340 - val_acc: 0.9638 - val_precision_m: 0.3742 - val_recall_m: 0.1353 - val_f1_m: 0.1870\n",
      "Epoch 30/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0985 - acc: 0.9681 - precision_m: 0.6635 - recall_m: 0.2519 - f1_m: 0.3415\n",
      "Epoch 30: val_acc did not improve from 0.96416\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.0985 - acc: 0.9681 - precision_m: 0.6635 - recall_m: 0.2517 - f1_m: 0.3414 - val_loss: 0.1213 - val_acc: 0.9639 - val_precision_m: 0.4086 - val_recall_m: 0.1232 - val_f1_m: 0.1740\n",
      "Score for fold 7: loss of 0.1248425766825676; acc of 96.41577005386353%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.11050374060869217; acc of 96.94156050682068%\n",
      "Test Precision: precision_m of 4.355400800704956%\n",
      "Test Recall: recall_m of 2.514518052339554%\n",
      "Test F1: f1_m of 2.8670979663729668%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1635 - acc: 0.9604 - precision_m: 2.0066e-04 - recall_m: 0.0034 - f1_m: 3.7911e-04\n",
      "Epoch 1: val_acc improved from -inf to 0.96299, saving model to models/best_model_7_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 9s 20ms/step - loss: 0.1635 - acc: 0.9604 - precision_m: 2.0066e-04 - recall_m: 0.0034 - f1_m: 3.7911e-04 - val_loss: 0.1461 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1479 - acc: 0.9633 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 2: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1477 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1477 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 3/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1438 - acc: 0.9635 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 3: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 5s 15ms/step - loss: 0.1443 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1429 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 4/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1423 - acc: 0.9635 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 4: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1424 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1419 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 5/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1412 - acc: 0.9635 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 5: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1415 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1410 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 6/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1416 - acc: 0.9635 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 6: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1418 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1414 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 7/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1394 - acc: 0.9636 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 7: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1398 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1467 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 8/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1381 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 8: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1383 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1401 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 9/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1373 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 9: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1373 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1358 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 10/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1357 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 10: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1355 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1352 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 11/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1337 - acc: 0.9635 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 11: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 5s 15ms/step - loss: 0.1338 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1355 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 12/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1318 - acc: 0.9635 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 12: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1319 - acc: 0.9634 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1326 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 13/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1305 - acc: 0.9634 - precision_m: 0.0092 - recall_m: 0.0023 - f1_m: 0.0036\n",
      "Epoch 13: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1307 - acc: 0.9634 - precision_m: 0.0091 - recall_m: 0.0023 - f1_m: 0.0035 - val_loss: 0.1317 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 14/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1289 - acc: 0.9635 - precision_m: 0.0035 - recall_m: 3.4602e-04 - f1_m: 6.2913e-04\n",
      "Epoch 14: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1293 - acc: 0.9634 - precision_m: 0.0034 - recall_m: 3.4247e-04 - f1_m: 6.2266e-04 - val_loss: 0.1306 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 15/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1261 - acc: 0.9633 - precision_m: 0.0427 - recall_m: 0.0075 - f1_m: 0.0123\n",
      "Epoch 15: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1261 - acc: 0.9633 - precision_m: 0.0422 - recall_m: 0.0074 - f1_m: 0.0122 - val_loss: 0.1299 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 16/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1248 - acc: 0.9635 - precision_m: 0.0842 - recall_m: 0.0124 - f1_m: 0.0212\n",
      "Epoch 16: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1246 - acc: 0.9636 - precision_m: 0.0833 - recall_m: 0.0123 - f1_m: 0.0210 - val_loss: 0.1295 - val_acc: 0.9629 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 17/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1220 - acc: 0.9638 - precision_m: 0.2751 - recall_m: 0.0523 - f1_m: 0.0817\n",
      "Epoch 17: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1221 - acc: 0.9637 - precision_m: 0.2723 - recall_m: 0.0517 - f1_m: 0.0808 - val_loss: 0.1310 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 18/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1196 - acc: 0.9645 - precision_m: 0.3699 - recall_m: 0.0716 - f1_m: 0.1141\n",
      "Epoch 18: val_acc improved from 0.96299 to 0.96382, saving model to models/best_model_7_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 5s 16ms/step - loss: 0.1198 - acc: 0.9644 - precision_m: 0.3695 - recall_m: 0.0714 - f1_m: 0.1138 - val_loss: 0.1240 - val_acc: 0.9638 - val_precision_m: 0.2727 - val_recall_m: 0.0493 - val_f1_m: 0.0764\n",
      "Epoch 19/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1172 - acc: 0.9647 - precision_m: 0.4370 - recall_m: 0.0929 - f1_m: 0.1461\n",
      "Epoch 19: val_acc did not improve from 0.96382\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1173 - acc: 0.9647 - precision_m: 0.4394 - recall_m: 0.0926 - f1_m: 0.1458 - val_loss: 0.1221 - val_acc: 0.9637 - val_precision_m: 0.4193 - val_recall_m: 0.1126 - val_f1_m: 0.1641\n",
      "Epoch 20/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1142 - acc: 0.9649 - precision_m: 0.4463 - recall_m: 0.1044 - f1_m: 0.1567\n",
      "Epoch 20: val_acc improved from 0.96382 to 0.96466, saving model to models/best_model_7_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 5s 16ms/step - loss: 0.1142 - acc: 0.9649 - precision_m: 0.4434 - recall_m: 0.1036 - f1_m: 0.1556 - val_loss: 0.1221 - val_acc: 0.9647 - val_precision_m: 0.3900 - val_recall_m: 0.0957 - val_f1_m: 0.1417\n",
      "Epoch 21/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1131 - acc: 0.9651 - precision_m: 0.5173 - recall_m: 0.1063 - f1_m: 0.1676\n",
      "Epoch 21: val_acc did not improve from 0.96466\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1129 - acc: 0.9652 - precision_m: 0.5171 - recall_m: 0.1064 - f1_m: 0.1676 - val_loss: 0.1212 - val_acc: 0.9626 - val_precision_m: 0.3384 - val_recall_m: 0.0818 - val_f1_m: 0.1191\n",
      "Epoch 22/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1104 - acc: 0.9660 - precision_m: 0.5549 - recall_m: 0.1418 - f1_m: 0.2123\n",
      "Epoch 22: val_acc improved from 0.96466 to 0.96502, saving model to models/best_model_7_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 5s 16ms/step - loss: 0.1106 - acc: 0.9659 - precision_m: 0.5571 - recall_m: 0.1426 - f1_m: 0.2135 - val_loss: 0.1201 - val_acc: 0.9650 - val_precision_m: 0.4317 - val_recall_m: 0.2200 - val_f1_m: 0.2620\n",
      "Epoch 23/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1085 - acc: 0.9664 - precision_m: 0.5939 - recall_m: 0.1918 - f1_m: 0.2698\n",
      "Epoch 23: val_acc did not improve from 0.96502\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1084 - acc: 0.9664 - precision_m: 0.5929 - recall_m: 0.1907 - f1_m: 0.2685 - val_loss: 0.1239 - val_acc: 0.9612 - val_precision_m: 0.3740 - val_recall_m: 0.1367 - val_f1_m: 0.1809\n",
      "Epoch 24/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1048 - acc: 0.9671 - precision_m: 0.6423 - recall_m: 0.1972 - f1_m: 0.2828\n",
      "Epoch 24: val_acc did not improve from 0.96502\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1051 - acc: 0.9670 - precision_m: 0.6409 - recall_m: 0.1965 - f1_m: 0.2818 - val_loss: 0.1219 - val_acc: 0.9643 - val_precision_m: 0.4704 - val_recall_m: 0.2009 - val_f1_m: 0.2636\n",
      "Epoch 25/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1024 - acc: 0.9674 - precision_m: 0.5945 - recall_m: 0.1988 - f1_m: 0.2809\n",
      "Epoch 25: val_acc did not improve from 0.96502\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1027 - acc: 0.9673 - precision_m: 0.5978 - recall_m: 0.1983 - f1_m: 0.2806 - val_loss: 0.1209 - val_acc: 0.9648 - val_precision_m: 0.4560 - val_recall_m: 0.1646 - val_f1_m: 0.2247\n",
      "Epoch 26/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1015 - acc: 0.9680 - precision_m: 0.6272 - recall_m: 0.2276 - f1_m: 0.3160\n",
      "Epoch 26: val_acc did not improve from 0.96502\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1015 - acc: 0.9680 - precision_m: 0.6286 - recall_m: 0.2281 - f1_m: 0.3167 - val_loss: 0.1215 - val_acc: 0.9642 - val_precision_m: 0.4143 - val_recall_m: 0.1346 - val_f1_m: 0.1896\n",
      "Epoch 27/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0997 - acc: 0.9684 - precision_m: 0.6747 - recall_m: 0.2410 - f1_m: 0.3311\n",
      "Epoch 27: val_acc did not improve from 0.96502\n",
      "292/292 [==============================] - 5s 15ms/step - loss: 0.0995 - acc: 0.9685 - precision_m: 0.6703 - recall_m: 0.2398 - f1_m: 0.3294 - val_loss: 0.1280 - val_acc: 0.9645 - val_precision_m: 0.4485 - val_recall_m: 0.1119 - val_f1_m: 0.1706\n",
      "Epoch 28/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0959 - acc: 0.9690 - precision_m: 0.6797 - recall_m: 0.2619 - f1_m: 0.3524\n",
      "Epoch 28: val_acc did not improve from 0.96502\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.0958 - acc: 0.9691 - precision_m: 0.6773 - recall_m: 0.2611 - f1_m: 0.3515 - val_loss: 0.1199 - val_acc: 0.9631 - val_precision_m: 0.3793 - val_recall_m: 0.1673 - val_f1_m: 0.2195\n",
      "Epoch 29/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0943 - acc: 0.9694 - precision_m: 0.6900 - recall_m: 0.2714 - f1_m: 0.3670\n",
      "Epoch 29: val_acc did not improve from 0.96502\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.0947 - acc: 0.9693 - precision_m: 0.6885 - recall_m: 0.2717 - f1_m: 0.3671 - val_loss: 0.1229 - val_acc: 0.9635 - val_precision_m: 0.4212 - val_recall_m: 0.1680 - val_f1_m: 0.2191\n",
      "Epoch 30/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0911 - acc: 0.9701 - precision_m: 0.7261 - recall_m: 0.2901 - f1_m: 0.3929\n",
      "Epoch 30: val_acc did not improve from 0.96502\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.0910 - acc: 0.9701 - precision_m: 0.7269 - recall_m: 0.2910 - f1_m: 0.3940 - val_loss: 0.1268 - val_acc: 0.9623 - val_precision_m: 0.3873 - val_recall_m: 0.1704 - val_f1_m: 0.2179\n",
      "Score for fold 8: loss of 0.12009139358997345; acc of 96.5021550655365%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.1212511658668518; acc of 96.38234376907349%\n",
      "Test Precision: precision_m of 9.175501018762589%\n",
      "Test Recall: recall_m of 4.938047379255295%\n",
      "Test F1: f1_m of 5.800294503569603%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "Epoch 1/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.1603 - acc: 0.9619 - precision_m: 9.4407e-05 - recall_m: 0.0025 - f1_m: 1.8182e-04\n",
      "Epoch 1: val_acc improved from -inf to 0.96151, saving model to models/best_model_7_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 9s 22ms/step - loss: 0.1603 - acc: 0.9619 - precision_m: 9.4407e-05 - recall_m: 0.0025 - f1_m: 1.8182e-04 - val_loss: 0.1627 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1462 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 2: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1462 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1478 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 3/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1428 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 3: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1427 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1469 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 4/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1411 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 4: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1409 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1534 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 5/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1422 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 5: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 5s 15ms/step - loss: 0.1421 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1469 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 6/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1385 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 6: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1383 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1425 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 7/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1381 - acc: 0.9643 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 7: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1381 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1444 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 8/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1366 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 8: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1365 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1396 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 9/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1365 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 9: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1363 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1399 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 10/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1357 - acc: 0.9643 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 10: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1357 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1393 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 11/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1349 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 11: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1347 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1409 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 12/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1334 - acc: 0.9643 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 12: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1336 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1392 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 13/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1330 - acc: 0.9643 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 13: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1332 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1379 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 14/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1305 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 14: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1306 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1370 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 15/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1297 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 15: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1298 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1338 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 16/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1280 - acc: 0.9643 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 16: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1283 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1375 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 17/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1260 - acc: 0.9643 - precision_m: 0.0225 - recall_m: 0.0029 - f1_m: 0.0049  \n",
      "Epoch 17: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1259 - acc: 0.9643 - precision_m: 0.0223 - recall_m: 0.0028 - f1_m: 0.0049 - val_loss: 0.1318 - val_acc: 0.9614 - val_precision_m: 0.3030 - val_recall_m: 0.0291 - val_f1_m: 0.0525\n",
      "Epoch 18/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1245 - acc: 0.9645 - precision_m: 0.1517 - recall_m: 0.0276 - f1_m: 0.0441\n",
      "Epoch 18: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1245 - acc: 0.9645 - precision_m: 0.1506 - recall_m: 0.0274 - f1_m: 0.0438 - val_loss: 0.1412 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 19/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1225 - acc: 0.9647 - precision_m: 0.2018 - recall_m: 0.0326 - f1_m: 0.0537\n",
      "Epoch 19: val_acc improved from 0.96151 to 0.96163, saving model to models/best_model_7_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 5s 16ms/step - loss: 0.1226 - acc: 0.9647 - precision_m: 0.2005 - recall_m: 0.0324 - f1_m: 0.0533 - val_loss: 0.1299 - val_acc: 0.9616 - val_precision_m: 0.0606 - val_recall_m: 0.0068 - val_f1_m: 0.0122\n",
      "Epoch 20/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1205 - acc: 0.9649 - precision_m: 0.2517 - recall_m: 0.0408 - f1_m: 0.0674\n",
      "Epoch 20: val_acc did not improve from 0.96163\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1206 - acc: 0.9648 - precision_m: 0.2500 - recall_m: 0.0405 - f1_m: 0.0670 - val_loss: 0.1314 - val_acc: 0.9600 - val_precision_m: 0.3513 - val_recall_m: 0.1444 - val_f1_m: 0.1893\n",
      "Epoch 21/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1181 - acc: 0.9648 - precision_m: 0.3134 - recall_m: 0.0648 - f1_m: 0.1008\n",
      "Epoch 21: val_acc did not improve from 0.96163\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1181 - acc: 0.9648 - precision_m: 0.3112 - recall_m: 0.0643 - f1_m: 0.1001 - val_loss: 0.1298 - val_acc: 0.9615 - val_precision_m: 0.2222 - val_recall_m: 0.0260 - val_f1_m: 0.0442\n",
      "Epoch 22/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1159 - acc: 0.9653 - precision_m: 0.3854 - recall_m: 0.0784 - f1_m: 0.1221\n",
      "Epoch 22: val_acc improved from 0.96163 to 0.96187, saving model to models/best_model_7_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 5s 16ms/step - loss: 0.1160 - acc: 0.9653 - precision_m: 0.3828 - recall_m: 0.0778 - f1_m: 0.1213 - val_loss: 0.1253 - val_acc: 0.9619 - val_precision_m: 0.1061 - val_recall_m: 0.0100 - val_f1_m: 0.0175\n",
      "Epoch 23/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1137 - acc: 0.9658 - precision_m: 0.4120 - recall_m: 0.0918 - f1_m: 0.1411\n",
      "Epoch 23: val_acc improved from 0.96187 to 0.96211, saving model to models/best_model_7_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 5s 16ms/step - loss: 0.1136 - acc: 0.9659 - precision_m: 0.4135 - recall_m: 0.0933 - f1_m: 0.1430 - val_loss: 0.1262 - val_acc: 0.9621 - val_precision_m: 0.4364 - val_recall_m: 0.1547 - val_f1_m: 0.2077\n",
      "Epoch 24/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1107 - acc: 0.9661 - precision_m: 0.5202 - recall_m: 0.1236 - f1_m: 0.1858\n",
      "Epoch 24: val_acc improved from 0.96211 to 0.96282, saving model to models/best_model_7_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 5s 16ms/step - loss: 0.1106 - acc: 0.9661 - precision_m: 0.5183 - recall_m: 0.1233 - f1_m: 0.1854 - val_loss: 0.1283 - val_acc: 0.9628 - val_precision_m: 0.3258 - val_recall_m: 0.0828 - val_f1_m: 0.1217\n",
      "Epoch 25/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1090 - acc: 0.9668 - precision_m: 0.5297 - recall_m: 0.1295 - f1_m: 0.1972\n",
      "Epoch 25: val_acc did not improve from 0.96282\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1091 - acc: 0.9668 - precision_m: 0.5318 - recall_m: 0.1298 - f1_m: 0.1978 - val_loss: 0.1288 - val_acc: 0.9628 - val_precision_m: 0.5025 - val_recall_m: 0.1588 - val_f1_m: 0.2192\n",
      "Epoch 26/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1080 - acc: 0.9665 - precision_m: 0.5609 - recall_m: 0.1375 - f1_m: 0.2073\n",
      "Epoch 26: val_acc improved from 0.96282 to 0.96306, saving model to models/best_model_7_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 5s 16ms/step - loss: 0.1078 - acc: 0.9665 - precision_m: 0.5571 - recall_m: 0.1365 - f1_m: 0.2059 - val_loss: 0.1236 - val_acc: 0.9631 - val_precision_m: 0.3485 - val_recall_m: 0.0819 - val_f1_m: 0.1231\n",
      "Epoch 27/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1043 - acc: 0.9675 - precision_m: 0.5898 - recall_m: 0.1607 - f1_m: 0.2346\n",
      "Epoch 27: val_acc improved from 0.96306 to 0.96354, saving model to models/best_model_7_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 5s 16ms/step - loss: 0.1044 - acc: 0.9675 - precision_m: 0.5883 - recall_m: 0.1604 - f1_m: 0.2342 - val_loss: 0.1202 - val_acc: 0.9635 - val_precision_m: 0.5113 - val_recall_m: 0.1921 - val_f1_m: 0.2500\n",
      "Epoch 28/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1014 - acc: 0.9679 - precision_m: 0.6255 - recall_m: 0.1907 - f1_m: 0.2755\n",
      "Epoch 28: val_acc improved from 0.96354 to 0.96437, saving model to models/best_model_7_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 5s 16ms/step - loss: 0.1015 - acc: 0.9679 - precision_m: 0.6269 - recall_m: 0.1908 - f1_m: 0.2757 - val_loss: 0.1214 - val_acc: 0.9644 - val_precision_m: 0.5452 - val_recall_m: 0.2116 - val_f1_m: 0.2697\n",
      "Epoch 29/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1007 - acc: 0.9681 - precision_m: 0.6202 - recall_m: 0.2006 - f1_m: 0.2863\n",
      "Epoch 29: val_acc did not improve from 0.96437\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.1008 - acc: 0.9681 - precision_m: 0.6200 - recall_m: 0.2002 - f1_m: 0.2860 - val_loss: 0.1196 - val_acc: 0.9641 - val_precision_m: 0.5672 - val_recall_m: 0.2211 - val_f1_m: 0.2886\n",
      "Epoch 30/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0975 - acc: 0.9689 - precision_m: 0.6471 - recall_m: 0.2245 - f1_m: 0.3132\n",
      "Epoch 30: val_acc did not improve from 0.96437\n",
      "291/291 [==============================] - 4s 15ms/step - loss: 0.0974 - acc: 0.9689 - precision_m: 0.6489 - recall_m: 0.2258 - f1_m: 0.3149 - val_loss: 0.1235 - val_acc: 0.9625 - val_precision_m: 0.4704 - val_recall_m: 0.1888 - val_f1_m: 0.2440\n",
      "Score for fold 9: loss of 0.12137952446937561; acc of 96.4370846748352%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.12824130058288574; acc of 96.01516127586365%\n",
      "Test Precision: precision_m of 9.550172835588455%\n",
      "Test Recall: recall_m of 4.364530369639397%\n",
      "Test F1: f1_m of 5.601566284894943%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1639 - acc: 0.9632 - precision_m: 8.3528e-05 - recall_m: 9.7847e-04 - f1_m: 1.5392e-04\n",
      "Epoch 1: val_acc improved from -inf to 0.96034, saving model to models/best_model_7_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 9s 21ms/step - loss: 0.1639 - acc: 0.9632 - precision_m: 8.3528e-05 - recall_m: 9.7847e-04 - f1_m: 1.5392e-04 - val_loss: 0.1637 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1483 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 2: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 5s 15ms/step - loss: 0.1483 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1563 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 3/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1416 - acc: 0.9643 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 3: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 5s 15ms/step - loss: 0.1417 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1508 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 4/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1406 - acc: 0.9643 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 4: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1406 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1529 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 5/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1392 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 5: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1391 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1508 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 6/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1379 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 6: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 5s 15ms/step - loss: 0.1378 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1558 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 7/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1374 - acc: 0.9643 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 7: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1374 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1488 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 8/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1365 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 8: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 5s 15ms/step - loss: 0.1363 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1480 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 9/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1356 - acc: 0.9643 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 9: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1359 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1473 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 10/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1342 - acc: 0.9641 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 10: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 5s 15ms/step - loss: 0.1339 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1515 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 11/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1337 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 11: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1340 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1494 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 12/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1328 - acc: 0.9643 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 12: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1331 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1518 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 13/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1321 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 13: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1320 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1498 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 14/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1305 - acc: 0.9643 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 14: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 5s 15ms/step - loss: 0.1307 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1488 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 15/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1292 - acc: 0.9644 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 15: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1295 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1434 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 16/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1275 - acc: 0.9643 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 16: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1276 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1410 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 17/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1264 - acc: 0.9643 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 17: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1267 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1439 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 18/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1250 - acc: 0.9643 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 18: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1250 - acc: 0.9642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1430 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 19/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1252 - acc: 0.9642 - precision_m: 0.0208 - recall_m: 0.0022 - f1_m: 0.0039\n",
      "Epoch 19: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1250 - acc: 0.9642 - precision_m: 0.0205 - recall_m: 0.0021 - f1_m: 0.0038 - val_loss: 0.1441 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 20/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1217 - acc: 0.9643 - precision_m: 0.0824 - recall_m: 0.0133 - f1_m: 0.0217\n",
      "Epoch 20: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1216 - acc: 0.9644 - precision_m: 0.0816 - recall_m: 0.0132 - f1_m: 0.0215 - val_loss: 0.1385 - val_acc: 0.9602 - val_precision_m: 0.1515 - val_recall_m: 0.0136 - val_f1_m: 0.0245\n",
      "Epoch 21/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1195 - acc: 0.9648 - precision_m: 0.2340 - recall_m: 0.0406 - f1_m: 0.0661\n",
      "Epoch 21: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 5s 15ms/step - loss: 0.1193 - acc: 0.9648 - precision_m: 0.2316 - recall_m: 0.0402 - f1_m: 0.0654 - val_loss: 0.1458 - val_acc: 0.9603 - val_precision_m: 0.0909 - val_recall_m: 0.0083 - val_f1_m: 0.0149\n",
      "Epoch 22/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1183 - acc: 0.9646 - precision_m: 0.2639 - recall_m: 0.0485 - f1_m: 0.0776\n",
      "Epoch 22: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 5s 15ms/step - loss: 0.1182 - acc: 0.9646 - precision_m: 0.2612 - recall_m: 0.0480 - f1_m: 0.0768 - val_loss: 0.1395 - val_acc: 0.9602 - val_precision_m: 0.1515 - val_recall_m: 0.0126 - val_f1_m: 0.0228\n",
      "Epoch 23/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1154 - acc: 0.9651 - precision_m: 0.3371 - recall_m: 0.0636 - f1_m: 0.1014\n",
      "Epoch 23: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1150 - acc: 0.9652 - precision_m: 0.3364 - recall_m: 0.0645 - f1_m: 0.1023 - val_loss: 0.1375 - val_acc: 0.9593 - val_precision_m: 0.4441 - val_recall_m: 0.1458 - val_f1_m: 0.2081\n",
      "Epoch 24/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1127 - acc: 0.9655 - precision_m: 0.3898 - recall_m: 0.0803 - f1_m: 0.1269\n",
      "Epoch 24: val_acc improved from 0.96034 to 0.96094, saving model to models/best_model_7_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 5s 16ms/step - loss: 0.1126 - acc: 0.9655 - precision_m: 0.3892 - recall_m: 0.0801 - f1_m: 0.1266 - val_loss: 0.1378 - val_acc: 0.9609 - val_precision_m: 0.3838 - val_recall_m: 0.0651 - val_f1_m: 0.1039\n",
      "Epoch 25/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1112 - acc: 0.9662 - precision_m: 0.4901 - recall_m: 0.1220 - f1_m: 0.1827\n",
      "Epoch 25: val_acc improved from 0.96094 to 0.96118, saving model to models/best_model_7_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 5s 16ms/step - loss: 0.1113 - acc: 0.9662 - precision_m: 0.4885 - recall_m: 0.1212 - f1_m: 0.1817 - val_loss: 0.1357 - val_acc: 0.9612 - val_precision_m: 0.4318 - val_recall_m: 0.0570 - val_f1_m: 0.0968\n",
      "Epoch 26/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1085 - acc: 0.9660 - precision_m: 0.5155 - recall_m: 0.1229 - f1_m: 0.1856\n",
      "Epoch 26: val_acc did not improve from 0.96118\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1085 - acc: 0.9659 - precision_m: 0.5165 - recall_m: 0.1228 - f1_m: 0.1856 - val_loss: 0.1355 - val_acc: 0.9591 - val_precision_m: 0.4025 - val_recall_m: 0.1370 - val_f1_m: 0.1932\n",
      "Epoch 27/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1068 - acc: 0.9664 - precision_m: 0.5278 - recall_m: 0.1383 - f1_m: 0.2051\n",
      "Epoch 27: val_acc improved from 0.96118 to 0.96154, saving model to models/best_model_7_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 5s 16ms/step - loss: 0.1068 - acc: 0.9663 - precision_m: 0.5275 - recall_m: 0.1383 - f1_m: 0.2052 - val_loss: 0.1384 - val_acc: 0.9615 - val_precision_m: 0.4152 - val_recall_m: 0.0667 - val_f1_m: 0.1108\n",
      "Epoch 28/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1042 - acc: 0.9673 - precision_m: 0.6025 - recall_m: 0.1709 - f1_m: 0.2492\n",
      "Epoch 28: val_acc did not improve from 0.96154\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1042 - acc: 0.9673 - precision_m: 0.6066 - recall_m: 0.1710 - f1_m: 0.2497 - val_loss: 0.1312 - val_acc: 0.9611 - val_precision_m: 0.3273 - val_recall_m: 0.0599 - val_f1_m: 0.0967\n",
      "Epoch 29/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1019 - acc: 0.9677 - precision_m: 0.6206 - recall_m: 0.1840 - f1_m: 0.2677\n",
      "Epoch 29: val_acc did not improve from 0.96154\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.1017 - acc: 0.9677 - precision_m: 0.6160 - recall_m: 0.1826 - f1_m: 0.2657 - val_loss: 0.1373 - val_acc: 0.9609 - val_precision_m: 0.2020 - val_recall_m: 0.0233 - val_f1_m: 0.0411\n",
      "Epoch 30/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0986 - acc: 0.9686 - precision_m: 0.6207 - recall_m: 0.2106 - f1_m: 0.2959\n",
      "Epoch 30: val_acc did not improve from 0.96154\n",
      "292/292 [==============================] - 4s 15ms/step - loss: 0.0989 - acc: 0.9684 - precision_m: 0.6182 - recall_m: 0.2098 - f1_m: 0.2949 - val_loss: 0.1388 - val_acc: 0.9578 - val_precision_m: 0.4397 - val_recall_m: 0.1914 - val_f1_m: 0.2418\n",
      "Score for fold 10: loss of 0.13843315839767456; acc of 96.15384340286255%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.12899117171764374; acc of 96.23366594314575%\n",
      "Test Precision: precision_m of 5.730993673205376%\n",
      "Test Recall: recall_m of 3.504316508769989%\n",
      "Test F1: f1_m of 3.8137007504701614%\n",
      "------------------------------------------------------------------------\n",
      "Validation score per fold\n",
      "> Fold 1 - Loss: 0.13419558107852936 - Accuracy: 96.19013667106628%\n",
      "> Fold 2 - Loss: 0.1271340399980545 - Accuracy: 96.49143815040588%\n",
      "> Fold 3 - Loss: 0.12082887440919876 - Accuracy: 96.55007123947144%\n",
      "> Fold 4 - Loss: 0.13136957585811615 - Accuracy: 96.33432626724243%\n",
      "> Fold 5 - Loss: 0.12969060242176056 - Accuracy: 96.35472893714905%\n",
      "> Fold 6 - Loss: 0.13555467128753662 - Accuracy: 96.2878167629242%\n",
      "> Fold 7 - Loss: 0.1248425766825676 - Accuracy: 96.41577005386353%\n",
      "> Fold 8 - Loss: 0.12009139358997345 - Accuracy: 96.5021550655365%\n",
      "> Fold 9 - Loss: 0.12137952446937561 - Accuracy: 96.4370846748352%\n",
      "> Fold 10 - Loss: 0.13843315839767456 - Accuracy: 96.15384340286255%\n",
      "------------------------------------------------------------------------\n",
      "Testing score per fold\n",
      "> Fold 1 - Accuracy: 97.31454849243164 - Precision: 2.464788593351841 - Recall: 1.2676055543124676 - F1: 1.60211231559515%\n",
      "> Fold 2 - Accuracy: 95.81679701805115 - Precision: 8.036530017852783 - Recall: 3.3378180116415024 - F1: 4.263202100992203%\n",
      "> Fold 3 - Accuracy: 96.6833770275116 - Precision: 8.673469722270966 - Recall: 5.096776410937309 - F1: 5.821455642580986%\n",
      "> Fold 4 - Accuracy: 95.7156777381897 - Precision: 4.267589375376701 - Recall: 1.6839675605297089 - F1: 2.1810539066791534%\n",
      "> Fold 5 - Accuracy: 96.4552640914917 - Precision: 6.1433445662260056 - Recall: 2.549569495022297 - F1: 3.3794131129980087%\n",
      "> Fold 6 - Accuracy: 96.53934240341187 - Precision: 5.55555522441864 - Recall: 2.3383762687444687 - F1: 3.005676530301571%\n",
      "> Fold 7 - Accuracy: 96.94156050682068 - Precision: 4.355400800704956 - Recall: 2.514518052339554 - F1: 2.8670979663729668%\n",
      "> Fold 8 - Accuracy: 96.38234376907349 - Precision: 9.175501018762589 - Recall: 4.938047379255295 - F1: 5.800294503569603%\n",
      "> Fold 9 - Accuracy: 96.01516127586365 - Precision: 9.550172835588455 - Recall: 4.364530369639397 - F1: 5.601566284894943%\n",
      "> Fold 10 - Accuracy: 96.23366594314575 - Precision: 5.730993673205376 - Recall: 3.504316508769989 - F1: 3.8137007504701614%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Validation Accuracy: 96.3717371225357 (+- 0.12591159958240017)\n",
      "> Validation Loss: 0.12835199981927872\n",
      "> Testing Accuracy: 96.40977382659912 (+- 0.4707448030865011)\n",
      "> Testing Precision: 6.395334582775831\n",
      "> Testing Recall: 3.159552561119199\n",
      "> Testing F1: 3.8335573114454746\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Lists to hold cross-validation results\n",
    "acc_7_per_fold = []\n",
    "loss_7_per_fold = []\n",
    "precision_7_per_fold = []\n",
    "recall_7_per_fold = []\n",
    "f1_7_per_fold = []\n",
    "\n",
    "testing_acc_7_per_fold = []\n",
    "testing_precision_7_per_fold = []\n",
    "testing_recall_7_per_fold = []\n",
    "testing_f1_7_per_fold = []\n",
    "\n",
    "# Load data from .npz files\n",
    "for fold_no in range(1, 11):\n",
    "    with np.load(f'fold_{fold_no}.npz') as data:\n",
    "        x_train = data['x_train_fold.npy']\n",
    "        y_train = data['y_train_fold.npy']\n",
    "        x_val = data['x_val_fold.npy']\n",
    "        y_val = data['y_val_fold.npy']\n",
    "        x_test = data['x_test_fold.npy']\n",
    "        y_test = data['y_test_fold.npy']\n",
    "        \n",
    "        # Converting ground truth arrays to one wake word (1) and 'other' (0)\n",
    "        wake_word_index = all_targets.index(wake_word)\n",
    "        y_train = np.equal(y_train, wake_word_index).astype('float64')\n",
    "        y_val = np.equal(y_val, wake_word_index).astype('float64')\n",
    "        y_test = np.equal(y_test, wake_word_index).astype('float64')\n",
    "        \n",
    "        # CNN for TF expects (batch, height, width, channels)\n",
    "        x_train = x_train.reshape(x_train.shape[0], \n",
    "                          x_train.shape[1], \n",
    "                          x_train.shape[2], \n",
    "                          1)\n",
    "        x_val = x_val.reshape(x_val.shape[0], \n",
    "                          x_val.shape[1], \n",
    "                          x_val.shape[2], \n",
    "                          1)\n",
    "        x_test = x_test.reshape(x_test.shape[0], \n",
    "                          x_test.shape[1], \n",
    "                          x_test.shape[2], \n",
    "                          1)\n",
    "        sample_shape = x_test.shape[1:]\n",
    "\n",
    "    # CNN model\n",
    "    model_7 = models.Sequential()\n",
    "    model_7.add(layers.Conv2D(64, \n",
    "                            (1, 1), \n",
    "                            activation='relu',\n",
    "                            input_shape=sample_shape))\n",
    "    model_7.add(layers.Conv2D(64, (1, 1), activation='relu'))\n",
    "    model_7.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model_7.add(layers.Conv2D(128, (1, 1), activation='relu'))\n",
    "    model_7.add(layers.Conv2D(128, (1, 1), activation='relu'))\n",
    "    model_7.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model_7.add(layers.Conv2D(256, (1, 1), activation='relu'))\n",
    "    model_7.add(layers.Conv2D(256, (1, 1), activation='relu'))\n",
    "    model_7.add(layers.Conv2D(256, (1, 1), activation='relu'))\n",
    "    model_7.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model_7.add(layers.Conv2D(512, (1, 1), activation='relu'))\n",
    "    model_7.add(layers.Conv2D(512, (1, 1), activation='relu'))\n",
    "    model_7.add(layers.Conv2D(512, (1, 1), activation='relu'))\n",
    "    model_7.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model_7.add(layers.Conv2D(512, (1, 1), activation='relu'))\n",
    "    model_7.add(layers.Conv2D(512, (1, 1), activation='relu'))\n",
    "    model_7.add(layers.Conv2D(512, (1, 1), activation='relu'))\n",
    "    #model_7.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Classifier\n",
    "    model_7.add(layers.Flatten())\n",
    "    model_7.add(layers.Dense(512, activation='relu'))\n",
    "    model_7.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "\n",
    "    model_7.compile(loss='binary_crossentropy', \n",
    "              optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "              metrics=['acc', precision_m, recall_m, f1_m])\n",
    "\n",
    "    checkpoint_filepath = f'models/best_model_7_fold_{fold_no}.h5'\n",
    "    model_checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=False,\n",
    "        monitor='val_acc',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "        save_freq='epoch'\n",
    "    )\n",
    "\n",
    "    # Instantiate the custom callback\n",
    "    metrics_history = MetricsHistory()\n",
    "\n",
    "    # Print fold number\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Train\n",
    "    history_7 = model_7.fit(x_train, \n",
    "                    y_train, \n",
    "                    epochs=30, \n",
    "                    batch_size=256, \n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[model_checkpoint_callback, metrics_history])\n",
    "\n",
    "    model_7.load_weights(checkpoint_filepath)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    scores = model_7.evaluate(x_val, y_val, verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model_7.metrics_names[0]} of {scores[0]}; {model_7.metrics_names[1]} of {scores[1] * 100}%')\n",
    "    acc_7_per_fold.append(scores[1] * 100)\n",
    "    loss_7_per_fold.append(scores[0])\n",
    "    precision_7_per_fold.append(metrics_history.best_metrics['precision_m'] * 100)\n",
    "    recall_7_per_fold.append(metrics_history.best_metrics['recall_m'] * 100)\n",
    "    f1_7_per_fold.append(metrics_history.best_metrics['f1_m'] * 100)\n",
    "\n",
    "    # Final evaluation on test set\n",
    "    final_scores = model_7.evaluate(x_test, y_test, verbose=0)\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Final test score: {model_7.metrics_names[0]} of {final_scores[0]}; {model_7.metrics_names[1]} of {final_scores[1] * 100}%')\n",
    "    print(f'Test Precision: {model_7.metrics_names[2]} of {final_scores[2] * 100}%')\n",
    "    print(f'Test Recall: {model_7.metrics_names[3]} of {final_scores[3] * 100}%')\n",
    "    print(f'Test F1: {model_7.metrics_names[4]} of {final_scores[4] * 100}%')\n",
    "\n",
    "    # Append test metrics to lists\n",
    "    testing_acc_7_per_fold.append(final_scores[1] * 100)\n",
    "    testing_precision_7_per_fold.append(final_scores[2] * 100)\n",
    "    testing_recall_7_per_fold.append(final_scores[3] * 100)\n",
    "    testing_f1_7_per_fold.append(final_scores[4] * 100)\n",
    "\n",
    "# Print the results\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Validation score per fold')\n",
    "for i in range(0, len(acc_7_per_fold)):\n",
    "    print(f'> Fold {i+1} - Loss: {loss_7_per_fold[i]} - Accuracy: {acc_7_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Testing score per fold')\n",
    "for i in range(0, len(testing_acc_7_per_fold)):\n",
    "    print(f'> Fold {i+1} - Accuracy: {testing_acc_7_per_fold[i]} - Precision: {testing_precision_7_per_fold[i]} - Recall: {testing_recall_7_per_fold[i]} - F1: {testing_f1_7_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Validation Accuracy: {np.mean(acc_7_per_fold)} (+- {np.std(acc_7_per_fold)})')\n",
    "print(f'> Validation Loss: {np.mean(loss_7_per_fold)}')\n",
    "print(f'> Testing Accuracy: {np.mean(testing_acc_7_per_fold)} (+- {np.std(testing_acc_7_per_fold)})')\n",
    "print(f'> Testing Precision: {np.mean(testing_precision_7_per_fold)}')\n",
    "print(f'> Testing Recall: {np.mean(testing_recall_7_per_fold)}')\n",
    "print(f'> Testing F1: {np.mean(testing_f1_7_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1668 - acc: 0.9602 - precision_m: 3.5034e-04 - recall_m: 0.0027 - f1_m: 6.1973e-04\n",
      "Epoch 1: val_acc improved from -inf to 0.96023, saving model to models/best_model_8_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 3s 5ms/step - loss: 0.1668 - acc: 0.9602 - precision_m: 3.5034e-04 - recall_m: 0.0027 - f1_m: 6.1973e-04 - val_loss: 0.1329 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1254 - acc: 0.9631 - precision_m: 0.1159 - recall_m: 0.0160 - f1_m: 0.0274\n",
      "Epoch 2: val_acc improved from 0.96023 to 0.96047, saving model to models/best_model_8_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1254 - acc: 0.9631 - precision_m: 0.1159 - recall_m: 0.0160 - f1_m: 0.0274 - val_loss: 0.1191 - val_acc: 0.9605 - val_precision_m: 0.0758 - val_recall_m: 0.0106 - val_f1_m: 0.0183\n",
      "Epoch 3/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.1101 - acc: 0.9637 - precision_m: 0.3258 - recall_m: 0.0616 - f1_m: 0.0987\n",
      "Epoch 3: val_acc improved from 0.96047 to 0.96369, saving model to models/best_model_8_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1101 - acc: 0.9636 - precision_m: 0.3294 - recall_m: 0.0621 - f1_m: 0.0996 - val_loss: 0.1118 - val_acc: 0.9637 - val_precision_m: 0.4861 - val_recall_m: 0.1089 - val_f1_m: 0.1672\n",
      "Epoch 4/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.1022 - acc: 0.9652 - precision_m: 0.5143 - recall_m: 0.1310 - f1_m: 0.1970\n",
      "Epoch 4: val_acc did not improve from 0.96369\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1021 - acc: 0.9652 - precision_m: 0.5143 - recall_m: 0.1312 - f1_m: 0.1973 - val_loss: 0.1103 - val_acc: 0.9626 - val_precision_m: 0.4287 - val_recall_m: 0.0861 - val_f1_m: 0.1334\n",
      "Epoch 5/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.0977 - acc: 0.9661 - precision_m: 0.5826 - recall_m: 0.1846 - f1_m: 0.2605\n",
      "Epoch 5: val_acc did not improve from 0.96369\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0974 - acc: 0.9662 - precision_m: 0.5923 - recall_m: 0.1866 - f1_m: 0.2645 - val_loss: 0.1172 - val_acc: 0.9623 - val_precision_m: 0.3985 - val_recall_m: 0.0605 - val_f1_m: 0.1002\n",
      "Epoch 6/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0946 - acc: 0.9674 - precision_m: 0.6604 - recall_m: 0.2337 - f1_m: 0.3214\n",
      "Epoch 6: val_acc did not improve from 0.96369\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0945 - acc: 0.9674 - precision_m: 0.6548 - recall_m: 0.2324 - f1_m: 0.3195 - val_loss: 0.1203 - val_acc: 0.9626 - val_precision_m: 0.4413 - val_recall_m: 0.0786 - val_f1_m: 0.1229\n",
      "Epoch 7/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0919 - acc: 0.9682 - precision_m: 0.6459 - recall_m: 0.2570 - f1_m: 0.3455\n",
      "Epoch 7: val_acc improved from 0.96369 to 0.96728, saving model to models/best_model_8_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0920 - acc: 0.9682 - precision_m: 0.6485 - recall_m: 0.2594 - f1_m: 0.3484 - val_loss: 0.1039 - val_acc: 0.9673 - val_precision_m: 0.6504 - val_recall_m: 0.2621 - val_f1_m: 0.3542\n",
      "Epoch 8/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0885 - acc: 0.9683 - precision_m: 0.6652 - recall_m: 0.2780 - f1_m: 0.3720\n",
      "Epoch 8: val_acc did not improve from 0.96728\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0882 - acc: 0.9684 - precision_m: 0.6707 - recall_m: 0.2789 - f1_m: 0.3739 - val_loss: 0.1098 - val_acc: 0.9668 - val_precision_m: 0.6737 - val_recall_m: 0.2016 - val_f1_m: 0.2865\n",
      "Epoch 9/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.0858 - acc: 0.9698 - precision_m: 0.7071 - recall_m: 0.3214 - f1_m: 0.4187\n",
      "Epoch 9: val_acc improved from 0.96728 to 0.96871, saving model to models/best_model_8_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0858 - acc: 0.9698 - precision_m: 0.7081 - recall_m: 0.3213 - f1_m: 0.4188 - val_loss: 0.1038 - val_acc: 0.9687 - val_precision_m: 0.6830 - val_recall_m: 0.2549 - val_f1_m: 0.3542\n",
      "Epoch 10/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0851 - acc: 0.9700 - precision_m: 0.7040 - recall_m: 0.3345 - f1_m: 0.4267\n",
      "Epoch 10: val_acc did not improve from 0.96871\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0849 - acc: 0.9701 - precision_m: 0.7060 - recall_m: 0.3339 - f1_m: 0.4264 - val_loss: 0.1054 - val_acc: 0.9669 - val_precision_m: 0.6722 - val_recall_m: 0.1915 - val_f1_m: 0.2796\n",
      "Epoch 11/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0829 - acc: 0.9703 - precision_m: 0.7348 - recall_m: 0.3446 - f1_m: 0.4416\n",
      "Epoch 11: val_acc did not improve from 0.96871\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0826 - acc: 0.9705 - precision_m: 0.7307 - recall_m: 0.3425 - f1_m: 0.4386 - val_loss: 0.1060 - val_acc: 0.9682 - val_precision_m: 0.6805 - val_recall_m: 0.2499 - val_f1_m: 0.3490\n",
      "Epoch 12/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.0799 - acc: 0.9711 - precision_m: 0.7266 - recall_m: 0.3692 - f1_m: 0.4634\n",
      "Epoch 12: val_acc did not improve from 0.96871\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0799 - acc: 0.9711 - precision_m: 0.7266 - recall_m: 0.3692 - f1_m: 0.4634 - val_loss: 0.1014 - val_acc: 0.9687 - val_precision_m: 0.6199 - val_recall_m: 0.3291 - val_f1_m: 0.4127\n",
      "Epoch 13/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0793 - acc: 0.9717 - precision_m: 0.7225 - recall_m: 0.3828 - f1_m: 0.4765\n",
      "Epoch 13: val_acc did not improve from 0.96871\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0787 - acc: 0.9719 - precision_m: 0.7249 - recall_m: 0.3850 - f1_m: 0.4795 - val_loss: 0.1015 - val_acc: 0.9680 - val_precision_m: 0.6034 - val_recall_m: 0.3559 - val_f1_m: 0.4336\n",
      "Epoch 14/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0778 - acc: 0.9725 - precision_m: 0.7624 - recall_m: 0.4080 - f1_m: 0.5053\n",
      "Epoch 14: val_acc improved from 0.96871 to 0.96978, saving model to models/best_model_8_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0775 - acc: 0.9726 - precision_m: 0.7610 - recall_m: 0.4052 - f1_m: 0.5031 - val_loss: 0.1046 - val_acc: 0.9698 - val_precision_m: 0.6797 - val_recall_m: 0.3130 - val_f1_m: 0.4100\n",
      "Epoch 15/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.0754 - acc: 0.9731 - precision_m: 0.7396 - recall_m: 0.4182 - f1_m: 0.5108\n",
      "Epoch 15: val_acc did not improve from 0.96978\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0754 - acc: 0.9731 - precision_m: 0.7396 - recall_m: 0.4182 - f1_m: 0.5108 - val_loss: 0.1018 - val_acc: 0.9685 - val_precision_m: 0.6051 - val_recall_m: 0.3413 - val_f1_m: 0.4189\n",
      "Epoch 16/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0736 - acc: 0.9738 - precision_m: 0.7590 - recall_m: 0.4278 - f1_m: 0.5243\n",
      "Epoch 16: val_acc did not improve from 0.96978\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0736 - acc: 0.9738 - precision_m: 0.7588 - recall_m: 0.4257 - f1_m: 0.5227 - val_loss: 0.1015 - val_acc: 0.9689 - val_precision_m: 0.6099 - val_recall_m: 0.3326 - val_f1_m: 0.4126\n",
      "Epoch 17/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.0722 - acc: 0.9738 - precision_m: 0.7537 - recall_m: 0.4404 - f1_m: 0.5300\n",
      "Epoch 17: val_acc did not improve from 0.96978\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0723 - acc: 0.9738 - precision_m: 0.7545 - recall_m: 0.4403 - f1_m: 0.5303 - val_loss: 0.1009 - val_acc: 0.9667 - val_precision_m: 0.5767 - val_recall_m: 0.3471 - val_f1_m: 0.4119\n",
      "Epoch 18/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.0717 - acc: 0.9741 - precision_m: 0.7582 - recall_m: 0.4416 - f1_m: 0.5305\n",
      "Epoch 18: val_acc improved from 0.96978 to 0.96990, saving model to models/best_model_8_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0717 - acc: 0.9741 - precision_m: 0.7582 - recall_m: 0.4416 - f1_m: 0.5305 - val_loss: 0.1035 - val_acc: 0.9699 - val_precision_m: 0.6986 - val_recall_m: 0.2957 - val_f1_m: 0.4000\n",
      "Epoch 19/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0694 - acc: 0.9748 - precision_m: 0.7825 - recall_m: 0.4462 - f1_m: 0.5463\n",
      "Epoch 19: val_acc did not improve from 0.96990\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0693 - acc: 0.9748 - precision_m: 0.7840 - recall_m: 0.4455 - f1_m: 0.5461 - val_loss: 0.1023 - val_acc: 0.9682 - val_precision_m: 0.5850 - val_recall_m: 0.3866 - val_f1_m: 0.4518\n",
      "Epoch 20/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0668 - acc: 0.9754 - precision_m: 0.7649 - recall_m: 0.4732 - f1_m: 0.5654\n",
      "Epoch 20: val_acc did not improve from 0.96990\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0667 - acc: 0.9755 - precision_m: 0.7661 - recall_m: 0.4746 - f1_m: 0.5669 - val_loss: 0.1003 - val_acc: 0.9682 - val_precision_m: 0.5825 - val_recall_m: 0.4107 - val_f1_m: 0.4637\n",
      "Epoch 21/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.0672 - acc: 0.9758 - precision_m: 0.7927 - recall_m: 0.4806 - f1_m: 0.5747\n",
      "Epoch 21: val_acc did not improve from 0.96990\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0672 - acc: 0.9758 - precision_m: 0.7927 - recall_m: 0.4806 - f1_m: 0.5747 - val_loss: 0.1130 - val_acc: 0.9698 - val_precision_m: 0.7148 - val_recall_m: 0.2937 - val_f1_m: 0.3955\n",
      "Epoch 22/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.0648 - acc: 0.9763 - precision_m: 0.7956 - recall_m: 0.5065 - f1_m: 0.5935\n",
      "Epoch 22: val_acc did not improve from 0.96990\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0648 - acc: 0.9763 - precision_m: 0.7956 - recall_m: 0.5065 - f1_m: 0.5935 - val_loss: 0.1059 - val_acc: 0.9686 - val_precision_m: 0.6132 - val_recall_m: 0.3626 - val_f1_m: 0.4362\n",
      "Epoch 23/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0639 - acc: 0.9763 - precision_m: 0.7954 - recall_m: 0.4915 - f1_m: 0.5861\n",
      "Epoch 23: val_acc did not improve from 0.96990\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0639 - acc: 0.9763 - precision_m: 0.7973 - recall_m: 0.4933 - f1_m: 0.5880 - val_loss: 0.1090 - val_acc: 0.9699 - val_precision_m: 0.6717 - val_recall_m: 0.3443 - val_f1_m: 0.4370\n",
      "Epoch 24/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.0628 - acc: 0.9768 - precision_m: 0.7962 - recall_m: 0.5167 - f1_m: 0.6010\n",
      "Epoch 24: val_acc did not improve from 0.96990\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0628 - acc: 0.9768 - precision_m: 0.7962 - recall_m: 0.5167 - f1_m: 0.6010 - val_loss: 0.1009 - val_acc: 0.9685 - val_precision_m: 0.6053 - val_recall_m: 0.3994 - val_f1_m: 0.4634\n",
      "Epoch 25/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0618 - acc: 0.9777 - precision_m: 0.8098 - recall_m: 0.5393 - f1_m: 0.6227\n",
      "Epoch 25: val_acc did not improve from 0.96990\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0620 - acc: 0.9777 - precision_m: 0.8104 - recall_m: 0.5412 - f1_m: 0.6248 - val_loss: 0.1099 - val_acc: 0.9694 - val_precision_m: 0.6321 - val_recall_m: 0.3759 - val_f1_m: 0.4541\n",
      "Epoch 26/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0600 - acc: 0.9781 - precision_m: 0.8122 - recall_m: 0.5373 - f1_m: 0.6238\n",
      "Epoch 26: val_acc did not improve from 0.96990\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0599 - acc: 0.9782 - precision_m: 0.8125 - recall_m: 0.5390 - f1_m: 0.6251 - val_loss: 0.1083 - val_acc: 0.9639 - val_precision_m: 0.5190 - val_recall_m: 0.4757 - val_f1_m: 0.4790\n",
      "Epoch 27/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9778 - precision_m: 0.8067 - recall_m: 0.5386 - f1_m: 0.6226\n",
      "Epoch 27: val_acc did not improve from 0.96990\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0590 - acc: 0.9778 - precision_m: 0.8066 - recall_m: 0.5383 - f1_m: 0.6224 - val_loss: 0.1085 - val_acc: 0.9630 - val_precision_m: 0.4961 - val_recall_m: 0.4434 - val_f1_m: 0.4476\n",
      "Epoch 28/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0578 - acc: 0.9791 - precision_m: 0.8349 - recall_m: 0.5650 - f1_m: 0.6527\n",
      "Epoch 28: val_acc did not improve from 0.96990\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0577 - acc: 0.9791 - precision_m: 0.8325 - recall_m: 0.5647 - f1_m: 0.6518 - val_loss: 0.1071 - val_acc: 0.9693 - val_precision_m: 0.6344 - val_recall_m: 0.3573 - val_f1_m: 0.4389\n",
      "Epoch 29/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0568 - acc: 0.9785 - precision_m: 0.8207 - recall_m: 0.5627 - f1_m: 0.6471\n",
      "Epoch 29: val_acc did not improve from 0.96990\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0568 - acc: 0.9785 - precision_m: 0.8204 - recall_m: 0.5635 - f1_m: 0.6477 - val_loss: 0.1087 - val_acc: 0.9695 - val_precision_m: 0.6461 - val_recall_m: 0.3678 - val_f1_m: 0.4532\n",
      "Epoch 30/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0541 - acc: 0.9799 - precision_m: 0.8292 - recall_m: 0.5934 - f1_m: 0.6737\n",
      "Epoch 30: val_acc did not improve from 0.96990\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0543 - acc: 0.9799 - precision_m: 0.8258 - recall_m: 0.5893 - f1_m: 0.6683 - val_loss: 0.1108 - val_acc: 0.9693 - val_precision_m: 0.6204 - val_recall_m: 0.3628 - val_f1_m: 0.4420\n",
      "Score for fold 1: loss of 0.10350768268108368; acc of 96.9903290271759%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.07393530011177063; acc of 97.54567742347717%\n",
      "Test Precision: precision_m of 13.967135548591614%\n",
      "Test Recall: recall_m of 8.102503418922424%\n",
      "Test F1: f1_m of 9.646868705749512%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.1567 - acc: 0.9637 - precision_m: 0.0054 - recall_m: 0.0011 - f1_m: 0.0015       \n",
      "Epoch 1: val_acc improved from -inf to 0.96336, saving model to models/best_model_8_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 2s 5ms/step - loss: 0.1567 - acc: 0.9637 - precision_m: 0.0054 - recall_m: 0.0011 - f1_m: 0.0015 - val_loss: 0.1321 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.1243 - acc: 0.9643 - precision_m: 0.0618 - recall_m: 0.0092 - f1_m: 0.0153\n",
      "Epoch 2: val_acc did not improve from 0.96336\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.1241 - acc: 0.9643 - precision_m: 0.0610 - recall_m: 0.0090 - f1_m: 0.0151 - val_loss: 0.1214 - val_acc: 0.9632 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 3/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.1160 - acc: 0.9647 - precision_m: 0.2670 - recall_m: 0.0496 - f1_m: 0.0792\n",
      "Epoch 3: val_acc improved from 0.96336 to 0.96372, saving model to models/best_model_8_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.1156 - acc: 0.9648 - precision_m: 0.2649 - recall_m: 0.0489 - f1_m: 0.0783 - val_loss: 0.1191 - val_acc: 0.9637 - val_precision_m: 0.0909 - val_recall_m: 0.0067 - val_f1_m: 0.0125\n",
      "Epoch 4/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.1085 - acc: 0.9655 - precision_m: 0.4429 - recall_m: 0.0912 - f1_m: 0.1429\n",
      "Epoch 4: val_acc improved from 0.96372 to 0.96396, saving model to models/best_model_8_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.1081 - acc: 0.9655 - precision_m: 0.4435 - recall_m: 0.0906 - f1_m: 0.1422 - val_loss: 0.1112 - val_acc: 0.9640 - val_precision_m: 0.2424 - val_recall_m: 0.0593 - val_f1_m: 0.0874\n",
      "Epoch 5/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.1023 - acc: 0.9659 - precision_m: 0.4861 - recall_m: 0.1227 - f1_m: 0.1835\n",
      "Epoch 5: val_acc improved from 0.96396 to 0.96456, saving model to models/best_model_8_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.1024 - acc: 0.9659 - precision_m: 0.4845 - recall_m: 0.1226 - f1_m: 0.1833 - val_loss: 0.1140 - val_acc: 0.9646 - val_precision_m: 0.2677 - val_recall_m: 0.0467 - val_f1_m: 0.0745\n",
      "Epoch 6/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.1009 - acc: 0.9665 - precision_m: 0.5310 - recall_m: 0.1425 - f1_m: 0.2087\n",
      "Epoch 6: val_acc improved from 0.96456 to 0.96551, saving model to models/best_model_8_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.1009 - acc: 0.9665 - precision_m: 0.5310 - recall_m: 0.1425 - f1_m: 0.2087 - val_loss: 0.1111 - val_acc: 0.9655 - val_precision_m: 0.4419 - val_recall_m: 0.0910 - val_f1_m: 0.1384\n",
      "Epoch 7/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0970 - acc: 0.9668 - precision_m: 0.5609 - recall_m: 0.1716 - f1_m: 0.2453\n",
      "Epoch 7: val_acc did not improve from 0.96551\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0970 - acc: 0.9667 - precision_m: 0.5593 - recall_m: 0.1715 - f1_m: 0.2452 - val_loss: 0.1075 - val_acc: 0.9655 - val_precision_m: 0.5721 - val_recall_m: 0.2452 - val_f1_m: 0.3207\n",
      "Epoch 8/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.0946 - acc: 0.9680 - precision_m: 0.6136 - recall_m: 0.2156 - f1_m: 0.2962\n",
      "Epoch 8: val_acc improved from 0.96551 to 0.96647, saving model to models/best_model_8_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0946 - acc: 0.9680 - precision_m: 0.6133 - recall_m: 0.2164 - f1_m: 0.2968 - val_loss: 0.1088 - val_acc: 0.9665 - val_precision_m: 0.5199 - val_recall_m: 0.3137 - val_f1_m: 0.3686\n",
      "Epoch 9/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0902 - acc: 0.9689 - precision_m: 0.6482 - recall_m: 0.2578 - f1_m: 0.3491\n",
      "Epoch 9: val_acc improved from 0.96647 to 0.96719, saving model to models/best_model_8_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0902 - acc: 0.9689 - precision_m: 0.6482 - recall_m: 0.2585 - f1_m: 0.3498 - val_loss: 0.1094 - val_acc: 0.9672 - val_precision_m: 0.4949 - val_recall_m: 0.1194 - val_f1_m: 0.1762\n",
      "Epoch 10/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0894 - acc: 0.9696 - precision_m: 0.6407 - recall_m: 0.2699 - f1_m: 0.3538\n",
      "Epoch 10: val_acc improved from 0.96719 to 0.96779, saving model to models/best_model_8_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0894 - acc: 0.9696 - precision_m: 0.6397 - recall_m: 0.2686 - f1_m: 0.3523 - val_loss: 0.0993 - val_acc: 0.9678 - val_precision_m: 0.5908 - val_recall_m: 0.2389 - val_f1_m: 0.3163\n",
      "Epoch 11/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.0869 - acc: 0.9699 - precision_m: 0.6615 - recall_m: 0.3033 - f1_m: 0.3920\n",
      "Epoch 11: val_acc did not improve from 0.96779\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0869 - acc: 0.9699 - precision_m: 0.6614 - recall_m: 0.3051 - f1_m: 0.3931 - val_loss: 0.1032 - val_acc: 0.9644 - val_precision_m: 0.5195 - val_recall_m: 0.3485 - val_f1_m: 0.3943\n",
      "Epoch 12/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0860 - acc: 0.9708 - precision_m: 0.6936 - recall_m: 0.3024 - f1_m: 0.3968\n",
      "Epoch 12: val_acc improved from 0.96779 to 0.96875, saving model to models/best_model_8_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0860 - acc: 0.9708 - precision_m: 0.6923 - recall_m: 0.3011 - f1_m: 0.3953 - val_loss: 0.0986 - val_acc: 0.9687 - val_precision_m: 0.5690 - val_recall_m: 0.2181 - val_f1_m: 0.2922\n",
      "Epoch 13/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0829 - acc: 0.9714 - precision_m: 0.6932 - recall_m: 0.3376 - f1_m: 0.4264\n",
      "Epoch 13: val_acc did not improve from 0.96875\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0830 - acc: 0.9714 - precision_m: 0.6945 - recall_m: 0.3379 - f1_m: 0.4271 - val_loss: 0.0966 - val_acc: 0.9686 - val_precision_m: 0.6027 - val_recall_m: 0.2527 - val_f1_m: 0.3332\n",
      "Epoch 14/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0819 - acc: 0.9716 - precision_m: 0.7083 - recall_m: 0.3568 - f1_m: 0.4426\n",
      "Epoch 14: val_acc improved from 0.96875 to 0.96970, saving model to models/best_model_8_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0820 - acc: 0.9715 - precision_m: 0.7099 - recall_m: 0.3556 - f1_m: 0.4415 - val_loss: 0.0971 - val_acc: 0.9697 - val_precision_m: 0.6535 - val_recall_m: 0.2630 - val_f1_m: 0.3567\n",
      "Epoch 15/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.0799 - acc: 0.9727 - precision_m: 0.7326 - recall_m: 0.3697 - f1_m: 0.4650\n",
      "Epoch 15: val_acc did not improve from 0.96970\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0800 - acc: 0.9726 - precision_m: 0.7322 - recall_m: 0.3696 - f1_m: 0.4649 - val_loss: 0.0984 - val_acc: 0.9692 - val_precision_m: 0.6044 - val_recall_m: 0.3264 - val_f1_m: 0.3998\n",
      "Epoch 16/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.0788 - acc: 0.9726 - precision_m: 0.7050 - recall_m: 0.3708 - f1_m: 0.4608\n",
      "Epoch 16: val_acc did not improve from 0.96970\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0790 - acc: 0.9726 - precision_m: 0.7051 - recall_m: 0.3703 - f1_m: 0.4605 - val_loss: 0.0966 - val_acc: 0.9696 - val_precision_m: 0.5911 - val_recall_m: 0.2607 - val_f1_m: 0.3402\n",
      "Epoch 17/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.0777 - acc: 0.9728 - precision_m: 0.7275 - recall_m: 0.3774 - f1_m: 0.4705\n",
      "Epoch 17: val_acc did not improve from 0.96970\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0777 - acc: 0.9728 - precision_m: 0.7285 - recall_m: 0.3774 - f1_m: 0.4707 - val_loss: 0.1000 - val_acc: 0.9646 - val_precision_m: 0.4818 - val_recall_m: 0.3943 - val_f1_m: 0.4090\n",
      "Epoch 18/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0753 - acc: 0.9732 - precision_m: 0.7344 - recall_m: 0.3999 - f1_m: 0.4930\n",
      "Epoch 18: val_acc did not improve from 0.96970\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0753 - acc: 0.9732 - precision_m: 0.7362 - recall_m: 0.3994 - f1_m: 0.4930 - val_loss: 0.0971 - val_acc: 0.9693 - val_precision_m: 0.5997 - val_recall_m: 0.2869 - val_f1_m: 0.3720\n",
      "Epoch 19/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.0746 - acc: 0.9736 - precision_m: 0.7415 - recall_m: 0.4024 - f1_m: 0.4972\n",
      "Epoch 19: val_acc improved from 0.96970 to 0.96982, saving model to models/best_model_8_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0745 - acc: 0.9736 - precision_m: 0.7423 - recall_m: 0.4027 - f1_m: 0.4978 - val_loss: 0.1056 - val_acc: 0.9698 - val_precision_m: 0.6579 - val_recall_m: 0.2152 - val_f1_m: 0.3098\n",
      "Epoch 20/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0738 - acc: 0.9745 - precision_m: 0.7460 - recall_m: 0.4182 - f1_m: 0.5113\n",
      "Epoch 20: val_acc improved from 0.96982 to 0.97018, saving model to models/best_model_8_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0739 - acc: 0.9745 - precision_m: 0.7476 - recall_m: 0.4189 - f1_m: 0.5122 - val_loss: 0.0954 - val_acc: 0.9702 - val_precision_m: 0.6474 - val_recall_m: 0.2562 - val_f1_m: 0.3490\n",
      "Epoch 21/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0710 - acc: 0.9748 - precision_m: 0.7619 - recall_m: 0.4306 - f1_m: 0.5261\n",
      "Epoch 21: val_acc did not improve from 0.97018\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0709 - acc: 0.9748 - precision_m: 0.7626 - recall_m: 0.4314 - f1_m: 0.5270 - val_loss: 0.0922 - val_acc: 0.9698 - val_precision_m: 0.6029 - val_recall_m: 0.3705 - val_f1_m: 0.4357\n",
      "Epoch 22/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.0721 - acc: 0.9750 - precision_m: 0.7834 - recall_m: 0.4453 - f1_m: 0.5352\n",
      "Epoch 22: val_acc did not improve from 0.97018\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0720 - acc: 0.9750 - precision_m: 0.7831 - recall_m: 0.4442 - f1_m: 0.5348 - val_loss: 0.0955 - val_acc: 0.9690 - val_precision_m: 0.5751 - val_recall_m: 0.3009 - val_f1_m: 0.3715\n",
      "Epoch 23/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0703 - acc: 0.9745 - precision_m: 0.7450 - recall_m: 0.4257 - f1_m: 0.5152\n",
      "Epoch 23: val_acc did not improve from 0.97018\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0705 - acc: 0.9744 - precision_m: 0.7438 - recall_m: 0.4247 - f1_m: 0.5142 - val_loss: 0.0996 - val_acc: 0.9701 - val_precision_m: 0.6307 - val_recall_m: 0.3206 - val_f1_m: 0.4035\n",
      "Epoch 24/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0681 - acc: 0.9758 - precision_m: 0.7759 - recall_m: 0.4709 - f1_m: 0.5571\n",
      "Epoch 24: val_acc did not improve from 0.97018\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0683 - acc: 0.9757 - precision_m: 0.7728 - recall_m: 0.4702 - f1_m: 0.5556 - val_loss: 0.0993 - val_acc: 0.9680 - val_precision_m: 0.5684 - val_recall_m: 0.3267 - val_f1_m: 0.3956\n",
      "Epoch 25/30\n",
      "276/291 [===========================>..] - ETA: 0s - loss: 0.0687 - acc: 0.9756 - precision_m: 0.7899 - recall_m: 0.4544 - f1_m: 0.5447\n",
      "Epoch 25: val_acc did not improve from 0.97018\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0689 - acc: 0.9754 - precision_m: 0.7874 - recall_m: 0.4590 - f1_m: 0.5475 - val_loss: 0.0971 - val_acc: 0.9678 - val_precision_m: 0.5451 - val_recall_m: 0.3607 - val_f1_m: 0.4156\n",
      "Epoch 26/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0665 - acc: 0.9767 - precision_m: 0.7897 - recall_m: 0.4875 - f1_m: 0.5755\n",
      "Epoch 26: val_acc improved from 0.97018 to 0.97042, saving model to models/best_model_8_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0667 - acc: 0.9767 - precision_m: 0.7898 - recall_m: 0.4888 - f1_m: 0.5757 - val_loss: 0.1033 - val_acc: 0.9704 - val_precision_m: 0.6803 - val_recall_m: 0.2558 - val_f1_m: 0.3539\n",
      "Epoch 27/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9761 - precision_m: 0.7938 - recall_m: 0.4806 - f1_m: 0.5714\n",
      "Epoch 27: val_acc did not improve from 0.97042\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0662 - acc: 0.9762 - precision_m: 0.7943 - recall_m: 0.4809 - f1_m: 0.5719 - val_loss: 0.0973 - val_acc: 0.9689 - val_precision_m: 0.5627 - val_recall_m: 0.3778 - val_f1_m: 0.4354\n",
      "Epoch 28/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.0641 - acc: 0.9770 - precision_m: 0.7803 - recall_m: 0.5036 - f1_m: 0.5850\n",
      "Epoch 28: val_acc improved from 0.97042 to 0.97162, saving model to models/best_model_8_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0641 - acc: 0.9770 - precision_m: 0.7803 - recall_m: 0.5036 - f1_m: 0.5850 - val_loss: 0.1037 - val_acc: 0.9716 - val_precision_m: 0.6298 - val_recall_m: 0.2916 - val_f1_m: 0.3792\n",
      "Epoch 29/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.0648 - acc: 0.9761 - precision_m: 0.7780 - recall_m: 0.4800 - f1_m: 0.5598\n",
      "Epoch 29: val_acc did not improve from 0.97162\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0648 - acc: 0.9761 - precision_m: 0.7779 - recall_m: 0.4798 - f1_m: 0.5597 - val_loss: 0.1014 - val_acc: 0.9707 - val_precision_m: 0.6257 - val_recall_m: 0.3000 - val_f1_m: 0.3876\n",
      "Epoch 30/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9773 - precision_m: 0.7755 - recall_m: 0.5112 - f1_m: 0.5911\n",
      "Epoch 30: val_acc did not improve from 0.97162\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0630 - acc: 0.9771 - precision_m: 0.7731 - recall_m: 0.5131 - f1_m: 0.5913 - val_loss: 0.0998 - val_acc: 0.9666 - val_precision_m: 0.5229 - val_recall_m: 0.4138 - val_f1_m: 0.4381\n",
      "Score for fold 2: loss of 0.10370606184005737; acc of 97.16201424598694%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.1012064665555954; acc of 96.97522521018982%\n",
      "Test Precision: precision_m of 22.220319509506226%\n",
      "Test Recall: recall_m of 13.998425006866455%\n",
      "Test F1: f1_m of 16.1665216088295%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.1779 - acc: 0.9599 - precision_m: 0.0173 - recall_m: 0.0049 - f1_m: 0.0041\n",
      "Epoch 1: val_acc improved from -inf to 0.96299, saving model to models/best_model_8_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 3s 5ms/step - loss: 0.1779 - acc: 0.9599 - precision_m: 0.0173 - recall_m: 0.0049 - f1_m: 0.0041 - val_loss: 0.1306 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.1259 - acc: 0.9636 - precision_m: 0.1623 - recall_m: 0.0218 - f1_m: 0.0377\n",
      "Epoch 2: val_acc improved from 0.96299 to 0.96418, saving model to models/best_model_8_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.1258 - acc: 0.9636 - precision_m: 0.1635 - recall_m: 0.0222 - f1_m: 0.0383 - val_loss: 0.1119 - val_acc: 0.9642 - val_precision_m: 0.3182 - val_recall_m: 0.0429 - val_f1_m: 0.0723\n",
      "Epoch 3/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.1129 - acc: 0.9643 - precision_m: 0.3925 - recall_m: 0.0824 - f1_m: 0.1283\n",
      "Epoch 3: val_acc did not improve from 0.96418\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.1128 - acc: 0.9644 - precision_m: 0.3896 - recall_m: 0.0820 - f1_m: 0.1276 - val_loss: 0.1125 - val_acc: 0.9629 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 4/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1090 - acc: 0.9650 - precision_m: 0.4227 - recall_m: 0.0982 - f1_m: 0.1488\n",
      "Epoch 4: val_acc did not improve from 0.96418\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.1090 - acc: 0.9649 - precision_m: 0.4197 - recall_m: 0.0975 - f1_m: 0.1478 - val_loss: 0.1063 - val_acc: 0.9631 - val_precision_m: 0.1869 - val_recall_m: 0.0265 - val_f1_m: 0.0456\n",
      "Epoch 5/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.1013 - acc: 0.9659 - precision_m: 0.5454 - recall_m: 0.1504 - f1_m: 0.2201\n",
      "Epoch 5: val_acc improved from 0.96418 to 0.96430, saving model to models/best_model_8_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.1011 - acc: 0.9659 - precision_m: 0.5491 - recall_m: 0.1517 - f1_m: 0.2220 - val_loss: 0.1045 - val_acc: 0.9643 - val_precision_m: 0.3399 - val_recall_m: 0.0678 - val_f1_m: 0.1059\n",
      "Epoch 6/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.1005 - acc: 0.9655 - precision_m: 0.5228 - recall_m: 0.1543 - f1_m: 0.2227\n",
      "Epoch 6: val_acc improved from 0.96430 to 0.96586, saving model to models/best_model_8_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.1004 - acc: 0.9656 - precision_m: 0.5207 - recall_m: 0.1540 - f1_m: 0.2222 - val_loss: 0.0994 - val_acc: 0.9659 - val_precision_m: 0.5381 - val_recall_m: 0.1066 - val_f1_m: 0.1661\n",
      "Epoch 7/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.0959 - acc: 0.9670 - precision_m: 0.6035 - recall_m: 0.1935 - f1_m: 0.2726\n",
      "Epoch 7: val_acc improved from 0.96586 to 0.96754, saving model to models/best_model_8_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0962 - acc: 0.9670 - precision_m: 0.6089 - recall_m: 0.2008 - f1_m: 0.2809 - val_loss: 0.0981 - val_acc: 0.9675 - val_precision_m: 0.5326 - val_recall_m: 0.2985 - val_f1_m: 0.3583\n",
      "Epoch 8/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0937 - acc: 0.9677 - precision_m: 0.6514 - recall_m: 0.2411 - f1_m: 0.3241\n",
      "Epoch 8: val_acc did not improve from 0.96754\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0937 - acc: 0.9678 - precision_m: 0.6539 - recall_m: 0.2412 - f1_m: 0.3248 - val_loss: 0.1042 - val_acc: 0.9648 - val_precision_m: 0.4452 - val_recall_m: 0.0639 - val_f1_m: 0.1036\n",
      "Epoch 9/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0915 - acc: 0.9682 - precision_m: 0.6607 - recall_m: 0.2666 - f1_m: 0.3553\n",
      "Epoch 9: val_acc improved from 0.96754 to 0.96981, saving model to models/best_model_8_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0914 - acc: 0.9683 - precision_m: 0.6622 - recall_m: 0.2675 - f1_m: 0.3565 - val_loss: 0.0975 - val_acc: 0.9698 - val_precision_m: 0.5996 - val_recall_m: 0.2383 - val_f1_m: 0.3146\n",
      "Epoch 10/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0906 - acc: 0.9689 - precision_m: 0.6603 - recall_m: 0.2852 - f1_m: 0.3703\n",
      "Epoch 10: val_acc did not improve from 0.96981\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0904 - acc: 0.9688 - precision_m: 0.6585 - recall_m: 0.2852 - f1_m: 0.3701 - val_loss: 0.1003 - val_acc: 0.9654 - val_precision_m: 0.5405 - val_recall_m: 0.4044 - val_f1_m: 0.4331\n",
      "Epoch 11/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0871 - acc: 0.9697 - precision_m: 0.6860 - recall_m: 0.3018 - f1_m: 0.3934\n",
      "Epoch 11: val_acc improved from 0.96981 to 0.97041, saving model to models/best_model_8_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0871 - acc: 0.9697 - precision_m: 0.6863 - recall_m: 0.3049 - f1_m: 0.3963 - val_loss: 0.0952 - val_acc: 0.9704 - val_precision_m: 0.6479 - val_recall_m: 0.2443 - val_f1_m: 0.3212\n",
      "Epoch 12/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0863 - acc: 0.9699 - precision_m: 0.7036 - recall_m: 0.3192 - f1_m: 0.4074\n",
      "Epoch 12: val_acc did not improve from 0.97041\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0863 - acc: 0.9699 - precision_m: 0.7056 - recall_m: 0.3208 - f1_m: 0.4093 - val_loss: 0.0934 - val_acc: 0.9698 - val_precision_m: 0.5968 - val_recall_m: 0.3208 - val_f1_m: 0.3914\n",
      "Epoch 13/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0843 - acc: 0.9706 - precision_m: 0.7054 - recall_m: 0.3410 - f1_m: 0.4293\n",
      "Epoch 13: val_acc did not improve from 0.97041\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0843 - acc: 0.9706 - precision_m: 0.7078 - recall_m: 0.3405 - f1_m: 0.4290 - val_loss: 0.0971 - val_acc: 0.9666 - val_precision_m: 0.5080 - val_recall_m: 0.3637 - val_f1_m: 0.3978\n",
      "Epoch 14/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0823 - acc: 0.9707 - precision_m: 0.7118 - recall_m: 0.3382 - f1_m: 0.4314\n",
      "Epoch 14: val_acc did not improve from 0.97041\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0823 - acc: 0.9707 - precision_m: 0.7103 - recall_m: 0.3389 - f1_m: 0.4322 - val_loss: 0.0961 - val_acc: 0.9692 - val_precision_m: 0.6682 - val_recall_m: 0.2003 - val_f1_m: 0.2901\n",
      "Epoch 15/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0800 - acc: 0.9717 - precision_m: 0.7269 - recall_m: 0.3750 - f1_m: 0.4667\n",
      "Epoch 15: val_acc did not improve from 0.97041\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0801 - acc: 0.9717 - precision_m: 0.7291 - recall_m: 0.3751 - f1_m: 0.4674 - val_loss: 0.0930 - val_acc: 0.9690 - val_precision_m: 0.5847 - val_recall_m: 0.2866 - val_f1_m: 0.3615\n",
      "Epoch 16/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0791 - acc: 0.9717 - precision_m: 0.7270 - recall_m: 0.3656 - f1_m: 0.4604\n",
      "Epoch 16: val_acc did not improve from 0.97041\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0790 - acc: 0.9718 - precision_m: 0.7281 - recall_m: 0.3644 - f1_m: 0.4595 - val_loss: 0.1014 - val_acc: 0.9693 - val_precision_m: 0.6826 - val_recall_m: 0.2138 - val_f1_m: 0.2979\n",
      "Epoch 17/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0782 - acc: 0.9720 - precision_m: 0.7357 - recall_m: 0.3813 - f1_m: 0.4709\n",
      "Epoch 17: val_acc did not improve from 0.97041\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0783 - acc: 0.9721 - precision_m: 0.7356 - recall_m: 0.3788 - f1_m: 0.4688 - val_loss: 0.1001 - val_acc: 0.9690 - val_precision_m: 0.6317 - val_recall_m: 0.2313 - val_f1_m: 0.3105\n",
      "Epoch 18/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0774 - acc: 0.9721 - precision_m: 0.7285 - recall_m: 0.3941 - f1_m: 0.4811\n",
      "Epoch 18: val_acc did not improve from 0.97041\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0771 - acc: 0.9723 - precision_m: 0.7301 - recall_m: 0.3950 - f1_m: 0.4820 - val_loss: 0.1062 - val_acc: 0.9691 - val_precision_m: 0.6187 - val_recall_m: 0.1877 - val_f1_m: 0.2679\n",
      "Epoch 19/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0757 - acc: 0.9727 - precision_m: 0.7440 - recall_m: 0.4051 - f1_m: 0.4924\n",
      "Epoch 19: val_acc did not improve from 0.97041\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0757 - acc: 0.9727 - precision_m: 0.7459 - recall_m: 0.4058 - f1_m: 0.4937 - val_loss: 0.0973 - val_acc: 0.9644 - val_precision_m: 0.4981 - val_recall_m: 0.4613 - val_f1_m: 0.4477\n",
      "Epoch 20/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0736 - acc: 0.9728 - precision_m: 0.7304 - recall_m: 0.4047 - f1_m: 0.4934\n",
      "Epoch 20: val_acc did not improve from 0.97041\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0736 - acc: 0.9728 - precision_m: 0.7313 - recall_m: 0.4060 - f1_m: 0.4949 - val_loss: 0.0947 - val_acc: 0.9696 - val_precision_m: 0.5807 - val_recall_m: 0.2614 - val_f1_m: 0.3282\n",
      "Epoch 21/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0724 - acc: 0.9742 - precision_m: 0.7608 - recall_m: 0.4414 - f1_m: 0.5340\n",
      "Epoch 21: val_acc did not improve from 0.97041\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0724 - acc: 0.9742 - precision_m: 0.7595 - recall_m: 0.4414 - f1_m: 0.5338 - val_loss: 0.0922 - val_acc: 0.9697 - val_precision_m: 0.5688 - val_recall_m: 0.3205 - val_f1_m: 0.3835\n",
      "Epoch 22/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0705 - acc: 0.9745 - precision_m: 0.7588 - recall_m: 0.4601 - f1_m: 0.5492\n",
      "Epoch 22: val_acc did not improve from 0.97041\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0705 - acc: 0.9745 - precision_m: 0.7595 - recall_m: 0.4579 - f1_m: 0.5476 - val_loss: 0.0937 - val_acc: 0.9699 - val_precision_m: 0.5572 - val_recall_m: 0.2280 - val_f1_m: 0.3106\n",
      "Epoch 23/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.0697 - acc: 0.9743 - precision_m: 0.7667 - recall_m: 0.4476 - f1_m: 0.5384\n",
      "Epoch 23: val_acc did not improve from 0.97041\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0697 - acc: 0.9744 - precision_m: 0.7674 - recall_m: 0.4493 - f1_m: 0.5401 - val_loss: 0.0973 - val_acc: 0.9704 - val_precision_m: 0.6008 - val_recall_m: 0.2841 - val_f1_m: 0.3581\n",
      "Epoch 24/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0676 - acc: 0.9754 - precision_m: 0.7638 - recall_m: 0.4802 - f1_m: 0.5647\n",
      "Epoch 24: val_acc did not improve from 0.97041\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0675 - acc: 0.9754 - precision_m: 0.7666 - recall_m: 0.4803 - f1_m: 0.5652 - val_loss: 0.0972 - val_acc: 0.9645 - val_precision_m: 0.4714 - val_recall_m: 0.4451 - val_f1_m: 0.4326\n",
      "Epoch 25/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0677 - acc: 0.9751 - precision_m: 0.7794 - recall_m: 0.4694 - f1_m: 0.5596\n",
      "Epoch 25: val_acc did not improve from 0.97041\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0676 - acc: 0.9751 - precision_m: 0.7774 - recall_m: 0.4707 - f1_m: 0.5600 - val_loss: 0.1040 - val_acc: 0.9692 - val_precision_m: 0.6078 - val_recall_m: 0.1903 - val_f1_m: 0.2752\n",
      "Epoch 26/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0664 - acc: 0.9757 - precision_m: 0.7700 - recall_m: 0.4864 - f1_m: 0.5722\n",
      "Epoch 26: val_acc did not improve from 0.97041\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0663 - acc: 0.9757 - precision_m: 0.7707 - recall_m: 0.4882 - f1_m: 0.5739 - val_loss: 0.0924 - val_acc: 0.9675 - val_precision_m: 0.5494 - val_recall_m: 0.3855 - val_f1_m: 0.4268\n",
      "Epoch 27/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0650 - acc: 0.9764 - precision_m: 0.7898 - recall_m: 0.5054 - f1_m: 0.5890\n",
      "Epoch 27: val_acc improved from 0.97041 to 0.97077, saving model to models/best_model_8_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0651 - acc: 0.9764 - precision_m: 0.7902 - recall_m: 0.5047 - f1_m: 0.5884 - val_loss: 0.0961 - val_acc: 0.9708 - val_precision_m: 0.6159 - val_recall_m: 0.2621 - val_f1_m: 0.3502\n",
      "Epoch 28/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0630 - acc: 0.9769 - precision_m: 0.7908 - recall_m: 0.5089 - f1_m: 0.5929\n",
      "Epoch 28: val_acc did not improve from 0.97077\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0630 - acc: 0.9768 - precision_m: 0.7905 - recall_m: 0.5073 - f1_m: 0.5910 - val_loss: 0.0900 - val_acc: 0.9699 - val_precision_m: 0.5672 - val_recall_m: 0.3323 - val_f1_m: 0.3905\n",
      "Epoch 29/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0627 - acc: 0.9769 - precision_m: 0.7932 - recall_m: 0.5105 - f1_m: 0.5955\n",
      "Epoch 29: val_acc did not improve from 0.97077\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0629 - acc: 0.9769 - precision_m: 0.7897 - recall_m: 0.5128 - f1_m: 0.5959 - val_loss: 0.0996 - val_acc: 0.9701 - val_precision_m: 0.6452 - val_recall_m: 0.3354 - val_f1_m: 0.4202\n",
      "Epoch 30/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0615 - acc: 0.9772 - precision_m: 0.7883 - recall_m: 0.5254 - f1_m: 0.6077\n",
      "Epoch 30: val_acc did not improve from 0.97077\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0614 - acc: 0.9773 - precision_m: 0.7894 - recall_m: 0.5266 - f1_m: 0.6092 - val_loss: 0.0952 - val_acc: 0.9697 - val_precision_m: 0.5815 - val_recall_m: 0.3665 - val_f1_m: 0.4238\n",
      "Score for fold 3: loss of 0.09607960283756256; acc of 97.07714319229126%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.09147965908050537; acc of 97.25925326347351%\n",
      "Test Precision: precision_m of 16.213150322437286%\n",
      "Test Recall: recall_m of 10.314220935106277%\n",
      "Test F1: f1_m of 11.716336756944656%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1677 - acc: 0.9610 - precision_m: 0.0157 - recall_m: 0.0052 - f1_m: 0.0037\n",
      "Epoch 1: val_acc improved from -inf to 0.96143, saving model to models/best_model_8_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 3s 5ms/step - loss: 0.1677 - acc: 0.9610 - precision_m: 0.0157 - recall_m: 0.0052 - f1_m: 0.0037 - val_loss: 0.1338 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.1168 - acc: 0.9653 - precision_m: 0.2600 - recall_m: 0.0529 - f1_m: 0.0842\n",
      "Epoch 2: val_acc improved from 0.96143 to 0.96191, saving model to models/best_model_8_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1173 - acc: 0.9651 - precision_m: 0.2593 - recall_m: 0.0565 - f1_m: 0.0874 - val_loss: 0.1304 - val_acc: 0.9619 - val_precision_m: 0.5152 - val_recall_m: 0.2159 - val_f1_m: 0.2752\n",
      "Epoch 3/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.1076 - acc: 0.9657 - precision_m: 0.4688 - recall_m: 0.1148 - f1_m: 0.1718\n",
      "Epoch 3: val_acc improved from 0.96191 to 0.96215, saving model to models/best_model_8_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1072 - acc: 0.9659 - precision_m: 0.4679 - recall_m: 0.1152 - f1_m: 0.1721 - val_loss: 0.1363 - val_acc: 0.9621 - val_precision_m: 0.1212 - val_recall_m: 0.0155 - val_f1_m: 0.0262\n",
      "Epoch 4/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.1003 - acc: 0.9671 - precision_m: 0.5607 - recall_m: 0.1541 - f1_m: 0.2259\n",
      "Epoch 4: val_acc improved from 0.96215 to 0.96561, saving model to models/best_model_8_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1003 - acc: 0.9671 - precision_m: 0.5627 - recall_m: 0.1553 - f1_m: 0.2277 - val_loss: 0.1073 - val_acc: 0.9656 - val_precision_m: 0.5689 - val_recall_m: 0.1935 - val_f1_m: 0.2664\n",
      "Epoch 5/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0967 - acc: 0.9680 - precision_m: 0.5867 - recall_m: 0.2024 - f1_m: 0.2772\n",
      "Epoch 5: val_acc improved from 0.96561 to 0.96669, saving model to models/best_model_8_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0967 - acc: 0.9680 - precision_m: 0.5872 - recall_m: 0.2016 - f1_m: 0.2767 - val_loss: 0.1035 - val_acc: 0.9667 - val_precision_m: 0.5994 - val_recall_m: 0.2206 - val_f1_m: 0.2905\n",
      "Epoch 6/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0927 - acc: 0.9689 - precision_m: 0.6332 - recall_m: 0.2409 - f1_m: 0.3285\n",
      "Epoch 6: val_acc improved from 0.96669 to 0.96812, saving model to models/best_model_8_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0924 - acc: 0.9689 - precision_m: 0.6290 - recall_m: 0.2387 - f1_m: 0.3257 - val_loss: 0.1011 - val_acc: 0.9681 - val_precision_m: 0.6082 - val_recall_m: 0.3268 - val_f1_m: 0.3933\n",
      "Epoch 7/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0922 - acc: 0.9691 - precision_m: 0.6173 - recall_m: 0.2510 - f1_m: 0.3339\n",
      "Epoch 7: val_acc improved from 0.96812 to 0.96836, saving model to models/best_model_8_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0919 - acc: 0.9691 - precision_m: 0.6178 - recall_m: 0.2523 - f1_m: 0.3360 - val_loss: 0.0985 - val_acc: 0.9684 - val_precision_m: 0.6161 - val_recall_m: 0.3295 - val_f1_m: 0.3937\n",
      "Epoch 8/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9703 - precision_m: 0.6621 - recall_m: 0.3116 - f1_m: 0.3948\n",
      "Epoch 8: val_acc did not improve from 0.96836\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0886 - acc: 0.9704 - precision_m: 0.6616 - recall_m: 0.3115 - f1_m: 0.3951 - val_loss: 0.1085 - val_acc: 0.9663 - val_precision_m: 0.5051 - val_recall_m: 0.1328 - val_f1_m: 0.1977\n",
      "Epoch 9/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0855 - acc: 0.9709 - precision_m: 0.6992 - recall_m: 0.3211 - f1_m: 0.4126\n",
      "Epoch 9: val_acc improved from 0.96836 to 0.96896, saving model to models/best_model_8_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0853 - acc: 0.9709 - precision_m: 0.6961 - recall_m: 0.3213 - f1_m: 0.4123 - val_loss: 0.0985 - val_acc: 0.9690 - val_precision_m: 0.6306 - val_recall_m: 0.3172 - val_f1_m: 0.3873\n",
      "Epoch 10/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0831 - acc: 0.9713 - precision_m: 0.6912 - recall_m: 0.3352 - f1_m: 0.4253\n",
      "Epoch 10: val_acc did not improve from 0.96896\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0834 - acc: 0.9713 - precision_m: 0.6894 - recall_m: 0.3358 - f1_m: 0.4257 - val_loss: 0.0979 - val_acc: 0.9690 - val_precision_m: 0.6671 - val_recall_m: 0.2967 - val_f1_m: 0.3777\n",
      "Epoch 11/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0818 - acc: 0.9719 - precision_m: 0.6895 - recall_m: 0.3505 - f1_m: 0.4398\n",
      "Epoch 11: val_acc improved from 0.96896 to 0.96919, saving model to models/best_model_8_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0818 - acc: 0.9719 - precision_m: 0.6860 - recall_m: 0.3504 - f1_m: 0.4394 - val_loss: 0.1009 - val_acc: 0.9692 - val_precision_m: 0.7074 - val_recall_m: 0.2312 - val_f1_m: 0.3231\n",
      "Epoch 12/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0802 - acc: 0.9721 - precision_m: 0.7124 - recall_m: 0.3710 - f1_m: 0.4599\n",
      "Epoch 12: val_acc improved from 0.96919 to 0.96991, saving model to models/best_model_8_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0802 - acc: 0.9721 - precision_m: 0.7140 - recall_m: 0.3696 - f1_m: 0.4587 - val_loss: 0.0941 - val_acc: 0.9699 - val_precision_m: 0.7140 - val_recall_m: 0.2763 - val_f1_m: 0.3676\n",
      "Epoch 13/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0795 - acc: 0.9724 - precision_m: 0.7358 - recall_m: 0.3788 - f1_m: 0.4666\n",
      "Epoch 13: val_acc improved from 0.96991 to 0.97099, saving model to models/best_model_8_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0795 - acc: 0.9724 - precision_m: 0.7346 - recall_m: 0.3776 - f1_m: 0.4658 - val_loss: 0.0928 - val_acc: 0.9710 - val_precision_m: 0.6933 - val_recall_m: 0.3379 - val_f1_m: 0.4155\n",
      "Epoch 14/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0764 - acc: 0.9730 - precision_m: 0.7198 - recall_m: 0.4095 - f1_m: 0.4929\n",
      "Epoch 14: val_acc did not improve from 0.97099\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0763 - acc: 0.9731 - precision_m: 0.7172 - recall_m: 0.4073 - f1_m: 0.4903 - val_loss: 0.0952 - val_acc: 0.9685 - val_precision_m: 0.5939 - val_recall_m: 0.3777 - val_f1_m: 0.4296\n",
      "Epoch 15/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0751 - acc: 0.9737 - precision_m: 0.7283 - recall_m: 0.4158 - f1_m: 0.5001\n",
      "Epoch 15: val_acc did not improve from 0.97099\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0750 - acc: 0.9738 - precision_m: 0.7268 - recall_m: 0.4167 - f1_m: 0.5006 - val_loss: 0.0990 - val_acc: 0.9694 - val_precision_m: 0.6580 - val_recall_m: 0.3024 - val_f1_m: 0.3767\n",
      "Epoch 16/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0742 - acc: 0.9738 - precision_m: 0.7307 - recall_m: 0.4103 - f1_m: 0.5007\n",
      "Epoch 16: val_acc did not improve from 0.97099\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0741 - acc: 0.9738 - precision_m: 0.7284 - recall_m: 0.4112 - f1_m: 0.5006 - val_loss: 0.0972 - val_acc: 0.9701 - val_precision_m: 0.6687 - val_recall_m: 0.3064 - val_f1_m: 0.3857\n",
      "Epoch 17/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0728 - acc: 0.9742 - precision_m: 0.7391 - recall_m: 0.4317 - f1_m: 0.5174\n",
      "Epoch 17: val_acc did not improve from 0.97099\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0729 - acc: 0.9742 - precision_m: 0.7377 - recall_m: 0.4301 - f1_m: 0.5156 - val_loss: 0.0928 - val_acc: 0.9697 - val_precision_m: 0.6108 - val_recall_m: 0.4165 - val_f1_m: 0.4545\n",
      "Epoch 18/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0713 - acc: 0.9746 - precision_m: 0.7346 - recall_m: 0.4301 - f1_m: 0.5134\n",
      "Epoch 18: val_acc did not improve from 0.97099\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0715 - acc: 0.9746 - precision_m: 0.7341 - recall_m: 0.4318 - f1_m: 0.5146 - val_loss: 0.1057 - val_acc: 0.9694 - val_precision_m: 0.6825 - val_recall_m: 0.2235 - val_f1_m: 0.3078\n",
      "Epoch 19/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0705 - acc: 0.9752 - precision_m: 0.7467 - recall_m: 0.4493 - f1_m: 0.5335\n",
      "Epoch 19: val_acc did not improve from 0.97099\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0705 - acc: 0.9752 - precision_m: 0.7431 - recall_m: 0.4470 - f1_m: 0.5310 - val_loss: 0.0977 - val_acc: 0.9709 - val_precision_m: 0.6847 - val_recall_m: 0.3533 - val_f1_m: 0.4327\n",
      "Epoch 20/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0692 - acc: 0.9754 - precision_m: 0.7626 - recall_m: 0.4654 - f1_m: 0.5518\n",
      "Epoch 20: val_acc did not improve from 0.97099\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0692 - acc: 0.9754 - precision_m: 0.7595 - recall_m: 0.4647 - f1_m: 0.5507 - val_loss: 0.0973 - val_acc: 0.9698 - val_precision_m: 0.6825 - val_recall_m: 0.3045 - val_f1_m: 0.3873\n",
      "Epoch 21/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9761 - precision_m: 0.7608 - recall_m: 0.4714 - f1_m: 0.5516\n",
      "Epoch 21: val_acc did not improve from 0.97099\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0680 - acc: 0.9761 - precision_m: 0.7605 - recall_m: 0.4702 - f1_m: 0.5506 - val_loss: 0.1001 - val_acc: 0.9705 - val_precision_m: 0.6996 - val_recall_m: 0.3219 - val_f1_m: 0.3914\n",
      "Epoch 22/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0668 - acc: 0.9762 - precision_m: 0.7657 - recall_m: 0.4656 - f1_m: 0.5558\n",
      "Epoch 22: val_acc did not improve from 0.97099\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0668 - acc: 0.9763 - precision_m: 0.7654 - recall_m: 0.4633 - f1_m: 0.5538 - val_loss: 0.0935 - val_acc: 0.9681 - val_precision_m: 0.5788 - val_recall_m: 0.4372 - val_f1_m: 0.4577\n",
      "Epoch 23/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0652 - acc: 0.9765 - precision_m: 0.7735 - recall_m: 0.4921 - f1_m: 0.5764\n",
      "Epoch 23: val_acc did not improve from 0.97099\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0655 - acc: 0.9764 - precision_m: 0.7686 - recall_m: 0.4880 - f1_m: 0.5720 - val_loss: 0.1080 - val_acc: 0.9690 - val_precision_m: 0.5795 - val_recall_m: 0.1983 - val_f1_m: 0.2753\n",
      "Epoch 24/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0683 - acc: 0.9755 - precision_m: 0.7640 - recall_m: 0.4401 - f1_m: 0.5258\n",
      "Epoch 24: val_acc improved from 0.97099 to 0.97110, saving model to models/best_model_8_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0681 - acc: 0.9757 - precision_m: 0.7629 - recall_m: 0.4430 - f1_m: 0.5282 - val_loss: 0.0970 - val_acc: 0.9711 - val_precision_m: 0.6871 - val_recall_m: 0.3710 - val_f1_m: 0.4395\n",
      "Epoch 25/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0651 - acc: 0.9765 - precision_m: 0.7758 - recall_m: 0.4909 - f1_m: 0.5708\n",
      "Epoch 25: val_acc did not improve from 0.97110\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0648 - acc: 0.9766 - precision_m: 0.7746 - recall_m: 0.4907 - f1_m: 0.5701 - val_loss: 0.0977 - val_acc: 0.9703 - val_precision_m: 0.6557 - val_recall_m: 0.3256 - val_f1_m: 0.3970\n",
      "Epoch 26/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0647 - acc: 0.9767 - precision_m: 0.7910 - recall_m: 0.4815 - f1_m: 0.5735\n",
      "Epoch 26: val_acc did not improve from 0.97110\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0648 - acc: 0.9767 - precision_m: 0.7875 - recall_m: 0.4823 - f1_m: 0.5735 - val_loss: 0.0995 - val_acc: 0.9707 - val_precision_m: 0.6368 - val_recall_m: 0.3805 - val_f1_m: 0.4424\n",
      "Epoch 27/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0609 - acc: 0.9776 - precision_m: 0.7835 - recall_m: 0.5156 - f1_m: 0.5959\n",
      "Epoch 27: val_acc did not improve from 0.97110\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0610 - acc: 0.9776 - precision_m: 0.7818 - recall_m: 0.5143 - f1_m: 0.5949 - val_loss: 0.0966 - val_acc: 0.9698 - val_precision_m: 0.5947 - val_recall_m: 0.3267 - val_f1_m: 0.3927\n",
      "Epoch 28/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0613 - acc: 0.9781 - precision_m: 0.7931 - recall_m: 0.5210 - f1_m: 0.6048\n",
      "Epoch 28: val_acc did not improve from 0.97110\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0613 - acc: 0.9782 - precision_m: 0.7915 - recall_m: 0.5199 - f1_m: 0.6036 - val_loss: 0.0976 - val_acc: 0.9693 - val_precision_m: 0.6083 - val_recall_m: 0.3892 - val_f1_m: 0.4272\n",
      "Epoch 29/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0598 - acc: 0.9783 - precision_m: 0.8047 - recall_m: 0.5393 - f1_m: 0.6217\n",
      "Epoch 29: val_acc did not improve from 0.97110\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0597 - acc: 0.9783 - precision_m: 0.7990 - recall_m: 0.5332 - f1_m: 0.6153 - val_loss: 0.1151 - val_acc: 0.9690 - val_precision_m: 0.6478 - val_recall_m: 0.2306 - val_f1_m: 0.3195\n",
      "Epoch 30/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0598 - acc: 0.9786 - precision_m: 0.8089 - recall_m: 0.5386 - f1_m: 0.6148\n",
      "Epoch 30: val_acc did not improve from 0.97110\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0599 - acc: 0.9785 - precision_m: 0.8067 - recall_m: 0.5369 - f1_m: 0.6127 - val_loss: 0.1067 - val_acc: 0.9699 - val_precision_m: 0.6498 - val_recall_m: 0.2540 - val_f1_m: 0.3437\n",
      "Score for fold 4: loss of 0.09697937220335007; acc of 97.11045026779175%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.11166542768478394; acc of 96.54874205589294%\n",
      "Test Precision: precision_m of 19.54440474510193%\n",
      "Test Recall: recall_m of 13.148252665996552%\n",
      "Test F1: f1_m of 14.565859735012054%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.1733 - acc: 0.9621 - precision_m: 0.0024 - recall_m: 0.0026 - f1_m: 0.0021\n",
      "Epoch 1: val_acc improved from -inf to 0.96211, saving model to models/best_model_8_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 3s 5ms/step - loss: 0.1733 - acc: 0.9621 - precision_m: 0.0024 - recall_m: 0.0026 - f1_m: 0.0021 - val_loss: 0.1387 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.1274 - acc: 0.9638 - precision_m: 0.0390 - recall_m: 0.0046 - f1_m: 0.0081\n",
      "Epoch 2: val_acc improved from 0.96211 to 0.96235, saving model to models/best_model_8_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.1271 - acc: 0.9639 - precision_m: 0.0378 - recall_m: 0.0044 - f1_m: 0.0079 - val_loss: 0.1200 - val_acc: 0.9624 - val_precision_m: 0.0303 - val_recall_m: 0.0025 - val_f1_m: 0.0047\n",
      "Epoch 3/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.1157 - acc: 0.9641 - precision_m: 0.2249 - recall_m: 0.0329 - f1_m: 0.0559\n",
      "Epoch 3: val_acc did not improve from 0.96235\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.1152 - acc: 0.9642 - precision_m: 0.2254 - recall_m: 0.0333 - f1_m: 0.0565 - val_loss: 0.1351 - val_acc: 0.9622 - val_precision_m: 0.0303 - val_recall_m: 0.0030 - val_f1_m: 0.0055\n",
      "Epoch 4/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.1095 - acc: 0.9643 - precision_m: 0.3034 - recall_m: 0.0545 - f1_m: 0.0880\n",
      "Epoch 4: val_acc improved from 0.96235 to 0.96379, saving model to models/best_model_8_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.1095 - acc: 0.9643 - precision_m: 0.3097 - recall_m: 0.0573 - f1_m: 0.0917 - val_loss: 0.1115 - val_acc: 0.9638 - val_precision_m: 0.3182 - val_recall_m: 0.0609 - val_f1_m: 0.0961\n",
      "Epoch 5/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.1025 - acc: 0.9654 - precision_m: 0.5163 - recall_m: 0.1231 - f1_m: 0.1864\n",
      "Epoch 5: val_acc improved from 0.96379 to 0.96558, saving model to models/best_model_8_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.1027 - acc: 0.9654 - precision_m: 0.5159 - recall_m: 0.1227 - f1_m: 0.1860 - val_loss: 0.1081 - val_acc: 0.9656 - val_precision_m: 0.4975 - val_recall_m: 0.2307 - val_f1_m: 0.2905\n",
      "Epoch 6/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.0989 - acc: 0.9668 - precision_m: 0.5886 - recall_m: 0.1723 - f1_m: 0.2476\n",
      "Epoch 6: val_acc did not improve from 0.96558\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0987 - acc: 0.9668 - precision_m: 0.5872 - recall_m: 0.1725 - f1_m: 0.2480 - val_loss: 0.1032 - val_acc: 0.9656 - val_precision_m: 0.5155 - val_recall_m: 0.1798 - val_f1_m: 0.2471\n",
      "Epoch 7/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0951 - acc: 0.9674 - precision_m: 0.6216 - recall_m: 0.2229 - f1_m: 0.3074\n",
      "Epoch 7: val_acc did not improve from 0.96558\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0945 - acc: 0.9677 - precision_m: 0.6220 - recall_m: 0.2230 - f1_m: 0.3079 - val_loss: 0.1067 - val_acc: 0.9653 - val_precision_m: 0.4394 - val_recall_m: 0.0949 - val_f1_m: 0.1476\n",
      "Epoch 8/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0907 - acc: 0.9689 - precision_m: 0.6566 - recall_m: 0.2603 - f1_m: 0.3547\n",
      "Epoch 8: val_acc improved from 0.96558 to 0.96642, saving model to models/best_model_8_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0906 - acc: 0.9690 - precision_m: 0.6569 - recall_m: 0.2601 - f1_m: 0.3550 - val_loss: 0.0994 - val_acc: 0.9664 - val_precision_m: 0.6062 - val_recall_m: 0.3882 - val_f1_m: 0.4345\n",
      "Epoch 9/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9691 - precision_m: 0.6779 - recall_m: 0.2836 - f1_m: 0.3753\n",
      "Epoch 9: val_acc improved from 0.96642 to 0.96940, saving model to models/best_model_8_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0886 - acc: 0.9691 - precision_m: 0.6780 - recall_m: 0.2845 - f1_m: 0.3763 - val_loss: 0.0994 - val_acc: 0.9694 - val_precision_m: 0.6586 - val_recall_m: 0.3273 - val_f1_m: 0.3979\n",
      "Epoch 10/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0879 - acc: 0.9696 - precision_m: 0.6642 - recall_m: 0.2906 - f1_m: 0.3824\n",
      "Epoch 10: val_acc did not improve from 0.96940\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0881 - acc: 0.9696 - precision_m: 0.6650 - recall_m: 0.2892 - f1_m: 0.3812 - val_loss: 0.1010 - val_acc: 0.9675 - val_precision_m: 0.5769 - val_recall_m: 0.1895 - val_f1_m: 0.2662\n",
      "Epoch 11/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0848 - acc: 0.9704 - precision_m: 0.7065 - recall_m: 0.3147 - f1_m: 0.4090\n",
      "Epoch 11: val_acc improved from 0.96940 to 0.97012, saving model to models/best_model_8_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0849 - acc: 0.9704 - precision_m: 0.7054 - recall_m: 0.3142 - f1_m: 0.4085 - val_loss: 0.0937 - val_acc: 0.9701 - val_precision_m: 0.6709 - val_recall_m: 0.3601 - val_f1_m: 0.4327\n",
      "Epoch 12/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0826 - acc: 0.9709 - precision_m: 0.6948 - recall_m: 0.3362 - f1_m: 0.4306\n",
      "Epoch 12: val_acc did not improve from 0.97012\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0826 - acc: 0.9709 - precision_m: 0.6959 - recall_m: 0.3353 - f1_m: 0.4299 - val_loss: 0.0967 - val_acc: 0.9700 - val_precision_m: 0.7062 - val_recall_m: 0.2829 - val_f1_m: 0.3718\n",
      "Epoch 13/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0812 - acc: 0.9708 - precision_m: 0.6936 - recall_m: 0.3409 - f1_m: 0.4308\n",
      "Epoch 13: val_acc improved from 0.97012 to 0.97072, saving model to models/best_model_8_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0811 - acc: 0.9708 - precision_m: 0.6899 - recall_m: 0.3388 - f1_m: 0.4284 - val_loss: 0.0945 - val_acc: 0.9707 - val_precision_m: 0.6579 - val_recall_m: 0.3496 - val_f1_m: 0.4227\n",
      "Epoch 14/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0804 - acc: 0.9714 - precision_m: 0.7010 - recall_m: 0.3632 - f1_m: 0.4553\n",
      "Epoch 14: val_acc did not improve from 0.97072\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0801 - acc: 0.9715 - precision_m: 0.6971 - recall_m: 0.3599 - f1_m: 0.4516 - val_loss: 0.1031 - val_acc: 0.9682 - val_precision_m: 0.6465 - val_recall_m: 0.1777 - val_f1_m: 0.2624\n",
      "Epoch 15/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.0780 - acc: 0.9720 - precision_m: 0.7365 - recall_m: 0.3583 - f1_m: 0.4586\n",
      "Epoch 15: val_acc did not improve from 0.97072\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0783 - acc: 0.9719 - precision_m: 0.7381 - recall_m: 0.3570 - f1_m: 0.4579 - val_loss: 0.1119 - val_acc: 0.9680 - val_precision_m: 0.6051 - val_recall_m: 0.1923 - val_f1_m: 0.2719\n",
      "Epoch 16/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0766 - acc: 0.9725 - precision_m: 0.7495 - recall_m: 0.3852 - f1_m: 0.4851\n",
      "Epoch 16: val_acc did not improve from 0.97072\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0762 - acc: 0.9726 - precision_m: 0.7467 - recall_m: 0.3841 - f1_m: 0.4834 - val_loss: 0.0995 - val_acc: 0.9700 - val_precision_m: 0.7029 - val_recall_m: 0.2373 - val_f1_m: 0.3288\n",
      "Epoch 17/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0751 - acc: 0.9728 - precision_m: 0.7311 - recall_m: 0.3942 - f1_m: 0.4863\n",
      "Epoch 17: val_acc did not improve from 0.97072\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0751 - acc: 0.9728 - precision_m: 0.7337 - recall_m: 0.3949 - f1_m: 0.4876 - val_loss: 0.0940 - val_acc: 0.9698 - val_precision_m: 0.6429 - val_recall_m: 0.3507 - val_f1_m: 0.4192\n",
      "Epoch 18/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0741 - acc: 0.9731 - precision_m: 0.7296 - recall_m: 0.4006 - f1_m: 0.4900\n",
      "Epoch 18: val_acc did not improve from 0.97072\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0740 - acc: 0.9732 - precision_m: 0.7302 - recall_m: 0.4023 - f1_m: 0.4919 - val_loss: 0.0938 - val_acc: 0.9698 - val_precision_m: 0.6483 - val_recall_m: 0.3828 - val_f1_m: 0.4423\n",
      "Epoch 19/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0715 - acc: 0.9739 - precision_m: 0.7425 - recall_m: 0.4323 - f1_m: 0.5181\n",
      "Epoch 19: val_acc did not improve from 0.97072\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0715 - acc: 0.9739 - precision_m: 0.7388 - recall_m: 0.4298 - f1_m: 0.5155 - val_loss: 0.0947 - val_acc: 0.9706 - val_precision_m: 0.7362 - val_recall_m: 0.3811 - val_f1_m: 0.4611\n",
      "Epoch 20/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0715 - acc: 0.9739 - precision_m: 0.7552 - recall_m: 0.4299 - f1_m: 0.5202\n",
      "Epoch 20: val_acc did not improve from 0.97072\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0713 - acc: 0.9740 - precision_m: 0.7532 - recall_m: 0.4290 - f1_m: 0.5192 - val_loss: 0.1018 - val_acc: 0.9701 - val_precision_m: 0.7066 - val_recall_m: 0.2624 - val_f1_m: 0.3587\n",
      "Epoch 21/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0693 - acc: 0.9749 - precision_m: 0.7745 - recall_m: 0.4620 - f1_m: 0.5537\n",
      "Epoch 21: val_acc did not improve from 0.97072\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0694 - acc: 0.9749 - precision_m: 0.7725 - recall_m: 0.4591 - f1_m: 0.5508 - val_loss: 0.0957 - val_acc: 0.9689 - val_precision_m: 0.6437 - val_recall_m: 0.4554 - val_f1_m: 0.4949\n",
      "Epoch 22/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0697 - acc: 0.9746 - precision_m: 0.7579 - recall_m: 0.4413 - f1_m: 0.5295\n",
      "Epoch 22: val_acc did not improve from 0.97072\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0699 - acc: 0.9745 - precision_m: 0.7567 - recall_m: 0.4384 - f1_m: 0.5272 - val_loss: 0.0970 - val_acc: 0.9677 - val_precision_m: 0.5903 - val_recall_m: 0.4619 - val_f1_m: 0.4853\n",
      "Epoch 23/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0677 - acc: 0.9751 - precision_m: 0.7602 - recall_m: 0.4531 - f1_m: 0.5469\n",
      "Epoch 23: val_acc did not improve from 0.97072\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0677 - acc: 0.9751 - precision_m: 0.7615 - recall_m: 0.4568 - f1_m: 0.5498 - val_loss: 0.0953 - val_acc: 0.9705 - val_precision_m: 0.6491 - val_recall_m: 0.4881 - val_f1_m: 0.5178\n",
      "Epoch 24/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0677 - acc: 0.9747 - precision_m: 0.7688 - recall_m: 0.4519 - f1_m: 0.5400\n",
      "Epoch 24: val_acc did not improve from 0.97072\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0677 - acc: 0.9747 - precision_m: 0.7694 - recall_m: 0.4515 - f1_m: 0.5401 - val_loss: 0.1031 - val_acc: 0.9699 - val_precision_m: 0.6040 - val_recall_m: 0.2633 - val_f1_m: 0.3415\n",
      "Epoch 25/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.0662 - acc: 0.9758 - precision_m: 0.7934 - recall_m: 0.4671 - f1_m: 0.5632\n",
      "Epoch 25: val_acc did not improve from 0.97072\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0661 - acc: 0.9759 - precision_m: 0.7937 - recall_m: 0.4704 - f1_m: 0.5649 - val_loss: 0.0995 - val_acc: 0.9686 - val_precision_m: 0.6372 - val_recall_m: 0.4334 - val_f1_m: 0.4687\n",
      "Epoch 26/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.0662 - acc: 0.9758 - precision_m: 0.7903 - recall_m: 0.4678 - f1_m: 0.5627\n",
      "Epoch 26: val_acc did not improve from 0.97072\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0662 - acc: 0.9758 - precision_m: 0.7919 - recall_m: 0.4681 - f1_m: 0.5631 - val_loss: 0.1118 - val_acc: 0.9696 - val_precision_m: 0.6160 - val_recall_m: 0.2586 - val_f1_m: 0.3366\n",
      "Epoch 27/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0659 - acc: 0.9758 - precision_m: 0.7802 - recall_m: 0.4741 - f1_m: 0.5655\n",
      "Epoch 27: val_acc did not improve from 0.97072\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0658 - acc: 0.9758 - precision_m: 0.7774 - recall_m: 0.4723 - f1_m: 0.5635 - val_loss: 0.0969 - val_acc: 0.9694 - val_precision_m: 0.6248 - val_recall_m: 0.3408 - val_f1_m: 0.4117\n",
      "Epoch 28/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9763 - precision_m: 0.7755 - recall_m: 0.4934 - f1_m: 0.5784\n",
      "Epoch 28: val_acc did not improve from 0.97072\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0627 - acc: 0.9763 - precision_m: 0.7752 - recall_m: 0.4919 - f1_m: 0.5774 - val_loss: 0.1020 - val_acc: 0.9673 - val_precision_m: 0.5951 - val_recall_m: 0.3937 - val_f1_m: 0.4321\n",
      "Epoch 29/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9767 - precision_m: 0.7808 - recall_m: 0.5083 - f1_m: 0.5901\n",
      "Epoch 29: val_acc did not improve from 0.97072\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0627 - acc: 0.9767 - precision_m: 0.7795 - recall_m: 0.5070 - f1_m: 0.5887 - val_loss: 0.0993 - val_acc: 0.9674 - val_precision_m: 0.5711 - val_recall_m: 0.4912 - val_f1_m: 0.5005\n",
      "Epoch 30/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.0620 - acc: 0.9764 - precision_m: 0.7896 - recall_m: 0.4904 - f1_m: 0.5781\n",
      "Epoch 30: val_acc did not improve from 0.97072\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0622 - acc: 0.9762 - precision_m: 0.7858 - recall_m: 0.4863 - f1_m: 0.5735 - val_loss: 0.1158 - val_acc: 0.9700 - val_precision_m: 0.7071 - val_recall_m: 0.2207 - val_f1_m: 0.3093\n",
      "Score for fold 5: loss of 0.09451320767402649; acc of 97.07183241844177%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.08745891600847244; acc of 97.14926481246948%\n",
      "Test Precision: precision_m of 23.2195645570755%\n",
      "Test Recall: recall_m of 16.55755490064621%\n",
      "Test F1: f1_m of 18.14153790473938%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1666 - acc: 0.9599 - precision_m: 0.0092 - recall_m: 0.0053 - f1_m: 0.0030 \n",
      "Epoch 1: val_acc improved from -inf to 0.96059, saving model to models/best_model_8_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 3s 5ms/step - loss: 0.1666 - acc: 0.9599 - precision_m: 0.0092 - recall_m: 0.0053 - f1_m: 0.0030 - val_loss: 0.1364 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.1253 - acc: 0.9640 - precision_m: 0.1530 - recall_m: 0.0221 - f1_m: 0.0374\n",
      "Epoch 2: val_acc improved from 0.96059 to 0.96143, saving model to models/best_model_8_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1252 - acc: 0.9640 - precision_m: 0.1598 - recall_m: 0.0231 - f1_m: 0.0391 - val_loss: 0.1170 - val_acc: 0.9614 - val_precision_m: 0.2424 - val_recall_m: 0.0187 - val_f1_m: 0.0345\n",
      "Epoch 3/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.1101 - acc: 0.9648 - precision_m: 0.3945 - recall_m: 0.0814 - f1_m: 0.1267\n",
      "Epoch 3: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1100 - acc: 0.9649 - precision_m: 0.3902 - recall_m: 0.0811 - f1_m: 0.1261 - val_loss: 0.1269 - val_acc: 0.9612 - val_precision_m: 0.1212 - val_recall_m: 0.0120 - val_f1_m: 0.0216\n",
      "Epoch 4/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.1049 - acc: 0.9660 - precision_m: 0.5198 - recall_m: 0.1383 - f1_m: 0.2057\n",
      "Epoch 4: val_acc improved from 0.96143 to 0.96372, saving model to models/best_model_8_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1046 - acc: 0.9662 - precision_m: 0.5202 - recall_m: 0.1389 - f1_m: 0.2063 - val_loss: 0.1106 - val_acc: 0.9637 - val_precision_m: 0.5076 - val_recall_m: 0.0875 - val_f1_m: 0.1453\n",
      "Epoch 5/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.1003 - acc: 0.9670 - precision_m: 0.5520 - recall_m: 0.1754 - f1_m: 0.2457\n",
      "Epoch 5: val_acc improved from 0.96372 to 0.96420, saving model to models/best_model_8_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1001 - acc: 0.9670 - precision_m: 0.5556 - recall_m: 0.1771 - f1_m: 0.2484 - val_loss: 0.1087 - val_acc: 0.9642 - val_precision_m: 0.5833 - val_recall_m: 0.1563 - val_f1_m: 0.2366\n",
      "Epoch 6/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0953 - acc: 0.9682 - precision_m: 0.6517 - recall_m: 0.2232 - f1_m: 0.3118\n",
      "Epoch 6: val_acc improved from 0.96420 to 0.96457, saving model to models/best_model_8_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0953 - acc: 0.9680 - precision_m: 0.6508 - recall_m: 0.2245 - f1_m: 0.3128 - val_loss: 0.1105 - val_acc: 0.9646 - val_precision_m: 0.5929 - val_recall_m: 0.1192 - val_f1_m: 0.1915\n",
      "Epoch 7/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0923 - acc: 0.9681 - precision_m: 0.6402 - recall_m: 0.2542 - f1_m: 0.3398\n",
      "Epoch 7: val_acc improved from 0.96457 to 0.96565, saving model to models/best_model_8_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0924 - acc: 0.9681 - precision_m: 0.6417 - recall_m: 0.2546 - f1_m: 0.3404 - val_loss: 0.1031 - val_acc: 0.9657 - val_precision_m: 0.5690 - val_recall_m: 0.3295 - val_f1_m: 0.3956\n",
      "Epoch 8/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0901 - acc: 0.9689 - precision_m: 0.6448 - recall_m: 0.2691 - f1_m: 0.3587\n",
      "Epoch 8: val_acc did not improve from 0.96565\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0903 - acc: 0.9687 - precision_m: 0.6428 - recall_m: 0.2689 - f1_m: 0.3584 - val_loss: 0.1073 - val_acc: 0.9635 - val_precision_m: 0.5266 - val_recall_m: 0.3874 - val_f1_m: 0.4230\n",
      "Epoch 9/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0882 - acc: 0.9696 - precision_m: 0.6705 - recall_m: 0.2956 - f1_m: 0.3838\n",
      "Epoch 9: val_acc improved from 0.96565 to 0.96806, saving model to models/best_model_8_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0882 - acc: 0.9696 - precision_m: 0.6725 - recall_m: 0.2991 - f1_m: 0.3877 - val_loss: 0.1025 - val_acc: 0.9681 - val_precision_m: 0.6854 - val_recall_m: 0.2477 - val_f1_m: 0.3437\n",
      "Epoch 10/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0862 - acc: 0.9704 - precision_m: 0.6961 - recall_m: 0.3240 - f1_m: 0.4158\n",
      "Epoch 10: val_acc did not improve from 0.96806\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0861 - acc: 0.9704 - precision_m: 0.6948 - recall_m: 0.3266 - f1_m: 0.4178 - val_loss: 0.1072 - val_acc: 0.9657 - val_precision_m: 0.5979 - val_recall_m: 0.2290 - val_f1_m: 0.3166\n",
      "Epoch 11/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0839 - acc: 0.9705 - precision_m: 0.6994 - recall_m: 0.3231 - f1_m: 0.4102\n",
      "Epoch 11: val_acc improved from 0.96806 to 0.96830, saving model to models/best_model_8_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0843 - acc: 0.9705 - precision_m: 0.6988 - recall_m: 0.3250 - f1_m: 0.4123 - val_loss: 0.1006 - val_acc: 0.9683 - val_precision_m: 0.6404 - val_recall_m: 0.2975 - val_f1_m: 0.3892\n",
      "Epoch 12/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0818 - acc: 0.9712 - precision_m: 0.7040 - recall_m: 0.3521 - f1_m: 0.4475\n",
      "Epoch 12: val_acc did not improve from 0.96830\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0817 - acc: 0.9712 - precision_m: 0.7027 - recall_m: 0.3517 - f1_m: 0.4468 - val_loss: 0.1037 - val_acc: 0.9675 - val_precision_m: 0.6804 - val_recall_m: 0.2475 - val_f1_m: 0.3371\n",
      "Epoch 13/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0815 - acc: 0.9711 - precision_m: 0.7159 - recall_m: 0.3442 - f1_m: 0.4334\n",
      "Epoch 13: val_acc did not improve from 0.96830\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0816 - acc: 0.9709 - precision_m: 0.7117 - recall_m: 0.3468 - f1_m: 0.4333 - val_loss: 0.1058 - val_acc: 0.9678 - val_precision_m: 0.7051 - val_recall_m: 0.2290 - val_f1_m: 0.3274\n",
      "Epoch 14/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0810 - acc: 0.9716 - precision_m: 0.7120 - recall_m: 0.3620 - f1_m: 0.4487\n",
      "Epoch 14: val_acc did not improve from 0.96830\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0809 - acc: 0.9716 - precision_m: 0.7106 - recall_m: 0.3609 - f1_m: 0.4477 - val_loss: 0.0975 - val_acc: 0.9679 - val_precision_m: 0.6326 - val_recall_m: 0.2591 - val_f1_m: 0.3453\n",
      "Epoch 15/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0762 - acc: 0.9723 - precision_m: 0.7171 - recall_m: 0.3804 - f1_m: 0.4754\n",
      "Epoch 15: val_acc did not improve from 0.96830\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0763 - acc: 0.9723 - precision_m: 0.7169 - recall_m: 0.3829 - f1_m: 0.4774 - val_loss: 0.1049 - val_acc: 0.9682 - val_precision_m: 0.6214 - val_recall_m: 0.3550 - val_f1_m: 0.4277\n",
      "Epoch 16/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0753 - acc: 0.9730 - precision_m: 0.7174 - recall_m: 0.3985 - f1_m: 0.4827\n",
      "Epoch 16: val_acc improved from 0.96830 to 0.96842, saving model to models/best_model_8_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0756 - acc: 0.9728 - precision_m: 0.7176 - recall_m: 0.3995 - f1_m: 0.4835 - val_loss: 0.1051 - val_acc: 0.9684 - val_precision_m: 0.7040 - val_recall_m: 0.2423 - val_f1_m: 0.3402\n",
      "Epoch 17/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0731 - acc: 0.9732 - precision_m: 0.7486 - recall_m: 0.4145 - f1_m: 0.5050\n",
      "Epoch 17: val_acc improved from 0.96842 to 0.96890, saving model to models/best_model_8_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0728 - acc: 0.9733 - precision_m: 0.7521 - recall_m: 0.4168 - f1_m: 0.5077 - val_loss: 0.1031 - val_acc: 0.9689 - val_precision_m: 0.6736 - val_recall_m: 0.3185 - val_f1_m: 0.4072\n",
      "Epoch 18/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0717 - acc: 0.9742 - precision_m: 0.7574 - recall_m: 0.4303 - f1_m: 0.5228\n",
      "Epoch 18: val_acc did not improve from 0.96890\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0721 - acc: 0.9741 - precision_m: 0.7564 - recall_m: 0.4291 - f1_m: 0.5218 - val_loss: 0.0989 - val_acc: 0.9684 - val_precision_m: 0.6172 - val_recall_m: 0.3557 - val_f1_m: 0.4319\n",
      "Epoch 19/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0704 - acc: 0.9745 - precision_m: 0.7556 - recall_m: 0.4549 - f1_m: 0.5457\n",
      "Epoch 19: val_acc improved from 0.96890 to 0.96939, saving model to models/best_model_8_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0704 - acc: 0.9745 - precision_m: 0.7563 - recall_m: 0.4586 - f1_m: 0.5484 - val_loss: 0.0996 - val_acc: 0.9694 - val_precision_m: 0.6686 - val_recall_m: 0.3182 - val_f1_m: 0.4104\n",
      "Epoch 20/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0697 - acc: 0.9748 - precision_m: 0.7601 - recall_m: 0.4520 - f1_m: 0.5396\n",
      "Epoch 20: val_acc improved from 0.96939 to 0.96963, saving model to models/best_model_8_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0702 - acc: 0.9747 - precision_m: 0.7616 - recall_m: 0.4474 - f1_m: 0.5354 - val_loss: 0.0976 - val_acc: 0.9696 - val_precision_m: 0.6433 - val_recall_m: 0.3334 - val_f1_m: 0.4195\n",
      "Epoch 21/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0689 - acc: 0.9754 - precision_m: 0.7624 - recall_m: 0.4703 - f1_m: 0.5531\n",
      "Epoch 21: val_acc did not improve from 0.96963\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0687 - acc: 0.9754 - precision_m: 0.7617 - recall_m: 0.4699 - f1_m: 0.5530 - val_loss: 0.1098 - val_acc: 0.9689 - val_precision_m: 0.7060 - val_recall_m: 0.2881 - val_f1_m: 0.3872\n",
      "Epoch 22/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0674 - acc: 0.9748 - precision_m: 0.7616 - recall_m: 0.4504 - f1_m: 0.5402\n",
      "Epoch 22: val_acc did not improve from 0.96963\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0671 - acc: 0.9749 - precision_m: 0.7637 - recall_m: 0.4501 - f1_m: 0.5408 - val_loss: 0.1026 - val_acc: 0.9676 - val_precision_m: 0.5964 - val_recall_m: 0.3526 - val_f1_m: 0.4207\n",
      "Epoch 23/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0654 - acc: 0.9763 - precision_m: 0.7905 - recall_m: 0.4951 - f1_m: 0.5830\n",
      "Epoch 23: val_acc did not improve from 0.96963\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0655 - acc: 0.9763 - precision_m: 0.7906 - recall_m: 0.4941 - f1_m: 0.5823 - val_loss: 0.1037 - val_acc: 0.9671 - val_precision_m: 0.5996 - val_recall_m: 0.3943 - val_f1_m: 0.4491\n",
      "Epoch 24/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0649 - acc: 0.9758 - precision_m: 0.7649 - recall_m: 0.4794 - f1_m: 0.5659\n",
      "Epoch 24: val_acc did not improve from 0.96963\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0649 - acc: 0.9759 - precision_m: 0.7676 - recall_m: 0.4802 - f1_m: 0.5676 - val_loss: 0.1019 - val_acc: 0.9687 - val_precision_m: 0.6158 - val_recall_m: 0.3450 - val_f1_m: 0.4253\n",
      "Epoch 25/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0621 - acc: 0.9773 - precision_m: 0.7757 - recall_m: 0.5208 - f1_m: 0.6027\n",
      "Epoch 25: val_acc did not improve from 0.96963\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0620 - acc: 0.9773 - precision_m: 0.7762 - recall_m: 0.5227 - f1_m: 0.6046 - val_loss: 0.1034 - val_acc: 0.9685 - val_precision_m: 0.6142 - val_recall_m: 0.4312 - val_f1_m: 0.4675\n",
      "Epoch 26/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9770 - precision_m: 0.7772 - recall_m: 0.5232 - f1_m: 0.6003\n",
      "Epoch 26: val_acc did not improve from 0.96963\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0620 - acc: 0.9770 - precision_m: 0.7781 - recall_m: 0.5230 - f1_m: 0.6005 - val_loss: 0.1097 - val_acc: 0.9687 - val_precision_m: 0.6417 - val_recall_m: 0.3072 - val_f1_m: 0.3898\n",
      "Epoch 27/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0607 - acc: 0.9773 - precision_m: 0.7776 - recall_m: 0.5184 - f1_m: 0.5991\n",
      "Epoch 27: val_acc did not improve from 0.96963\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0608 - acc: 0.9772 - precision_m: 0.7782 - recall_m: 0.5187 - f1_m: 0.5993 - val_loss: 0.1048 - val_acc: 0.9691 - val_precision_m: 0.6254 - val_recall_m: 0.4703 - val_f1_m: 0.4971\n",
      "Epoch 28/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0596 - acc: 0.9775 - precision_m: 0.7914 - recall_m: 0.5296 - f1_m: 0.6085\n",
      "Epoch 28: val_acc did not improve from 0.96963\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0594 - acc: 0.9775 - precision_m: 0.7915 - recall_m: 0.5309 - f1_m: 0.6097 - val_loss: 0.1108 - val_acc: 0.9688 - val_precision_m: 0.6683 - val_recall_m: 0.3023 - val_f1_m: 0.3962\n",
      "Epoch 29/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0580 - acc: 0.9782 - precision_m: 0.8013 - recall_m: 0.5377 - f1_m: 0.6184\n",
      "Epoch 29: val_acc did not improve from 0.96963\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0586 - acc: 0.9780 - precision_m: 0.7992 - recall_m: 0.5376 - f1_m: 0.6179 - val_loss: 0.1104 - val_acc: 0.9687 - val_precision_m: 0.6268 - val_recall_m: 0.4088 - val_f1_m: 0.4717\n",
      "Epoch 30/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0585 - acc: 0.9780 - precision_m: 0.7770 - recall_m: 0.5363 - f1_m: 0.6087\n",
      "Epoch 30: val_acc did not improve from 0.96963\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0587 - acc: 0.9779 - precision_m: 0.7778 - recall_m: 0.5366 - f1_m: 0.6093 - val_loss: 0.1095 - val_acc: 0.9694 - val_precision_m: 0.6474 - val_recall_m: 0.3440 - val_f1_m: 0.4331\n",
      "Score for fold 6: loss of 0.097646065056324; acc of 96.96275591850281%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.09389866888523102; acc of 97.09435105323792%\n",
      "Test Precision: precision_m of 21.480654180049896%\n",
      "Test Recall: recall_m of 15.612873435020447%\n",
      "Test F1: f1_m of 16.844749450683594%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1581 - acc: 0.9621 - precision_m: 0.0230 - recall_m: 0.0040 - f1_m: 0.0056    \n",
      "Epoch 1: val_acc improved from -inf to 0.96260, saving model to models/best_model_8_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 2s 5ms/step - loss: 0.1581 - acc: 0.9621 - precision_m: 0.0230 - recall_m: 0.0040 - f1_m: 0.0056 - val_loss: 0.1225 - val_acc: 0.9626 - val_precision_m: 0.0303 - val_recall_m: 0.0025 - val_f1_m: 0.0047\n",
      "Epoch 2/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.1197 - acc: 0.9634 - precision_m: 0.3351 - recall_m: 0.0724 - f1_m: 0.1104\n",
      "Epoch 2: val_acc did not improve from 0.96260\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1193 - acc: 0.9635 - precision_m: 0.3316 - recall_m: 0.0709 - f1_m: 0.1083 - val_loss: 0.1129 - val_acc: 0.9626 - val_precision_m: 0.0758 - val_recall_m: 0.0136 - val_f1_m: 0.0231\n",
      "Epoch 3/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.1076 - acc: 0.9649 - precision_m: 0.5085 - recall_m: 0.1332 - f1_m: 0.1987\n",
      "Epoch 3: val_acc improved from 0.96260 to 0.96619, saving model to models/best_model_8_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1074 - acc: 0.9649 - precision_m: 0.5075 - recall_m: 0.1336 - f1_m: 0.1991 - val_loss: 0.1068 - val_acc: 0.9662 - val_precision_m: 0.6043 - val_recall_m: 0.2710 - val_f1_m: 0.3418\n",
      "Epoch 4/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.1021 - acc: 0.9661 - precision_m: 0.5539 - recall_m: 0.2013 - f1_m: 0.2747\n",
      "Epoch 4: val_acc improved from 0.96619 to 0.96655, saving model to models/best_model_8_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1020 - acc: 0.9661 - precision_m: 0.5551 - recall_m: 0.2013 - f1_m: 0.2751 - val_loss: 0.1068 - val_acc: 0.9665 - val_precision_m: 0.5833 - val_recall_m: 0.1598 - val_f1_m: 0.2347\n",
      "Epoch 5/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0974 - acc: 0.9673 - precision_m: 0.6296 - recall_m: 0.2587 - f1_m: 0.3401\n",
      "Epoch 5: val_acc improved from 0.96655 to 0.96810, saving model to models/best_model_8_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0975 - acc: 0.9672 - precision_m: 0.6264 - recall_m: 0.2563 - f1_m: 0.3372 - val_loss: 0.1040 - val_acc: 0.9681 - val_precision_m: 0.6619 - val_recall_m: 0.3206 - val_f1_m: 0.3914\n",
      "Epoch 6/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0934 - acc: 0.9683 - precision_m: 0.6799 - recall_m: 0.2858 - f1_m: 0.3759\n",
      "Epoch 6: val_acc improved from 0.96810 to 0.96822, saving model to models/best_model_8_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0937 - acc: 0.9682 - precision_m: 0.6720 - recall_m: 0.2843 - f1_m: 0.3736 - val_loss: 0.0982 - val_acc: 0.9682 - val_precision_m: 0.6122 - val_recall_m: 0.2229 - val_f1_m: 0.3064\n",
      "Epoch 7/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0917 - acc: 0.9686 - precision_m: 0.6804 - recall_m: 0.2943 - f1_m: 0.3825\n",
      "Epoch 7: val_acc did not improve from 0.96822\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0917 - acc: 0.9686 - precision_m: 0.6810 - recall_m: 0.2946 - f1_m: 0.3823 - val_loss: 0.1050 - val_acc: 0.9645 - val_precision_m: 0.5161 - val_recall_m: 0.4545 - val_f1_m: 0.4481\n",
      "Epoch 8/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0889 - acc: 0.9697 - precision_m: 0.7002 - recall_m: 0.3248 - f1_m: 0.4129\n",
      "Epoch 8: val_acc improved from 0.96822 to 0.96894, saving model to models/best_model_8_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0889 - acc: 0.9697 - precision_m: 0.6965 - recall_m: 0.3231 - f1_m: 0.4108 - val_loss: 0.1038 - val_acc: 0.9689 - val_precision_m: 0.7315 - val_recall_m: 0.2022 - val_f1_m: 0.2915\n",
      "Epoch 9/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0868 - acc: 0.9704 - precision_m: 0.7204 - recall_m: 0.3538 - f1_m: 0.4454\n",
      "Epoch 9: val_acc improved from 0.96894 to 0.96930, saving model to models/best_model_8_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0865 - acc: 0.9705 - precision_m: 0.7152 - recall_m: 0.3518 - f1_m: 0.4428 - val_loss: 0.0963 - val_acc: 0.9693 - val_precision_m: 0.6485 - val_recall_m: 0.3093 - val_f1_m: 0.3870\n",
      "Epoch 10/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0838 - acc: 0.9710 - precision_m: 0.7118 - recall_m: 0.3728 - f1_m: 0.4653\n",
      "Epoch 10: val_acc improved from 0.96930 to 0.96941, saving model to models/best_model_8_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0840 - acc: 0.9710 - precision_m: 0.7108 - recall_m: 0.3713 - f1_m: 0.4637 - val_loss: 0.0961 - val_acc: 0.9694 - val_precision_m: 0.6366 - val_recall_m: 0.2867 - val_f1_m: 0.3667\n",
      "Epoch 11/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0819 - acc: 0.9713 - precision_m: 0.7251 - recall_m: 0.3729 - f1_m: 0.4668\n",
      "Epoch 11: val_acc did not improve from 0.96941\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0822 - acc: 0.9712 - precision_m: 0.7233 - recall_m: 0.3783 - f1_m: 0.4695 - val_loss: 0.1001 - val_acc: 0.9694 - val_precision_m: 0.6686 - val_recall_m: 0.3234 - val_f1_m: 0.3965\n",
      "Epoch 12/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0810 - acc: 0.9716 - precision_m: 0.7375 - recall_m: 0.3789 - f1_m: 0.4739\n",
      "Epoch 12: val_acc did not improve from 0.96941\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0817 - acc: 0.9713 - precision_m: 0.7364 - recall_m: 0.3766 - f1_m: 0.4717 - val_loss: 0.1000 - val_acc: 0.9681 - val_precision_m: 0.5832 - val_recall_m: 0.4457 - val_f1_m: 0.4718\n",
      "Epoch 13/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0789 - acc: 0.9727 - precision_m: 0.7448 - recall_m: 0.4081 - f1_m: 0.4992\n",
      "Epoch 13: val_acc improved from 0.96941 to 0.97013, saving model to models/best_model_8_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0791 - acc: 0.9726 - precision_m: 0.7409 - recall_m: 0.4060 - f1_m: 0.4969 - val_loss: 0.0933 - val_acc: 0.9701 - val_precision_m: 0.7037 - val_recall_m: 0.3295 - val_f1_m: 0.4084\n",
      "Epoch 14/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0789 - acc: 0.9726 - precision_m: 0.7464 - recall_m: 0.4137 - f1_m: 0.5036\n",
      "Epoch 14: val_acc did not improve from 0.97013\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0790 - acc: 0.9726 - precision_m: 0.7441 - recall_m: 0.4110 - f1_m: 0.5012 - val_loss: 0.0962 - val_acc: 0.9681 - val_precision_m: 0.5874 - val_recall_m: 0.4161 - val_f1_m: 0.4492\n",
      "Epoch 15/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0756 - acc: 0.9734 - precision_m: 0.7440 - recall_m: 0.4322 - f1_m: 0.5218\n",
      "Epoch 15: val_acc did not improve from 0.97013\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0758 - acc: 0.9734 - precision_m: 0.7463 - recall_m: 0.4312 - f1_m: 0.5220 - val_loss: 0.0946 - val_acc: 0.9689 - val_precision_m: 0.6029 - val_recall_m: 0.4184 - val_f1_m: 0.4568\n",
      "Epoch 16/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0760 - acc: 0.9729 - precision_m: 0.7462 - recall_m: 0.4255 - f1_m: 0.5139\n",
      "Epoch 16: val_acc did not improve from 0.97013\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0757 - acc: 0.9731 - precision_m: 0.7485 - recall_m: 0.4263 - f1_m: 0.5143 - val_loss: 0.0948 - val_acc: 0.9701 - val_precision_m: 0.6241 - val_recall_m: 0.4605 - val_f1_m: 0.5020\n",
      "Epoch 17/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0735 - acc: 0.9742 - precision_m: 0.7786 - recall_m: 0.4482 - f1_m: 0.5458\n",
      "Epoch 17: val_acc did not improve from 0.97013\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0734 - acc: 0.9743 - precision_m: 0.7775 - recall_m: 0.4484 - f1_m: 0.5459 - val_loss: 0.0973 - val_acc: 0.9682 - val_precision_m: 0.5849 - val_recall_m: 0.3850 - val_f1_m: 0.4283\n",
      "Epoch 18/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0725 - acc: 0.9742 - precision_m: 0.7579 - recall_m: 0.4418 - f1_m: 0.5348\n",
      "Epoch 18: val_acc did not improve from 0.97013\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0726 - acc: 0.9742 - precision_m: 0.7585 - recall_m: 0.4429 - f1_m: 0.5362 - val_loss: 0.0945 - val_acc: 0.9697 - val_precision_m: 0.6691 - val_recall_m: 0.3838 - val_f1_m: 0.4481\n",
      "Epoch 19/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0715 - acc: 0.9747 - precision_m: 0.7756 - recall_m: 0.4674 - f1_m: 0.5571\n",
      "Epoch 19: val_acc did not improve from 0.97013\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0715 - acc: 0.9747 - precision_m: 0.7773 - recall_m: 0.4670 - f1_m: 0.5575 - val_loss: 0.0953 - val_acc: 0.9701 - val_precision_m: 0.6906 - val_recall_m: 0.3184 - val_f1_m: 0.3948\n",
      "Epoch 20/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0708 - acc: 0.9749 - precision_m: 0.7791 - recall_m: 0.4697 - f1_m: 0.5607\n",
      "Epoch 20: val_acc did not improve from 0.97013\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0704 - acc: 0.9750 - precision_m: 0.7791 - recall_m: 0.4715 - f1_m: 0.5616 - val_loss: 0.1250 - val_acc: 0.9689 - val_precision_m: 0.7227 - val_recall_m: 0.1993 - val_f1_m: 0.2952\n",
      "Epoch 21/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0702 - acc: 0.9758 - precision_m: 0.7863 - recall_m: 0.4827 - f1_m: 0.5686\n",
      "Epoch 21: val_acc did not improve from 0.97013\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0703 - acc: 0.9757 - precision_m: 0.7891 - recall_m: 0.4804 - f1_m: 0.5676 - val_loss: 0.0962 - val_acc: 0.9676 - val_precision_m: 0.5923 - val_recall_m: 0.4574 - val_f1_m: 0.4856\n",
      "Epoch 22/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0689 - acc: 0.9750 - precision_m: 0.7724 - recall_m: 0.4838 - f1_m: 0.5681\n",
      "Epoch 22: val_acc did not improve from 0.97013\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0688 - acc: 0.9751 - precision_m: 0.7743 - recall_m: 0.4844 - f1_m: 0.5690 - val_loss: 0.1001 - val_acc: 0.9700 - val_precision_m: 0.7473 - val_recall_m: 0.3104 - val_f1_m: 0.4078\n",
      "Epoch 23/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0676 - acc: 0.9758 - precision_m: 0.7871 - recall_m: 0.4956 - f1_m: 0.5823\n",
      "Epoch 23: val_acc did not improve from 0.97013\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0676 - acc: 0.9758 - precision_m: 0.7880 - recall_m: 0.4961 - f1_m: 0.5828 - val_loss: 0.0961 - val_acc: 0.9687 - val_precision_m: 0.5918 - val_recall_m: 0.4818 - val_f1_m: 0.5041\n",
      "Epoch 24/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0649 - acc: 0.9759 - precision_m: 0.7834 - recall_m: 0.5029 - f1_m: 0.5877\n",
      "Epoch 24: val_acc improved from 0.97013 to 0.97037, saving model to models/best_model_8_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0653 - acc: 0.9759 - precision_m: 0.7824 - recall_m: 0.5060 - f1_m: 0.5892 - val_loss: 0.1099 - val_acc: 0.9704 - val_precision_m: 0.7618 - val_recall_m: 0.2543 - val_f1_m: 0.3549\n",
      "Epoch 25/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0633 - acc: 0.9767 - precision_m: 0.7920 - recall_m: 0.5126 - f1_m: 0.5952\n",
      "Epoch 25: val_acc did not improve from 0.97037\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0637 - acc: 0.9766 - precision_m: 0.7903 - recall_m: 0.5154 - f1_m: 0.5967 - val_loss: 0.1012 - val_acc: 0.9659 - val_precision_m: 0.5145 - val_recall_m: 0.4931 - val_f1_m: 0.4791\n",
      "Epoch 26/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0642 - acc: 0.9771 - precision_m: 0.8000 - recall_m: 0.5296 - f1_m: 0.6156\n",
      "Epoch 26: val_acc did not improve from 0.97037\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0639 - acc: 0.9773 - precision_m: 0.7993 - recall_m: 0.5245 - f1_m: 0.6116 - val_loss: 0.0993 - val_acc: 0.9677 - val_precision_m: 0.5772 - val_recall_m: 0.4823 - val_f1_m: 0.5011\n",
      "Epoch 27/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0635 - acc: 0.9766 - precision_m: 0.7916 - recall_m: 0.5160 - f1_m: 0.5984\n",
      "Epoch 27: val_acc improved from 0.97037 to 0.97061, saving model to models/best_model_8_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0635 - acc: 0.9766 - precision_m: 0.7896 - recall_m: 0.5169 - f1_m: 0.5986 - val_loss: 0.0974 - val_acc: 0.9706 - val_precision_m: 0.7156 - val_recall_m: 0.3526 - val_f1_m: 0.4401\n",
      "Epoch 28/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0618 - acc: 0.9769 - precision_m: 0.7918 - recall_m: 0.5232 - f1_m: 0.6087\n",
      "Epoch 28: val_acc did not improve from 0.97061\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0619 - acc: 0.9768 - precision_m: 0.7854 - recall_m: 0.5170 - f1_m: 0.6022 - val_loss: 0.0996 - val_acc: 0.9676 - val_precision_m: 0.5677 - val_recall_m: 0.4868 - val_f1_m: 0.4972\n",
      "Epoch 29/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0611 - acc: 0.9773 - precision_m: 0.7986 - recall_m: 0.5353 - f1_m: 0.6130\n",
      "Epoch 29: val_acc improved from 0.97061 to 0.97085, saving model to models/best_model_8_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0612 - acc: 0.9772 - precision_m: 0.7950 - recall_m: 0.5327 - f1_m: 0.6098 - val_loss: 0.1028 - val_acc: 0.9708 - val_precision_m: 0.6847 - val_recall_m: 0.3786 - val_f1_m: 0.4570\n",
      "Epoch 30/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0603 - acc: 0.9775 - precision_m: 0.8059 - recall_m: 0.5434 - f1_m: 0.6254\n",
      "Epoch 30: val_acc improved from 0.97085 to 0.97097, saving model to models/best_model_8_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0605 - acc: 0.9776 - precision_m: 0.8041 - recall_m: 0.5429 - f1_m: 0.6250 - val_loss: 0.0997 - val_acc: 0.9710 - val_precision_m: 0.7137 - val_recall_m: 0.3574 - val_f1_m: 0.4419\n",
      "Score for fold 7: loss of 0.0997496023774147; acc of 97.09677696228027%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.08685392886400223; acc of 97.46586680412292%\n",
      "Test Precision: precision_m of 16.114982962608337%\n",
      "Test Recall: recall_m of 9.63539332151413%\n",
      "Test F1: f1_m of 11.231701076030731%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1785 - acc: 0.9559 - precision_m: 6.9860e-04 - recall_m: 0.0084 - f1_m: 0.0012\n",
      "Epoch 1: val_acc improved from -inf to 0.96299, saving model to models/best_model_8_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 2s 5ms/step - loss: 0.1785 - acc: 0.9559 - precision_m: 6.9860e-04 - recall_m: 0.0084 - f1_m: 0.0012 - val_loss: 0.1281 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.1250 - acc: 0.9636 - precision_m: 0.0698 - recall_m: 0.0086 - f1_m: 0.0151\n",
      "Epoch 2: val_acc improved from 0.96299 to 0.96322, saving model to models/best_model_8_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1251 - acc: 0.9635 - precision_m: 0.0713 - recall_m: 0.0086 - f1_m: 0.0151 - val_loss: 0.1145 - val_acc: 0.9632 - val_precision_m: 0.0909 - val_recall_m: 0.0068 - val_f1_m: 0.0126\n",
      "Epoch 3/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.1127 - acc: 0.9642 - precision_m: 0.3157 - recall_m: 0.0522 - f1_m: 0.0848\n",
      "Epoch 3: val_acc improved from 0.96322 to 0.96514, saving model to models/best_model_8_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1120 - acc: 0.9645 - precision_m: 0.3140 - recall_m: 0.0522 - f1_m: 0.0849 - val_loss: 0.1066 - val_acc: 0.9651 - val_precision_m: 0.3684 - val_recall_m: 0.1120 - val_f1_m: 0.1595\n",
      "Epoch 4/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.1029 - acc: 0.9660 - precision_m: 0.5358 - recall_m: 0.1270 - f1_m: 0.1952\n",
      "Epoch 4: val_acc improved from 0.96514 to 0.96646, saving model to models/best_model_8_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1029 - acc: 0.9660 - precision_m: 0.5419 - recall_m: 0.1286 - f1_m: 0.1979 - val_loss: 0.1029 - val_acc: 0.9665 - val_precision_m: 0.4457 - val_recall_m: 0.1490 - val_f1_m: 0.2047\n",
      "Epoch 5/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.1005 - acc: 0.9666 - precision_m: 0.5532 - recall_m: 0.1742 - f1_m: 0.2464\n",
      "Epoch 5: val_acc did not improve from 0.96646\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1004 - acc: 0.9667 - precision_m: 0.5544 - recall_m: 0.1752 - f1_m: 0.2475 - val_loss: 0.1056 - val_acc: 0.9654 - val_precision_m: 0.2899 - val_recall_m: 0.0790 - val_f1_m: 0.1182\n",
      "Epoch 6/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0982 - acc: 0.9674 - precision_m: 0.5880 - recall_m: 0.2070 - f1_m: 0.2816\n",
      "Epoch 6: val_acc improved from 0.96646 to 0.96790, saving model to models/best_model_8_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0983 - acc: 0.9673 - precision_m: 0.5899 - recall_m: 0.2081 - f1_m: 0.2833 - val_loss: 0.0970 - val_acc: 0.9679 - val_precision_m: 0.6182 - val_recall_m: 0.1817 - val_f1_m: 0.2500\n",
      "Epoch 7/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0929 - acc: 0.9682 - precision_m: 0.6444 - recall_m: 0.2483 - f1_m: 0.3344\n",
      "Epoch 7: val_acc did not improve from 0.96790\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0930 - acc: 0.9681 - precision_m: 0.6452 - recall_m: 0.2489 - f1_m: 0.3353 - val_loss: 0.1000 - val_acc: 0.9675 - val_precision_m: 0.4495 - val_recall_m: 0.1475 - val_f1_m: 0.2012\n",
      "Epoch 8/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0889 - acc: 0.9693 - precision_m: 0.6560 - recall_m: 0.2854 - f1_m: 0.3775\n",
      "Epoch 8: val_acc did not improve from 0.96790\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0887 - acc: 0.9694 - precision_m: 0.6570 - recall_m: 0.2864 - f1_m: 0.3787 - val_loss: 0.0964 - val_acc: 0.9669 - val_precision_m: 0.5643 - val_recall_m: 0.3694 - val_f1_m: 0.4053\n",
      "Epoch 9/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0883 - acc: 0.9691 - precision_m: 0.6664 - recall_m: 0.3075 - f1_m: 0.3930\n",
      "Epoch 9: val_acc improved from 0.96790 to 0.96921, saving model to models/best_model_8_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0879 - acc: 0.9692 - precision_m: 0.6648 - recall_m: 0.3069 - f1_m: 0.3927 - val_loss: 0.0953 - val_acc: 0.9692 - val_precision_m: 0.6105 - val_recall_m: 0.3121 - val_f1_m: 0.3685\n",
      "Epoch 10/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0852 - acc: 0.9700 - precision_m: 0.6748 - recall_m: 0.3327 - f1_m: 0.4236\n",
      "Epoch 10: val_acc improved from 0.96921 to 0.96981, saving model to models/best_model_8_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0852 - acc: 0.9699 - precision_m: 0.6773 - recall_m: 0.3319 - f1_m: 0.4232 - val_loss: 0.0944 - val_acc: 0.9698 - val_precision_m: 0.6084 - val_recall_m: 0.3118 - val_f1_m: 0.3805\n",
      "Epoch 11/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0834 - acc: 0.9709 - precision_m: 0.7240 - recall_m: 0.3585 - f1_m: 0.4511\n",
      "Epoch 11: val_acc did not improve from 0.96981\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0832 - acc: 0.9710 - precision_m: 0.7245 - recall_m: 0.3615 - f1_m: 0.4536 - val_loss: 0.0967 - val_acc: 0.9691 - val_precision_m: 0.6029 - val_recall_m: 0.2977 - val_f1_m: 0.3669\n",
      "Epoch 12/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0817 - acc: 0.9716 - precision_m: 0.7029 - recall_m: 0.3564 - f1_m: 0.4457\n",
      "Epoch 12: val_acc improved from 0.96981 to 0.96993, saving model to models/best_model_8_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0820 - acc: 0.9714 - precision_m: 0.7017 - recall_m: 0.3562 - f1_m: 0.4452 - val_loss: 0.0924 - val_acc: 0.9699 - val_precision_m: 0.6497 - val_recall_m: 0.3795 - val_f1_m: 0.4384\n",
      "Epoch 13/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0802 - acc: 0.9712 - precision_m: 0.7069 - recall_m: 0.3658 - f1_m: 0.4514\n",
      "Epoch 13: val_acc did not improve from 0.96993\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0799 - acc: 0.9713 - precision_m: 0.7065 - recall_m: 0.3650 - f1_m: 0.4506 - val_loss: 0.0941 - val_acc: 0.9695 - val_precision_m: 0.6487 - val_recall_m: 0.3467 - val_f1_m: 0.4177\n",
      "Epoch 14/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0782 - acc: 0.9722 - precision_m: 0.7146 - recall_m: 0.3883 - f1_m: 0.4771\n",
      "Epoch 14: val_acc did not improve from 0.96993\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0782 - acc: 0.9722 - precision_m: 0.7163 - recall_m: 0.3889 - f1_m: 0.4781 - val_loss: 0.0948 - val_acc: 0.9695 - val_precision_m: 0.6200 - val_recall_m: 0.3588 - val_f1_m: 0.4135\n",
      "Epoch 15/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0773 - acc: 0.9726 - precision_m: 0.7244 - recall_m: 0.4018 - f1_m: 0.4917\n",
      "Epoch 15: val_acc improved from 0.96993 to 0.97005, saving model to models/best_model_8_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0775 - acc: 0.9724 - precision_m: 0.7254 - recall_m: 0.4015 - f1_m: 0.4920 - val_loss: 0.0903 - val_acc: 0.9701 - val_precision_m: 0.6250 - val_recall_m: 0.3710 - val_f1_m: 0.4265\n",
      "Epoch 16/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0776 - acc: 0.9726 - precision_m: 0.7441 - recall_m: 0.4066 - f1_m: 0.4921\n",
      "Epoch 16: val_acc improved from 0.97005 to 0.97017, saving model to models/best_model_8_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0772 - acc: 0.9728 - precision_m: 0.7440 - recall_m: 0.4075 - f1_m: 0.4937 - val_loss: 0.0954 - val_acc: 0.9702 - val_precision_m: 0.6825 - val_recall_m: 0.2576 - val_f1_m: 0.3372\n",
      "Epoch 17/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0725 - acc: 0.9739 - precision_m: 0.7522 - recall_m: 0.4367 - f1_m: 0.5282\n",
      "Epoch 17: val_acc did not improve from 0.97017\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0729 - acc: 0.9737 - precision_m: 0.7514 - recall_m: 0.4363 - f1_m: 0.5274 - val_loss: 0.0972 - val_acc: 0.9656 - val_precision_m: 0.5279 - val_recall_m: 0.5281 - val_f1_m: 0.4904\n",
      "Epoch 18/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0724 - acc: 0.9737 - precision_m: 0.7482 - recall_m: 0.4386 - f1_m: 0.5260\n",
      "Epoch 18: val_acc improved from 0.97017 to 0.97041, saving model to models/best_model_8_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0724 - acc: 0.9737 - precision_m: 0.7491 - recall_m: 0.4350 - f1_m: 0.5230 - val_loss: 0.0923 - val_acc: 0.9704 - val_precision_m: 0.6378 - val_recall_m: 0.4178 - val_f1_m: 0.4665\n",
      "Epoch 19/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0706 - acc: 0.9738 - precision_m: 0.7500 - recall_m: 0.4387 - f1_m: 0.5265\n",
      "Epoch 19: val_acc did not improve from 0.97041\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0713 - acc: 0.9736 - precision_m: 0.7523 - recall_m: 0.4329 - f1_m: 0.5211 - val_loss: 0.1003 - val_acc: 0.9654 - val_precision_m: 0.5481 - val_recall_m: 0.4693 - val_f1_m: 0.4603\n",
      "Epoch 20/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0705 - acc: 0.9741 - precision_m: 0.7520 - recall_m: 0.4484 - f1_m: 0.5330\n",
      "Epoch 20: val_acc improved from 0.97041 to 0.97101, saving model to models/best_model_8_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0702 - acc: 0.9743 - precision_m: 0.7544 - recall_m: 0.4489 - f1_m: 0.5341 - val_loss: 0.0973 - val_acc: 0.9710 - val_precision_m: 0.6832 - val_recall_m: 0.3507 - val_f1_m: 0.4184\n",
      "Epoch 21/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0684 - acc: 0.9750 - precision_m: 0.7630 - recall_m: 0.4752 - f1_m: 0.5561\n",
      "Epoch 21: val_acc improved from 0.97101 to 0.97161, saving model to models/best_model_8_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0683 - acc: 0.9749 - precision_m: 0.7620 - recall_m: 0.4742 - f1_m: 0.5554 - val_loss: 0.0980 - val_acc: 0.9716 - val_precision_m: 0.6848 - val_recall_m: 0.3324 - val_f1_m: 0.4088\n",
      "Epoch 22/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0661 - acc: 0.9757 - precision_m: 0.7726 - recall_m: 0.4790 - f1_m: 0.5683\n",
      "Epoch 22: val_acc did not improve from 0.97161\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0663 - acc: 0.9756 - precision_m: 0.7757 - recall_m: 0.4762 - f1_m: 0.5664 - val_loss: 0.1001 - val_acc: 0.9672 - val_precision_m: 0.5424 - val_recall_m: 0.4771 - val_f1_m: 0.4747\n",
      "Epoch 23/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0673 - acc: 0.9750 - precision_m: 0.7670 - recall_m: 0.4677 - f1_m: 0.5571\n",
      "Epoch 23: val_acc did not improve from 0.97161\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0670 - acc: 0.9752 - precision_m: 0.7676 - recall_m: 0.4686 - f1_m: 0.5579 - val_loss: 0.0968 - val_acc: 0.9714 - val_precision_m: 0.6816 - val_recall_m: 0.4245 - val_f1_m: 0.4787\n",
      "Epoch 24/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0666 - acc: 0.9753 - precision_m: 0.7701 - recall_m: 0.4734 - f1_m: 0.5619\n",
      "Epoch 24: val_acc did not improve from 0.97161\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0667 - acc: 0.9752 - precision_m: 0.7719 - recall_m: 0.4693 - f1_m: 0.5588 - val_loss: 0.0964 - val_acc: 0.9699 - val_precision_m: 0.6095 - val_recall_m: 0.4295 - val_f1_m: 0.4718\n",
      "Epoch 25/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0646 - acc: 0.9759 - precision_m: 0.7657 - recall_m: 0.4907 - f1_m: 0.5698\n",
      "Epoch 25: val_acc did not improve from 0.97161\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0646 - acc: 0.9759 - precision_m: 0.7662 - recall_m: 0.4908 - f1_m: 0.5705 - val_loss: 0.0976 - val_acc: 0.9696 - val_precision_m: 0.6066 - val_recall_m: 0.3785 - val_f1_m: 0.4313\n",
      "Epoch 26/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0643 - acc: 0.9764 - precision_m: 0.7794 - recall_m: 0.5000 - f1_m: 0.5839\n",
      "Epoch 26: val_acc did not improve from 0.97161\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0642 - acc: 0.9764 - precision_m: 0.7810 - recall_m: 0.5009 - f1_m: 0.5851 - val_loss: 0.0951 - val_acc: 0.9690 - val_precision_m: 0.5532 - val_recall_m: 0.4035 - val_f1_m: 0.4394\n",
      "Epoch 27/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9763 - precision_m: 0.7794 - recall_m: 0.5015 - f1_m: 0.5873\n",
      "Epoch 27: val_acc improved from 0.97161 to 0.97185, saving model to models/best_model_8_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0619 - acc: 0.9763 - precision_m: 0.7802 - recall_m: 0.5029 - f1_m: 0.5886 - val_loss: 0.1037 - val_acc: 0.9718 - val_precision_m: 0.6952 - val_recall_m: 0.3370 - val_f1_m: 0.4220\n",
      "Epoch 28/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0605 - acc: 0.9768 - precision_m: 0.8008 - recall_m: 0.5033 - f1_m: 0.5947\n",
      "Epoch 28: val_acc did not improve from 0.97185\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0604 - acc: 0.9769 - precision_m: 0.7990 - recall_m: 0.5005 - f1_m: 0.5919 - val_loss: 0.1061 - val_acc: 0.9715 - val_precision_m: 0.6525 - val_recall_m: 0.3267 - val_f1_m: 0.4009\n",
      "Epoch 29/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9776 - precision_m: 0.8092 - recall_m: 0.5360 - f1_m: 0.6206\n",
      "Epoch 29: val_acc did not improve from 0.97185\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0601 - acc: 0.9777 - precision_m: 0.8101 - recall_m: 0.5361 - f1_m: 0.6211 - val_loss: 0.0975 - val_acc: 0.9714 - val_precision_m: 0.6501 - val_recall_m: 0.3652 - val_f1_m: 0.4350\n",
      "Epoch 30/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9773 - precision_m: 0.8089 - recall_m: 0.5211 - f1_m: 0.6085\n",
      "Epoch 30: val_acc did not improve from 0.97185\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0600 - acc: 0.9772 - precision_m: 0.8043 - recall_m: 0.5207 - f1_m: 0.6066 - val_loss: 0.1145 - val_acc: 0.9714 - val_precision_m: 0.6375 - val_recall_m: 0.2968 - val_f1_m: 0.3770\n",
      "Score for fold 8: loss of 0.10369522124528885; acc of 97.18495607376099%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.10091046243906021; acc of 97.00188040733337%\n",
      "Test Precision: precision_m of 18.127208948135376%\n",
      "Test Recall: recall_m of 11.808468401432037%\n",
      "Test F1: f1_m of 13.401168584823608%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "Epoch 1/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.1784 - acc: 0.9571 - precision_m: 0.0045 - recall_m: 0.0090 - f1_m: 0.0031\n",
      "Epoch 1: val_acc improved from -inf to 0.96151, saving model to models/best_model_8_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 3s 5ms/step - loss: 0.1784 - acc: 0.9571 - precision_m: 0.0045 - recall_m: 0.0090 - f1_m: 0.0031 - val_loss: 0.1406 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.1248 - acc: 0.9641 - precision_m: 0.0316 - recall_m: 0.0045 - f1_m: 0.0075   \n",
      "Epoch 2: val_acc did not improve from 0.96151\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.1247 - acc: 0.9642 - precision_m: 0.0315 - recall_m: 0.0045 - f1_m: 0.0075 - val_loss: 0.1129 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 3/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.1098 - acc: 0.9652 - precision_m: 0.2772 - recall_m: 0.0498 - f1_m: 0.0803\n",
      "Epoch 3: val_acc improved from 0.96151 to 0.96270, saving model to models/best_model_8_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.1097 - acc: 0.9652 - precision_m: 0.2792 - recall_m: 0.0503 - f1_m: 0.0810 - val_loss: 0.1051 - val_acc: 0.9627 - val_precision_m: 0.2121 - val_recall_m: 0.0219 - val_f1_m: 0.0395\n",
      "Epoch 4/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.1029 - acc: 0.9655 - precision_m: 0.3875 - recall_m: 0.0820 - f1_m: 0.1282\n",
      "Epoch 4: val_acc improved from 0.96270 to 0.96509, saving model to models/best_model_8_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.1029 - acc: 0.9654 - precision_m: 0.3858 - recall_m: 0.0821 - f1_m: 0.1283 - val_loss: 0.1028 - val_acc: 0.9651 - val_precision_m: 0.4955 - val_recall_m: 0.1091 - val_f1_m: 0.1698\n",
      "Epoch 5/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0995 - acc: 0.9667 - precision_m: 0.5381 - recall_m: 0.1470 - f1_m: 0.2160\n",
      "Epoch 5: val_acc improved from 0.96509 to 0.96699, saving model to models/best_model_8_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0991 - acc: 0.9668 - precision_m: 0.5345 - recall_m: 0.1470 - f1_m: 0.2149 - val_loss: 0.1005 - val_acc: 0.9670 - val_precision_m: 0.5899 - val_recall_m: 0.1900 - val_f1_m: 0.2717\n",
      "Epoch 6/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0943 - acc: 0.9679 - precision_m: 0.6274 - recall_m: 0.1949 - f1_m: 0.2788\n",
      "Epoch 6: val_acc did not improve from 0.96699\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0942 - acc: 0.9680 - precision_m: 0.6259 - recall_m: 0.1956 - f1_m: 0.2789 - val_loss: 0.1014 - val_acc: 0.9656 - val_precision_m: 0.4672 - val_recall_m: 0.1076 - val_f1_m: 0.1663\n",
      "Epoch 7/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0908 - acc: 0.9692 - precision_m: 0.6535 - recall_m: 0.2553 - f1_m: 0.3433\n",
      "Epoch 7: val_acc improved from 0.96699 to 0.96854, saving model to models/best_model_8_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0908 - acc: 0.9692 - precision_m: 0.6526 - recall_m: 0.2529 - f1_m: 0.3406 - val_loss: 0.0990 - val_acc: 0.9685 - val_precision_m: 0.5909 - val_recall_m: 0.1691 - val_f1_m: 0.2464\n",
      "Epoch 8/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9693 - precision_m: 0.6672 - recall_m: 0.2715 - f1_m: 0.3650\n",
      "Epoch 8: val_acc did not improve from 0.96854\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0888 - acc: 0.9692 - precision_m: 0.6659 - recall_m: 0.2692 - f1_m: 0.3622 - val_loss: 0.0998 - val_acc: 0.9685 - val_precision_m: 0.6423 - val_recall_m: 0.2144 - val_f1_m: 0.2994\n",
      "Epoch 9/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0869 - acc: 0.9697 - precision_m: 0.6608 - recall_m: 0.2973 - f1_m: 0.3832\n",
      "Epoch 9: val_acc improved from 0.96854 to 0.97104, saving model to models/best_model_8_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0869 - acc: 0.9698 - precision_m: 0.6615 - recall_m: 0.2976 - f1_m: 0.3837 - val_loss: 0.0913 - val_acc: 0.9710 - val_precision_m: 0.6956 - val_recall_m: 0.2814 - val_f1_m: 0.3769\n",
      "Epoch 10/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0841 - acc: 0.9709 - precision_m: 0.7123 - recall_m: 0.3331 - f1_m: 0.4228\n",
      "Epoch 10: val_acc did not improve from 0.97104\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0840 - acc: 0.9710 - precision_m: 0.7152 - recall_m: 0.3324 - f1_m: 0.4222 - val_loss: 0.1071 - val_acc: 0.9666 - val_precision_m: 0.5803 - val_recall_m: 0.1387 - val_f1_m: 0.2055\n",
      "Epoch 11/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0813 - acc: 0.9710 - precision_m: 0.7056 - recall_m: 0.3385 - f1_m: 0.4303\n",
      "Epoch 11: val_acc did not improve from 0.97104\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0812 - acc: 0.9711 - precision_m: 0.7068 - recall_m: 0.3389 - f1_m: 0.4312 - val_loss: 0.0943 - val_acc: 0.9700 - val_precision_m: 0.7116 - val_recall_m: 0.2552 - val_f1_m: 0.3539\n",
      "Epoch 12/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0799 - acc: 0.9720 - precision_m: 0.7154 - recall_m: 0.3585 - f1_m: 0.4490\n",
      "Epoch 12: val_acc did not improve from 0.97104\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0802 - acc: 0.9721 - precision_m: 0.7190 - recall_m: 0.3579 - f1_m: 0.4489 - val_loss: 0.0965 - val_acc: 0.9709 - val_precision_m: 0.7337 - val_recall_m: 0.2872 - val_f1_m: 0.3863\n",
      "Epoch 13/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0789 - acc: 0.9722 - precision_m: 0.7281 - recall_m: 0.3880 - f1_m: 0.4771\n",
      "Epoch 13: val_acc did not improve from 0.97104\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0787 - acc: 0.9721 - precision_m: 0.7232 - recall_m: 0.3844 - f1_m: 0.4726 - val_loss: 0.0987 - val_acc: 0.9708 - val_precision_m: 0.7135 - val_recall_m: 0.2611 - val_f1_m: 0.3557\n",
      "Epoch 14/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0774 - acc: 0.9724 - precision_m: 0.7217 - recall_m: 0.3792 - f1_m: 0.4698\n",
      "Epoch 14: val_acc improved from 0.97104 to 0.97176, saving model to models/best_model_8_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0770 - acc: 0.9725 - precision_m: 0.7264 - recall_m: 0.3782 - f1_m: 0.4699 - val_loss: 0.0931 - val_acc: 0.9718 - val_precision_m: 0.6512 - val_recall_m: 0.3910 - val_f1_m: 0.4539\n",
      "Epoch 15/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.0736 - acc: 0.9735 - precision_m: 0.7516 - recall_m: 0.4198 - f1_m: 0.5093\n",
      "Epoch 15: val_acc improved from 0.97176 to 0.97295, saving model to models/best_model_8_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0736 - acc: 0.9735 - precision_m: 0.7497 - recall_m: 0.4213 - f1_m: 0.5101 - val_loss: 0.0899 - val_acc: 0.9730 - val_precision_m: 0.7253 - val_recall_m: 0.3855 - val_f1_m: 0.4705\n",
      "Epoch 16/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0737 - acc: 0.9741 - precision_m: 0.7349 - recall_m: 0.4268 - f1_m: 0.5151\n",
      "Epoch 16: val_acc improved from 0.97295 to 0.97343, saving model to models/best_model_8_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0734 - acc: 0.9741 - precision_m: 0.7338 - recall_m: 0.4293 - f1_m: 0.5164 - val_loss: 0.0881 - val_acc: 0.9734 - val_precision_m: 0.7281 - val_recall_m: 0.4139 - val_f1_m: 0.4896\n",
      "Epoch 17/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0730 - acc: 0.9737 - precision_m: 0.7331 - recall_m: 0.4155 - f1_m: 0.5023\n",
      "Epoch 17: val_acc did not improve from 0.97343\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0730 - acc: 0.9736 - precision_m: 0.7302 - recall_m: 0.4132 - f1_m: 0.5000 - val_loss: 0.0892 - val_acc: 0.9728 - val_precision_m: 0.7448 - val_recall_m: 0.4047 - val_f1_m: 0.4881\n",
      "Epoch 18/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0699 - acc: 0.9747 - precision_m: 0.7404 - recall_m: 0.4503 - f1_m: 0.5368\n",
      "Epoch 18: val_acc did not improve from 0.97343\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0700 - acc: 0.9745 - precision_m: 0.7394 - recall_m: 0.4483 - f1_m: 0.5353 - val_loss: 0.0913 - val_acc: 0.9707 - val_precision_m: 0.6177 - val_recall_m: 0.4828 - val_f1_m: 0.5132\n",
      "Epoch 19/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0689 - acc: 0.9750 - precision_m: 0.7506 - recall_m: 0.4676 - f1_m: 0.5551\n",
      "Epoch 19: val_acc did not improve from 0.97343\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0688 - acc: 0.9750 - precision_m: 0.7501 - recall_m: 0.4674 - f1_m: 0.5545 - val_loss: 0.0931 - val_acc: 0.9726 - val_precision_m: 0.6418 - val_recall_m: 0.4316 - val_f1_m: 0.4851\n",
      "Epoch 20/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0690 - acc: 0.9755 - precision_m: 0.7704 - recall_m: 0.4640 - f1_m: 0.5482\n",
      "Epoch 20: val_acc did not improve from 0.97343\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0691 - acc: 0.9755 - precision_m: 0.7712 - recall_m: 0.4645 - f1_m: 0.5490 - val_loss: 0.0922 - val_acc: 0.9727 - val_precision_m: 0.7144 - val_recall_m: 0.3800 - val_f1_m: 0.4582\n",
      "Epoch 21/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0670 - acc: 0.9756 - precision_m: 0.7651 - recall_m: 0.4714 - f1_m: 0.5522\n",
      "Epoch 21: val_acc did not improve from 0.97343\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0672 - acc: 0.9756 - precision_m: 0.7649 - recall_m: 0.4702 - f1_m: 0.5511 - val_loss: 0.0944 - val_acc: 0.9734 - val_precision_m: 0.7595 - val_recall_m: 0.3557 - val_f1_m: 0.4463\n",
      "Epoch 22/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0654 - acc: 0.9762 - precision_m: 0.7658 - recall_m: 0.4888 - f1_m: 0.5668\n",
      "Epoch 22: val_acc did not improve from 0.97343\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0656 - acc: 0.9761 - precision_m: 0.7650 - recall_m: 0.4849 - f1_m: 0.5637 - val_loss: 0.0914 - val_acc: 0.9722 - val_precision_m: 0.7036 - val_recall_m: 0.4285 - val_f1_m: 0.4926\n",
      "Epoch 23/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0639 - acc: 0.9764 - precision_m: 0.7725 - recall_m: 0.4991 - f1_m: 0.5794\n",
      "Epoch 23: val_acc did not improve from 0.97343\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0639 - acc: 0.9765 - precision_m: 0.7719 - recall_m: 0.5007 - f1_m: 0.5809 - val_loss: 0.0976 - val_acc: 0.9725 - val_precision_m: 0.6741 - val_recall_m: 0.4746 - val_f1_m: 0.5226\n",
      "Epoch 24/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.0623 - acc: 0.9769 - precision_m: 0.7854 - recall_m: 0.5123 - f1_m: 0.5951\n",
      "Epoch 24: val_acc did not improve from 0.97343\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0623 - acc: 0.9769 - precision_m: 0.7854 - recall_m: 0.5123 - f1_m: 0.5951 - val_loss: 0.1016 - val_acc: 0.9732 - val_precision_m: 0.7724 - val_recall_m: 0.3302 - val_f1_m: 0.4289\n",
      "Epoch 25/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9771 - precision_m: 0.7787 - recall_m: 0.5015 - f1_m: 0.5861\n",
      "Epoch 25: val_acc did not improve from 0.97343\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0615 - acc: 0.9771 - precision_m: 0.7788 - recall_m: 0.5055 - f1_m: 0.5891 - val_loss: 0.0976 - val_acc: 0.9728 - val_precision_m: 0.7126 - val_recall_m: 0.4074 - val_f1_m: 0.4822\n",
      "Epoch 26/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0598 - acc: 0.9776 - precision_m: 0.7895 - recall_m: 0.5205 - f1_m: 0.6062\n",
      "Epoch 26: val_acc did not improve from 0.97343\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0602 - acc: 0.9775 - precision_m: 0.7906 - recall_m: 0.5182 - f1_m: 0.6041 - val_loss: 0.0960 - val_acc: 0.9697 - val_precision_m: 0.6124 - val_recall_m: 0.5335 - val_f1_m: 0.5278\n",
      "Epoch 27/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0603 - acc: 0.9777 - precision_m: 0.7786 - recall_m: 0.5270 - f1_m: 0.6014\n",
      "Epoch 27: val_acc did not improve from 0.97343\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0602 - acc: 0.9777 - precision_m: 0.7786 - recall_m: 0.5249 - f1_m: 0.5996 - val_loss: 0.0987 - val_acc: 0.9727 - val_precision_m: 0.7451 - val_recall_m: 0.3646 - val_f1_m: 0.4505\n",
      "Epoch 28/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0574 - acc: 0.9790 - precision_m: 0.8178 - recall_m: 0.5490 - f1_m: 0.6305\n",
      "Epoch 28: val_acc did not improve from 0.97343\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0574 - acc: 0.9790 - precision_m: 0.8193 - recall_m: 0.5477 - f1_m: 0.6298 - val_loss: 0.0967 - val_acc: 0.9704 - val_precision_m: 0.6017 - val_recall_m: 0.5018 - val_f1_m: 0.5191\n",
      "Epoch 29/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0569 - acc: 0.9785 - precision_m: 0.7873 - recall_m: 0.5449 - f1_m: 0.6188\n",
      "Epoch 29: val_acc did not improve from 0.97343\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0573 - acc: 0.9783 - precision_m: 0.7846 - recall_m: 0.5446 - f1_m: 0.6181 - val_loss: 0.0973 - val_acc: 0.9731 - val_precision_m: 0.7063 - val_recall_m: 0.4256 - val_f1_m: 0.5009\n",
      "Epoch 30/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0564 - acc: 0.9787 - precision_m: 0.7980 - recall_m: 0.5495 - f1_m: 0.6282\n",
      "Epoch 30: val_acc did not improve from 0.97343\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0564 - acc: 0.9787 - precision_m: 0.7991 - recall_m: 0.5496 - f1_m: 0.6285 - val_loss: 0.0966 - val_acc: 0.9719 - val_precision_m: 0.6423 - val_recall_m: 0.4442 - val_f1_m: 0.4956\n",
      "Score for fold 9: loss of 0.08814111351966858; acc of 97.34270572662354%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.08564753085374832; acc of 97.03302383422852%\n",
      "Test Precision: precision_m of 23.203575611114502%\n",
      "Test Recall: recall_m of 16.778025031089783%\n",
      "Test F1: f1_m of 18.370701372623444%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1699 - acc: 0.9601 - precision_m: 0.0062 - recall_m: 0.0049 - f1_m: 0.0025\n",
      "Epoch 1: val_acc improved from -inf to 0.96034, saving model to models/best_model_8_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 3s 5ms/step - loss: 0.1699 - acc: 0.9601 - precision_m: 0.0062 - recall_m: 0.0049 - f1_m: 0.0025 - val_loss: 0.1380 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.1247 - acc: 0.9646 - precision_m: 0.2131 - recall_m: 0.0326 - f1_m: 0.0544\n",
      "Epoch 2: val_acc did not improve from 0.96034\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1245 - acc: 0.9648 - precision_m: 0.2154 - recall_m: 0.0334 - f1_m: 0.0557 - val_loss: 0.1182 - val_acc: 0.9602 - val_precision_m: 0.1616 - val_recall_m: 0.0225 - val_f1_m: 0.0384\n",
      "Epoch 3/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.1093 - acc: 0.9658 - precision_m: 0.4557 - recall_m: 0.1042 - f1_m: 0.1601\n",
      "Epoch 3: val_acc improved from 0.96034 to 0.96142, saving model to models/best_model_8_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1094 - acc: 0.9657 - precision_m: 0.4599 - recall_m: 0.1064 - f1_m: 0.1626 - val_loss: 0.1138 - val_acc: 0.9614 - val_precision_m: 0.4862 - val_recall_m: 0.1527 - val_f1_m: 0.2098\n",
      "Epoch 4/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.1026 - acc: 0.9669 - precision_m: 0.5628 - recall_m: 0.1712 - f1_m: 0.2456\n",
      "Epoch 4: val_acc improved from 0.96142 to 0.96358, saving model to models/best_model_8_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1023 - acc: 0.9671 - precision_m: 0.5688 - recall_m: 0.1716 - f1_m: 0.2467 - val_loss: 0.1088 - val_acc: 0.9636 - val_precision_m: 0.6111 - val_recall_m: 0.1389 - val_f1_m: 0.2109\n",
      "Epoch 5/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0970 - acc: 0.9685 - precision_m: 0.6388 - recall_m: 0.2239 - f1_m: 0.3112\n",
      "Epoch 5: val_acc did not improve from 0.96358\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0965 - acc: 0.9686 - precision_m: 0.6356 - recall_m: 0.2246 - f1_m: 0.3119 - val_loss: 0.1245 - val_acc: 0.9609 - val_precision_m: 0.3333 - val_recall_m: 0.0478 - val_f1_m: 0.0804\n",
      "Epoch 6/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0937 - acc: 0.9688 - precision_m: 0.6754 - recall_m: 0.2420 - f1_m: 0.3337\n",
      "Epoch 6: val_acc improved from 0.96358 to 0.96538, saving model to models/best_model_8_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0936 - acc: 0.9688 - precision_m: 0.6785 - recall_m: 0.2459 - f1_m: 0.3384 - val_loss: 0.1058 - val_acc: 0.9654 - val_precision_m: 0.6571 - val_recall_m: 0.2348 - val_f1_m: 0.3186\n",
      "Epoch 7/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0898 - acc: 0.9697 - precision_m: 0.6580 - recall_m: 0.2986 - f1_m: 0.3848\n",
      "Epoch 7: val_acc improved from 0.96538 to 0.96562, saving model to models/best_model_8_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0894 - acc: 0.9699 - precision_m: 0.6667 - recall_m: 0.2993 - f1_m: 0.3871 - val_loss: 0.1052 - val_acc: 0.9656 - val_precision_m: 0.6816 - val_recall_m: 0.2529 - val_f1_m: 0.3449\n",
      "Epoch 8/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0870 - acc: 0.9704 - precision_m: 0.6828 - recall_m: 0.3214 - f1_m: 0.4121\n",
      "Epoch 8: val_acc did not improve from 0.96562\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0868 - acc: 0.9705 - precision_m: 0.6858 - recall_m: 0.3205 - f1_m: 0.4114 - val_loss: 0.1058 - val_acc: 0.9651 - val_precision_m: 0.6444 - val_recall_m: 0.2010 - val_f1_m: 0.2892\n",
      "Epoch 9/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0851 - acc: 0.9712 - precision_m: 0.6840 - recall_m: 0.3442 - f1_m: 0.4298\n",
      "Epoch 9: val_acc did not improve from 0.96562\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0856 - acc: 0.9709 - precision_m: 0.6800 - recall_m: 0.3380 - f1_m: 0.4233 - val_loss: 0.1005 - val_acc: 0.9655 - val_precision_m: 0.6037 - val_recall_m: 0.2761 - val_f1_m: 0.3460\n",
      "Epoch 10/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0833 - acc: 0.9713 - precision_m: 0.6994 - recall_m: 0.3424 - f1_m: 0.4333\n",
      "Epoch 10: val_acc improved from 0.96562 to 0.96635, saving model to models/best_model_8_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0830 - acc: 0.9713 - precision_m: 0.6999 - recall_m: 0.3412 - f1_m: 0.4324 - val_loss: 0.1101 - val_acc: 0.9663 - val_precision_m: 0.6820 - val_recall_m: 0.1766 - val_f1_m: 0.2694\n",
      "Epoch 11/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0802 - acc: 0.9724 - precision_m: 0.7234 - recall_m: 0.3749 - f1_m: 0.4675\n",
      "Epoch 11: val_acc did not improve from 0.96635\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0800 - acc: 0.9725 - precision_m: 0.7274 - recall_m: 0.3756 - f1_m: 0.4686 - val_loss: 0.1155 - val_acc: 0.9649 - val_precision_m: 0.5775 - val_recall_m: 0.1484 - val_f1_m: 0.2242\n",
      "Epoch 12/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0788 - acc: 0.9728 - precision_m: 0.7258 - recall_m: 0.3860 - f1_m: 0.4766\n",
      "Epoch 12: val_acc improved from 0.96635 to 0.96779, saving model to models/best_model_8_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0788 - acc: 0.9728 - precision_m: 0.7225 - recall_m: 0.3852 - f1_m: 0.4756 - val_loss: 0.1083 - val_acc: 0.9678 - val_precision_m: 0.6654 - val_recall_m: 0.3179 - val_f1_m: 0.4066\n",
      "Epoch 13/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0767 - acc: 0.9731 - precision_m: 0.7168 - recall_m: 0.3956 - f1_m: 0.4851\n",
      "Epoch 13: val_acc did not improve from 0.96779\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0769 - acc: 0.9730 - precision_m: 0.7169 - recall_m: 0.3963 - f1_m: 0.4859 - val_loss: 0.0999 - val_acc: 0.9673 - val_precision_m: 0.6240 - val_recall_m: 0.3235 - val_f1_m: 0.3971\n",
      "Epoch 14/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0753 - acc: 0.9735 - precision_m: 0.7367 - recall_m: 0.4144 - f1_m: 0.5056\n",
      "Epoch 14: val_acc did not improve from 0.96779\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0750 - acc: 0.9735 - precision_m: 0.7382 - recall_m: 0.4146 - f1_m: 0.5066 - val_loss: 0.1036 - val_acc: 0.9667 - val_precision_m: 0.6404 - val_recall_m: 0.2631 - val_f1_m: 0.3499\n",
      "Epoch 15/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0736 - acc: 0.9748 - precision_m: 0.7587 - recall_m: 0.4346 - f1_m: 0.5280\n",
      "Epoch 15: val_acc did not improve from 0.96779\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0734 - acc: 0.9747 - precision_m: 0.7557 - recall_m: 0.4335 - f1_m: 0.5266 - val_loss: 0.0990 - val_acc: 0.9673 - val_precision_m: 0.5978 - val_recall_m: 0.3905 - val_f1_m: 0.4373\n",
      "Epoch 16/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0711 - acc: 0.9751 - precision_m: 0.7583 - recall_m: 0.4551 - f1_m: 0.5445\n",
      "Epoch 16: val_acc did not improve from 0.96779\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0710 - acc: 0.9752 - precision_m: 0.7591 - recall_m: 0.4531 - f1_m: 0.5427 - val_loss: 0.1013 - val_acc: 0.9678 - val_precision_m: 0.5930 - val_recall_m: 0.4788 - val_f1_m: 0.4962\n",
      "Epoch 17/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0714 - acc: 0.9744 - precision_m: 0.7447 - recall_m: 0.4393 - f1_m: 0.5251\n",
      "Epoch 17: val_acc did not improve from 0.96779\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0709 - acc: 0.9746 - precision_m: 0.7454 - recall_m: 0.4416 - f1_m: 0.5274 - val_loss: 0.0979 - val_acc: 0.9675 - val_precision_m: 0.5785 - val_recall_m: 0.3757 - val_f1_m: 0.4293\n",
      "Epoch 18/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0686 - acc: 0.9754 - precision_m: 0.7399 - recall_m: 0.4671 - f1_m: 0.5500\n",
      "Epoch 18: val_acc did not improve from 0.96779\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0684 - acc: 0.9754 - precision_m: 0.7420 - recall_m: 0.4667 - f1_m: 0.5499 - val_loss: 0.1029 - val_acc: 0.9666 - val_precision_m: 0.5700 - val_recall_m: 0.4741 - val_f1_m: 0.4870\n",
      "Epoch 19/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0680 - acc: 0.9757 - precision_m: 0.7711 - recall_m: 0.4711 - f1_m: 0.5594\n",
      "Epoch 19: val_acc improved from 0.96779 to 0.97031, saving model to models/best_model_8_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0677 - acc: 0.9757 - precision_m: 0.7735 - recall_m: 0.4702 - f1_m: 0.5592 - val_loss: 0.1021 - val_acc: 0.9703 - val_precision_m: 0.6479 - val_recall_m: 0.3439 - val_f1_m: 0.4223\n",
      "Epoch 20/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0671 - acc: 0.9762 - precision_m: 0.7624 - recall_m: 0.4873 - f1_m: 0.5676\n",
      "Epoch 20: val_acc did not improve from 0.97031\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0670 - acc: 0.9763 - precision_m: 0.7656 - recall_m: 0.4855 - f1_m: 0.5671 - val_loss: 0.1088 - val_acc: 0.9692 - val_precision_m: 0.7236 - val_recall_m: 0.3037 - val_f1_m: 0.4018\n",
      "Epoch 21/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0650 - acc: 0.9767 - precision_m: 0.7845 - recall_m: 0.5033 - f1_m: 0.5865\n",
      "Epoch 21: val_acc did not improve from 0.97031\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0650 - acc: 0.9767 - precision_m: 0.7835 - recall_m: 0.5040 - f1_m: 0.5870 - val_loss: 0.1007 - val_acc: 0.9683 - val_precision_m: 0.5967 - val_recall_m: 0.4411 - val_f1_m: 0.4777\n",
      "Epoch 22/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0637 - acc: 0.9771 - precision_m: 0.7854 - recall_m: 0.5147 - f1_m: 0.5954\n",
      "Epoch 22: val_acc did not improve from 0.97031\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0634 - acc: 0.9771 - precision_m: 0.7862 - recall_m: 0.5147 - f1_m: 0.5959 - val_loss: 0.1103 - val_acc: 0.9689 - val_precision_m: 0.6834 - val_recall_m: 0.3220 - val_f1_m: 0.4083\n",
      "Epoch 23/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0625 - acc: 0.9773 - precision_m: 0.7764 - recall_m: 0.5077 - f1_m: 0.5905\n",
      "Epoch 23: val_acc did not improve from 0.97031\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0625 - acc: 0.9773 - precision_m: 0.7789 - recall_m: 0.5082 - f1_m: 0.5915 - val_loss: 0.1065 - val_acc: 0.9697 - val_precision_m: 0.7177 - val_recall_m: 0.3361 - val_f1_m: 0.4298\n",
      "Epoch 24/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0614 - acc: 0.9778 - precision_m: 0.8017 - recall_m: 0.5254 - f1_m: 0.6094\n",
      "Epoch 24: val_acc did not improve from 0.97031\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0612 - acc: 0.9778 - precision_m: 0.8047 - recall_m: 0.5249 - f1_m: 0.6099 - val_loss: 0.1071 - val_acc: 0.9694 - val_precision_m: 0.6339 - val_recall_m: 0.3711 - val_f1_m: 0.4425\n",
      "Epoch 25/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0603 - acc: 0.9778 - precision_m: 0.7678 - recall_m: 0.5308 - f1_m: 0.6039\n",
      "Epoch 25: val_acc did not improve from 0.97031\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0607 - acc: 0.9777 - precision_m: 0.7647 - recall_m: 0.5286 - f1_m: 0.6016 - val_loss: 0.1040 - val_acc: 0.9669 - val_precision_m: 0.5655 - val_recall_m: 0.3998 - val_f1_m: 0.4435\n",
      "Epoch 26/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0582 - acc: 0.9787 - precision_m: 0.8071 - recall_m: 0.5432 - f1_m: 0.6225\n",
      "Epoch 26: val_acc did not improve from 0.97031\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0583 - acc: 0.9787 - precision_m: 0.8081 - recall_m: 0.5428 - f1_m: 0.6228 - val_loss: 0.1043 - val_acc: 0.9692 - val_precision_m: 0.6560 - val_recall_m: 0.3464 - val_f1_m: 0.4275\n",
      "Epoch 27/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0577 - acc: 0.9792 - precision_m: 0.8172 - recall_m: 0.5596 - f1_m: 0.6373\n",
      "Epoch 27: val_acc did not improve from 0.97031\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0579 - acc: 0.9792 - precision_m: 0.8161 - recall_m: 0.5613 - f1_m: 0.6385 - val_loss: 0.1077 - val_acc: 0.9698 - val_precision_m: 0.6668 - val_recall_m: 0.3062 - val_f1_m: 0.3977\n",
      "Epoch 28/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0556 - acc: 0.9798 - precision_m: 0.8134 - recall_m: 0.5696 - f1_m: 0.6492\n",
      "Epoch 28: val_acc did not improve from 0.97031\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0553 - acc: 0.9799 - precision_m: 0.8162 - recall_m: 0.5711 - f1_m: 0.6512 - val_loss: 0.1099 - val_acc: 0.9655 - val_precision_m: 0.5166 - val_recall_m: 0.5160 - val_f1_m: 0.4943\n",
      "Epoch 29/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0566 - acc: 0.9796 - precision_m: 0.8173 - recall_m: 0.5733 - f1_m: 0.6475\n",
      "Epoch 29: val_acc improved from 0.97031 to 0.97115, saving model to models/best_model_8_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0566 - acc: 0.9796 - precision_m: 0.8179 - recall_m: 0.5698 - f1_m: 0.6455 - val_loss: 0.1167 - val_acc: 0.9712 - val_precision_m: 0.7738 - val_recall_m: 0.3520 - val_f1_m: 0.4520\n",
      "Epoch 30/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0543 - acc: 0.9799 - precision_m: 0.8168 - recall_m: 0.5835 - f1_m: 0.6569\n",
      "Epoch 30: val_acc did not improve from 0.97115\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0541 - acc: 0.9801 - precision_m: 0.8177 - recall_m: 0.5870 - f1_m: 0.6596 - val_loss: 0.1146 - val_acc: 0.9701 - val_precision_m: 0.6707 - val_recall_m: 0.4062 - val_f1_m: 0.4727\n",
      "Score for fold 10: loss of 0.11669228225946426; acc of 97.11538553237915%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.09920551627874374; acc of 97.01328873634338%\n",
      "Test Precision: precision_m of 22.573097050189972%\n",
      "Test Recall: recall_m of 14.421053230762482%\n",
      "Test F1: f1_m of 16.542868316173553%\n",
      "------------------------------------------------------------------------\n",
      "Validation score per fold\n",
      "> Fold 1 - Loss: 0.10350768268108368 - Accuracy: 96.9903290271759%\n",
      "> Fold 2 - Loss: 0.10370606184005737 - Accuracy: 97.16201424598694%\n",
      "> Fold 3 - Loss: 0.09607960283756256 - Accuracy: 97.07714319229126%\n",
      "> Fold 4 - Loss: 0.09697937220335007 - Accuracy: 97.11045026779175%\n",
      "> Fold 5 - Loss: 0.09451320767402649 - Accuracy: 97.07183241844177%\n",
      "> Fold 6 - Loss: 0.097646065056324 - Accuracy: 96.96275591850281%\n",
      "> Fold 7 - Loss: 0.0997496023774147 - Accuracy: 97.09677696228027%\n",
      "> Fold 8 - Loss: 0.10369522124528885 - Accuracy: 97.18495607376099%\n",
      "> Fold 9 - Loss: 0.08814111351966858 - Accuracy: 97.34270572662354%\n",
      "> Fold 10 - Loss: 0.11669228225946426 - Accuracy: 97.11538553237915%\n",
      "------------------------------------------------------------------------\n",
      "Testing score per fold\n",
      "> Fold 1 - Accuracy: 97.54567742347717 - Precision: 13.967135548591614 - Recall: 8.102503418922424 - F1: 9.646868705749512%\n",
      "> Fold 2 - Accuracy: 96.97522521018982 - Precision: 22.220319509506226 - Recall: 13.998425006866455 - F1: 16.1665216088295%\n",
      "> Fold 3 - Accuracy: 97.25925326347351 - Precision: 16.213150322437286 - Recall: 10.314220935106277 - F1: 11.716336756944656%\n",
      "> Fold 4 - Accuracy: 96.54874205589294 - Precision: 19.54440474510193 - Recall: 13.148252665996552 - F1: 14.565859735012054%\n",
      "> Fold 5 - Accuracy: 97.14926481246948 - Precision: 23.2195645570755 - Recall: 16.55755490064621 - F1: 18.14153790473938%\n",
      "> Fold 6 - Accuracy: 97.09435105323792 - Precision: 21.480654180049896 - Recall: 15.612873435020447 - F1: 16.844749450683594%\n",
      "> Fold 7 - Accuracy: 97.46586680412292 - Precision: 16.114982962608337 - Recall: 9.63539332151413 - F1: 11.231701076030731%\n",
      "> Fold 8 - Accuracy: 97.00188040733337 - Precision: 18.127208948135376 - Recall: 11.808468401432037 - F1: 13.401168584823608%\n",
      "> Fold 9 - Accuracy: 97.03302383422852 - Precision: 23.203575611114502 - Recall: 16.778025031089783 - F1: 18.370701372623444%\n",
      "> Fold 10 - Accuracy: 97.01328873634338 - Precision: 22.573097050189972 - Recall: 14.421053230762482 - F1: 16.542868316173553%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Validation Accuracy: 97.11143493652344 (+- 0.10059702299195328)\n",
      "> Validation Loss: 0.10007102116942405\n",
      "> Testing Accuracy: 97.1086573600769 (+- 0.26469682529268335)\n",
      "> Testing Precision: 19.666409343481064\n",
      "> Testing Recall: 13.03767703473568\n",
      "> Testing F1: 14.662831351161003\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Lists to hold cross-validation results\n",
    "acc_8_per_fold = []\n",
    "loss_8_per_fold = []\n",
    "precision_8_per_fold = []\n",
    "recall_8_per_fold = []\n",
    "f1_8_per_fold = []\n",
    "\n",
    "testing_acc_8_per_fold = []\n",
    "testing_precision_8_per_fold = []\n",
    "testing_recall_8_per_fold = []\n",
    "testing_f1_8_per_fold = []\n",
    "\n",
    "# Load data from .npz files\n",
    "for fold_no in range(1, 11):\n",
    "    with np.load(f'fold_{fold_no}.npz') as data:\n",
    "        x_train = data['x_train_fold.npy']\n",
    "        y_train = data['y_train_fold.npy']\n",
    "        x_val = data['x_val_fold.npy']\n",
    "        y_val = data['y_val_fold.npy']\n",
    "        x_test = data['x_test_fold.npy']\n",
    "        y_test = data['y_test_fold.npy']\n",
    "        \n",
    "        # Converting ground truth arrays to one wake word (1) and 'other' (0)\n",
    "        wake_word_index = all_targets.index(wake_word)\n",
    "        y_train = np.equal(y_train, wake_word_index).astype('float64')\n",
    "        y_val = np.equal(y_val, wake_word_index).astype('float64')\n",
    "        y_test = np.equal(y_test, wake_word_index).astype('float64')\n",
    "        \n",
    "        # CNN for TF expects (batch, height, width, channels)\n",
    "        x_train = x_train.reshape(x_train.shape[0], \n",
    "                          x_train.shape[1], \n",
    "                          x_train.shape[2], \n",
    "                          1)\n",
    "        x_val = x_val.reshape(x_val.shape[0], \n",
    "                          x_val.shape[1], \n",
    "                          x_val.shape[2], \n",
    "                          1)\n",
    "        x_test = x_test.reshape(x_test.shape[0], \n",
    "                          x_test.shape[1], \n",
    "                          x_test.shape[2], \n",
    "                          1)\n",
    "        sample_shape = x_test.shape[1:]\n",
    "\n",
    "    # CNN model\n",
    "    model_8 = models.Sequential()\n",
    "    model_8.add(layers.Conv2D(16, \n",
    "                            (1, 1), \n",
    "                            activation='relu',\n",
    "                            input_shape=sample_shape))\n",
    "    model_8.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model_8.add(layers.Conv2D(32, (2, 2), activation='relu'))\n",
    "    model_8.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model_8.add(layers.Conv2D(64, (2, 2), activation='relu'))\n",
    "    model_8.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Classifier\n",
    "    model_8.add(layers.Flatten())\n",
    "    model_8.add(layers.Dense(64, activation='relu'))\n",
    "    model_8.add(layers.Dropout(0.5))\n",
    "    model_8.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "\n",
    "    model_8.compile(loss='binary_crossentropy', \n",
    "              optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "              metrics=['acc', precision_m, recall_m, f1_m])\n",
    "\n",
    "    checkpoint_filepath = f'models/best_model_8_fold_{fold_no}.h5'\n",
    "    model_checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=False,\n",
    "        monitor='val_acc',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "        save_freq='epoch'\n",
    "    )\n",
    "\n",
    "    # Instantiate the custom callback\n",
    "    metrics_history = MetricsHistory()\n",
    "\n",
    "    # Print fold number\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Train\n",
    "    history_8 = model_8.fit(x_train, \n",
    "                    y_train, \n",
    "                    epochs=30, \n",
    "                    batch_size=256, \n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[model_checkpoint_callback, metrics_history])\n",
    "\n",
    "    model_8.load_weights(checkpoint_filepath)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    scores = model_8.evaluate(x_val, y_val, verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model_8.metrics_names[0]} of {scores[0]}; {model_8.metrics_names[1]} of {scores[1] * 100}%')\n",
    "    acc_8_per_fold.append(scores[1] * 100)\n",
    "    loss_8_per_fold.append(scores[0])\n",
    "    precision_8_per_fold.append(metrics_history.best_metrics['precision_m'] * 100)\n",
    "    recall_8_per_fold.append(metrics_history.best_metrics['recall_m'] * 100)\n",
    "    f1_8_per_fold.append(metrics_history.best_metrics['f1_m'] * 100)\n",
    "\n",
    "    # Final evaluation on test set\n",
    "    final_scores = model_8.evaluate(x_test, y_test, verbose=0)\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Final test score: {model_8.metrics_names[0]} of {final_scores[0]}; {model_8.metrics_names[1]} of {final_scores[1] * 100}%')\n",
    "    print(f'Test Precision: {model_8.metrics_names[2]} of {final_scores[2] * 100}%')\n",
    "    print(f'Test Recall: {model_8.metrics_names[3]} of {final_scores[3] * 100}%')\n",
    "    print(f'Test F1: {model_8.metrics_names[4]} of {final_scores[4] * 100}%')\n",
    "\n",
    "    # Append test metrics to lists\n",
    "    testing_acc_8_per_fold.append(final_scores[1] * 100)\n",
    "    testing_precision_8_per_fold.append(final_scores[2] * 100)\n",
    "    testing_recall_8_per_fold.append(final_scores[3] * 100)\n",
    "    testing_f1_8_per_fold.append(final_scores[4] * 100)\n",
    "\n",
    "# Print the results\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Validation score per fold')\n",
    "for i in range(0, len(acc_8_per_fold)):\n",
    "    print(f'> Fold {i+1} - Loss: {loss_8_per_fold[i]} - Accuracy: {acc_8_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Testing score per fold')\n",
    "for i in range(0, len(testing_acc_8_per_fold)):\n",
    "    print(f'> Fold {i+1} - Accuracy: {testing_acc_8_per_fold[i]} - Precision: {testing_precision_8_per_fold[i]} - Recall: {testing_recall_8_per_fold[i]} - F1: {testing_f1_8_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Validation Accuracy: {np.mean(acc_8_per_fold)} (+- {np.std(acc_8_per_fold)})')\n",
    "print(f'> Validation Loss: {np.mean(loss_8_per_fold)}')\n",
    "print(f'> Testing Accuracy: {np.mean(testing_acc_8_per_fold)} (+- {np.std(testing_acc_8_per_fold)})')\n",
    "print(f'> Testing Precision: {np.mean(testing_precision_8_per_fold)}')\n",
    "print(f'> Testing Recall: {np.mean(testing_recall_8_per_fold)}')\n",
    "print(f'> Testing F1: {np.mean(testing_f1_8_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1696 - acc: 0.9554 - precision_m: 5.5651e-04 - recall_m: 0.0071 - f1_m: 9.9328e-04\n",
      "Epoch 1: val_acc improved from -inf to 0.96023, saving model to models/best_model_9_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 2s 3ms/step - loss: 0.1696 - acc: 0.9554 - precision_m: 5.5651e-04 - recall_m: 0.0071 - f1_m: 9.9328e-04 - val_loss: 0.1412 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1303 - acc: 0.9629 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 2: val_acc did not improve from 0.96023\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1304 - acc: 0.9628 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1362 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 3/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.1197 - acc: 0.9629 - precision_m: 0.0414 - recall_m: 0.0045 - f1_m: 0.0081     \n",
      "Epoch 3: val_acc improved from 0.96023 to 0.96071, saving model to models/best_model_9_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1196 - acc: 0.9629 - precision_m: 0.0411 - recall_m: 0.0045 - f1_m: 0.0080 - val_loss: 0.1289 - val_acc: 0.9607 - val_precision_m: 0.1515 - val_recall_m: 0.0097 - val_f1_m: 0.0181\n",
      "Epoch 4/30\n",
      "272/292 [==========================>...] - ETA: 0s - loss: 0.1112 - acc: 0.9639 - precision_m: 0.3205 - recall_m: 0.0521 - f1_m: 0.0866 \n",
      "Epoch 4: val_acc improved from 0.96071 to 0.96154, saving model to models/best_model_9_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1109 - acc: 0.9639 - precision_m: 0.3208 - recall_m: 0.0519 - f1_m: 0.0865 - val_loss: 0.1137 - val_acc: 0.9615 - val_precision_m: 0.3485 - val_recall_m: 0.0418 - val_f1_m: 0.0723\n",
      "Epoch 5/30\n",
      "272/292 [==========================>...] - ETA: 0s - loss: 0.1057 - acc: 0.9643 - precision_m: 0.4376 - recall_m: 0.0801 - f1_m: 0.1271 \n",
      "Epoch 5: val_acc improved from 0.96154 to 0.96202, saving model to models/best_model_9_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1057 - acc: 0.9642 - precision_m: 0.4321 - recall_m: 0.0785 - f1_m: 0.1250 - val_loss: 0.1154 - val_acc: 0.9620 - val_precision_m: 0.4343 - val_recall_m: 0.0779 - val_f1_m: 0.1260\n",
      "Epoch 6/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.1020 - acc: 0.9643 - precision_m: 0.4547 - recall_m: 0.0868 - f1_m: 0.1374\n",
      "Epoch 6: val_acc did not improve from 0.96202\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1025 - acc: 0.9640 - precision_m: 0.4550 - recall_m: 0.0865 - f1_m: 0.1372 - val_loss: 0.1099 - val_acc: 0.9620 - val_precision_m: 0.4975 - val_recall_m: 0.1047 - val_f1_m: 0.1608\n",
      "Epoch 7/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.1003 - acc: 0.9644 - precision_m: 0.4635 - recall_m: 0.1027 - f1_m: 0.1594\n",
      "Epoch 7: val_acc did not improve from 0.96202\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1003 - acc: 0.9644 - precision_m: 0.4672 - recall_m: 0.1038 - f1_m: 0.1612 - val_loss: 0.1083 - val_acc: 0.9618 - val_precision_m: 0.4545 - val_recall_m: 0.0768 - val_f1_m: 0.1236\n",
      "Epoch 8/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0982 - acc: 0.9648 - precision_m: 0.5016 - recall_m: 0.1081 - f1_m: 0.1683\n",
      "Epoch 8: val_acc improved from 0.96202 to 0.96286, saving model to models/best_model_9_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0984 - acc: 0.9647 - precision_m: 0.4998 - recall_m: 0.1075 - f1_m: 0.1674 - val_loss: 0.1079 - val_acc: 0.9629 - val_precision_m: 0.4495 - val_recall_m: 0.0893 - val_f1_m: 0.1418\n",
      "Epoch 9/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.0975 - acc: 0.9651 - precision_m: 0.5089 - recall_m: 0.1128 - f1_m: 0.1751\n",
      "Epoch 9: val_acc did not improve from 0.96286\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0974 - acc: 0.9651 - precision_m: 0.5072 - recall_m: 0.1124 - f1_m: 0.1745 - val_loss: 0.1091 - val_acc: 0.9624 - val_precision_m: 0.4545 - val_recall_m: 0.0758 - val_f1_m: 0.1244\n",
      "Epoch 10/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.0964 - acc: 0.9647 - precision_m: 0.5201 - recall_m: 0.1134 - f1_m: 0.1780\n",
      "Epoch 10: val_acc did not improve from 0.96286\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0964 - acc: 0.9647 - precision_m: 0.5201 - recall_m: 0.1134 - f1_m: 0.1780 - val_loss: 0.1144 - val_acc: 0.9611 - val_precision_m: 0.2424 - val_recall_m: 0.0290 - val_f1_m: 0.0509\n",
      "Epoch 11/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0967 - acc: 0.9650 - precision_m: 0.5234 - recall_m: 0.1179 - f1_m: 0.1825\n",
      "Epoch 11: val_acc did not improve from 0.96286\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0968 - acc: 0.9650 - precision_m: 0.5249 - recall_m: 0.1182 - f1_m: 0.1830 - val_loss: 0.1064 - val_acc: 0.9621 - val_precision_m: 0.4949 - val_recall_m: 0.0949 - val_f1_m: 0.1515\n",
      "Epoch 12/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0955 - acc: 0.9647 - precision_m: 0.5088 - recall_m: 0.1151 - f1_m: 0.1767\n",
      "Epoch 12: val_acc did not improve from 0.96286\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0955 - acc: 0.9647 - precision_m: 0.5052 - recall_m: 0.1139 - f1_m: 0.1751 - val_loss: 0.1085 - val_acc: 0.9627 - val_precision_m: 0.5253 - val_recall_m: 0.1241 - val_f1_m: 0.1912\n",
      "Epoch 13/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0945 - acc: 0.9648 - precision_m: 0.5127 - recall_m: 0.1182 - f1_m: 0.1831\n",
      "Epoch 13: val_acc did not improve from 0.96286\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0947 - acc: 0.9647 - precision_m: 0.5142 - recall_m: 0.1179 - f1_m: 0.1827 - val_loss: 0.1093 - val_acc: 0.9621 - val_precision_m: 0.4919 - val_recall_m: 0.1207 - val_f1_m: 0.1819\n",
      "Epoch 14/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.0943 - acc: 0.9651 - precision_m: 0.5719 - recall_m: 0.1282 - f1_m: 0.1992\n",
      "Epoch 14: val_acc did not improve from 0.96286\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0943 - acc: 0.9651 - precision_m: 0.5719 - recall_m: 0.1282 - f1_m: 0.1992 - val_loss: 0.1101 - val_acc: 0.9625 - val_precision_m: 0.4747 - val_recall_m: 0.0750 - val_f1_m: 0.1256\n",
      "Epoch 15/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0938 - acc: 0.9650 - precision_m: 0.5395 - recall_m: 0.1233 - f1_m: 0.1896\n",
      "Epoch 15: val_acc improved from 0.96286 to 0.96310, saving model to models/best_model_9_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0938 - acc: 0.9650 - precision_m: 0.5366 - recall_m: 0.1226 - f1_m: 0.1886 - val_loss: 0.1085 - val_acc: 0.9631 - val_precision_m: 0.5354 - val_recall_m: 0.0934 - val_f1_m: 0.1542\n",
      "Epoch 16/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0934 - acc: 0.9653 - precision_m: 0.5487 - recall_m: 0.1247 - f1_m: 0.1949\n",
      "Epoch 16: val_acc did not improve from 0.96310\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0934 - acc: 0.9653 - precision_m: 0.5526 - recall_m: 0.1254 - f1_m: 0.1961 - val_loss: 0.1087 - val_acc: 0.9621 - val_precision_m: 0.4848 - val_recall_m: 0.0792 - val_f1_m: 0.1316\n",
      "Epoch 17/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.0924 - acc: 0.9651 - precision_m: 0.5687 - recall_m: 0.1234 - f1_m: 0.1952\n",
      "Epoch 17: val_acc did not improve from 0.96310\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0924 - acc: 0.9651 - precision_m: 0.5687 - recall_m: 0.1234 - f1_m: 0.1952 - val_loss: 0.1082 - val_acc: 0.9623 - val_precision_m: 0.4949 - val_recall_m: 0.1244 - val_f1_m: 0.1899\n",
      "Epoch 18/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0922 - acc: 0.9654 - precision_m: 0.5568 - recall_m: 0.1264 - f1_m: 0.1961\n",
      "Epoch 18: val_acc did not improve from 0.96310\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0921 - acc: 0.9654 - precision_m: 0.5564 - recall_m: 0.1262 - f1_m: 0.1959 - val_loss: 0.1072 - val_acc: 0.9619 - val_precision_m: 0.4949 - val_recall_m: 0.1316 - val_f1_m: 0.1991\n",
      "Epoch 19/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0918 - acc: 0.9652 - precision_m: 0.5340 - recall_m: 0.1288 - f1_m: 0.1960\n",
      "Epoch 19: val_acc did not improve from 0.96310\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0919 - acc: 0.9652 - precision_m: 0.5348 - recall_m: 0.1295 - f1_m: 0.1966 - val_loss: 0.1047 - val_acc: 0.9627 - val_precision_m: 0.4646 - val_recall_m: 0.0962 - val_f1_m: 0.1560\n",
      "Epoch 20/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.0920 - acc: 0.9651 - precision_m: 0.5739 - recall_m: 0.1284 - f1_m: 0.1984\n",
      "Epoch 20: val_acc did not improve from 0.96310\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0919 - acc: 0.9652 - precision_m: 0.5719 - recall_m: 0.1279 - f1_m: 0.1977 - val_loss: 0.1083 - val_acc: 0.9619 - val_precision_m: 0.4091 - val_recall_m: 0.0637 - val_f1_m: 0.1065\n",
      "Epoch 21/30\n",
      "271/292 [==========================>...] - ETA: 0s - loss: 0.0908 - acc: 0.9656 - precision_m: 0.5901 - recall_m: 0.1307 - f1_m: 0.2045 \n",
      "Epoch 21: val_acc did not improve from 0.96310\n",
      "292/292 [==============================] - 1s 2ms/step - loss: 0.0908 - acc: 0.9655 - precision_m: 0.5879 - recall_m: 0.1318 - f1_m: 0.2055 - val_loss: 0.1086 - val_acc: 0.9612 - val_precision_m: 0.4641 - val_recall_m: 0.1234 - val_f1_m: 0.1845\n",
      "Epoch 22/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0914 - acc: 0.9654 - precision_m: 0.5557 - recall_m: 0.1299 - f1_m: 0.1997\n",
      "Epoch 22: val_acc did not improve from 0.96310\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0914 - acc: 0.9654 - precision_m: 0.5603 - recall_m: 0.1298 - f1_m: 0.1998 - val_loss: 0.1081 - val_acc: 0.9621 - val_precision_m: 0.5152 - val_recall_m: 0.1002 - val_f1_m: 0.1596\n",
      "Epoch 23/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.0898 - acc: 0.9655 - precision_m: 0.5598 - recall_m: 0.1286 - f1_m: 0.1993\n",
      "Epoch 23: val_acc did not improve from 0.96310\n",
      "292/292 [==============================] - 1s 2ms/step - loss: 0.0898 - acc: 0.9655 - precision_m: 0.5598 - recall_m: 0.1286 - f1_m: 0.1993 - val_loss: 0.1070 - val_acc: 0.9623 - val_precision_m: 0.5051 - val_recall_m: 0.1164 - val_f1_m: 0.1818\n",
      "Epoch 24/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.0901 - acc: 0.9655 - precision_m: 0.5738 - recall_m: 0.1322 - f1_m: 0.2037\n",
      "Epoch 24: val_acc did not improve from 0.96310\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0902 - acc: 0.9654 - precision_m: 0.5719 - recall_m: 0.1318 - f1_m: 0.2030 - val_loss: 0.1097 - val_acc: 0.9614 - val_precision_m: 0.4520 - val_recall_m: 0.1340 - val_f1_m: 0.2000\n",
      "Epoch 25/30\n",
      "272/292 [==========================>...] - ETA: 0s - loss: 0.0906 - acc: 0.9652 - precision_m: 0.5933 - recall_m: 0.1370 - f1_m: 0.2096\n",
      "Epoch 25: val_acc did not improve from 0.96310\n",
      "292/292 [==============================] - 1s 2ms/step - loss: 0.0902 - acc: 0.9653 - precision_m: 0.5855 - recall_m: 0.1350 - f1_m: 0.2071 - val_loss: 0.1117 - val_acc: 0.9614 - val_precision_m: 0.3939 - val_recall_m: 0.0548 - val_f1_m: 0.0918\n",
      "Epoch 26/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.0906 - acc: 0.9652 - precision_m: 0.5127 - recall_m: 0.1285 - f1_m: 0.1949\n",
      "Epoch 26: val_acc did not improve from 0.96310\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0907 - acc: 0.9652 - precision_m: 0.5109 - recall_m: 0.1280 - f1_m: 0.1942 - val_loss: 0.1091 - val_acc: 0.9629 - val_precision_m: 0.5455 - val_recall_m: 0.1027 - val_f1_m: 0.1668\n",
      "Epoch 27/30\n",
      "270/292 [==========================>...] - ETA: 0s - loss: 0.0893 - acc: 0.9657 - precision_m: 0.5465 - recall_m: 0.1346 - f1_m: 0.2035\n",
      "Epoch 27: val_acc did not improve from 0.96310\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0895 - acc: 0.9656 - precision_m: 0.5456 - recall_m: 0.1332 - f1_m: 0.2021 - val_loss: 0.1095 - val_acc: 0.9619 - val_precision_m: 0.4192 - val_recall_m: 0.0668 - val_f1_m: 0.1130\n",
      "Epoch 28/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0894 - acc: 0.9654 - precision_m: 0.5891 - recall_m: 0.1316 - f1_m: 0.2025\n",
      "Epoch 28: val_acc did not improve from 0.96310\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0896 - acc: 0.9654 - precision_m: 0.5885 - recall_m: 0.1310 - f1_m: 0.2017 - val_loss: 0.1076 - val_acc: 0.9618 - val_precision_m: 0.4646 - val_recall_m: 0.1317 - val_f1_m: 0.1987\n",
      "Epoch 29/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0896 - acc: 0.9653 - precision_m: 0.5386 - recall_m: 0.1339 - f1_m: 0.2022\n",
      "Epoch 29: val_acc did not improve from 0.96310\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0896 - acc: 0.9654 - precision_m: 0.5408 - recall_m: 0.1364 - f1_m: 0.2058 - val_loss: 0.1057 - val_acc: 0.9624 - val_precision_m: 0.4662 - val_recall_m: 0.1231 - val_f1_m: 0.1879\n",
      "Epoch 30/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9656 - precision_m: 0.5884 - recall_m: 0.1387 - f1_m: 0.2130\n",
      "Epoch 30: val_acc did not improve from 0.96310\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0888 - acc: 0.9656 - precision_m: 0.5835 - recall_m: 0.1379 - f1_m: 0.2117 - val_loss: 0.1073 - val_acc: 0.9609 - val_precision_m: 0.4288 - val_recall_m: 0.1401 - val_f1_m: 0.2031\n",
      "Score for fold 1: loss of 0.1084606721997261; acc of 96.30956649780273%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.08367341011762619; acc of 97.18247652053833%\n",
      "Test Precision: precision_m of 7.335679978132248%\n",
      "Test Recall: recall_m of 3.9094284176826477%\n",
      "Test F1: f1_m of 4.689855873584747%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.1407 - acc: 0.9635 - precision_m: 0.2327 - recall_m: 0.0570 - f1_m: 0.0866 \n",
      "Epoch 1: val_acc improved from -inf to 0.96276, saving model to models/best_model_9_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 2s 3ms/step - loss: 0.1407 - acc: 0.9635 - precision_m: 0.2327 - recall_m: 0.0570 - f1_m: 0.0866 - val_loss: 0.1167 - val_acc: 0.9628 - val_precision_m: 0.2852 - val_recall_m: 0.0782 - val_f1_m: 0.1168\n",
      "Epoch 2/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.1069 - acc: 0.9665 - precision_m: 0.5551 - recall_m: 0.1735 - f1_m: 0.2462\n",
      "Epoch 2: val_acc did not improve from 0.96276\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1070 - acc: 0.9665 - precision_m: 0.5542 - recall_m: 0.1741 - f1_m: 0.2468 - val_loss: 0.1215 - val_acc: 0.9558 - val_precision_m: 0.4092 - val_recall_m: 0.3461 - val_f1_m: 0.3535\n",
      "Epoch 3/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0949 - acc: 0.9684 - precision_m: 0.6175 - recall_m: 0.2597 - f1_m: 0.3387\n",
      "Epoch 3: val_acc improved from 0.96276 to 0.96791, saving model to models/best_model_9_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0949 - acc: 0.9684 - precision_m: 0.6184 - recall_m: 0.2590 - f1_m: 0.3382 - val_loss: 0.0918 - val_acc: 0.9679 - val_precision_m: 0.5555 - val_recall_m: 0.2169 - val_f1_m: 0.2936\n",
      "Epoch 4/30\n",
      "271/291 [==========================>...] - ETA: 0s - loss: 0.0886 - acc: 0.9699 - precision_m: 0.6699 - recall_m: 0.3254 - f1_m: 0.4132\n",
      "Epoch 4: val_acc improved from 0.96791 to 0.96827, saving model to models/best_model_9_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0887 - acc: 0.9697 - precision_m: 0.6583 - recall_m: 0.3228 - f1_m: 0.4082 - val_loss: 0.0950 - val_acc: 0.9683 - val_precision_m: 0.5769 - val_recall_m: 0.2281 - val_f1_m: 0.3078\n",
      "Epoch 5/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0842 - acc: 0.9711 - precision_m: 0.6842 - recall_m: 0.3730 - f1_m: 0.4540\n",
      "Epoch 5: val_acc improved from 0.96827 to 0.96899, saving model to models/best_model_9_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0841 - acc: 0.9712 - precision_m: 0.6863 - recall_m: 0.3740 - f1_m: 0.4553 - val_loss: 0.1034 - val_acc: 0.9690 - val_precision_m: 0.6023 - val_recall_m: 0.1707 - val_f1_m: 0.2478\n",
      "Epoch 6/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.0817 - acc: 0.9718 - precision_m: 0.6960 - recall_m: 0.3924 - f1_m: 0.4726\n",
      "Epoch 6: val_acc did not improve from 0.96899\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0817 - acc: 0.9718 - precision_m: 0.6960 - recall_m: 0.3924 - f1_m: 0.4726 - val_loss: 0.0924 - val_acc: 0.9686 - val_precision_m: 0.5852 - val_recall_m: 0.3080 - val_f1_m: 0.3784\n",
      "Epoch 7/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0800 - acc: 0.9726 - precision_m: 0.7024 - recall_m: 0.4201 - f1_m: 0.4988\n",
      "Epoch 7: val_acc did not improve from 0.96899\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0798 - acc: 0.9726 - precision_m: 0.7021 - recall_m: 0.4214 - f1_m: 0.4997 - val_loss: 0.0902 - val_acc: 0.9675 - val_precision_m: 0.5777 - val_recall_m: 0.2477 - val_f1_m: 0.3139\n",
      "Epoch 8/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0770 - acc: 0.9735 - precision_m: 0.7273 - recall_m: 0.4242 - f1_m: 0.5098\n",
      "Epoch 8: val_acc did not improve from 0.96899\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0770 - acc: 0.9735 - precision_m: 0.7271 - recall_m: 0.4252 - f1_m: 0.5106 - val_loss: 0.0918 - val_acc: 0.9690 - val_precision_m: 0.6534 - val_recall_m: 0.2813 - val_f1_m: 0.3556\n",
      "Epoch 9/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0760 - acc: 0.9734 - precision_m: 0.7139 - recall_m: 0.4415 - f1_m: 0.5185\n",
      "Epoch 9: val_acc did not improve from 0.96899\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0757 - acc: 0.9735 - precision_m: 0.7174 - recall_m: 0.4435 - f1_m: 0.5210 - val_loss: 0.0962 - val_acc: 0.9674 - val_precision_m: 0.5501 - val_recall_m: 0.1616 - val_f1_m: 0.2369\n",
      "Epoch 10/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0735 - acc: 0.9747 - precision_m: 0.7375 - recall_m: 0.4538 - f1_m: 0.5398\n",
      "Epoch 10: val_acc improved from 0.96899 to 0.96946, saving model to models/best_model_9_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0735 - acc: 0.9747 - precision_m: 0.7372 - recall_m: 0.4563 - f1_m: 0.5414 - val_loss: 0.0893 - val_acc: 0.9695 - val_precision_m: 0.5898 - val_recall_m: 0.3760 - val_f1_m: 0.4269\n",
      "Epoch 11/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0736 - acc: 0.9738 - precision_m: 0.7150 - recall_m: 0.4531 - f1_m: 0.5301\n",
      "Epoch 11: val_acc did not improve from 0.96946\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0737 - acc: 0.9738 - precision_m: 0.7135 - recall_m: 0.4519 - f1_m: 0.5289 - val_loss: 0.0909 - val_acc: 0.9681 - val_precision_m: 0.5638 - val_recall_m: 0.3501 - val_f1_m: 0.4065\n",
      "Epoch 12/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0726 - acc: 0.9746 - precision_m: 0.7154 - recall_m: 0.4554 - f1_m: 0.5269\n",
      "Epoch 12: val_acc did not improve from 0.96946\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0727 - acc: 0.9745 - precision_m: 0.7171 - recall_m: 0.4547 - f1_m: 0.5271 - val_loss: 0.0931 - val_acc: 0.9670 - val_precision_m: 0.5410 - val_recall_m: 0.4265 - val_f1_m: 0.4512\n",
      "Epoch 13/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.0705 - acc: 0.9755 - precision_m: 0.7520 - recall_m: 0.4836 - f1_m: 0.5628\n",
      "Epoch 13: val_acc did not improve from 0.96946\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0705 - acc: 0.9755 - precision_m: 0.7520 - recall_m: 0.4836 - f1_m: 0.5628 - val_loss: 0.0971 - val_acc: 0.9640 - val_precision_m: 0.5067 - val_recall_m: 0.5014 - val_f1_m: 0.4634\n",
      "Epoch 14/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0704 - acc: 0.9755 - precision_m: 0.7462 - recall_m: 0.4944 - f1_m: 0.5680\n",
      "Epoch 14: val_acc did not improve from 0.96946\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0704 - acc: 0.9755 - precision_m: 0.7454 - recall_m: 0.4966 - f1_m: 0.5692 - val_loss: 0.0890 - val_acc: 0.9689 - val_precision_m: 0.6039 - val_recall_m: 0.3876 - val_f1_m: 0.4345\n",
      "Epoch 15/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.0702 - acc: 0.9754 - precision_m: 0.7345 - recall_m: 0.4917 - f1_m: 0.5641\n",
      "Epoch 15: val_acc improved from 0.96946 to 0.97102, saving model to models/best_model_9_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0702 - acc: 0.9753 - precision_m: 0.7343 - recall_m: 0.4909 - f1_m: 0.5634 - val_loss: 0.0922 - val_acc: 0.9710 - val_precision_m: 0.7064 - val_recall_m: 0.2969 - val_f1_m: 0.3883\n",
      "Epoch 16/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.0687 - acc: 0.9758 - precision_m: 0.7463 - recall_m: 0.4887 - f1_m: 0.5678\n",
      "Epoch 16: val_acc did not improve from 0.97102\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0686 - acc: 0.9758 - precision_m: 0.7472 - recall_m: 0.4890 - f1_m: 0.5684 - val_loss: 0.0909 - val_acc: 0.9693 - val_precision_m: 0.5786 - val_recall_m: 0.3885 - val_f1_m: 0.4319\n",
      "Epoch 17/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.9764 - precision_m: 0.7664 - recall_m: 0.5078 - f1_m: 0.5834\n",
      "Epoch 17: val_acc did not improve from 0.97102\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0682 - acc: 0.9766 - precision_m: 0.7669 - recall_m: 0.5090 - f1_m: 0.5847 - val_loss: 0.0965 - val_acc: 0.9681 - val_precision_m: 0.5881 - val_recall_m: 0.2765 - val_f1_m: 0.3549\n",
      "Epoch 18/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0673 - acc: 0.9761 - precision_m: 0.7622 - recall_m: 0.5003 - f1_m: 0.5786\n",
      "Epoch 18: val_acc did not improve from 0.97102\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0675 - acc: 0.9760 - precision_m: 0.7616 - recall_m: 0.5013 - f1_m: 0.5791 - val_loss: 0.0892 - val_acc: 0.9686 - val_precision_m: 0.5942 - val_recall_m: 0.4262 - val_f1_m: 0.4523\n",
      "Epoch 19/30\n",
      "269/291 [==========================>...] - ETA: 0s - loss: 0.0669 - acc: 0.9766 - precision_m: 0.7742 - recall_m: 0.5146 - f1_m: 0.5929\n",
      "Epoch 19: val_acc did not improve from 0.97102\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.0670 - acc: 0.9765 - precision_m: 0.7724 - recall_m: 0.5105 - f1_m: 0.5892 - val_loss: 0.0920 - val_acc: 0.9660 - val_precision_m: 0.5262 - val_recall_m: 0.4322 - val_f1_m: 0.4458\n",
      "Epoch 20/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0666 - acc: 0.9764 - precision_m: 0.7685 - recall_m: 0.5095 - f1_m: 0.5866\n",
      "Epoch 20: val_acc did not improve from 0.97102\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0665 - acc: 0.9765 - precision_m: 0.7672 - recall_m: 0.5106 - f1_m: 0.5868 - val_loss: 0.0903 - val_acc: 0.9684 - val_precision_m: 0.5935 - val_recall_m: 0.4724 - val_f1_m: 0.4883\n",
      "Epoch 21/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.0670 - acc: 0.9764 - precision_m: 0.7594 - recall_m: 0.5120 - f1_m: 0.5853\n",
      "Epoch 21: val_acc did not improve from 0.97102\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0670 - acc: 0.9764 - precision_m: 0.7589 - recall_m: 0.5124 - f1_m: 0.5854 - val_loss: 0.0908 - val_acc: 0.9703 - val_precision_m: 0.5723 - val_recall_m: 0.4003 - val_f1_m: 0.4393\n",
      "Epoch 22/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.0664 - acc: 0.9770 - precision_m: 0.7666 - recall_m: 0.5342 - f1_m: 0.6036\n",
      "Epoch 22: val_acc did not improve from 0.97102\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0664 - acc: 0.9770 - precision_m: 0.7666 - recall_m: 0.5342 - f1_m: 0.6036 - val_loss: 0.0896 - val_acc: 0.9695 - val_precision_m: 0.6001 - val_recall_m: 0.3094 - val_f1_m: 0.3808\n",
      "Epoch 23/30\n",
      "272/291 [===========================>..] - ETA: 0s - loss: 0.0651 - acc: 0.9771 - precision_m: 0.7679 - recall_m: 0.5270 - f1_m: 0.6016\n",
      "Epoch 23: val_acc did not improve from 0.97102\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0658 - acc: 0.9769 - precision_m: 0.7652 - recall_m: 0.5195 - f1_m: 0.5940 - val_loss: 0.0941 - val_acc: 0.9704 - val_precision_m: 0.6047 - val_recall_m: 0.3374 - val_f1_m: 0.4103\n",
      "Epoch 24/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0646 - acc: 0.9774 - precision_m: 0.7720 - recall_m: 0.5283 - f1_m: 0.6034\n",
      "Epoch 24: val_acc did not improve from 0.97102\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0648 - acc: 0.9774 - precision_m: 0.7716 - recall_m: 0.5281 - f1_m: 0.6033 - val_loss: 0.0937 - val_acc: 0.9709 - val_precision_m: 0.6186 - val_recall_m: 0.3842 - val_f1_m: 0.4453\n",
      "Epoch 25/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0647 - acc: 0.9773 - precision_m: 0.7670 - recall_m: 0.5276 - f1_m: 0.6014\n",
      "Epoch 25: val_acc did not improve from 0.97102\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0647 - acc: 0.9773 - precision_m: 0.7677 - recall_m: 0.5265 - f1_m: 0.6007 - val_loss: 0.0900 - val_acc: 0.9697 - val_precision_m: 0.5841 - val_recall_m: 0.4083 - val_f1_m: 0.4463\n",
      "Epoch 26/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0649 - acc: 0.9771 - precision_m: 0.7579 - recall_m: 0.5236 - f1_m: 0.5983\n",
      "Epoch 26: val_acc did not improve from 0.97102\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0648 - acc: 0.9772 - precision_m: 0.7601 - recall_m: 0.5238 - f1_m: 0.5992 - val_loss: 0.0897 - val_acc: 0.9707 - val_precision_m: 0.6251 - val_recall_m: 0.4049 - val_f1_m: 0.4557\n",
      "Epoch 27/30\n",
      "269/291 [==========================>...] - ETA: 0s - loss: 0.0654 - acc: 0.9774 - precision_m: 0.7614 - recall_m: 0.5361 - f1_m: 0.6029\n",
      "Epoch 27: val_acc did not improve from 0.97102\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0648 - acc: 0.9775 - precision_m: 0.7630 - recall_m: 0.5361 - f1_m: 0.6038 - val_loss: 0.0934 - val_acc: 0.9698 - val_precision_m: 0.6577 - val_recall_m: 0.3314 - val_f1_m: 0.4090\n",
      "Epoch 28/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0635 - acc: 0.9779 - precision_m: 0.7771 - recall_m: 0.5413 - f1_m: 0.6145\n",
      "Epoch 28: val_acc did not improve from 0.97102\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0636 - acc: 0.9777 - precision_m: 0.7761 - recall_m: 0.5379 - f1_m: 0.6117 - val_loss: 0.0971 - val_acc: 0.9673 - val_precision_m: 0.5365 - val_recall_m: 0.3421 - val_f1_m: 0.3903\n",
      "Epoch 29/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.0632 - acc: 0.9778 - precision_m: 0.7807 - recall_m: 0.5362 - f1_m: 0.6122\n",
      "Epoch 29: val_acc did not improve from 0.97102\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0632 - acc: 0.9778 - precision_m: 0.7807 - recall_m: 0.5362 - f1_m: 0.6122 - val_loss: 0.0941 - val_acc: 0.9680 - val_precision_m: 0.5790 - val_recall_m: 0.3570 - val_f1_m: 0.4122\n",
      "Epoch 30/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.0627 - acc: 0.9779 - precision_m: 0.7693 - recall_m: 0.5341 - f1_m: 0.6105\n",
      "Epoch 30: val_acc did not improve from 0.97102\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0629 - acc: 0.9778 - precision_m: 0.7703 - recall_m: 0.5336 - f1_m: 0.6105 - val_loss: 0.0913 - val_acc: 0.9683 - val_precision_m: 0.5985 - val_recall_m: 0.4380 - val_f1_m: 0.4686\n",
      "Score for fold 2: loss of 0.09216631203889847; acc of 97.10214138031006%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.09806068241596222; acc of 96.79287672042847%\n",
      "Test Precision: precision_m of 21.03310525417328%\n",
      "Test Recall: recall_m of 12.373341619968414%\n",
      "Test F1: f1_m of 14.614848792552948%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.1474 - acc: 0.9631 - precision_m: 0.0515 - recall_m: 0.0081 - f1_m: 0.0132\n",
      "Epoch 1: val_acc improved from -inf to 0.96287, saving model to models/best_model_9_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 2s 3ms/step - loss: 0.1474 - acc: 0.9630 - precision_m: 0.0510 - recall_m: 0.0080 - f1_m: 0.0131 - val_loss: 0.1264 - val_acc: 0.9629 - val_precision_m: 0.0909 - val_recall_m: 0.0083 - val_f1_m: 0.0144\n",
      "Epoch 2/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.1219 - acc: 0.9636 - precision_m: 0.2697 - recall_m: 0.0515 - f1_m: 0.0810\n",
      "Epoch 2: val_acc improved from 0.96287 to 0.96442, saving model to models/best_model_9_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1217 - acc: 0.9637 - precision_m: 0.2677 - recall_m: 0.0516 - f1_m: 0.0811 - val_loss: 0.1166 - val_acc: 0.9644 - val_precision_m: 0.3232 - val_recall_m: 0.0444 - val_f1_m: 0.0764\n",
      "Epoch 3/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.1098 - acc: 0.9650 - precision_m: 0.4562 - recall_m: 0.0866 - f1_m: 0.1379\n",
      "Epoch 3: val_acc improved from 0.96442 to 0.96526, saving model to models/best_model_9_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1096 - acc: 0.9650 - precision_m: 0.4609 - recall_m: 0.0882 - f1_m: 0.1404 - val_loss: 0.1062 - val_acc: 0.9653 - val_precision_m: 0.3636 - val_recall_m: 0.0631 - val_f1_m: 0.1044\n",
      "Epoch 4/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1006 - acc: 0.9657 - precision_m: 0.5483 - recall_m: 0.1290 - f1_m: 0.1983\n",
      "Epoch 4: val_acc did not improve from 0.96526\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1004 - acc: 0.9657 - precision_m: 0.5480 - recall_m: 0.1287 - f1_m: 0.1979 - val_loss: 0.1082 - val_acc: 0.9651 - val_precision_m: 0.3485 - val_recall_m: 0.0508 - val_f1_m: 0.0860\n",
      "Epoch 5/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0951 - acc: 0.9665 - precision_m: 0.5860 - recall_m: 0.1668 - f1_m: 0.2443\n",
      "Epoch 5: val_acc improved from 0.96526 to 0.96706, saving model to models/best_model_9_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0951 - acc: 0.9664 - precision_m: 0.5846 - recall_m: 0.1680 - f1_m: 0.2447 - val_loss: 0.0963 - val_acc: 0.9671 - val_precision_m: 0.5614 - val_recall_m: 0.1414 - val_f1_m: 0.2160\n",
      "Epoch 6/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0896 - acc: 0.9672 - precision_m: 0.6357 - recall_m: 0.1930 - f1_m: 0.2794\n",
      "Epoch 6: val_acc improved from 0.96706 to 0.96742, saving model to models/best_model_9_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0894 - acc: 0.9673 - precision_m: 0.6423 - recall_m: 0.1936 - f1_m: 0.2807 - val_loss: 0.0924 - val_acc: 0.9674 - val_precision_m: 0.6086 - val_recall_m: 0.1868 - val_f1_m: 0.2642\n",
      "Epoch 7/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0868 - acc: 0.9680 - precision_m: 0.6609 - recall_m: 0.2256 - f1_m: 0.3183\n",
      "Epoch 7: val_acc did not improve from 0.96742\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0867 - acc: 0.9681 - precision_m: 0.6552 - recall_m: 0.2270 - f1_m: 0.3186 - val_loss: 0.0953 - val_acc: 0.9668 - val_precision_m: 0.5343 - val_recall_m: 0.1209 - val_f1_m: 0.1882\n",
      "Epoch 8/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0851 - acc: 0.9691 - precision_m: 0.6976 - recall_m: 0.2575 - f1_m: 0.3567\n",
      "Epoch 8: val_acc did not improve from 0.96742\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0846 - acc: 0.9693 - precision_m: 0.6946 - recall_m: 0.2573 - f1_m: 0.3559 - val_loss: 0.1001 - val_acc: 0.9660 - val_precision_m: 0.4343 - val_recall_m: 0.0818 - val_f1_m: 0.1313\n",
      "Epoch 9/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0836 - acc: 0.9690 - precision_m: 0.6934 - recall_m: 0.2661 - f1_m: 0.3602\n",
      "Epoch 9: val_acc improved from 0.96742 to 0.96862, saving model to models/best_model_9_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0837 - acc: 0.9689 - precision_m: 0.6882 - recall_m: 0.2650 - f1_m: 0.3583 - val_loss: 0.0919 - val_acc: 0.9686 - val_precision_m: 0.5949 - val_recall_m: 0.1763 - val_f1_m: 0.2587\n",
      "Epoch 10/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0817 - acc: 0.9695 - precision_m: 0.6822 - recall_m: 0.2719 - f1_m: 0.3646\n",
      "Epoch 10: val_acc did not improve from 0.96862\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0823 - acc: 0.9692 - precision_m: 0.6808 - recall_m: 0.2706 - f1_m: 0.3631 - val_loss: 0.0981 - val_acc: 0.9650 - val_precision_m: 0.5201 - val_recall_m: 0.2765 - val_f1_m: 0.3336\n",
      "Epoch 11/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0816 - acc: 0.9692 - precision_m: 0.6945 - recall_m: 0.2698 - f1_m: 0.3657\n",
      "Epoch 11: val_acc did not improve from 0.96862\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0814 - acc: 0.9693 - precision_m: 0.6948 - recall_m: 0.2703 - f1_m: 0.3665 - val_loss: 0.0926 - val_acc: 0.9673 - val_precision_m: 0.5578 - val_recall_m: 0.1662 - val_f1_m: 0.2424\n",
      "Epoch 12/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0789 - acc: 0.9699 - precision_m: 0.6998 - recall_m: 0.2936 - f1_m: 0.3915\n",
      "Epoch 12: val_acc did not improve from 0.96862\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0788 - acc: 0.9700 - precision_m: 0.6995 - recall_m: 0.2935 - f1_m: 0.3916 - val_loss: 0.0935 - val_acc: 0.9675 - val_precision_m: 0.5866 - val_recall_m: 0.1387 - val_f1_m: 0.2124\n",
      "Epoch 13/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0791 - acc: 0.9702 - precision_m: 0.6870 - recall_m: 0.2923 - f1_m: 0.3904\n",
      "Epoch 13: val_acc improved from 0.96862 to 0.96897, saving model to models/best_model_9_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0793 - acc: 0.9702 - precision_m: 0.6893 - recall_m: 0.2921 - f1_m: 0.3908 - val_loss: 0.0896 - val_acc: 0.9690 - val_precision_m: 0.6066 - val_recall_m: 0.1928 - val_f1_m: 0.2725\n",
      "Epoch 14/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0785 - acc: 0.9702 - precision_m: 0.7105 - recall_m: 0.2905 - f1_m: 0.3907\n",
      "Epoch 14: val_acc did not improve from 0.96897\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0784 - acc: 0.9702 - precision_m: 0.7097 - recall_m: 0.2913 - f1_m: 0.3913 - val_loss: 0.0895 - val_acc: 0.9674 - val_precision_m: 0.5585 - val_recall_m: 0.2621 - val_f1_m: 0.3308\n",
      "Epoch 15/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0766 - acc: 0.9708 - precision_m: 0.7235 - recall_m: 0.3064 - f1_m: 0.4107\n",
      "Epoch 15: val_acc did not improve from 0.96897\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0768 - acc: 0.9706 - precision_m: 0.7216 - recall_m: 0.3046 - f1_m: 0.4086 - val_loss: 0.0899 - val_acc: 0.9668 - val_precision_m: 0.5610 - val_recall_m: 0.2341 - val_f1_m: 0.3095\n",
      "Epoch 16/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0761 - acc: 0.9704 - precision_m: 0.7240 - recall_m: 0.3133 - f1_m: 0.4158\n",
      "Epoch 16: val_acc did not improve from 0.96897\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0759 - acc: 0.9705 - precision_m: 0.7227 - recall_m: 0.3143 - f1_m: 0.4165 - val_loss: 0.0923 - val_acc: 0.9683 - val_precision_m: 0.5545 - val_recall_m: 0.1682 - val_f1_m: 0.2427\n",
      "Epoch 17/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0761 - acc: 0.9704 - precision_m: 0.7204 - recall_m: 0.3059 - f1_m: 0.4093\n",
      "Epoch 17: val_acc did not improve from 0.96897\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0761 - acc: 0.9704 - precision_m: 0.7193 - recall_m: 0.3036 - f1_m: 0.4062 - val_loss: 0.0973 - val_acc: 0.9667 - val_precision_m: 0.5354 - val_recall_m: 0.1132 - val_f1_m: 0.1755\n",
      "Epoch 18/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0763 - acc: 0.9706 - precision_m: 0.7057 - recall_m: 0.3042 - f1_m: 0.4053\n",
      "Epoch 18: val_acc did not improve from 0.96897\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0761 - acc: 0.9707 - precision_m: 0.7075 - recall_m: 0.3021 - f1_m: 0.4032 - val_loss: 0.0913 - val_acc: 0.9654 - val_precision_m: 0.5077 - val_recall_m: 0.2371 - val_f1_m: 0.3049\n",
      "Epoch 19/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0759 - acc: 0.9709 - precision_m: 0.7313 - recall_m: 0.3186 - f1_m: 0.4198\n",
      "Epoch 19: val_acc did not improve from 0.96897\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0759 - acc: 0.9709 - precision_m: 0.7270 - recall_m: 0.3154 - f1_m: 0.4159 - val_loss: 0.0953 - val_acc: 0.9678 - val_precision_m: 0.5455 - val_recall_m: 0.1352 - val_f1_m: 0.2081\n",
      "Epoch 20/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0747 - acc: 0.9710 - precision_m: 0.7503 - recall_m: 0.3221 - f1_m: 0.4277\n",
      "Epoch 20: val_acc did not improve from 0.96897\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0747 - acc: 0.9710 - precision_m: 0.7503 - recall_m: 0.3218 - f1_m: 0.4275 - val_loss: 0.0914 - val_acc: 0.9669 - val_precision_m: 0.5603 - val_recall_m: 0.2450 - val_f1_m: 0.3138\n",
      "Epoch 21/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0742 - acc: 0.9711 - precision_m: 0.7359 - recall_m: 0.3226 - f1_m: 0.4273\n",
      "Epoch 21: val_acc did not improve from 0.96897\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0746 - acc: 0.9710 - precision_m: 0.7326 - recall_m: 0.3196 - f1_m: 0.4239 - val_loss: 0.0895 - val_acc: 0.9666 - val_precision_m: 0.5710 - val_recall_m: 0.2208 - val_f1_m: 0.2917\n",
      "Epoch 22/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0730 - acc: 0.9713 - precision_m: 0.7479 - recall_m: 0.3272 - f1_m: 0.4353\n",
      "Epoch 22: val_acc did not improve from 0.96897\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0730 - acc: 0.9714 - precision_m: 0.7497 - recall_m: 0.3274 - f1_m: 0.4357 - val_loss: 0.0911 - val_acc: 0.9661 - val_precision_m: 0.5227 - val_recall_m: 0.2341 - val_f1_m: 0.2959\n",
      "Epoch 23/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.0750 - acc: 0.9711 - precision_m: 0.7281 - recall_m: 0.3219 - f1_m: 0.4242\n",
      "Epoch 23: val_acc did not improve from 0.96897\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0745 - acc: 0.9711 - precision_m: 0.7336 - recall_m: 0.3225 - f1_m: 0.4263 - val_loss: 0.0888 - val_acc: 0.9681 - val_precision_m: 0.5928 - val_recall_m: 0.1951 - val_f1_m: 0.2734\n",
      "Epoch 24/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0737 - acc: 0.9711 - precision_m: 0.7287 - recall_m: 0.3212 - f1_m: 0.4233\n",
      "Epoch 24: val_acc did not improve from 0.96897\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0740 - acc: 0.9709 - precision_m: 0.7277 - recall_m: 0.3213 - f1_m: 0.4233 - val_loss: 0.0868 - val_acc: 0.9667 - val_precision_m: 0.5867 - val_recall_m: 0.2257 - val_f1_m: 0.3064\n",
      "Epoch 25/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0725 - acc: 0.9713 - precision_m: 0.7163 - recall_m: 0.3273 - f1_m: 0.4230\n",
      "Epoch 25: val_acc did not improve from 0.96897\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0732 - acc: 0.9712 - precision_m: 0.7214 - recall_m: 0.3260 - f1_m: 0.4225 - val_loss: 0.1033 - val_acc: 0.9598 - val_precision_m: 0.4493 - val_recall_m: 0.3242 - val_f1_m: 0.3481\n",
      "Epoch 26/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0735 - acc: 0.9731 - precision_m: 0.7353 - recall_m: 0.4172 - f1_m: 0.5051\n",
      "Epoch 26: val_acc improved from 0.96897 to 0.97005, saving model to models/best_model_9_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0736 - acc: 0.9730 - precision_m: 0.7380 - recall_m: 0.4167 - f1_m: 0.5050 - val_loss: 0.0908 - val_acc: 0.9701 - val_precision_m: 0.6288 - val_recall_m: 0.3240 - val_f1_m: 0.4061\n",
      "Epoch 27/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0726 - acc: 0.9745 - precision_m: 0.7601 - recall_m: 0.4615 - f1_m: 0.5495\n",
      "Epoch 27: val_acc did not improve from 0.97005\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0727 - acc: 0.9745 - precision_m: 0.7585 - recall_m: 0.4628 - f1_m: 0.5500 - val_loss: 0.0873 - val_acc: 0.9678 - val_precision_m: 0.6068 - val_recall_m: 0.3764 - val_f1_m: 0.4388\n",
      "Epoch 28/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0715 - acc: 0.9748 - precision_m: 0.7537 - recall_m: 0.4536 - f1_m: 0.5415\n",
      "Epoch 28: val_acc did not improve from 0.97005\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0721 - acc: 0.9746 - precision_m: 0.7520 - recall_m: 0.4539 - f1_m: 0.5412 - val_loss: 0.0982 - val_acc: 0.9647 - val_precision_m: 0.5328 - val_recall_m: 0.4616 - val_f1_m: 0.4691\n",
      "Epoch 29/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0720 - acc: 0.9742 - precision_m: 0.7471 - recall_m: 0.4488 - f1_m: 0.5367\n",
      "Epoch 29: val_acc did not improve from 0.97005\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0719 - acc: 0.9742 - precision_m: 0.7484 - recall_m: 0.4479 - f1_m: 0.5367 - val_loss: 0.0905 - val_acc: 0.9677 - val_precision_m: 0.6105 - val_recall_m: 0.4204 - val_f1_m: 0.4680\n",
      "Epoch 30/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0713 - acc: 0.9749 - precision_m: 0.7452 - recall_m: 0.4722 - f1_m: 0.5558\n",
      "Epoch 30: val_acc did not improve from 0.97005\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0713 - acc: 0.9749 - precision_m: 0.7439 - recall_m: 0.4705 - f1_m: 0.5541 - val_loss: 0.0902 - val_acc: 0.9697 - val_precision_m: 0.5958 - val_recall_m: 0.3056 - val_f1_m: 0.3814\n",
      "Score for fold 3: loss of 0.09083075821399689; acc of 97.0052719116211%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.09473772346973419; acc of 97.0779538154602%\n",
      "Test Precision: precision_m of 20.54988592863083%\n",
      "Test Recall: recall_m of 15.579850971698761%\n",
      "Test F1: f1_m of 16.808880865573883%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.1731 - acc: 0.9594 - precision_m: 0.0092 - recall_m: 0.0071 - f1_m: 0.0024\n",
      "Epoch 1: val_acc improved from -inf to 0.96096, saving model to models/best_model_9_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 2s 3ms/step - loss: 0.1727 - acc: 0.9595 - precision_m: 0.0091 - recall_m: 0.0070 - f1_m: 0.0024 - val_loss: 0.1404 - val_acc: 0.9610 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.1274 - acc: 0.9647 - precision_m: 0.1355 - recall_m: 0.0178 - f1_m: 0.0304  \n",
      "Epoch 2: val_acc improved from 0.96096 to 0.96107, saving model to models/best_model_9_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1267 - acc: 0.9647 - precision_m: 0.1347 - recall_m: 0.0176 - f1_m: 0.0300 - val_loss: 0.1289 - val_acc: 0.9611 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 3/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.1140 - acc: 0.9657 - precision_m: 0.3405 - recall_m: 0.0629 - f1_m: 0.1021\n",
      "Epoch 3: val_acc improved from 0.96107 to 0.96322, saving model to models/best_model_9_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1139 - acc: 0.9656 - precision_m: 0.3545 - recall_m: 0.0715 - f1_m: 0.1127 - val_loss: 0.1170 - val_acc: 0.9632 - val_precision_m: 0.3030 - val_recall_m: 0.0779 - val_f1_m: 0.1181\n",
      "Epoch 4/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.1049 - acc: 0.9669 - precision_m: 0.5305 - recall_m: 0.1341 - f1_m: 0.2023\n",
      "Epoch 4: val_acc improved from 0.96322 to 0.96442, saving model to models/best_model_9_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1051 - acc: 0.9670 - precision_m: 0.5269 - recall_m: 0.1343 - f1_m: 0.2022 - val_loss: 0.1128 - val_acc: 0.9644 - val_precision_m: 0.3980 - val_recall_m: 0.0806 - val_f1_m: 0.1315\n",
      "Epoch 5/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0979 - acc: 0.9682 - precision_m: 0.6203 - recall_m: 0.1945 - f1_m: 0.2780\n",
      "Epoch 5: val_acc improved from 0.96442 to 0.96454, saving model to models/best_model_9_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0975 - acc: 0.9683 - precision_m: 0.6171 - recall_m: 0.1949 - f1_m: 0.2779 - val_loss: 0.1107 - val_acc: 0.9645 - val_precision_m: 0.4394 - val_recall_m: 0.0786 - val_f1_m: 0.1275\n",
      "Epoch 6/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0884 - acc: 0.9704 - precision_m: 0.6664 - recall_m: 0.2850 - f1_m: 0.3722\n",
      "Epoch 6: val_acc improved from 0.96454 to 0.96704, saving model to models/best_model_9_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0887 - acc: 0.9703 - precision_m: 0.6677 - recall_m: 0.2881 - f1_m: 0.3745 - val_loss: 0.0986 - val_acc: 0.9670 - val_precision_m: 0.5587 - val_recall_m: 0.3297 - val_f1_m: 0.3816\n",
      "Epoch 7/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0835 - acc: 0.9715 - precision_m: 0.7180 - recall_m: 0.3508 - f1_m: 0.4369\n",
      "Epoch 7: val_acc improved from 0.96704 to 0.96824, saving model to models/best_model_9_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0837 - acc: 0.9714 - precision_m: 0.7132 - recall_m: 0.3513 - f1_m: 0.4365 - val_loss: 0.0967 - val_acc: 0.9682 - val_precision_m: 0.5896 - val_recall_m: 0.1920 - val_f1_m: 0.2787\n",
      "Epoch 8/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0796 - acc: 0.9726 - precision_m: 0.7239 - recall_m: 0.3802 - f1_m: 0.4653\n",
      "Epoch 8: val_acc did not improve from 0.96824\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0797 - acc: 0.9726 - precision_m: 0.7224 - recall_m: 0.3793 - f1_m: 0.4645 - val_loss: 0.1059 - val_acc: 0.9639 - val_precision_m: 0.5512 - val_recall_m: 0.4397 - val_f1_m: 0.4399\n",
      "Epoch 9/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0835 - acc: 0.9716 - precision_m: 0.6730 - recall_m: 0.3921 - f1_m: 0.4692\n",
      "Epoch 9: val_acc did not improve from 0.96824\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0835 - acc: 0.9717 - precision_m: 0.6732 - recall_m: 0.3933 - f1_m: 0.4703 - val_loss: 0.0991 - val_acc: 0.9678 - val_precision_m: 0.6095 - val_recall_m: 0.2512 - val_f1_m: 0.3262\n",
      "Epoch 10/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0752 - acc: 0.9742 - precision_m: 0.7312 - recall_m: 0.4286 - f1_m: 0.5209\n",
      "Epoch 10: val_acc did not improve from 0.96824\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0751 - acc: 0.9742 - precision_m: 0.7273 - recall_m: 0.4281 - f1_m: 0.5197 - val_loss: 0.1067 - val_acc: 0.9669 - val_precision_m: 0.5189 - val_recall_m: 0.1509 - val_f1_m: 0.2222\n",
      "Epoch 11/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0744 - acc: 0.9742 - precision_m: 0.7143 - recall_m: 0.4326 - f1_m: 0.5100\n",
      "Epoch 11: val_acc improved from 0.96824 to 0.96943, saving model to models/best_model_9_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0746 - acc: 0.9740 - precision_m: 0.7115 - recall_m: 0.4306 - f1_m: 0.5078 - val_loss: 0.0921 - val_acc: 0.9694 - val_precision_m: 0.5823 - val_recall_m: 0.3343 - val_f1_m: 0.3958\n",
      "Epoch 12/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0722 - acc: 0.9750 - precision_m: 0.7488 - recall_m: 0.4515 - f1_m: 0.5390\n",
      "Epoch 12: val_acc did not improve from 0.96943\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0724 - acc: 0.9749 - precision_m: 0.7450 - recall_m: 0.4481 - f1_m: 0.5355 - val_loss: 0.0900 - val_acc: 0.9694 - val_precision_m: 0.6282 - val_recall_m: 0.4069 - val_f1_m: 0.4608\n",
      "Epoch 13/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0731 - acc: 0.9742 - precision_m: 0.7221 - recall_m: 0.4472 - f1_m: 0.5268\n",
      "Epoch 13: val_acc improved from 0.96943 to 0.97087, saving model to models/best_model_9_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0732 - acc: 0.9742 - precision_m: 0.7189 - recall_m: 0.4450 - f1_m: 0.5243 - val_loss: 0.0948 - val_acc: 0.9709 - val_precision_m: 0.6438 - val_recall_m: 0.3055 - val_f1_m: 0.3873\n",
      "Epoch 14/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0721 - acc: 0.9753 - precision_m: 0.7566 - recall_m: 0.4680 - f1_m: 0.5511\n",
      "Epoch 14: val_acc did not improve from 0.97087\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0720 - acc: 0.9752 - precision_m: 0.7540 - recall_m: 0.4662 - f1_m: 0.5494 - val_loss: 0.0932 - val_acc: 0.9660 - val_precision_m: 0.5729 - val_recall_m: 0.4484 - val_f1_m: 0.4581\n",
      "Epoch 15/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0700 - acc: 0.9757 - precision_m: 0.7551 - recall_m: 0.4706 - f1_m: 0.5541\n",
      "Epoch 15: val_acc did not improve from 0.97087\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0701 - acc: 0.9757 - precision_m: 0.7565 - recall_m: 0.4734 - f1_m: 0.5566 - val_loss: 0.0920 - val_acc: 0.9697 - val_precision_m: 0.5942 - val_recall_m: 0.3739 - val_f1_m: 0.4242\n",
      "Epoch 16/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0715 - acc: 0.9746 - precision_m: 0.7400 - recall_m: 0.4645 - f1_m: 0.5444\n",
      "Epoch 16: val_acc did not improve from 0.97087\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0713 - acc: 0.9747 - precision_m: 0.7393 - recall_m: 0.4684 - f1_m: 0.5467 - val_loss: 0.0949 - val_acc: 0.9690 - val_precision_m: 0.6466 - val_recall_m: 0.3376 - val_f1_m: 0.3983\n",
      "Epoch 17/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0694 - acc: 0.9760 - precision_m: 0.7552 - recall_m: 0.4903 - f1_m: 0.5682\n",
      "Epoch 17: val_acc did not improve from 0.97087\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0695 - acc: 0.9760 - precision_m: 0.7517 - recall_m: 0.4897 - f1_m: 0.5668 - val_loss: 0.0915 - val_acc: 0.9679 - val_precision_m: 0.5732 - val_recall_m: 0.3843 - val_f1_m: 0.4271\n",
      "Epoch 18/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0677 - acc: 0.9763 - precision_m: 0.7453 - recall_m: 0.4951 - f1_m: 0.5753\n",
      "Epoch 18: val_acc did not improve from 0.97087\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0675 - acc: 0.9764 - precision_m: 0.7454 - recall_m: 0.4940 - f1_m: 0.5744 - val_loss: 0.0903 - val_acc: 0.9704 - val_precision_m: 0.6559 - val_recall_m: 0.3855 - val_f1_m: 0.4498\n",
      "Epoch 19/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.9760 - precision_m: 0.7538 - recall_m: 0.4904 - f1_m: 0.5723\n",
      "Epoch 19: val_acc did not improve from 0.97087\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0684 - acc: 0.9761 - precision_m: 0.7534 - recall_m: 0.4926 - f1_m: 0.5738 - val_loss: 0.1150 - val_acc: 0.9584 - val_precision_m: 0.4384 - val_recall_m: 0.4619 - val_f1_m: 0.4189\n",
      "Epoch 20/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0788 - acc: 0.9737 - precision_m: 0.7321 - recall_m: 0.4489 - f1_m: 0.5318\n",
      "Epoch 20: val_acc did not improve from 0.97087\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0784 - acc: 0.9737 - precision_m: 0.7304 - recall_m: 0.4496 - f1_m: 0.5320 - val_loss: 0.0944 - val_acc: 0.9704 - val_precision_m: 0.6318 - val_recall_m: 0.3195 - val_f1_m: 0.3970\n",
      "Epoch 21/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0669 - acc: 0.9766 - precision_m: 0.7696 - recall_m: 0.5069 - f1_m: 0.5914\n",
      "Epoch 21: val_acc did not improve from 0.97087\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0669 - acc: 0.9766 - precision_m: 0.7625 - recall_m: 0.5057 - f1_m: 0.5873 - val_loss: 0.0938 - val_acc: 0.9704 - val_precision_m: 0.6463 - val_recall_m: 0.3482 - val_f1_m: 0.4211\n",
      "Epoch 22/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9768 - precision_m: 0.7673 - recall_m: 0.5076 - f1_m: 0.5866\n",
      "Epoch 22: val_acc did not improve from 0.97087\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0662 - acc: 0.9768 - precision_m: 0.7660 - recall_m: 0.5083 - f1_m: 0.5868 - val_loss: 0.0927 - val_acc: 0.9709 - val_precision_m: 0.6694 - val_recall_m: 0.3779 - val_f1_m: 0.4498\n",
      "Epoch 23/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9769 - precision_m: 0.7682 - recall_m: 0.5056 - f1_m: 0.5868\n",
      "Epoch 23: val_acc did not improve from 0.97087\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0659 - acc: 0.9769 - precision_m: 0.7668 - recall_m: 0.5086 - f1_m: 0.5884 - val_loss: 0.0954 - val_acc: 0.9680 - val_precision_m: 0.5890 - val_recall_m: 0.4517 - val_f1_m: 0.4670\n",
      "Epoch 24/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0657 - acc: 0.9767 - precision_m: 0.7740 - recall_m: 0.5135 - f1_m: 0.5921\n",
      "Epoch 24: val_acc did not improve from 0.97087\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0662 - acc: 0.9766 - precision_m: 0.7736 - recall_m: 0.5129 - f1_m: 0.5917 - val_loss: 0.0920 - val_acc: 0.9686 - val_precision_m: 0.5764 - val_recall_m: 0.4348 - val_f1_m: 0.4495\n",
      "Epoch 25/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0656 - acc: 0.9773 - precision_m: 0.7704 - recall_m: 0.5096 - f1_m: 0.5885\n",
      "Epoch 25: val_acc did not improve from 0.97087\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0656 - acc: 0.9773 - precision_m: 0.7675 - recall_m: 0.5079 - f1_m: 0.5865 - val_loss: 0.0946 - val_acc: 0.9680 - val_precision_m: 0.5721 - val_recall_m: 0.4577 - val_f1_m: 0.4668\n",
      "Epoch 26/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0648 - acc: 0.9774 - precision_m: 0.7820 - recall_m: 0.5251 - f1_m: 0.6050\n",
      "Epoch 26: val_acc did not improve from 0.97087\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0649 - acc: 0.9774 - precision_m: 0.7816 - recall_m: 0.5230 - f1_m: 0.6036 - val_loss: 0.0942 - val_acc: 0.9698 - val_precision_m: 0.6414 - val_recall_m: 0.3803 - val_f1_m: 0.4359\n",
      "Epoch 27/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0646 - acc: 0.9773 - precision_m: 0.7684 - recall_m: 0.5169 - f1_m: 0.5997\n",
      "Epoch 27: val_acc did not improve from 0.97087\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0646 - acc: 0.9772 - precision_m: 0.7670 - recall_m: 0.5117 - f1_m: 0.5951 - val_loss: 0.0947 - val_acc: 0.9700 - val_precision_m: 0.6082 - val_recall_m: 0.4316 - val_f1_m: 0.4718\n",
      "Epoch 28/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0659 - acc: 0.9770 - precision_m: 0.7574 - recall_m: 0.5189 - f1_m: 0.5936\n",
      "Epoch 28: val_acc did not improve from 0.97087\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0654 - acc: 0.9772 - precision_m: 0.7589 - recall_m: 0.5185 - f1_m: 0.5936 - val_loss: 0.0947 - val_acc: 0.9709 - val_precision_m: 0.6590 - val_recall_m: 0.3881 - val_f1_m: 0.4520\n",
      "Epoch 29/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0651 - acc: 0.9770 - precision_m: 0.7673 - recall_m: 0.5130 - f1_m: 0.5893\n",
      "Epoch 29: val_acc improved from 0.97087 to 0.97122, saving model to models/best_model_9_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0654 - acc: 0.9768 - precision_m: 0.7596 - recall_m: 0.5086 - f1_m: 0.5844 - val_loss: 0.0952 - val_acc: 0.9712 - val_precision_m: 0.6720 - val_recall_m: 0.3852 - val_f1_m: 0.4561\n",
      "Epoch 30/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0644 - acc: 0.9775 - precision_m: 0.7800 - recall_m: 0.5250 - f1_m: 0.6019\n",
      "Epoch 30: val_acc did not improve from 0.97122\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0641 - acc: 0.9775 - precision_m: 0.7798 - recall_m: 0.5228 - f1_m: 0.6003 - val_loss: 0.0952 - val_acc: 0.9679 - val_precision_m: 0.5633 - val_recall_m: 0.3766 - val_f1_m: 0.4067\n",
      "Score for fold 4: loss of 0.09521619230508804; acc of 97.12238907814026%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.10545767843723297; acc of 96.7434823513031%\n",
      "Test Precision: precision_m of 22.871971130371094%\n",
      "Test Recall: recall_m of 16.34843200445175%\n",
      "Test F1: f1_m of 18.056918680667877%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.1602 - acc: 0.9618 - precision_m: 0.0111 - recall_m: 0.0044 - f1_m: 0.0033\n",
      "Epoch 1: val_acc improved from -inf to 0.96211, saving model to models/best_model_9_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 2s 3ms/step - loss: 0.1600 - acc: 0.9618 - precision_m: 0.0110 - recall_m: 0.0043 - f1_m: 0.0033 - val_loss: 0.1360 - val_acc: 0.9621 - val_precision_m: 0.0303 - val_recall_m: 0.0030 - val_f1_m: 0.0055\n",
      "Epoch 2/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.1250 - acc: 0.9643 - precision_m: 0.2491 - recall_m: 0.0413 - f1_m: 0.0671\n",
      "Epoch 2: val_acc improved from 0.96211 to 0.96343, saving model to models/best_model_9_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1247 - acc: 0.9643 - precision_m: 0.2557 - recall_m: 0.0429 - f1_m: 0.0697 - val_loss: 0.1207 - val_acc: 0.9634 - val_precision_m: 0.2424 - val_recall_m: 0.0493 - val_f1_m: 0.0781\n",
      "Epoch 3/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.1127 - acc: 0.9653 - precision_m: 0.4491 - recall_m: 0.0934 - f1_m: 0.1467\n",
      "Epoch 3: val_acc improved from 0.96343 to 0.96438, saving model to models/best_model_9_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1126 - acc: 0.9653 - precision_m: 0.4517 - recall_m: 0.0942 - f1_m: 0.1480 - val_loss: 0.1146 - val_acc: 0.9644 - val_precision_m: 0.3990 - val_recall_m: 0.0940 - val_f1_m: 0.1419\n",
      "Epoch 4/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.1062 - acc: 0.9658 - precision_m: 0.5298 - recall_m: 0.1193 - f1_m: 0.1848\n",
      "Epoch 4: val_acc improved from 0.96438 to 0.96558, saving model to models/best_model_9_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1063 - acc: 0.9658 - precision_m: 0.5276 - recall_m: 0.1191 - f1_m: 0.1845 - val_loss: 0.1107 - val_acc: 0.9656 - val_precision_m: 0.4747 - val_recall_m: 0.1206 - val_f1_m: 0.1837\n",
      "Epoch 5/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.1002 - acc: 0.9660 - precision_m: 0.5588 - recall_m: 0.1351 - f1_m: 0.2052\n",
      "Epoch 5: val_acc did not improve from 0.96558\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1000 - acc: 0.9661 - precision_m: 0.5595 - recall_m: 0.1339 - f1_m: 0.2038 - val_loss: 0.1079 - val_acc: 0.9645 - val_precision_m: 0.4091 - val_recall_m: 0.0963 - val_f1_m: 0.1498\n",
      "Epoch 6/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0969 - acc: 0.9663 - precision_m: 0.5793 - recall_m: 0.1500 - f1_m: 0.2249\n",
      "Epoch 6: val_acc did not improve from 0.96558\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0967 - acc: 0.9663 - precision_m: 0.5837 - recall_m: 0.1504 - f1_m: 0.2256 - val_loss: 0.1075 - val_acc: 0.9647 - val_precision_m: 0.3636 - val_recall_m: 0.1105 - val_f1_m: 0.1624\n",
      "Epoch 7/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0947 - acc: 0.9666 - precision_m: 0.5910 - recall_m: 0.1589 - f1_m: 0.2387\n",
      "Epoch 7: val_acc did not improve from 0.96558\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0950 - acc: 0.9666 - precision_m: 0.5899 - recall_m: 0.1571 - f1_m: 0.2363 - val_loss: 0.1055 - val_acc: 0.9641 - val_precision_m: 0.4711 - val_recall_m: 0.1400 - val_f1_m: 0.1996\n",
      "Epoch 8/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0930 - acc: 0.9664 - precision_m: 0.5908 - recall_m: 0.1623 - f1_m: 0.2418\n",
      "Epoch 8: val_acc did not improve from 0.96558\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0929 - acc: 0.9665 - precision_m: 0.5883 - recall_m: 0.1616 - f1_m: 0.2406 - val_loss: 0.1067 - val_acc: 0.9647 - val_precision_m: 0.3838 - val_recall_m: 0.0918 - val_f1_m: 0.1430\n",
      "Epoch 9/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0909 - acc: 0.9668 - precision_m: 0.6095 - recall_m: 0.1650 - f1_m: 0.2450\n",
      "Epoch 9: val_acc did not improve from 0.96558\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0905 - acc: 0.9670 - precision_m: 0.6098 - recall_m: 0.1675 - f1_m: 0.2478 - val_loss: 0.1094 - val_acc: 0.9643 - val_precision_m: 0.4182 - val_recall_m: 0.1021 - val_f1_m: 0.1547\n",
      "Epoch 10/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.0903 - acc: 0.9667 - precision_m: 0.5757 - recall_m: 0.1804 - f1_m: 0.2588\n",
      "Epoch 10: val_acc did not improve from 0.96558\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0901 - acc: 0.9668 - precision_m: 0.5754 - recall_m: 0.1802 - f1_m: 0.2589 - val_loss: 0.1038 - val_acc: 0.9652 - val_precision_m: 0.5431 - val_recall_m: 0.1815 - val_f1_m: 0.2484\n",
      "Epoch 11/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0891 - acc: 0.9669 - precision_m: 0.5866 - recall_m: 0.1797 - f1_m: 0.2588\n",
      "Epoch 11: val_acc did not improve from 0.96558\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0894 - acc: 0.9669 - precision_m: 0.5866 - recall_m: 0.1795 - f1_m: 0.2586 - val_loss: 0.1038 - val_acc: 0.9656 - val_precision_m: 0.5899 - val_recall_m: 0.1785 - val_f1_m: 0.2531\n",
      "Epoch 12/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0888 - acc: 0.9672 - precision_m: 0.5835 - recall_m: 0.1825 - f1_m: 0.2631\n",
      "Epoch 12: val_acc did not improve from 0.96558\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0888 - acc: 0.9672 - precision_m: 0.5843 - recall_m: 0.1843 - f1_m: 0.2650 - val_loss: 0.1143 - val_acc: 0.9639 - val_precision_m: 0.2727 - val_recall_m: 0.0524 - val_f1_m: 0.0838\n",
      "Epoch 13/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0883 - acc: 0.9668 - precision_m: 0.5975 - recall_m: 0.1735 - f1_m: 0.2523\n",
      "Epoch 13: val_acc did not improve from 0.96558\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0881 - acc: 0.9669 - precision_m: 0.5990 - recall_m: 0.1765 - f1_m: 0.2550 - val_loss: 0.1039 - val_acc: 0.9638 - val_precision_m: 0.4970 - val_recall_m: 0.1848 - val_f1_m: 0.2465\n",
      "Epoch 14/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0864 - acc: 0.9677 - precision_m: 0.6388 - recall_m: 0.1822 - f1_m: 0.2689\n",
      "Epoch 14: val_acc did not improve from 0.96558\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0865 - acc: 0.9676 - precision_m: 0.6369 - recall_m: 0.1818 - f1_m: 0.2685 - val_loss: 0.1020 - val_acc: 0.9645 - val_precision_m: 0.5431 - val_recall_m: 0.1756 - val_f1_m: 0.2460\n",
      "Epoch 15/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0854 - acc: 0.9671 - precision_m: 0.6164 - recall_m: 0.1842 - f1_m: 0.2685\n",
      "Epoch 15: val_acc did not improve from 0.96558\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0855 - acc: 0.9671 - precision_m: 0.6139 - recall_m: 0.1832 - f1_m: 0.2671 - val_loss: 0.1023 - val_acc: 0.9646 - val_precision_m: 0.5783 - val_recall_m: 0.1662 - val_f1_m: 0.2387\n",
      "Epoch 16/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0851 - acc: 0.9675 - precision_m: 0.6267 - recall_m: 0.1808 - f1_m: 0.2670\n",
      "Epoch 16: val_acc improved from 0.96558 to 0.96582, saving model to models/best_model_9_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0856 - acc: 0.9673 - precision_m: 0.6233 - recall_m: 0.1828 - f1_m: 0.2680 - val_loss: 0.1040 - val_acc: 0.9658 - val_precision_m: 0.4798 - val_recall_m: 0.1279 - val_f1_m: 0.1894\n",
      "Epoch 17/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0843 - acc: 0.9678 - precision_m: 0.6307 - recall_m: 0.1916 - f1_m: 0.2776\n",
      "Epoch 17: val_acc did not improve from 0.96582\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0848 - acc: 0.9676 - precision_m: 0.6300 - recall_m: 0.1920 - f1_m: 0.2782 - val_loss: 0.1027 - val_acc: 0.9638 - val_precision_m: 0.5432 - val_recall_m: 0.2324 - val_f1_m: 0.2966\n",
      "Epoch 18/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0837 - acc: 0.9678 - precision_m: 0.6429 - recall_m: 0.1943 - f1_m: 0.2853\n",
      "Epoch 18: val_acc did not improve from 0.96582\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0837 - acc: 0.9679 - precision_m: 0.6439 - recall_m: 0.1957 - f1_m: 0.2867 - val_loss: 0.1064 - val_acc: 0.9620 - val_precision_m: 0.4454 - val_recall_m: 0.2379 - val_f1_m: 0.2854\n",
      "Epoch 19/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0834 - acc: 0.9680 - precision_m: 0.6730 - recall_m: 0.2078 - f1_m: 0.3001\n",
      "Epoch 19: val_acc did not improve from 0.96582\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0834 - acc: 0.9680 - precision_m: 0.6646 - recall_m: 0.2055 - f1_m: 0.2967 - val_loss: 0.1104 - val_acc: 0.9651 - val_precision_m: 0.3485 - val_recall_m: 0.0850 - val_f1_m: 0.1283\n",
      "Epoch 20/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0826 - acc: 0.9683 - precision_m: 0.6586 - recall_m: 0.2051 - f1_m: 0.2960\n",
      "Epoch 20: val_acc did not improve from 0.96582\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0831 - acc: 0.9682 - precision_m: 0.6565 - recall_m: 0.2033 - f1_m: 0.2938 - val_loss: 0.1023 - val_acc: 0.9647 - val_precision_m: 0.5366 - val_recall_m: 0.2094 - val_f1_m: 0.2736\n",
      "Epoch 21/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0830 - acc: 0.9682 - precision_m: 0.6661 - recall_m: 0.2159 - f1_m: 0.3063\n",
      "Epoch 21: val_acc did not improve from 0.96582\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0831 - acc: 0.9682 - precision_m: 0.6559 - recall_m: 0.2142 - f1_m: 0.3029 - val_loss: 0.1156 - val_acc: 0.9639 - val_precision_m: 0.2727 - val_recall_m: 0.0428 - val_f1_m: 0.0711\n",
      "Epoch 22/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0817 - acc: 0.9686 - precision_m: 0.6801 - recall_m: 0.2088 - f1_m: 0.3023\n",
      "Epoch 22: val_acc did not improve from 0.96582\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0817 - acc: 0.9685 - precision_m: 0.6850 - recall_m: 0.2106 - f1_m: 0.3049 - val_loss: 0.1036 - val_acc: 0.9650 - val_precision_m: 0.5227 - val_recall_m: 0.1252 - val_f1_m: 0.1871\n",
      "Epoch 23/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0815 - acc: 0.9676 - precision_m: 0.6097 - recall_m: 0.1925 - f1_m: 0.2767\n",
      "Epoch 23: val_acc did not improve from 0.96582\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0817 - acc: 0.9677 - precision_m: 0.6153 - recall_m: 0.1953 - f1_m: 0.2802 - val_loss: 0.1049 - val_acc: 0.9626 - val_precision_m: 0.5003 - val_recall_m: 0.2323 - val_f1_m: 0.2905\n",
      "Epoch 24/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0817 - acc: 0.9680 - precision_m: 0.6569 - recall_m: 0.2027 - f1_m: 0.2894\n",
      "Epoch 24: val_acc did not improve from 0.96582\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0820 - acc: 0.9679 - precision_m: 0.6505 - recall_m: 0.2032 - f1_m: 0.2896 - val_loss: 0.1022 - val_acc: 0.9650 - val_precision_m: 0.4823 - val_recall_m: 0.1765 - val_f1_m: 0.2359\n",
      "Epoch 25/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0802 - acc: 0.9686 - precision_m: 0.6812 - recall_m: 0.2321 - f1_m: 0.3247\n",
      "Epoch 25: val_acc did not improve from 0.96582\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0806 - acc: 0.9684 - precision_m: 0.6767 - recall_m: 0.2323 - f1_m: 0.3244 - val_loss: 0.1052 - val_acc: 0.9652 - val_precision_m: 0.4821 - val_recall_m: 0.2209 - val_f1_m: 0.2916\n",
      "Epoch 26/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0815 - acc: 0.9703 - precision_m: 0.7023 - recall_m: 0.3238 - f1_m: 0.4197\n",
      "Epoch 26: val_acc did not improve from 0.96582\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0817 - acc: 0.9702 - precision_m: 0.6999 - recall_m: 0.3233 - f1_m: 0.4189 - val_loss: 0.1033 - val_acc: 0.9653 - val_precision_m: 0.5459 - val_recall_m: 0.3306 - val_f1_m: 0.3913\n",
      "Epoch 27/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0812 - acc: 0.9709 - precision_m: 0.7015 - recall_m: 0.3419 - f1_m: 0.4363\n",
      "Epoch 27: val_acc did not improve from 0.96582\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0809 - acc: 0.9709 - precision_m: 0.6948 - recall_m: 0.3385 - f1_m: 0.4323 - val_loss: 0.1017 - val_acc: 0.9655 - val_precision_m: 0.5410 - val_recall_m: 0.2414 - val_f1_m: 0.3150\n",
      "Epoch 28/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0809 - acc: 0.9705 - precision_m: 0.7000 - recall_m: 0.3387 - f1_m: 0.4319\n",
      "Epoch 28: val_acc improved from 0.96582 to 0.96630, saving model to models/best_model_9_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0809 - acc: 0.9706 - precision_m: 0.6988 - recall_m: 0.3446 - f1_m: 0.4355 - val_loss: 0.1038 - val_acc: 0.9663 - val_precision_m: 0.5797 - val_recall_m: 0.2597 - val_f1_m: 0.3378\n",
      "Epoch 29/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0801 - acc: 0.9709 - precision_m: 0.7193 - recall_m: 0.3427 - f1_m: 0.4421\n",
      "Epoch 29: val_acc improved from 0.96630 to 0.96701, saving model to models/best_model_9_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0798 - acc: 0.9711 - precision_m: 0.7189 - recall_m: 0.3443 - f1_m: 0.4433 - val_loss: 0.1035 - val_acc: 0.9670 - val_precision_m: 0.5467 - val_recall_m: 0.2881 - val_f1_m: 0.3524\n",
      "Epoch 30/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0794 - acc: 0.9708 - precision_m: 0.6996 - recall_m: 0.3403 - f1_m: 0.4354\n",
      "Epoch 30: val_acc did not improve from 0.96701\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0796 - acc: 0.9709 - precision_m: 0.7056 - recall_m: 0.3403 - f1_m: 0.4363 - val_loss: 0.1114 - val_acc: 0.9669 - val_precision_m: 0.5409 - val_recall_m: 0.1607 - val_f1_m: 0.2375\n",
      "Score for fold 5: loss of 0.1035035029053688; acc of 96.70132398605347%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.09289825707674026; acc of 96.66880369186401%\n",
      "Test Precision: precision_m of 18.293514847755432%\n",
      "Test Recall: recall_m of 10.206551849842072%\n",
      "Test F1: f1_m of 12.200526893138885%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Epoch 1/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1271 - acc: 0.9647 - precision_m: 0.3404 - recall_m: 0.0823 - f1_m: 0.1244  \n",
      "Epoch 1: val_acc improved from -inf to 0.96288, saving model to models/best_model_9_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 2s 3ms/step - loss: 0.1271 - acc: 0.9647 - precision_m: 0.3455 - recall_m: 0.0829 - f1_m: 0.1256 - val_loss: 0.1150 - val_acc: 0.9629 - val_precision_m: 0.4873 - val_recall_m: 0.1033 - val_f1_m: 0.1612\n",
      "Epoch 2/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0991 - acc: 0.9679 - precision_m: 0.6341 - recall_m: 0.2387 - f1_m: 0.3244\n",
      "Epoch 2: val_acc improved from 0.96288 to 0.96469, saving model to models/best_model_9_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0983 - acc: 0.9682 - precision_m: 0.6396 - recall_m: 0.2451 - f1_m: 0.3308 - val_loss: 0.1043 - val_acc: 0.9647 - val_precision_m: 0.5188 - val_recall_m: 0.1273 - val_f1_m: 0.1973\n",
      "Epoch 3/30\n",
      "273/292 [===========================>..] - ETA: 0s - loss: 0.0885 - acc: 0.9702 - precision_m: 0.6887 - recall_m: 0.3424 - f1_m: 0.4318\n",
      "Epoch 3: val_acc improved from 0.96469 to 0.96698, saving model to models/best_model_9_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0878 - acc: 0.9703 - precision_m: 0.6800 - recall_m: 0.3402 - f1_m: 0.4281 - val_loss: 0.0971 - val_acc: 0.9670 - val_precision_m: 0.6035 - val_recall_m: 0.2954 - val_f1_m: 0.3704\n",
      "Epoch 4/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0826 - acc: 0.9716 - precision_m: 0.7152 - recall_m: 0.3785 - f1_m: 0.4662\n",
      "Epoch 4: val_acc improved from 0.96698 to 0.96794, saving model to models/best_model_9_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0825 - acc: 0.9716 - precision_m: 0.7143 - recall_m: 0.3771 - f1_m: 0.4651 - val_loss: 0.0960 - val_acc: 0.9679 - val_precision_m: 0.5875 - val_recall_m: 0.4218 - val_f1_m: 0.4626\n",
      "Epoch 5/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0795 - acc: 0.9722 - precision_m: 0.6847 - recall_m: 0.4066 - f1_m: 0.4857\n",
      "Epoch 5: val_acc improved from 0.96794 to 0.96890, saving model to models/best_model_9_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0795 - acc: 0.9722 - precision_m: 0.6824 - recall_m: 0.4059 - f1_m: 0.4845 - val_loss: 0.0935 - val_acc: 0.9689 - val_precision_m: 0.6348 - val_recall_m: 0.4116 - val_f1_m: 0.4638\n",
      "Epoch 6/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0766 - acc: 0.9734 - precision_m: 0.7332 - recall_m: 0.4347 - f1_m: 0.5241\n",
      "Epoch 6: val_acc did not improve from 0.96890\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0763 - acc: 0.9734 - precision_m: 0.7346 - recall_m: 0.4324 - f1_m: 0.5224 - val_loss: 0.0937 - val_acc: 0.9663 - val_precision_m: 0.5978 - val_recall_m: 0.3807 - val_f1_m: 0.4354\n",
      "Epoch 7/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0748 - acc: 0.9739 - precision_m: 0.7286 - recall_m: 0.4442 - f1_m: 0.5253\n",
      "Epoch 7: val_acc did not improve from 0.96890\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0748 - acc: 0.9739 - precision_m: 0.7280 - recall_m: 0.4434 - f1_m: 0.5248 - val_loss: 0.0941 - val_acc: 0.9684 - val_precision_m: 0.6016 - val_recall_m: 0.5212 - val_f1_m: 0.5257\n",
      "Epoch 8/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0729 - acc: 0.9744 - precision_m: 0.7317 - recall_m: 0.4720 - f1_m: 0.5484\n",
      "Epoch 8: val_acc improved from 0.96890 to 0.96951, saving model to models/best_model_9_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0729 - acc: 0.9744 - precision_m: 0.7313 - recall_m: 0.4709 - f1_m: 0.5475 - val_loss: 0.0949 - val_acc: 0.9695 - val_precision_m: 0.6907 - val_recall_m: 0.3152 - val_f1_m: 0.4110\n",
      "Epoch 9/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0713 - acc: 0.9750 - precision_m: 0.7361 - recall_m: 0.4782 - f1_m: 0.5581\n",
      "Epoch 9: val_acc did not improve from 0.96951\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0715 - acc: 0.9750 - precision_m: 0.7355 - recall_m: 0.4781 - f1_m: 0.5582 - val_loss: 0.0906 - val_acc: 0.9695 - val_precision_m: 0.6509 - val_recall_m: 0.4552 - val_f1_m: 0.5072\n",
      "Epoch 10/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0694 - acc: 0.9753 - precision_m: 0.7489 - recall_m: 0.4847 - f1_m: 0.5666\n",
      "Epoch 10: val_acc did not improve from 0.96951\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0696 - acc: 0.9752 - precision_m: 0.7456 - recall_m: 0.4871 - f1_m: 0.5659 - val_loss: 0.0928 - val_acc: 0.9694 - val_precision_m: 0.6687 - val_recall_m: 0.3466 - val_f1_m: 0.4294\n",
      "Epoch 11/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0688 - acc: 0.9754 - precision_m: 0.7512 - recall_m: 0.4860 - f1_m: 0.5682\n",
      "Epoch 11: val_acc did not improve from 0.96951\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0687 - acc: 0.9754 - precision_m: 0.7509 - recall_m: 0.4826 - f1_m: 0.5651 - val_loss: 0.0957 - val_acc: 0.9660 - val_precision_m: 0.5558 - val_recall_m: 0.4796 - val_f1_m: 0.4890\n",
      "Epoch 12/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0693 - acc: 0.9753 - precision_m: 0.7388 - recall_m: 0.5120 - f1_m: 0.5805\n",
      "Epoch 12: val_acc did not improve from 0.96951\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0690 - acc: 0.9754 - precision_m: 0.7393 - recall_m: 0.5090 - f1_m: 0.5784 - val_loss: 0.0940 - val_acc: 0.9684 - val_precision_m: 0.6527 - val_recall_m: 0.3766 - val_f1_m: 0.4529\n",
      "Epoch 13/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0670 - acc: 0.9766 - precision_m: 0.7614 - recall_m: 0.5218 - f1_m: 0.5956\n",
      "Epoch 13: val_acc improved from 0.96951 to 0.96987, saving model to models/best_model_9_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0666 - acc: 0.9767 - precision_m: 0.7610 - recall_m: 0.5219 - f1_m: 0.5950 - val_loss: 0.1000 - val_acc: 0.9699 - val_precision_m: 0.7154 - val_recall_m: 0.2790 - val_f1_m: 0.3819\n",
      "Epoch 14/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0666 - acc: 0.9766 - precision_m: 0.7768 - recall_m: 0.5299 - f1_m: 0.6040\n",
      "Epoch 14: val_acc did not improve from 0.96987\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0664 - acc: 0.9768 - precision_m: 0.7811 - recall_m: 0.5313 - f1_m: 0.6063 - val_loss: 0.0960 - val_acc: 0.9696 - val_precision_m: 0.6983 - val_recall_m: 0.3812 - val_f1_m: 0.4580\n",
      "Epoch 15/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.0653 - acc: 0.9767 - precision_m: 0.7670 - recall_m: 0.5247 - f1_m: 0.6008\n",
      "Epoch 15: val_acc improved from 0.96987 to 0.97023, saving model to models/best_model_9_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0659 - acc: 0.9765 - precision_m: 0.7649 - recall_m: 0.5242 - f1_m: 0.5992 - val_loss: 0.0921 - val_acc: 0.9702 - val_precision_m: 0.6708 - val_recall_m: 0.4048 - val_f1_m: 0.4712\n",
      "Epoch 16/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0638 - acc: 0.9772 - precision_m: 0.7742 - recall_m: 0.5361 - f1_m: 0.6131\n",
      "Epoch 16: val_acc improved from 0.97023 to 0.97095, saving model to models/best_model_9_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0642 - acc: 0.9771 - precision_m: 0.7778 - recall_m: 0.5332 - f1_m: 0.6109 - val_loss: 0.0915 - val_acc: 0.9710 - val_precision_m: 0.6852 - val_recall_m: 0.4034 - val_f1_m: 0.4780\n",
      "Epoch 17/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.0647 - acc: 0.9774 - precision_m: 0.7758 - recall_m: 0.5367 - f1_m: 0.6063\n",
      "Epoch 17: val_acc did not improve from 0.97095\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0646 - acc: 0.9775 - precision_m: 0.7773 - recall_m: 0.5435 - f1_m: 0.6118 - val_loss: 0.0955 - val_acc: 0.9679 - val_precision_m: 0.5975 - val_recall_m: 0.5041 - val_f1_m: 0.5211\n",
      "Epoch 18/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9777 - precision_m: 0.7822 - recall_m: 0.5442 - f1_m: 0.6203\n",
      "Epoch 18: val_acc did not improve from 0.97095\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0629 - acc: 0.9777 - precision_m: 0.7849 - recall_m: 0.5434 - f1_m: 0.6199 - val_loss: 0.0947 - val_acc: 0.9701 - val_precision_m: 0.6518 - val_recall_m: 0.4344 - val_f1_m: 0.4845\n",
      "Epoch 19/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9784 - precision_m: 0.7863 - recall_m: 0.5652 - f1_m: 0.6384\n",
      "Epoch 19: val_acc did not improve from 0.97095\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0623 - acc: 0.9783 - precision_m: 0.7841 - recall_m: 0.5666 - f1_m: 0.6381 - val_loss: 0.1038 - val_acc: 0.9694 - val_precision_m: 0.7254 - val_recall_m: 0.2882 - val_f1_m: 0.3891\n",
      "Epoch 20/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0618 - acc: 0.9780 - precision_m: 0.7813 - recall_m: 0.5548 - f1_m: 0.6278\n",
      "Epoch 20: val_acc did not improve from 0.97095\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0620 - acc: 0.9780 - precision_m: 0.7799 - recall_m: 0.5579 - f1_m: 0.6293 - val_loss: 0.0958 - val_acc: 0.9693 - val_precision_m: 0.7035 - val_recall_m: 0.4239 - val_f1_m: 0.4792\n",
      "Epoch 21/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0617 - acc: 0.9779 - precision_m: 0.7708 - recall_m: 0.5480 - f1_m: 0.6217\n",
      "Epoch 21: val_acc did not improve from 0.97095\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0615 - acc: 0.9779 - precision_m: 0.7732 - recall_m: 0.5485 - f1_m: 0.6228 - val_loss: 0.0957 - val_acc: 0.9672 - val_precision_m: 0.5853 - val_recall_m: 0.4572 - val_f1_m: 0.4868\n",
      "Epoch 22/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0621 - acc: 0.9774 - precision_m: 0.7685 - recall_m: 0.5550 - f1_m: 0.6210\n",
      "Epoch 22: val_acc did not improve from 0.97095\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0621 - acc: 0.9774 - precision_m: 0.7687 - recall_m: 0.5551 - f1_m: 0.6213 - val_loss: 0.0950 - val_acc: 0.9675 - val_precision_m: 0.6023 - val_recall_m: 0.4768 - val_f1_m: 0.4931\n",
      "Epoch 23/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0603 - acc: 0.9790 - precision_m: 0.7799 - recall_m: 0.5800 - f1_m: 0.6483\n",
      "Epoch 23: val_acc did not improve from 0.97095\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0601 - acc: 0.9791 - precision_m: 0.7818 - recall_m: 0.5806 - f1_m: 0.6493 - val_loss: 0.0992 - val_acc: 0.9706 - val_precision_m: 0.7247 - val_recall_m: 0.3986 - val_f1_m: 0.4820\n",
      "Epoch 24/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9789 - precision_m: 0.7869 - recall_m: 0.5765 - f1_m: 0.6442\n",
      "Epoch 24: val_acc did not improve from 0.97095\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0603 - acc: 0.9789 - precision_m: 0.7857 - recall_m: 0.5771 - f1_m: 0.6446 - val_loss: 0.0956 - val_acc: 0.9694 - val_precision_m: 0.6410 - val_recall_m: 0.4466 - val_f1_m: 0.4977\n",
      "Epoch 25/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0600 - acc: 0.9789 - precision_m: 0.7944 - recall_m: 0.5794 - f1_m: 0.6472\n",
      "Epoch 25: val_acc did not improve from 0.97095\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0598 - acc: 0.9790 - precision_m: 0.7942 - recall_m: 0.5806 - f1_m: 0.6475 - val_loss: 0.0979 - val_acc: 0.9694 - val_precision_m: 0.6447 - val_recall_m: 0.4158 - val_f1_m: 0.4751\n",
      "Epoch 26/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9790 - precision_m: 0.7978 - recall_m: 0.5804 - f1_m: 0.6490\n",
      "Epoch 26: val_acc did not improve from 0.97095\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0596 - acc: 0.9790 - precision_m: 0.7992 - recall_m: 0.5807 - f1_m: 0.6498 - val_loss: 0.0986 - val_acc: 0.9673 - val_precision_m: 0.6170 - val_recall_m: 0.4645 - val_f1_m: 0.4989\n",
      "Epoch 27/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9794 - precision_m: 0.7903 - recall_m: 0.5832 - f1_m: 0.6526\n",
      "Epoch 27: val_acc did not improve from 0.97095\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0588 - acc: 0.9794 - precision_m: 0.7922 - recall_m: 0.5845 - f1_m: 0.6543 - val_loss: 0.1022 - val_acc: 0.9700 - val_precision_m: 0.6688 - val_recall_m: 0.3991 - val_f1_m: 0.4685\n",
      "Epoch 28/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0585 - acc: 0.9793 - precision_m: 0.7914 - recall_m: 0.5857 - f1_m: 0.6556\n",
      "Epoch 28: val_acc did not improve from 0.97095\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0586 - acc: 0.9792 - precision_m: 0.7914 - recall_m: 0.5840 - f1_m: 0.6542 - val_loss: 0.0981 - val_acc: 0.9676 - val_precision_m: 0.6010 - val_recall_m: 0.4768 - val_f1_m: 0.4960\n",
      "Epoch 29/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0590 - acc: 0.9787 - precision_m: 0.7919 - recall_m: 0.5828 - f1_m: 0.6465\n",
      "Epoch 29: val_acc did not improve from 0.97095\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0589 - acc: 0.9788 - precision_m: 0.7913 - recall_m: 0.5839 - f1_m: 0.6473 - val_loss: 0.0997 - val_acc: 0.9689 - val_precision_m: 0.6443 - val_recall_m: 0.4077 - val_f1_m: 0.4671\n",
      "Epoch 30/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0590 - acc: 0.9791 - precision_m: 0.7915 - recall_m: 0.5842 - f1_m: 0.6489\n",
      "Epoch 30: val_acc did not improve from 0.97095\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0591 - acc: 0.9790 - precision_m: 0.7896 - recall_m: 0.5858 - f1_m: 0.6488 - val_loss: 0.1025 - val_acc: 0.9681 - val_precision_m: 0.6654 - val_recall_m: 0.3911 - val_f1_m: 0.4638\n",
      "Score for fold 6: loss of 0.09147573262453079; acc of 97.09533452987671%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.09102196246385574; acc of 97.11611866950989%\n",
      "Test Precision: precision_m of 22.295522689819336%\n",
      "Test Recall: recall_m of 16.27245992422104%\n",
      "Test F1: f1_m of 17.760097980499268%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1628 - acc: 0.9592 - precision_m: 0.0208 - recall_m: 0.0057 - f1_m: 0.0042    \n",
      "Epoch 1: val_acc improved from -inf to 0.96225, saving model to models/best_model_9_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 2s 3ms/step - loss: 0.1628 - acc: 0.9592 - precision_m: 0.0208 - recall_m: 0.0057 - f1_m: 0.0042 - val_loss: 0.1257 - val_acc: 0.9622 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.1186 - acc: 0.9639 - precision_m: 0.3681 - recall_m: 0.0661 - f1_m: 0.1078\n",
      "Epoch 2: val_acc improved from 0.96225 to 0.96464, saving model to models/best_model_9_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1183 - acc: 0.9639 - precision_m: 0.3688 - recall_m: 0.0682 - f1_m: 0.1104 - val_loss: 0.1104 - val_acc: 0.9646 - val_precision_m: 0.2727 - val_recall_m: 0.0421 - val_f1_m: 0.0716\n",
      "Epoch 3/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.1041 - acc: 0.9658 - precision_m: 0.6022 - recall_m: 0.1640 - f1_m: 0.2453\n",
      "Epoch 3: val_acc improved from 0.96464 to 0.96810, saving model to models/best_model_9_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1036 - acc: 0.9660 - precision_m: 0.6072 - recall_m: 0.1655 - f1_m: 0.2469 - val_loss: 0.1022 - val_acc: 0.9681 - val_precision_m: 0.4651 - val_recall_m: 0.1640 - val_f1_m: 0.2342\n",
      "Epoch 4/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0964 - acc: 0.9675 - precision_m: 0.6477 - recall_m: 0.2381 - f1_m: 0.3320\n",
      "Epoch 4: val_acc did not improve from 0.96810\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0965 - acc: 0.9674 - precision_m: 0.6482 - recall_m: 0.2387 - f1_m: 0.3326 - val_loss: 0.1038 - val_acc: 0.9671 - val_precision_m: 0.5680 - val_recall_m: 0.2881 - val_f1_m: 0.3541\n",
      "Epoch 5/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0935 - acc: 0.9680 - precision_m: 0.6519 - recall_m: 0.2782 - f1_m: 0.3684\n",
      "Epoch 5: val_acc did not improve from 0.96810\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0933 - acc: 0.9681 - precision_m: 0.6461 - recall_m: 0.2753 - f1_m: 0.3645 - val_loss: 0.1044 - val_acc: 0.9664 - val_precision_m: 0.5317 - val_recall_m: 0.1622 - val_f1_m: 0.2320\n",
      "Epoch 6/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0905 - acc: 0.9684 - precision_m: 0.6552 - recall_m: 0.3020 - f1_m: 0.3929\n",
      "Epoch 6: val_acc did not improve from 0.96810\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0904 - acc: 0.9684 - precision_m: 0.6556 - recall_m: 0.3010 - f1_m: 0.3922 - val_loss: 0.0980 - val_acc: 0.9659 - val_precision_m: 0.4760 - val_recall_m: 0.2037 - val_f1_m: 0.2658\n",
      "Epoch 7/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0881 - acc: 0.9692 - precision_m: 0.6694 - recall_m: 0.3078 - f1_m: 0.4004\n",
      "Epoch 7: val_acc did not improve from 0.96810\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0880 - acc: 0.9691 - precision_m: 0.6636 - recall_m: 0.3072 - f1_m: 0.3986 - val_loss: 0.0948 - val_acc: 0.9679 - val_precision_m: 0.5395 - val_recall_m: 0.2852 - val_f1_m: 0.3491\n",
      "Epoch 8/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0870 - acc: 0.9689 - precision_m: 0.6852 - recall_m: 0.3109 - f1_m: 0.4039\n",
      "Epoch 8: val_acc did not improve from 0.96810\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0869 - acc: 0.9690 - precision_m: 0.6856 - recall_m: 0.3105 - f1_m: 0.4036 - val_loss: 0.1001 - val_acc: 0.9649 - val_precision_m: 0.5447 - val_recall_m: 0.3364 - val_f1_m: 0.3773\n",
      "Epoch 9/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0865 - acc: 0.9692 - precision_m: 0.6853 - recall_m: 0.3315 - f1_m: 0.4213\n",
      "Epoch 9: val_acc did not improve from 0.96810\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0866 - acc: 0.9693 - precision_m: 0.6851 - recall_m: 0.3305 - f1_m: 0.4200 - val_loss: 0.0944 - val_acc: 0.9674 - val_precision_m: 0.5555 - val_recall_m: 0.1496 - val_f1_m: 0.2252\n",
      "Epoch 10/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0846 - acc: 0.9699 - precision_m: 0.6789 - recall_m: 0.3364 - f1_m: 0.4290\n",
      "Epoch 10: val_acc did not improve from 0.96810\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0845 - acc: 0.9699 - precision_m: 0.6838 - recall_m: 0.3372 - f1_m: 0.4305 - val_loss: 0.0945 - val_acc: 0.9668 - val_precision_m: 0.5849 - val_recall_m: 0.3128 - val_f1_m: 0.3738\n",
      "Epoch 11/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.0837 - acc: 0.9703 - precision_m: 0.6971 - recall_m: 0.3447 - f1_m: 0.4416\n",
      "Epoch 11: val_acc did not improve from 0.96810\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0838 - acc: 0.9703 - precision_m: 0.6994 - recall_m: 0.3423 - f1_m: 0.4398 - val_loss: 0.0926 - val_acc: 0.9680 - val_precision_m: 0.5616 - val_recall_m: 0.2936 - val_f1_m: 0.3622\n",
      "Epoch 12/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.0824 - acc: 0.9702 - precision_m: 0.7123 - recall_m: 0.3625 - f1_m: 0.4570\n",
      "Epoch 12: val_acc improved from 0.96810 to 0.96858, saving model to models/best_model_9_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0820 - acc: 0.9704 - precision_m: 0.7077 - recall_m: 0.3615 - f1_m: 0.4549 - val_loss: 0.0896 - val_acc: 0.9686 - val_precision_m: 0.6304 - val_recall_m: 0.2965 - val_f1_m: 0.3759\n",
      "Epoch 13/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0800 - acc: 0.9712 - precision_m: 0.6987 - recall_m: 0.3639 - f1_m: 0.4551\n",
      "Epoch 13: val_acc did not improve from 0.96858\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0802 - acc: 0.9711 - precision_m: 0.6982 - recall_m: 0.3669 - f1_m: 0.4568 - val_loss: 0.0919 - val_acc: 0.9683 - val_precision_m: 0.5714 - val_recall_m: 0.3365 - val_f1_m: 0.3997\n",
      "Epoch 14/30\n",
      "275/292 [===========================>..] - ETA: 0s - loss: 0.0786 - acc: 0.9715 - precision_m: 0.7214 - recall_m: 0.3883 - f1_m: 0.4801\n",
      "Epoch 14: val_acc did not improve from 0.96858\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0787 - acc: 0.9715 - precision_m: 0.7194 - recall_m: 0.3878 - f1_m: 0.4784 - val_loss: 0.0898 - val_acc: 0.9680 - val_precision_m: 0.5806 - val_recall_m: 0.3446 - val_f1_m: 0.3979\n",
      "Epoch 15/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0781 - acc: 0.9720 - precision_m: 0.7302 - recall_m: 0.4017 - f1_m: 0.4949\n",
      "Epoch 15: val_acc did not improve from 0.96858\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0779 - acc: 0.9721 - precision_m: 0.7263 - recall_m: 0.3980 - f1_m: 0.4911 - val_loss: 0.0944 - val_acc: 0.9670 - val_precision_m: 0.5265 - val_recall_m: 0.3525 - val_f1_m: 0.3946\n",
      "Epoch 16/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0770 - acc: 0.9722 - precision_m: 0.7257 - recall_m: 0.4140 - f1_m: 0.5043\n",
      "Epoch 16: val_acc improved from 0.96858 to 0.96882, saving model to models/best_model_9_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0774 - acc: 0.9721 - precision_m: 0.7251 - recall_m: 0.4147 - f1_m: 0.5048 - val_loss: 0.0915 - val_acc: 0.9688 - val_precision_m: 0.6177 - val_recall_m: 0.3274 - val_f1_m: 0.3939\n",
      "Epoch 17/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0753 - acc: 0.9727 - precision_m: 0.7361 - recall_m: 0.4288 - f1_m: 0.5150\n",
      "Epoch 17: val_acc did not improve from 0.96882\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0759 - acc: 0.9725 - precision_m: 0.7332 - recall_m: 0.4271 - f1_m: 0.5132 - val_loss: 0.0960 - val_acc: 0.9652 - val_precision_m: 0.5285 - val_recall_m: 0.4151 - val_f1_m: 0.4308\n",
      "Epoch 18/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0757 - acc: 0.9728 - precision_m: 0.7172 - recall_m: 0.4233 - f1_m: 0.5091\n",
      "Epoch 18: val_acc improved from 0.96882 to 0.96906, saving model to models/best_model_9_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0757 - acc: 0.9728 - precision_m: 0.7170 - recall_m: 0.4226 - f1_m: 0.5086 - val_loss: 0.0913 - val_acc: 0.9691 - val_precision_m: 0.5985 - val_recall_m: 0.2773 - val_f1_m: 0.3643\n",
      "Epoch 19/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0738 - acc: 0.9733 - precision_m: 0.7384 - recall_m: 0.4390 - f1_m: 0.5295\n",
      "Epoch 19: val_acc improved from 0.96906 to 0.96965, saving model to models/best_model_9_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0738 - acc: 0.9732 - precision_m: 0.7393 - recall_m: 0.4363 - f1_m: 0.5269 - val_loss: 0.0899 - val_acc: 0.9697 - val_precision_m: 0.6721 - val_recall_m: 0.3038 - val_f1_m: 0.3876\n",
      "Epoch 20/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0734 - acc: 0.9733 - precision_m: 0.7400 - recall_m: 0.4442 - f1_m: 0.5349\n",
      "Epoch 20: val_acc improved from 0.96965 to 0.97061, saving model to models/best_model_9_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0735 - acc: 0.9733 - precision_m: 0.7411 - recall_m: 0.4467 - f1_m: 0.5368 - val_loss: 0.0919 - val_acc: 0.9706 - val_precision_m: 0.6879 - val_recall_m: 0.3006 - val_f1_m: 0.3923\n",
      "Epoch 21/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.0733 - acc: 0.9743 - precision_m: 0.7387 - recall_m: 0.4639 - f1_m: 0.5464\n",
      "Epoch 21: val_acc did not improve from 0.97061\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0732 - acc: 0.9743 - precision_m: 0.7450 - recall_m: 0.4616 - f1_m: 0.5457 - val_loss: 0.0889 - val_acc: 0.9691 - val_precision_m: 0.6320 - val_recall_m: 0.3321 - val_f1_m: 0.4040\n",
      "Epoch 22/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0736 - acc: 0.9737 - precision_m: 0.7389 - recall_m: 0.4576 - f1_m: 0.5391\n",
      "Epoch 22: val_acc did not improve from 0.97061\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0733 - acc: 0.9738 - precision_m: 0.7324 - recall_m: 0.4570 - f1_m: 0.5370 - val_loss: 0.0968 - val_acc: 0.9694 - val_precision_m: 0.7029 - val_recall_m: 0.2244 - val_f1_m: 0.3163\n",
      "Epoch 23/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0725 - acc: 0.9740 - precision_m: 0.7428 - recall_m: 0.4662 - f1_m: 0.5471\n",
      "Epoch 23: val_acc did not improve from 0.97061\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0728 - acc: 0.9739 - precision_m: 0.7422 - recall_m: 0.4648 - f1_m: 0.5461 - val_loss: 0.0898 - val_acc: 0.9695 - val_precision_m: 0.6306 - val_recall_m: 0.3884 - val_f1_m: 0.4430\n",
      "Epoch 24/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0714 - acc: 0.9744 - precision_m: 0.7525 - recall_m: 0.4728 - f1_m: 0.5572\n",
      "Epoch 24: val_acc did not improve from 0.97061\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0714 - acc: 0.9743 - precision_m: 0.7542 - recall_m: 0.4733 - f1_m: 0.5572 - val_loss: 0.0888 - val_acc: 0.9694 - val_precision_m: 0.6165 - val_recall_m: 0.3515 - val_f1_m: 0.4147\n",
      "Epoch 25/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0721 - acc: 0.9737 - precision_m: 0.7252 - recall_m: 0.4709 - f1_m: 0.5535\n",
      "Epoch 25: val_acc did not improve from 0.97061\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0717 - acc: 0.9739 - precision_m: 0.7309 - recall_m: 0.4671 - f1_m: 0.5518 - val_loss: 0.0924 - val_acc: 0.9671 - val_precision_m: 0.5688 - val_recall_m: 0.3779 - val_f1_m: 0.4174\n",
      "Epoch 26/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0709 - acc: 0.9748 - precision_m: 0.7357 - recall_m: 0.4838 - f1_m: 0.5663\n",
      "Epoch 26: val_acc did not improve from 0.97061\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0714 - acc: 0.9747 - precision_m: 0.7344 - recall_m: 0.4779 - f1_m: 0.5611 - val_loss: 0.0891 - val_acc: 0.9688 - val_precision_m: 0.6208 - val_recall_m: 0.3742 - val_f1_m: 0.4376\n",
      "Epoch 27/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.0705 - acc: 0.9754 - precision_m: 0.7594 - recall_m: 0.4975 - f1_m: 0.5770\n",
      "Epoch 27: val_acc did not improve from 0.97061\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0712 - acc: 0.9752 - precision_m: 0.7557 - recall_m: 0.4949 - f1_m: 0.5740 - val_loss: 0.0903 - val_acc: 0.9670 - val_precision_m: 0.5695 - val_recall_m: 0.4059 - val_f1_m: 0.4412\n",
      "Epoch 28/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0695 - acc: 0.9751 - precision_m: 0.7624 - recall_m: 0.4910 - f1_m: 0.5772\n",
      "Epoch 28: val_acc did not improve from 0.97061\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0697 - acc: 0.9751 - precision_m: 0.7598 - recall_m: 0.4916 - f1_m: 0.5768 - val_loss: 0.0952 - val_acc: 0.9688 - val_precision_m: 0.6008 - val_recall_m: 0.2798 - val_f1_m: 0.3625\n",
      "Epoch 29/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0701 - acc: 0.9750 - precision_m: 0.7521 - recall_m: 0.4814 - f1_m: 0.5640\n",
      "Epoch 29: val_acc did not improve from 0.97061\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0703 - acc: 0.9748 - precision_m: 0.7476 - recall_m: 0.4806 - f1_m: 0.5618 - val_loss: 0.0879 - val_acc: 0.9704 - val_precision_m: 0.6469 - val_recall_m: 0.3585 - val_f1_m: 0.4251\n",
      "Epoch 30/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0689 - acc: 0.9755 - precision_m: 0.7595 - recall_m: 0.4943 - f1_m: 0.5783\n",
      "Epoch 30: val_acc did not improve from 0.97061\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0691 - acc: 0.9754 - precision_m: 0.7614 - recall_m: 0.4933 - f1_m: 0.5779 - val_loss: 0.0902 - val_acc: 0.9693 - val_precision_m: 0.6312 - val_recall_m: 0.4282 - val_f1_m: 0.4793\n",
      "Score for fold 7: loss of 0.09189733117818832; acc of 97.06093072891235%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.07181836664676666; acc of 97.70616888999939%\n",
      "Test Precision: precision_m of 18.234610557556152%\n",
      "Test Recall: recall_m of 12.517836689949036%\n",
      "Test F1: f1_m of 14.127962291240692%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1450 - acc: 0.9627 - precision_m: 0.1070 - recall_m: 0.0150 - f1_m: 0.0241\n",
      "Epoch 1: val_acc improved from -inf to 0.96263, saving model to models/best_model_9_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 2s 3ms/step - loss: 0.1450 - acc: 0.9627 - precision_m: 0.1070 - recall_m: 0.0150 - f1_m: 0.0241 - val_loss: 0.1197 - val_acc: 0.9626 - val_precision_m: 0.0909 - val_recall_m: 0.0095 - val_f1_m: 0.0166\n",
      "Epoch 2/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.1145 - acc: 0.9644 - precision_m: 0.3709 - recall_m: 0.0814 - f1_m: 0.1263\n",
      "Epoch 2: val_acc improved from 0.96263 to 0.96287, saving model to models/best_model_9_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1143 - acc: 0.9643 - precision_m: 0.3712 - recall_m: 0.0843 - f1_m: 0.1294 - val_loss: 0.1096 - val_acc: 0.9629 - val_precision_m: 0.4330 - val_recall_m: 0.0731 - val_f1_m: 0.1187\n",
      "Epoch 3/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.1018 - acc: 0.9664 - precision_m: 0.5868 - recall_m: 0.1886 - f1_m: 0.2654\n",
      "Epoch 3: val_acc improved from 0.96287 to 0.96790, saving model to models/best_model_9_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1015 - acc: 0.9666 - precision_m: 0.5929 - recall_m: 0.1906 - f1_m: 0.2684 - val_loss: 0.0994 - val_acc: 0.9679 - val_precision_m: 0.5297 - val_recall_m: 0.2351 - val_f1_m: 0.3060\n",
      "Epoch 4/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0941 - acc: 0.9680 - precision_m: 0.6483 - recall_m: 0.2671 - f1_m: 0.3517\n",
      "Epoch 4: val_acc improved from 0.96790 to 0.97005, saving model to models/best_model_9_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0935 - acc: 0.9681 - precision_m: 0.6428 - recall_m: 0.2630 - f1_m: 0.3473 - val_loss: 0.0944 - val_acc: 0.9701 - val_precision_m: 0.5608 - val_recall_m: 0.2737 - val_f1_m: 0.3485\n",
      "Epoch 5/30\n",
      "274/292 [===========================>..] - ETA: 0s - loss: 0.0890 - acc: 0.9698 - precision_m: 0.6829 - recall_m: 0.3333 - f1_m: 0.4242\n",
      "Epoch 5: val_acc did not improve from 0.97005\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0885 - acc: 0.9699 - precision_m: 0.6783 - recall_m: 0.3317 - f1_m: 0.4226 - val_loss: 0.0937 - val_acc: 0.9698 - val_precision_m: 0.6016 - val_recall_m: 0.2442 - val_f1_m: 0.3279\n",
      "Epoch 6/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.0862 - acc: 0.9703 - precision_m: 0.6989 - recall_m: 0.3504 - f1_m: 0.4424\n",
      "Epoch 6: val_acc improved from 0.97005 to 0.97017, saving model to models/best_model_9_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0859 - acc: 0.9705 - precision_m: 0.6998 - recall_m: 0.3488 - f1_m: 0.4414 - val_loss: 0.0919 - val_acc: 0.9702 - val_precision_m: 0.5790 - val_recall_m: 0.2943 - val_f1_m: 0.3587\n",
      "Epoch 7/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0835 - acc: 0.9708 - precision_m: 0.6919 - recall_m: 0.3753 - f1_m: 0.4662\n",
      "Epoch 7: val_acc did not improve from 0.97017\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0834 - acc: 0.9710 - precision_m: 0.6938 - recall_m: 0.3770 - f1_m: 0.4674 - val_loss: 0.0918 - val_acc: 0.9702 - val_precision_m: 0.5832 - val_recall_m: 0.3079 - val_f1_m: 0.3796\n",
      "Epoch 8/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0814 - acc: 0.9715 - precision_m: 0.6932 - recall_m: 0.3789 - f1_m: 0.4676\n",
      "Epoch 8: val_acc did not improve from 0.97017\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0815 - acc: 0.9715 - precision_m: 0.6933 - recall_m: 0.3813 - f1_m: 0.4698 - val_loss: 0.0929 - val_acc: 0.9693 - val_precision_m: 0.6057 - val_recall_m: 0.3699 - val_f1_m: 0.4296\n",
      "Epoch 9/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0813 - acc: 0.9717 - precision_m: 0.7146 - recall_m: 0.4144 - f1_m: 0.5008\n",
      "Epoch 9: val_acc improved from 0.97017 to 0.97185, saving model to models/best_model_9_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0810 - acc: 0.9719 - precision_m: 0.7163 - recall_m: 0.4116 - f1_m: 0.4989 - val_loss: 0.0910 - val_acc: 0.9718 - val_precision_m: 0.6243 - val_recall_m: 0.3313 - val_f1_m: 0.4091\n",
      "Epoch 10/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0804 - acc: 0.9722 - precision_m: 0.7075 - recall_m: 0.4134 - f1_m: 0.4960\n",
      "Epoch 10: val_acc did not improve from 0.97185\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0804 - acc: 0.9722 - precision_m: 0.7065 - recall_m: 0.4121 - f1_m: 0.4948 - val_loss: 0.0950 - val_acc: 0.9691 - val_precision_m: 0.5754 - val_recall_m: 0.3641 - val_f1_m: 0.4147\n",
      "Epoch 11/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0788 - acc: 0.9733 - precision_m: 0.7307 - recall_m: 0.4334 - f1_m: 0.5185\n",
      "Epoch 11: val_acc did not improve from 0.97185\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0788 - acc: 0.9732 - precision_m: 0.7296 - recall_m: 0.4288 - f1_m: 0.5141 - val_loss: 0.0999 - val_acc: 0.9661 - val_precision_m: 0.4991 - val_recall_m: 0.4724 - val_f1_m: 0.4528\n",
      "Epoch 12/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0783 - acc: 0.9726 - precision_m: 0.7257 - recall_m: 0.4264 - f1_m: 0.5118\n",
      "Epoch 12: val_acc did not improve from 0.97185\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0780 - acc: 0.9729 - precision_m: 0.7279 - recall_m: 0.4315 - f1_m: 0.5165 - val_loss: 0.1006 - val_acc: 0.9686 - val_precision_m: 0.5597 - val_recall_m: 0.2489 - val_f1_m: 0.3254\n",
      "Epoch 13/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0771 - acc: 0.9730 - precision_m: 0.7153 - recall_m: 0.4326 - f1_m: 0.5172\n",
      "Epoch 13: val_acc did not improve from 0.97185\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0769 - acc: 0.9731 - precision_m: 0.7156 - recall_m: 0.4293 - f1_m: 0.5138 - val_loss: 0.0908 - val_acc: 0.9714 - val_precision_m: 0.6354 - val_recall_m: 0.3186 - val_f1_m: 0.3919\n",
      "Epoch 14/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.0755 - acc: 0.9737 - precision_m: 0.7331 - recall_m: 0.4389 - f1_m: 0.5263\n",
      "Epoch 14: val_acc did not improve from 0.97185\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0751 - acc: 0.9739 - precision_m: 0.7337 - recall_m: 0.4408 - f1_m: 0.5274 - val_loss: 0.0950 - val_acc: 0.9687 - val_precision_m: 0.5305 - val_recall_m: 0.4517 - val_f1_m: 0.4562\n",
      "Epoch 15/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.0753 - acc: 0.9738 - precision_m: 0.7419 - recall_m: 0.4550 - f1_m: 0.5373\n",
      "Epoch 15: val_acc did not improve from 0.97185\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0753 - acc: 0.9737 - precision_m: 0.7387 - recall_m: 0.4540 - f1_m: 0.5350 - val_loss: 0.0947 - val_acc: 0.9690 - val_precision_m: 0.5647 - val_recall_m: 0.4022 - val_f1_m: 0.4427\n",
      "Epoch 16/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0745 - acc: 0.9738 - precision_m: 0.7253 - recall_m: 0.4432 - f1_m: 0.5264\n",
      "Epoch 16: val_acc did not improve from 0.97185\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0745 - acc: 0.9738 - precision_m: 0.7275 - recall_m: 0.4416 - f1_m: 0.5255 - val_loss: 0.0930 - val_acc: 0.9709 - val_precision_m: 0.6017 - val_recall_m: 0.3280 - val_f1_m: 0.3932\n",
      "Epoch 17/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.0731 - acc: 0.9742 - precision_m: 0.7520 - recall_m: 0.4557 - f1_m: 0.5422\n",
      "Epoch 17: val_acc did not improve from 0.97185\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0735 - acc: 0.9742 - precision_m: 0.7557 - recall_m: 0.4571 - f1_m: 0.5447 - val_loss: 0.0904 - val_acc: 0.9711 - val_precision_m: 0.5847 - val_recall_m: 0.3511 - val_f1_m: 0.4098\n",
      "Epoch 18/30\n",
      "274/292 [===========================>..] - ETA: 0s - loss: 0.0736 - acc: 0.9748 - precision_m: 0.7633 - recall_m: 0.4577 - f1_m: 0.5454\n",
      "Epoch 18: val_acc did not improve from 0.97185\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0738 - acc: 0.9746 - precision_m: 0.7571 - recall_m: 0.4572 - f1_m: 0.5430 - val_loss: 0.0930 - val_acc: 0.9695 - val_precision_m: 0.5338 - val_recall_m: 0.3604 - val_f1_m: 0.4071\n",
      "Epoch 19/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0749 - acc: 0.9737 - precision_m: 0.7431 - recall_m: 0.4521 - f1_m: 0.5300\n",
      "Epoch 19: val_acc did not improve from 0.97185\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0747 - acc: 0.9738 - precision_m: 0.7426 - recall_m: 0.4540 - f1_m: 0.5322 - val_loss: 0.0976 - val_acc: 0.9711 - val_precision_m: 0.6583 - val_recall_m: 0.2758 - val_f1_m: 0.3560\n",
      "Epoch 20/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.0726 - acc: 0.9744 - precision_m: 0.7607 - recall_m: 0.4574 - f1_m: 0.5444\n",
      "Epoch 20: val_acc did not improve from 0.97185\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0729 - acc: 0.9744 - precision_m: 0.7610 - recall_m: 0.4599 - f1_m: 0.5471 - val_loss: 0.0940 - val_acc: 0.9693 - val_precision_m: 0.5704 - val_recall_m: 0.4277 - val_f1_m: 0.4595\n",
      "Epoch 21/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0724 - acc: 0.9743 - precision_m: 0.7512 - recall_m: 0.4595 - f1_m: 0.5456\n",
      "Epoch 21: val_acc did not improve from 0.97185\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0723 - acc: 0.9743 - precision_m: 0.7501 - recall_m: 0.4572 - f1_m: 0.5437 - val_loss: 0.0895 - val_acc: 0.9718 - val_precision_m: 0.6390 - val_recall_m: 0.4127 - val_f1_m: 0.4713\n",
      "Epoch 22/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0712 - acc: 0.9753 - precision_m: 0.7700 - recall_m: 0.4747 - f1_m: 0.5632\n",
      "Epoch 22: val_acc did not improve from 0.97185\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0712 - acc: 0.9753 - precision_m: 0.7685 - recall_m: 0.4746 - f1_m: 0.5629 - val_loss: 0.0946 - val_acc: 0.9698 - val_precision_m: 0.5730 - val_recall_m: 0.4155 - val_f1_m: 0.4437\n",
      "Epoch 23/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0714 - acc: 0.9748 - precision_m: 0.7612 - recall_m: 0.4733 - f1_m: 0.5576\n",
      "Epoch 23: val_acc did not improve from 0.97185\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0718 - acc: 0.9747 - precision_m: 0.7622 - recall_m: 0.4700 - f1_m: 0.5552 - val_loss: 0.0938 - val_acc: 0.9689 - val_precision_m: 0.5540 - val_recall_m: 0.4153 - val_f1_m: 0.4504\n",
      "Epoch 24/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0712 - acc: 0.9746 - precision_m: 0.7415 - recall_m: 0.4617 - f1_m: 0.5463\n",
      "Epoch 24: val_acc did not improve from 0.97185\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0711 - acc: 0.9746 - precision_m: 0.7444 - recall_m: 0.4652 - f1_m: 0.5489 - val_loss: 0.0928 - val_acc: 0.9691 - val_precision_m: 0.5413 - val_recall_m: 0.3735 - val_f1_m: 0.4188\n",
      "Epoch 25/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.0709 - acc: 0.9750 - precision_m: 0.7501 - recall_m: 0.4752 - f1_m: 0.5614\n",
      "Epoch 25: val_acc did not improve from 0.97185\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0710 - acc: 0.9749 - precision_m: 0.7457 - recall_m: 0.4772 - f1_m: 0.5614 - val_loss: 0.0960 - val_acc: 0.9701 - val_precision_m: 0.5845 - val_recall_m: 0.2779 - val_f1_m: 0.3518\n",
      "Epoch 26/30\n",
      "275/292 [===========================>..] - ETA: 0s - loss: 0.0696 - acc: 0.9755 - precision_m: 0.7688 - recall_m: 0.4853 - f1_m: 0.5716\n",
      "Epoch 26: val_acc did not improve from 0.97185\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0705 - acc: 0.9753 - precision_m: 0.7713 - recall_m: 0.4849 - f1_m: 0.5707 - val_loss: 0.0954 - val_acc: 0.9707 - val_precision_m: 0.6163 - val_recall_m: 0.3495 - val_f1_m: 0.4192\n",
      "Epoch 27/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.0699 - acc: 0.9753 - precision_m: 0.7625 - recall_m: 0.4864 - f1_m: 0.5708\n",
      "Epoch 27: val_acc did not improve from 0.97185\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0703 - acc: 0.9753 - precision_m: 0.7638 - recall_m: 0.4849 - f1_m: 0.5701 - val_loss: 0.0931 - val_acc: 0.9701 - val_precision_m: 0.6002 - val_recall_m: 0.3779 - val_f1_m: 0.4369\n",
      "Epoch 28/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0705 - acc: 0.9750 - precision_m: 0.7605 - recall_m: 0.4708 - f1_m: 0.5596\n",
      "Epoch 28: val_acc did not improve from 0.97185\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0700 - acc: 0.9752 - precision_m: 0.7617 - recall_m: 0.4720 - f1_m: 0.5612 - val_loss: 0.0928 - val_acc: 0.9711 - val_precision_m: 0.5789 - val_recall_m: 0.3355 - val_f1_m: 0.3927\n",
      "Epoch 29/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0694 - acc: 0.9754 - precision_m: 0.7640 - recall_m: 0.4801 - f1_m: 0.5646\n",
      "Epoch 29: val_acc did not improve from 0.97185\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0693 - acc: 0.9754 - precision_m: 0.7632 - recall_m: 0.4788 - f1_m: 0.5629 - val_loss: 0.0946 - val_acc: 0.9710 - val_precision_m: 0.5894 - val_recall_m: 0.3090 - val_f1_m: 0.3736\n",
      "Epoch 30/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0695 - acc: 0.9756 - precision_m: 0.7715 - recall_m: 0.4913 - f1_m: 0.5777\n",
      "Epoch 30: val_acc did not improve from 0.97185\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0688 - acc: 0.9757 - precision_m: 0.7724 - recall_m: 0.4903 - f1_m: 0.5775 - val_loss: 0.0967 - val_acc: 0.9681 - val_precision_m: 0.5529 - val_recall_m: 0.4130 - val_f1_m: 0.4479\n",
      "Score for fold 8: loss of 0.09099625051021576; acc of 97.18495607376099%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.0892074778676033; acc of 96.90231084823608%\n",
      "Test Precision: precision_m of 17.561838030815125%\n",
      "Test Recall: recall_m of 11.618353426456451%\n",
      "Test F1: f1_m of 12.998424470424652%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "Epoch 1/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.1358 - acc: 0.9636 - precision_m: 0.2769 - recall_m: 0.0734 - f1_m: 0.1071 \n",
      "Epoch 1: val_acc improved from -inf to 0.96592, saving model to models/best_model_9_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 2s 3ms/step - loss: 0.1358 - acc: 0.9636 - precision_m: 0.2769 - recall_m: 0.0734 - f1_m: 0.1071 - val_loss: 0.1091 - val_acc: 0.9659 - val_precision_m: 0.4679 - val_recall_m: 0.1374 - val_f1_m: 0.2034\n",
      "Epoch 2/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.1024 - acc: 0.9675 - precision_m: 0.5494 - recall_m: 0.2148 - f1_m: 0.2830\n",
      "Epoch 2: val_acc improved from 0.96592 to 0.96616, saving model to models/best_model_9_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1024 - acc: 0.9674 - precision_m: 0.5563 - recall_m: 0.2199 - f1_m: 0.2887 - val_loss: 0.0971 - val_acc: 0.9662 - val_precision_m: 0.5058 - val_recall_m: 0.1697 - val_f1_m: 0.2330\n",
      "Epoch 3/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0871 - acc: 0.9702 - precision_m: 0.6545 - recall_m: 0.3097 - f1_m: 0.3958\n",
      "Epoch 3: val_acc improved from 0.96616 to 0.96961, saving model to models/best_model_9_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0871 - acc: 0.9703 - precision_m: 0.6549 - recall_m: 0.3100 - f1_m: 0.3957 - val_loss: 0.0965 - val_acc: 0.9696 - val_precision_m: 0.6220 - val_recall_m: 0.4026 - val_f1_m: 0.4357\n",
      "Epoch 4/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0833 - acc: 0.9716 - precision_m: 0.6993 - recall_m: 0.3806 - f1_m: 0.4581\n",
      "Epoch 4: val_acc did not improve from 0.96961\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0837 - acc: 0.9715 - precision_m: 0.6949 - recall_m: 0.3810 - f1_m: 0.4579 - val_loss: 0.0979 - val_acc: 0.9683 - val_precision_m: 0.5929 - val_recall_m: 0.3292 - val_f1_m: 0.3934\n",
      "Epoch 5/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0802 - acc: 0.9722 - precision_m: 0.7130 - recall_m: 0.3989 - f1_m: 0.4767\n",
      "Epoch 5: val_acc improved from 0.96961 to 0.96997, saving model to models/best_model_9_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0799 - acc: 0.9723 - precision_m: 0.7143 - recall_m: 0.4030 - f1_m: 0.4808 - val_loss: 0.0871 - val_acc: 0.9700 - val_precision_m: 0.6020 - val_recall_m: 0.4279 - val_f1_m: 0.4634\n",
      "Epoch 6/30\n",
      "275/291 [===========================>..] - ETA: 0s - loss: 0.0749 - acc: 0.9735 - precision_m: 0.7095 - recall_m: 0.4354 - f1_m: 0.5177\n",
      "Epoch 6: val_acc improved from 0.96997 to 0.97128, saving model to models/best_model_9_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0755 - acc: 0.9733 - precision_m: 0.7057 - recall_m: 0.4317 - f1_m: 0.5137 - val_loss: 0.0919 - val_acc: 0.9713 - val_precision_m: 0.7348 - val_recall_m: 0.3485 - val_f1_m: 0.4389\n",
      "Epoch 7/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.0735 - acc: 0.9744 - precision_m: 0.7352 - recall_m: 0.4576 - f1_m: 0.5378\n",
      "Epoch 7: val_acc did not improve from 0.97128\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0736 - acc: 0.9742 - precision_m: 0.7303 - recall_m: 0.4557 - f1_m: 0.5351 - val_loss: 0.0972 - val_acc: 0.9683 - val_precision_m: 0.7330 - val_recall_m: 0.2833 - val_f1_m: 0.3773\n",
      "Epoch 8/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.0720 - acc: 0.9746 - precision_m: 0.7389 - recall_m: 0.4686 - f1_m: 0.5446\n",
      "Epoch 8: val_acc did not improve from 0.97128\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0719 - acc: 0.9747 - precision_m: 0.7405 - recall_m: 0.4708 - f1_m: 0.5469 - val_loss: 0.0946 - val_acc: 0.9672 - val_precision_m: 0.5351 - val_recall_m: 0.4325 - val_f1_m: 0.4458\n",
      "Epoch 9/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0698 - acc: 0.9756 - precision_m: 0.7482 - recall_m: 0.4961 - f1_m: 0.5723\n",
      "Epoch 9: val_acc did not improve from 0.97128\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0701 - acc: 0.9753 - precision_m: 0.7438 - recall_m: 0.4955 - f1_m: 0.5704 - val_loss: 0.0971 - val_acc: 0.9693 - val_precision_m: 0.7167 - val_recall_m: 0.2517 - val_f1_m: 0.3517\n",
      "Epoch 10/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.0684 - acc: 0.9759 - precision_m: 0.7560 - recall_m: 0.4923 - f1_m: 0.5726\n",
      "Epoch 10: val_acc improved from 0.97128 to 0.97224, saving model to models/best_model_9_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0686 - acc: 0.9758 - precision_m: 0.7539 - recall_m: 0.4935 - f1_m: 0.5727 - val_loss: 0.0876 - val_acc: 0.9722 - val_precision_m: 0.7025 - val_recall_m: 0.3772 - val_f1_m: 0.4569\n",
      "Epoch 11/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0661 - acc: 0.9761 - precision_m: 0.7609 - recall_m: 0.5070 - f1_m: 0.5837\n",
      "Epoch 11: val_acc did not improve from 0.97224\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0662 - acc: 0.9761 - precision_m: 0.7626 - recall_m: 0.5062 - f1_m: 0.5834 - val_loss: 0.0880 - val_acc: 0.9709 - val_precision_m: 0.6595 - val_recall_m: 0.3579 - val_f1_m: 0.4354\n",
      "Epoch 12/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0653 - acc: 0.9767 - precision_m: 0.7581 - recall_m: 0.5321 - f1_m: 0.6044\n",
      "Epoch 12: val_acc did not improve from 0.97224\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0652 - acc: 0.9767 - precision_m: 0.7593 - recall_m: 0.5322 - f1_m: 0.6050 - val_loss: 0.0906 - val_acc: 0.9695 - val_precision_m: 0.6164 - val_recall_m: 0.4205 - val_f1_m: 0.4715\n",
      "Epoch 13/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0644 - acc: 0.9773 - precision_m: 0.7623 - recall_m: 0.5304 - f1_m: 0.6026\n",
      "Epoch 13: val_acc did not improve from 0.97224\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0643 - acc: 0.9774 - precision_m: 0.7639 - recall_m: 0.5325 - f1_m: 0.6050 - val_loss: 0.0926 - val_acc: 0.9681 - val_precision_m: 0.5454 - val_recall_m: 0.5579 - val_f1_m: 0.5208\n",
      "Epoch 14/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.0646 - acc: 0.9776 - precision_m: 0.7789 - recall_m: 0.5439 - f1_m: 0.6156\n",
      "Epoch 14: val_acc did not improve from 0.97224\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0641 - acc: 0.9778 - precision_m: 0.7809 - recall_m: 0.5433 - f1_m: 0.6163 - val_loss: 0.0875 - val_acc: 0.9702 - val_precision_m: 0.5880 - val_recall_m: 0.5000 - val_f1_m: 0.5012\n",
      "Epoch 15/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.0630 - acc: 0.9778 - precision_m: 0.7648 - recall_m: 0.5596 - f1_m: 0.6229\n",
      "Epoch 15: val_acc did not improve from 0.97224\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0628 - acc: 0.9778 - precision_m: 0.7634 - recall_m: 0.5589 - f1_m: 0.6220 - val_loss: 0.0857 - val_acc: 0.9708 - val_precision_m: 0.6093 - val_recall_m: 0.4880 - val_f1_m: 0.5105\n",
      "Epoch 16/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0621 - acc: 0.9780 - precision_m: 0.7776 - recall_m: 0.5615 - f1_m: 0.6280\n",
      "Epoch 16: val_acc did not improve from 0.97224\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0624 - acc: 0.9779 - precision_m: 0.7761 - recall_m: 0.5593 - f1_m: 0.6267 - val_loss: 0.0950 - val_acc: 0.9662 - val_precision_m: 0.5382 - val_recall_m: 0.5427 - val_f1_m: 0.5092\n",
      "Epoch 17/30\n",
      "275/291 [===========================>..] - ETA: 0s - loss: 0.0619 - acc: 0.9774 - precision_m: 0.7605 - recall_m: 0.5559 - f1_m: 0.6167\n",
      "Epoch 17: val_acc did not improve from 0.97224\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0614 - acc: 0.9776 - precision_m: 0.7627 - recall_m: 0.5552 - f1_m: 0.6175 - val_loss: 0.0944 - val_acc: 0.9693 - val_precision_m: 0.6030 - val_recall_m: 0.4607 - val_f1_m: 0.4760\n",
      "Epoch 18/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0603 - acc: 0.9780 - precision_m: 0.7769 - recall_m: 0.5712 - f1_m: 0.6354\n",
      "Epoch 18: val_acc did not improve from 0.97224\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0597 - acc: 0.9782 - precision_m: 0.7764 - recall_m: 0.5680 - f1_m: 0.6328 - val_loss: 0.0942 - val_acc: 0.9676 - val_precision_m: 0.5661 - val_recall_m: 0.5425 - val_f1_m: 0.5187\n",
      "Epoch 19/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.0594 - acc: 0.9787 - precision_m: 0.7820 - recall_m: 0.5724 - f1_m: 0.6344\n",
      "Epoch 19: val_acc did not improve from 0.97224\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0595 - acc: 0.9786 - precision_m: 0.7806 - recall_m: 0.5735 - f1_m: 0.6348 - val_loss: 0.0890 - val_acc: 0.9693 - val_precision_m: 0.5885 - val_recall_m: 0.4331 - val_f1_m: 0.4670\n",
      "Epoch 20/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.0578 - acc: 0.9793 - precision_m: 0.7977 - recall_m: 0.5843 - f1_m: 0.6491\n",
      "Epoch 20: val_acc did not improve from 0.97224\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0579 - acc: 0.9793 - precision_m: 0.7976 - recall_m: 0.5845 - f1_m: 0.6493 - val_loss: 0.0948 - val_acc: 0.9670 - val_precision_m: 0.5344 - val_recall_m: 0.5728 - val_f1_m: 0.5186\n",
      "Epoch 21/30\n",
      "275/291 [===========================>..] - ETA: 0s - loss: 0.0581 - acc: 0.9790 - precision_m: 0.7847 - recall_m: 0.5941 - f1_m: 0.6523\n",
      "Epoch 21: val_acc did not improve from 0.97224\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0579 - acc: 0.9791 - precision_m: 0.7836 - recall_m: 0.5956 - f1_m: 0.6529 - val_loss: 0.0950 - val_acc: 0.9707 - val_precision_m: 0.6342 - val_recall_m: 0.4108 - val_f1_m: 0.4730\n",
      "Epoch 22/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.0567 - acc: 0.9797 - precision_m: 0.7936 - recall_m: 0.6017 - f1_m: 0.6642\n",
      "Epoch 22: val_acc did not improve from 0.97224\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0569 - acc: 0.9797 - precision_m: 0.7939 - recall_m: 0.6002 - f1_m: 0.6631 - val_loss: 0.0893 - val_acc: 0.9691 - val_precision_m: 0.5629 - val_recall_m: 0.4348 - val_f1_m: 0.4653\n",
      "Epoch 23/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.0574 - acc: 0.9795 - precision_m: 0.8001 - recall_m: 0.5861 - f1_m: 0.6550\n",
      "Epoch 23: val_acc did not improve from 0.97224\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0573 - acc: 0.9795 - precision_m: 0.8006 - recall_m: 0.5894 - f1_m: 0.6576 - val_loss: 0.1018 - val_acc: 0.9650 - val_precision_m: 0.5014 - val_recall_m: 0.5984 - val_f1_m: 0.5129\n",
      "Epoch 24/30\n",
      "274/291 [===========================>..] - ETA: 0s - loss: 0.0567 - acc: 0.9798 - precision_m: 0.7937 - recall_m: 0.6084 - f1_m: 0.6658\n",
      "Epoch 24: val_acc did not improve from 0.97224\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0570 - acc: 0.9798 - precision_m: 0.7957 - recall_m: 0.6026 - f1_m: 0.6620 - val_loss: 0.0887 - val_acc: 0.9709 - val_precision_m: 0.6182 - val_recall_m: 0.4505 - val_f1_m: 0.4971\n",
      "Epoch 25/30\n",
      "274/291 [===========================>..] - ETA: 0s - loss: 0.0555 - acc: 0.9801 - precision_m: 0.8023 - recall_m: 0.6112 - f1_m: 0.6739\n",
      "Epoch 25: val_acc did not improve from 0.97224\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0552 - acc: 0.9801 - precision_m: 0.8005 - recall_m: 0.6078 - f1_m: 0.6711 - val_loss: 0.0968 - val_acc: 0.9657 - val_precision_m: 0.5099 - val_recall_m: 0.5511 - val_f1_m: 0.5019\n",
      "Epoch 26/30\n",
      "275/291 [===========================>..] - ETA: 0s - loss: 0.0536 - acc: 0.9806 - precision_m: 0.7999 - recall_m: 0.6194 - f1_m: 0.6797\n",
      "Epoch 26: val_acc did not improve from 0.97224\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0539 - acc: 0.9804 - precision_m: 0.7983 - recall_m: 0.6190 - f1_m: 0.6786 - val_loss: 0.0923 - val_acc: 0.9714 - val_precision_m: 0.6360 - val_recall_m: 0.3966 - val_f1_m: 0.4573\n",
      "Epoch 27/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0548 - acc: 0.9805 - precision_m: 0.8028 - recall_m: 0.6126 - f1_m: 0.6724\n",
      "Epoch 27: val_acc did not improve from 0.97224\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0550 - acc: 0.9805 - precision_m: 0.8032 - recall_m: 0.6141 - f1_m: 0.6737 - val_loss: 0.0903 - val_acc: 0.9695 - val_precision_m: 0.5756 - val_recall_m: 0.5150 - val_f1_m: 0.5102\n",
      "Epoch 28/30\n",
      "274/291 [===========================>..] - ETA: 0s - loss: 0.0535 - acc: 0.9807 - precision_m: 0.7997 - recall_m: 0.6194 - f1_m: 0.6750\n",
      "Epoch 28: val_acc did not improve from 0.97224\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0540 - acc: 0.9804 - precision_m: 0.7995 - recall_m: 0.6148 - f1_m: 0.6714 - val_loss: 0.1008 - val_acc: 0.9679 - val_precision_m: 0.5430 - val_recall_m: 0.5102 - val_f1_m: 0.4952\n",
      "Epoch 29/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0537 - acc: 0.9808 - precision_m: 0.8137 - recall_m: 0.6206 - f1_m: 0.6834\n",
      "Epoch 29: val_acc did not improve from 0.97224\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0538 - acc: 0.9807 - precision_m: 0.8113 - recall_m: 0.6134 - f1_m: 0.6773 - val_loss: 0.0937 - val_acc: 0.9687 - val_precision_m: 0.5556 - val_recall_m: 0.5204 - val_f1_m: 0.5132\n",
      "Epoch 30/30\n",
      "276/291 [===========================>..] - ETA: 0s - loss: 0.0517 - acc: 0.9817 - precision_m: 0.8221 - recall_m: 0.6360 - f1_m: 0.7035\n",
      "Epoch 30: val_acc did not improve from 0.97224\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.0519 - acc: 0.9816 - precision_m: 0.8165 - recall_m: 0.6319 - f1_m: 0.6984 - val_loss: 0.0921 - val_acc: 0.9706 - val_precision_m: 0.5944 - val_recall_m: 0.5047 - val_f1_m: 0.5166\n",
      "Score for fold 9: loss of 0.08761202543973923; acc of 97.22354412078857%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.08563520014286041; acc of 97.08716869354248%\n",
      "Test Precision: precision_m of 23.22046309709549%\n",
      "Test Recall: recall_m of 14.808866381645203%\n",
      "Test F1: f1_m of 16.764400899410248%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1613 - acc: 0.9603 - precision_m: 0.0139 - recall_m: 0.0054 - f1_m: 0.0033  \n",
      "Epoch 1: val_acc improved from -inf to 0.96058, saving model to models/best_model_9_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 2s 3ms/step - loss: 0.1613 - acc: 0.9603 - precision_m: 0.0139 - recall_m: 0.0054 - f1_m: 0.0033 - val_loss: 0.1401 - val_acc: 0.9606 - val_precision_m: 0.0606 - val_recall_m: 0.0066 - val_f1_m: 0.0117\n",
      "Epoch 2/30\n",
      "272/292 [==========================>...] - ETA: 0s - loss: 0.1245 - acc: 0.9645 - precision_m: 0.1406 - recall_m: 0.0208 - f1_m: 0.0350\n",
      "Epoch 2: val_acc improved from 0.96058 to 0.96214, saving model to models/best_model_9_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1241 - acc: 0.9645 - precision_m: 0.1550 - recall_m: 0.0235 - f1_m: 0.0391 - val_loss: 0.1244 - val_acc: 0.9621 - val_precision_m: 0.2879 - val_recall_m: 0.0397 - val_f1_m: 0.0680\n",
      "Epoch 3/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.1126 - acc: 0.9648 - precision_m: 0.3306 - recall_m: 0.0507 - f1_m: 0.0848\n",
      "Epoch 3: val_acc improved from 0.96214 to 0.96274, saving model to models/best_model_9_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1124 - acc: 0.9649 - precision_m: 0.3307 - recall_m: 0.0505 - f1_m: 0.0846 - val_loss: 0.1195 - val_acc: 0.9627 - val_precision_m: 0.3727 - val_recall_m: 0.0624 - val_f1_m: 0.1041\n",
      "Epoch 4/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.1055 - acc: 0.9654 - precision_m: 0.3931 - recall_m: 0.0739 - f1_m: 0.1175\n",
      "Epoch 4: val_acc improved from 0.96274 to 0.96310, saving model to models/best_model_9_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1056 - acc: 0.9653 - precision_m: 0.3928 - recall_m: 0.0743 - f1_m: 0.1181 - val_loss: 0.1156 - val_acc: 0.9631 - val_precision_m: 0.3939 - val_recall_m: 0.0676 - val_f1_m: 0.1128\n",
      "Epoch 5/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.1018 - acc: 0.9654 - precision_m: 0.4357 - recall_m: 0.0925 - f1_m: 0.1466\n",
      "Epoch 5: val_acc improved from 0.96310 to 0.96346, saving model to models/best_model_9_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1015 - acc: 0.9655 - precision_m: 0.4302 - recall_m: 0.0904 - f1_m: 0.1435 - val_loss: 0.1107 - val_acc: 0.9635 - val_precision_m: 0.5101 - val_recall_m: 0.1102 - val_f1_m: 0.1730\n",
      "Epoch 6/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.0995 - acc: 0.9655 - precision_m: 0.4607 - recall_m: 0.1035 - f1_m: 0.1623\n",
      "Epoch 6: val_acc did not improve from 0.96346\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.1000 - acc: 0.9654 - precision_m: 0.4584 - recall_m: 0.1041 - f1_m: 0.1631 - val_loss: 0.1125 - val_acc: 0.9630 - val_precision_m: 0.4040 - val_recall_m: 0.0662 - val_f1_m: 0.1098\n",
      "Epoch 7/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0994 - acc: 0.9654 - precision_m: 0.4596 - recall_m: 0.1099 - f1_m: 0.1691\n",
      "Epoch 7: val_acc did not improve from 0.96346\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0990 - acc: 0.9656 - precision_m: 0.4548 - recall_m: 0.1100 - f1_m: 0.1689 - val_loss: 0.1208 - val_acc: 0.9624 - val_precision_m: 0.2970 - val_recall_m: 0.0437 - val_f1_m: 0.0749\n",
      "Epoch 8/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0971 - acc: 0.9659 - precision_m: 0.4927 - recall_m: 0.1220 - f1_m: 0.1837\n",
      "Epoch 8: val_acc improved from 0.96346 to 0.96418, saving model to models/best_model_9_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0968 - acc: 0.9659 - precision_m: 0.4979 - recall_m: 0.1240 - f1_m: 0.1868 - val_loss: 0.1095 - val_acc: 0.9642 - val_precision_m: 0.5678 - val_recall_m: 0.1476 - val_f1_m: 0.2260\n",
      "Epoch 9/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0938 - acc: 0.9664 - precision_m: 0.5473 - recall_m: 0.1490 - f1_m: 0.2191\n",
      "Epoch 9: val_acc did not improve from 0.96418\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0933 - acc: 0.9666 - precision_m: 0.5353 - recall_m: 0.1471 - f1_m: 0.2157 - val_loss: 0.1101 - val_acc: 0.9627 - val_precision_m: 0.3434 - val_recall_m: 0.0597 - val_f1_m: 0.0994\n",
      "Epoch 10/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.0882 - acc: 0.9673 - precision_m: 0.6025 - recall_m: 0.1998 - f1_m: 0.2813\n",
      "Epoch 10: val_acc did not improve from 0.96418\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0883 - acc: 0.9673 - precision_m: 0.5993 - recall_m: 0.1994 - f1_m: 0.2810 - val_loss: 0.1057 - val_acc: 0.9629 - val_precision_m: 0.5979 - val_recall_m: 0.1909 - val_f1_m: 0.2654\n",
      "Epoch 11/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.0857 - acc: 0.9683 - precision_m: 0.6426 - recall_m: 0.2251 - f1_m: 0.3146\n",
      "Epoch 11: val_acc improved from 0.96418 to 0.96430, saving model to models/best_model_9_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0854 - acc: 0.9684 - precision_m: 0.6425 - recall_m: 0.2271 - f1_m: 0.3165 - val_loss: 0.0993 - val_acc: 0.9643 - val_precision_m: 0.6513 - val_recall_m: 0.2271 - val_f1_m: 0.3105\n",
      "Epoch 12/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0833 - acc: 0.9687 - precision_m: 0.6143 - recall_m: 0.2330 - f1_m: 0.3205\n",
      "Epoch 12: val_acc improved from 0.96430 to 0.96442, saving model to models/best_model_9_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0840 - acc: 0.9684 - precision_m: 0.6163 - recall_m: 0.2334 - f1_m: 0.3217 - val_loss: 0.0989 - val_acc: 0.9644 - val_precision_m: 0.6504 - val_recall_m: 0.2218 - val_f1_m: 0.3107\n",
      "Epoch 13/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.0822 - acc: 0.9690 - precision_m: 0.6536 - recall_m: 0.2647 - f1_m: 0.3556\n",
      "Epoch 13: val_acc improved from 0.96442 to 0.96490, saving model to models/best_model_9_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0827 - acc: 0.9687 - precision_m: 0.6556 - recall_m: 0.2679 - f1_m: 0.3589 - val_loss: 0.1023 - val_acc: 0.9649 - val_precision_m: 0.6212 - val_recall_m: 0.1579 - val_f1_m: 0.2392\n",
      "Epoch 14/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0812 - acc: 0.9692 - precision_m: 0.6677 - recall_m: 0.2564 - f1_m: 0.3502\n",
      "Epoch 14: val_acc did not improve from 0.96490\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0812 - acc: 0.9691 - precision_m: 0.6673 - recall_m: 0.2589 - f1_m: 0.3527 - val_loss: 0.1010 - val_acc: 0.9636 - val_precision_m: 0.5722 - val_recall_m: 0.2953 - val_f1_m: 0.3643\n",
      "Epoch 15/30\n",
      "271/292 [==========================>...] - ETA: 0s - loss: 0.0806 - acc: 0.9695 - precision_m: 0.6448 - recall_m: 0.2653 - f1_m: 0.3547\n",
      "Epoch 15: val_acc did not improve from 0.96490\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0810 - acc: 0.9693 - precision_m: 0.6363 - recall_m: 0.2629 - f1_m: 0.3517 - val_loss: 0.1007 - val_acc: 0.9649 - val_precision_m: 0.6245 - val_recall_m: 0.1632 - val_f1_m: 0.2515\n",
      "Epoch 16/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0809 - acc: 0.9691 - precision_m: 0.6630 - recall_m: 0.2794 - f1_m: 0.3679\n",
      "Epoch 16: val_acc did not improve from 0.96490\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0807 - acc: 0.9692 - precision_m: 0.6642 - recall_m: 0.2758 - f1_m: 0.3643 - val_loss: 0.1026 - val_acc: 0.9639 - val_precision_m: 0.5964 - val_recall_m: 0.1768 - val_f1_m: 0.2620\n",
      "Epoch 17/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.0801 - acc: 0.9698 - precision_m: 0.6650 - recall_m: 0.2822 - f1_m: 0.3765\n",
      "Epoch 17: val_acc did not improve from 0.96490\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0802 - acc: 0.9697 - precision_m: 0.6652 - recall_m: 0.2823 - f1_m: 0.3760 - val_loss: 0.0986 - val_acc: 0.9631 - val_precision_m: 0.5829 - val_recall_m: 0.2624 - val_f1_m: 0.3332\n",
      "Epoch 18/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0798 - acc: 0.9697 - precision_m: 0.6919 - recall_m: 0.2901 - f1_m: 0.3832\n",
      "Epoch 18: val_acc did not improve from 0.96490\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0797 - acc: 0.9698 - precision_m: 0.6940 - recall_m: 0.2929 - f1_m: 0.3857 - val_loss: 0.1001 - val_acc: 0.9643 - val_precision_m: 0.6111 - val_recall_m: 0.1602 - val_f1_m: 0.2453\n",
      "Epoch 19/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0786 - acc: 0.9696 - precision_m: 0.6557 - recall_m: 0.2938 - f1_m: 0.3823\n",
      "Epoch 19: val_acc did not improve from 0.96490\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0784 - acc: 0.9697 - precision_m: 0.6561 - recall_m: 0.2969 - f1_m: 0.3845 - val_loss: 0.0973 - val_acc: 0.9644 - val_precision_m: 0.5985 - val_recall_m: 0.2740 - val_f1_m: 0.3447\n",
      "Epoch 20/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0785 - acc: 0.9701 - precision_m: 0.6654 - recall_m: 0.2910 - f1_m: 0.3834\n",
      "Epoch 20: val_acc improved from 0.96490 to 0.96550, saving model to models/best_model_9_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0782 - acc: 0.9703 - precision_m: 0.6713 - recall_m: 0.2927 - f1_m: 0.3861 - val_loss: 0.0997 - val_acc: 0.9655 - val_precision_m: 0.6386 - val_recall_m: 0.2394 - val_f1_m: 0.3266\n",
      "Epoch 21/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0780 - acc: 0.9703 - precision_m: 0.6824 - recall_m: 0.2966 - f1_m: 0.3891\n",
      "Epoch 21: val_acc did not improve from 0.96550\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0784 - acc: 0.9702 - precision_m: 0.6762 - recall_m: 0.2928 - f1_m: 0.3851 - val_loss: 0.0985 - val_acc: 0.9630 - val_precision_m: 0.5370 - val_recall_m: 0.2668 - val_f1_m: 0.3251\n",
      "Epoch 22/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0776 - acc: 0.9703 - precision_m: 0.7069 - recall_m: 0.2922 - f1_m: 0.3869\n",
      "Epoch 22: val_acc did not improve from 0.96550\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0778 - acc: 0.9702 - precision_m: 0.7056 - recall_m: 0.2936 - f1_m: 0.3887 - val_loss: 0.1005 - val_acc: 0.9655 - val_precision_m: 0.6339 - val_recall_m: 0.2434 - val_f1_m: 0.3333\n",
      "Epoch 23/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.0773 - acc: 0.9705 - precision_m: 0.6936 - recall_m: 0.3032 - f1_m: 0.3976\n",
      "Epoch 23: val_acc did not improve from 0.96550\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0775 - acc: 0.9704 - precision_m: 0.6956 - recall_m: 0.3022 - f1_m: 0.3975 - val_loss: 0.0969 - val_acc: 0.9651 - val_precision_m: 0.6438 - val_recall_m: 0.2395 - val_f1_m: 0.3207\n",
      "Epoch 24/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0764 - acc: 0.9708 - precision_m: 0.7047 - recall_m: 0.3079 - f1_m: 0.4041\n",
      "Epoch 24: val_acc did not improve from 0.96550\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0765 - acc: 0.9708 - precision_m: 0.7094 - recall_m: 0.3093 - f1_m: 0.4064 - val_loss: 0.0963 - val_acc: 0.9650 - val_precision_m: 0.6095 - val_recall_m: 0.2450 - val_f1_m: 0.3266\n",
      "Epoch 25/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0761 - acc: 0.9704 - precision_m: 0.7024 - recall_m: 0.3038 - f1_m: 0.4023\n",
      "Epoch 25: val_acc did not improve from 0.96550\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0758 - acc: 0.9705 - precision_m: 0.7043 - recall_m: 0.3055 - f1_m: 0.4042 - val_loss: 0.0995 - val_acc: 0.9654 - val_precision_m: 0.6252 - val_recall_m: 0.2356 - val_f1_m: 0.3153\n",
      "Epoch 26/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0761 - acc: 0.9706 - precision_m: 0.7227 - recall_m: 0.3133 - f1_m: 0.4156\n",
      "Epoch 26: val_acc did not improve from 0.96550\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0760 - acc: 0.9707 - precision_m: 0.7213 - recall_m: 0.3140 - f1_m: 0.4161 - val_loss: 0.1007 - val_acc: 0.9653 - val_precision_m: 0.6758 - val_recall_m: 0.1901 - val_f1_m: 0.2765\n",
      "Epoch 27/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.0750 - acc: 0.9710 - precision_m: 0.7070 - recall_m: 0.3152 - f1_m: 0.4106\n",
      "Epoch 27: val_acc did not improve from 0.96550\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0755 - acc: 0.9706 - precision_m: 0.7039 - recall_m: 0.3119 - f1_m: 0.4070 - val_loss: 0.1002 - val_acc: 0.9654 - val_precision_m: 0.6318 - val_recall_m: 0.1818 - val_f1_m: 0.2634\n",
      "Epoch 28/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0751 - acc: 0.9709 - precision_m: 0.7221 - recall_m: 0.3224 - f1_m: 0.4199\n",
      "Epoch 28: val_acc did not improve from 0.96550\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0747 - acc: 0.9710 - precision_m: 0.7232 - recall_m: 0.3195 - f1_m: 0.4172 - val_loss: 0.1026 - val_acc: 0.9648 - val_precision_m: 0.6270 - val_recall_m: 0.2413 - val_f1_m: 0.3288\n",
      "Epoch 29/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0750 - acc: 0.9708 - precision_m: 0.6842 - recall_m: 0.3077 - f1_m: 0.3996\n",
      "Epoch 29: val_acc did not improve from 0.96550\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0748 - acc: 0.9708 - precision_m: 0.6836 - recall_m: 0.3062 - f1_m: 0.3982 - val_loss: 0.0983 - val_acc: 0.9650 - val_precision_m: 0.6068 - val_recall_m: 0.2577 - val_f1_m: 0.3389\n",
      "Epoch 30/30\n",
      "274/292 [===========================>..] - ETA: 0s - loss: 0.0730 - acc: 0.9712 - precision_m: 0.7269 - recall_m: 0.3189 - f1_m: 0.4214\n",
      "Epoch 30: val_acc did not improve from 0.96550\n",
      "292/292 [==============================] - 1s 3ms/step - loss: 0.0731 - acc: 0.9712 - precision_m: 0.7261 - recall_m: 0.3195 - f1_m: 0.4211 - val_loss: 0.0992 - val_acc: 0.9638 - val_precision_m: 0.5628 - val_recall_m: 0.2555 - val_f1_m: 0.3235\n",
      "Score for fold 10: loss of 0.0996936708688736; acc of 96.55048251152039%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.08282872289419174; acc of 96.99132442474365%\n",
      "Test Precision: precision_m of 23.274852335453033%\n",
      "Test Recall: recall_m of 14.827345311641693%\n",
      "Test F1: f1_m of 16.879475116729736%\n",
      "------------------------------------------------------------------------\n",
      "Validation score per fold\n",
      "> Fold 1 - Loss: 0.1084606721997261 - Accuracy: 96.30956649780273%\n",
      "> Fold 2 - Loss: 0.09216631203889847 - Accuracy: 97.10214138031006%\n",
      "> Fold 3 - Loss: 0.09083075821399689 - Accuracy: 97.0052719116211%\n",
      "> Fold 4 - Loss: 0.09521619230508804 - Accuracy: 97.12238907814026%\n",
      "> Fold 5 - Loss: 0.1035035029053688 - Accuracy: 96.70132398605347%\n",
      "> Fold 6 - Loss: 0.09147573262453079 - Accuracy: 97.09533452987671%\n",
      "> Fold 7 - Loss: 0.09189733117818832 - Accuracy: 97.06093072891235%\n",
      "> Fold 8 - Loss: 0.09099625051021576 - Accuracy: 97.18495607376099%\n",
      "> Fold 9 - Loss: 0.08761202543973923 - Accuracy: 97.22354412078857%\n",
      "> Fold 10 - Loss: 0.0996936708688736 - Accuracy: 96.55048251152039%\n",
      "------------------------------------------------------------------------\n",
      "Testing score per fold\n",
      "> Fold 1 - Accuracy: 97.18247652053833 - Precision: 7.335679978132248 - Recall: 3.9094284176826477 - F1: 4.689855873584747%\n",
      "> Fold 2 - Accuracy: 96.79287672042847 - Precision: 21.03310525417328 - Recall: 12.373341619968414 - F1: 14.614848792552948%\n",
      "> Fold 3 - Accuracy: 97.0779538154602 - Precision: 20.54988592863083 - Recall: 15.579850971698761 - F1: 16.808880865573883%\n",
      "> Fold 4 - Accuracy: 96.7434823513031 - Precision: 22.871971130371094 - Recall: 16.34843200445175 - F1: 18.056918680667877%\n",
      "> Fold 5 - Accuracy: 96.66880369186401 - Precision: 18.293514847755432 - Recall: 10.206551849842072 - F1: 12.200526893138885%\n",
      "> Fold 6 - Accuracy: 97.11611866950989 - Precision: 22.295522689819336 - Recall: 16.27245992422104 - F1: 17.760097980499268%\n",
      "> Fold 7 - Accuracy: 97.70616888999939 - Precision: 18.234610557556152 - Recall: 12.517836689949036 - F1: 14.127962291240692%\n",
      "> Fold 8 - Accuracy: 96.90231084823608 - Precision: 17.561838030815125 - Recall: 11.618353426456451 - F1: 12.998424470424652%\n",
      "> Fold 9 - Accuracy: 97.08716869354248 - Precision: 23.22046309709549 - Recall: 14.808866381645203 - F1: 16.764400899410248%\n",
      "> Fold 10 - Accuracy: 96.99132442474365 - Precision: 23.274852335453033 - Recall: 14.827345311641693 - F1: 16.879475116729736%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Validation Accuracy: 96.93559408187866 (+- 0.29136098269440497)\n",
      "> Validation Loss: 0.0951852448284626\n",
      "> Testing Accuracy: 97.02686846256256 (+- 0.27927093482283183)\n",
      "> Testing Precision: 19.4671443849802\n",
      "> Testing Recall: 12.846246659755707\n",
      "> Testing F1: 14.490139186382294\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Lists to hold cross-validation results\n",
    "acc_9_per_fold = []\n",
    "loss_9_per_fold = []\n",
    "precision_9_per_fold = []\n",
    "recall_9_per_fold = []\n",
    "f1_9_per_fold = []\n",
    "\n",
    "testing_acc_9_per_fold = []\n",
    "testing_precision_9_per_fold = []\n",
    "testing_recall_9_per_fold = []\n",
    "testing_f1_9_per_fold = []\n",
    "\n",
    "# Load data from .npz files\n",
    "for fold_no in range(1, 11):\n",
    "    with np.load(f'fold_{fold_no}.npz') as data:\n",
    "        x_train = data['x_train_fold.npy']\n",
    "        y_train = data['y_train_fold.npy']\n",
    "        x_val = data['x_val_fold.npy']\n",
    "        y_val = data['y_val_fold.npy']\n",
    "        x_test = data['x_test_fold.npy']\n",
    "        y_test = data['y_test_fold.npy']\n",
    "        \n",
    "        # Converting ground truth arrays to one wake word (1) and 'other' (0)\n",
    "        wake_word_index = all_targets.index(wake_word)\n",
    "        y_train = np.equal(y_train, wake_word_index).astype('float64')\n",
    "        y_val = np.equal(y_val, wake_word_index).astype('float64')\n",
    "        y_test = np.equal(y_test, wake_word_index).astype('float64')\n",
    "        \n",
    "        # CNN for TF expects (batch, height, width, channels)\n",
    "        x_train = x_train.reshape(x_train.shape[0], \n",
    "                          x_train.shape[1], \n",
    "                          x_train.shape[2], \n",
    "                          1)\n",
    "        x_val = x_val.reshape(x_val.shape[0], \n",
    "                          x_val.shape[1], \n",
    "                          x_val.shape[2], \n",
    "                          1)\n",
    "        x_test = x_test.reshape(x_test.shape[0], \n",
    "                          x_test.shape[1], \n",
    "                          x_test.shape[2], \n",
    "                          1)\n",
    "        sample_shape = x_test.shape[1:]\n",
    "\n",
    "    # CNN model\n",
    "    model_9 = models.Sequential()\n",
    "    model_9.add(layers.Conv2D(16, \n",
    "                            (16, 16), \n",
    "                            activation='relu',\n",
    "                            input_shape=sample_shape))\n",
    "    \n",
    "    # Classifier\n",
    "    model_9.add(layers.Flatten())\n",
    "    model_9.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "\n",
    "    model_9.compile(loss='binary_crossentropy', \n",
    "              optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "              metrics=['acc', precision_m, recall_m, f1_m])\n",
    "\n",
    "    checkpoint_filepath = f'models/best_model_9_fold_{fold_no}.h5'\n",
    "    model_checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=False,\n",
    "        monitor='val_acc',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "        save_freq='epoch'\n",
    "    )\n",
    "\n",
    "    # Instantiate the custom callback\n",
    "    metrics_history = MetricsHistory()\n",
    "\n",
    "    # Print fold number\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Train\n",
    "    history_9 = model_9.fit(x_train, \n",
    "                    y_train, \n",
    "                    epochs=30, \n",
    "                    batch_size=256, \n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[model_checkpoint_callback, metrics_history])\n",
    "\n",
    "    model_9.load_weights(checkpoint_filepath)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    scores = model_9.evaluate(x_val, y_val, verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model_9.metrics_names[0]} of {scores[0]}; {model_9.metrics_names[1]} of {scores[1] * 100}%')\n",
    "    acc_9_per_fold.append(scores[1] * 100)\n",
    "    loss_9_per_fold.append(scores[0])\n",
    "    precision_9_per_fold.append(metrics_history.best_metrics['precision_m'] * 100)\n",
    "    recall_9_per_fold.append(metrics_history.best_metrics['recall_m'] * 100)\n",
    "    f1_9_per_fold.append(metrics_history.best_metrics['f1_m'] * 100)\n",
    "\n",
    "    # Final evaluation on test set\n",
    "    final_scores = model_9.evaluate(x_test, y_test, verbose=0)\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Final test score: {model_9.metrics_names[0]} of {final_scores[0]}; {model_9.metrics_names[1]} of {final_scores[1] * 100}%')\n",
    "    print(f'Test Precision: {model_9.metrics_names[2]} of {final_scores[2] * 100}%')\n",
    "    print(f'Test Recall: {model_9.metrics_names[3]} of {final_scores[3] * 100}%')\n",
    "    print(f'Test F1: {model_9.metrics_names[4]} of {final_scores[4] * 100}%')\n",
    "\n",
    "    # Append test metrics to lists\n",
    "    testing_acc_9_per_fold.append(final_scores[1] * 100)\n",
    "    testing_precision_9_per_fold.append(final_scores[2] * 100)\n",
    "    testing_recall_9_per_fold.append(final_scores[3] * 100)\n",
    "    testing_f1_9_per_fold.append(final_scores[4] * 100)\n",
    "\n",
    "# Print the results\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Validation score per fold')\n",
    "for i in range(0, len(acc_9_per_fold)):\n",
    "    print(f'> Fold {i+1} - Loss: {loss_9_per_fold[i]} - Accuracy: {acc_9_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Testing score per fold')\n",
    "for i in range(0, len(testing_acc_9_per_fold)):\n",
    "    print(f'> Fold {i+1} - Accuracy: {testing_acc_9_per_fold[i]} - Precision: {testing_precision_9_per_fold[i]} - Recall: {testing_recall_9_per_fold[i]} - F1: {testing_f1_9_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Validation Accuracy: {np.mean(acc_9_per_fold)} (+- {np.std(acc_9_per_fold)})')\n",
    "print(f'> Validation Loss: {np.mean(loss_9_per_fold)}')\n",
    "print(f'> Testing Accuracy: {np.mean(testing_acc_9_per_fold)} (+- {np.std(testing_acc_9_per_fold)})')\n",
    "print(f'> Testing Precision: {np.mean(testing_precision_9_per_fold)}')\n",
    "print(f'> Testing Recall: {np.mean(testing_recall_9_per_fold)}')\n",
    "print(f'> Testing F1: {np.mean(testing_f1_9_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1800 - acc: 0.9595 - precision_m: 0.0067 - recall_m: 0.0040 - f1_m: 0.0035\n",
      "Epoch 1: val_acc improved from -inf to 0.96023, saving model to models/best_model_10_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 3s 5ms/step - loss: 0.1800 - acc: 0.9595 - precision_m: 0.0067 - recall_m: 0.0040 - f1_m: 0.0035 - val_loss: 0.1390 - val_acc: 0.9602 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.1285 - acc: 0.9628 - precision_m: 0.0374 - recall_m: 0.0042 - f1_m: 0.0075 \n",
      "Epoch 2: val_acc improved from 0.96023 to 0.96047, saving model to models/best_model_10_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1279 - acc: 0.9628 - precision_m: 0.0394 - recall_m: 0.0044 - f1_m: 0.0079 - val_loss: 0.1180 - val_acc: 0.9605 - val_precision_m: 0.0606 - val_recall_m: 0.0040 - val_f1_m: 0.0075\n",
      "Epoch 3/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.1094 - acc: 0.9633 - precision_m: 0.2981 - recall_m: 0.0611 - f1_m: 0.0961\n",
      "Epoch 3: val_acc improved from 0.96047 to 0.96154, saving model to models/best_model_10_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1091 - acc: 0.9634 - precision_m: 0.2935 - recall_m: 0.0621 - f1_m: 0.0970 - val_loss: 0.1112 - val_acc: 0.9615 - val_precision_m: 0.2222 - val_recall_m: 0.0390 - val_f1_m: 0.0629\n",
      "Epoch 4/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.1006 - acc: 0.9655 - precision_m: 0.5743 - recall_m: 0.1652 - f1_m: 0.2404\n",
      "Epoch 4: val_acc improved from 0.96154 to 0.96310, saving model to models/best_model_10_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1006 - acc: 0.9656 - precision_m: 0.5746 - recall_m: 0.1648 - f1_m: 0.2399 - val_loss: 0.1059 - val_acc: 0.9631 - val_precision_m: 0.3455 - val_recall_m: 0.0700 - val_f1_m: 0.1067\n",
      "Epoch 5/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0951 - acc: 0.9670 - precision_m: 0.6360 - recall_m: 0.2184 - f1_m: 0.3044\n",
      "Epoch 5: val_acc improved from 0.96310 to 0.96692, saving model to models/best_model_10_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0950 - acc: 0.9669 - precision_m: 0.6381 - recall_m: 0.2181 - f1_m: 0.3044 - val_loss: 0.1024 - val_acc: 0.9669 - val_precision_m: 0.6112 - val_recall_m: 0.2400 - val_f1_m: 0.3196\n",
      "Epoch 6/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0900 - acc: 0.9692 - precision_m: 0.7013 - recall_m: 0.3033 - f1_m: 0.3971\n",
      "Epoch 6: val_acc improved from 0.96692 to 0.96799, saving model to models/best_model_10_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0902 - acc: 0.9691 - precision_m: 0.6998 - recall_m: 0.3012 - f1_m: 0.3949 - val_loss: 0.0992 - val_acc: 0.9680 - val_precision_m: 0.6686 - val_recall_m: 0.2521 - val_f1_m: 0.3416\n",
      "Epoch 7/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0862 - acc: 0.9702 - precision_m: 0.7039 - recall_m: 0.3384 - f1_m: 0.4372\n",
      "Epoch 7: val_acc improved from 0.96799 to 0.96871, saving model to models/best_model_10_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0862 - acc: 0.9703 - precision_m: 0.7014 - recall_m: 0.3393 - f1_m: 0.4374 - val_loss: 0.1055 - val_acc: 0.9687 - val_precision_m: 0.6656 - val_recall_m: 0.2302 - val_f1_m: 0.3231\n",
      "Epoch 8/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0845 - acc: 0.9704 - precision_m: 0.7036 - recall_m: 0.3651 - f1_m: 0.4565\n",
      "Epoch 8: val_acc improved from 0.96871 to 0.96907, saving model to models/best_model_10_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0842 - acc: 0.9706 - precision_m: 0.7051 - recall_m: 0.3667 - f1_m: 0.4586 - val_loss: 0.0948 - val_acc: 0.9691 - val_precision_m: 0.6768 - val_recall_m: 0.3756 - val_f1_m: 0.4534\n",
      "Epoch 9/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.0819 - acc: 0.9724 - precision_m: 0.7352 - recall_m: 0.4044 - f1_m: 0.4992\n",
      "Epoch 9: val_acc did not improve from 0.96907\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0824 - acc: 0.9722 - precision_m: 0.7397 - recall_m: 0.4005 - f1_m: 0.4953 - val_loss: 0.1013 - val_acc: 0.9681 - val_precision_m: 0.7193 - val_recall_m: 0.2004 - val_f1_m: 0.2955\n",
      "Epoch 10/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0795 - acc: 0.9739 - precision_m: 0.7617 - recall_m: 0.4415 - f1_m: 0.5366\n",
      "Epoch 10: val_acc improved from 0.96907 to 0.97110, saving model to models/best_model_10_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0795 - acc: 0.9738 - precision_m: 0.7625 - recall_m: 0.4443 - f1_m: 0.5384 - val_loss: 0.0905 - val_acc: 0.9711 - val_precision_m: 0.7169 - val_recall_m: 0.4159 - val_f1_m: 0.4963\n",
      "Epoch 11/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0793 - acc: 0.9725 - precision_m: 0.7348 - recall_m: 0.4110 - f1_m: 0.5039\n",
      "Epoch 11: val_acc improved from 0.97110 to 0.97193, saving model to models/best_model_10_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0793 - acc: 0.9726 - precision_m: 0.7406 - recall_m: 0.4141 - f1_m: 0.5084 - val_loss: 0.0903 - val_acc: 0.9719 - val_precision_m: 0.7147 - val_recall_m: 0.4206 - val_f1_m: 0.5074\n",
      "Epoch 12/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0765 - acc: 0.9744 - precision_m: 0.7673 - recall_m: 0.4487 - f1_m: 0.5411\n",
      "Epoch 12: val_acc did not improve from 0.97193\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0766 - acc: 0.9745 - precision_m: 0.7688 - recall_m: 0.4496 - f1_m: 0.5419 - val_loss: 0.0923 - val_acc: 0.9711 - val_precision_m: 0.7363 - val_recall_m: 0.3823 - val_f1_m: 0.4745\n",
      "Epoch 13/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0759 - acc: 0.9741 - precision_m: 0.7661 - recall_m: 0.4544 - f1_m: 0.5429\n",
      "Epoch 13: val_acc did not improve from 0.97193\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0760 - acc: 0.9740 - precision_m: 0.7650 - recall_m: 0.4488 - f1_m: 0.5382 - val_loss: 0.1012 - val_acc: 0.9680 - val_precision_m: 0.6186 - val_recall_m: 0.5561 - val_f1_m: 0.5542\n",
      "Epoch 14/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.0738 - acc: 0.9752 - precision_m: 0.7688 - recall_m: 0.4751 - f1_m: 0.5647\n",
      "Epoch 14: val_acc improved from 0.97193 to 0.97229, saving model to models/best_model_10_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0743 - acc: 0.9751 - precision_m: 0.7666 - recall_m: 0.4783 - f1_m: 0.5667 - val_loss: 0.0913 - val_acc: 0.9723 - val_precision_m: 0.7924 - val_recall_m: 0.3627 - val_f1_m: 0.4659\n",
      "Epoch 15/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0729 - acc: 0.9757 - precision_m: 0.7983 - recall_m: 0.4877 - f1_m: 0.5776\n",
      "Epoch 15: val_acc did not improve from 0.97229\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0728 - acc: 0.9756 - precision_m: 0.7976 - recall_m: 0.4800 - f1_m: 0.5707 - val_loss: 0.0881 - val_acc: 0.9713 - val_precision_m: 0.6708 - val_recall_m: 0.4987 - val_f1_m: 0.5484\n",
      "Epoch 16/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0723 - acc: 0.9752 - precision_m: 0.7799 - recall_m: 0.4801 - f1_m: 0.5712\n",
      "Epoch 16: val_acc improved from 0.97229 to 0.97265, saving model to models/best_model_10_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0719 - acc: 0.9753 - precision_m: 0.7829 - recall_m: 0.4846 - f1_m: 0.5756 - val_loss: 0.0888 - val_acc: 0.9727 - val_precision_m: 0.7532 - val_recall_m: 0.4530 - val_f1_m: 0.5359\n",
      "Epoch 17/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0700 - acc: 0.9760 - precision_m: 0.7903 - recall_m: 0.4942 - f1_m: 0.5874\n",
      "Epoch 17: val_acc improved from 0.97265 to 0.97277, saving model to models/best_model_10_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0702 - acc: 0.9760 - precision_m: 0.7910 - recall_m: 0.4951 - f1_m: 0.5884 - val_loss: 0.0899 - val_acc: 0.9728 - val_precision_m: 0.6822 - val_recall_m: 0.5053 - val_f1_m: 0.5576\n",
      "Epoch 18/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0712 - acc: 0.9755 - precision_m: 0.7820 - recall_m: 0.4808 - f1_m: 0.5709\n",
      "Epoch 18: val_acc improved from 0.97277 to 0.97349, saving model to models/best_model_10_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0710 - acc: 0.9756 - precision_m: 0.7802 - recall_m: 0.4800 - f1_m: 0.5703 - val_loss: 0.0866 - val_acc: 0.9735 - val_precision_m: 0.7685 - val_recall_m: 0.4520 - val_f1_m: 0.5346\n",
      "Epoch 19/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0696 - acc: 0.9765 - precision_m: 0.8011 - recall_m: 0.5011 - f1_m: 0.5920\n",
      "Epoch 19: val_acc did not improve from 0.97349\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0694 - acc: 0.9767 - precision_m: 0.8061 - recall_m: 0.5023 - f1_m: 0.5944 - val_loss: 0.0890 - val_acc: 0.9724 - val_precision_m: 0.8035 - val_recall_m: 0.3910 - val_f1_m: 0.4964\n",
      "Epoch 20/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0672 - acc: 0.9771 - precision_m: 0.8103 - recall_m: 0.4979 - f1_m: 0.5935\n",
      "Epoch 20: val_acc improved from 0.97349 to 0.97373, saving model to models/best_model_10_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0677 - acc: 0.9769 - precision_m: 0.8079 - recall_m: 0.4978 - f1_m: 0.5930 - val_loss: 0.0873 - val_acc: 0.9737 - val_precision_m: 0.7804 - val_recall_m: 0.4648 - val_f1_m: 0.5484\n",
      "Epoch 21/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0670 - acc: 0.9770 - precision_m: 0.7976 - recall_m: 0.5197 - f1_m: 0.6102\n",
      "Epoch 21: val_acc did not improve from 0.97373\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0671 - acc: 0.9769 - precision_m: 0.7937 - recall_m: 0.5213 - f1_m: 0.6098 - val_loss: 0.0881 - val_acc: 0.9724 - val_precision_m: 0.7513 - val_recall_m: 0.4130 - val_f1_m: 0.5045\n",
      "Epoch 22/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0674 - acc: 0.9767 - precision_m: 0.8156 - recall_m: 0.4887 - f1_m: 0.5873\n",
      "Epoch 22: val_acc did not improve from 0.97373\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0671 - acc: 0.9768 - precision_m: 0.8167 - recall_m: 0.4935 - f1_m: 0.5918 - val_loss: 0.0870 - val_acc: 0.9721 - val_precision_m: 0.6612 - val_recall_m: 0.5472 - val_f1_m: 0.5743\n",
      "Epoch 23/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0654 - acc: 0.9774 - precision_m: 0.8151 - recall_m: 0.5105 - f1_m: 0.6078\n",
      "Epoch 23: val_acc did not improve from 0.97373\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0651 - acc: 0.9774 - precision_m: 0.8169 - recall_m: 0.5107 - f1_m: 0.6083 - val_loss: 0.0862 - val_acc: 0.9735 - val_precision_m: 0.7483 - val_recall_m: 0.4574 - val_f1_m: 0.5324\n",
      "Epoch 24/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0656 - acc: 0.9777 - precision_m: 0.8090 - recall_m: 0.5187 - f1_m: 0.6106\n",
      "Epoch 24: val_acc did not improve from 0.97373\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0653 - acc: 0.9778 - precision_m: 0.8100 - recall_m: 0.5218 - f1_m: 0.6137 - val_loss: 0.0920 - val_acc: 0.9731 - val_precision_m: 0.8098 - val_recall_m: 0.3840 - val_f1_m: 0.4849\n",
      "Epoch 25/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0657 - acc: 0.9779 - precision_m: 0.8217 - recall_m: 0.5193 - f1_m: 0.6114\n",
      "Epoch 25: val_acc did not improve from 0.97373\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0655 - acc: 0.9780 - precision_m: 0.8212 - recall_m: 0.5212 - f1_m: 0.6133 - val_loss: 0.0850 - val_acc: 0.9729 - val_precision_m: 0.6983 - val_recall_m: 0.4906 - val_f1_m: 0.5539\n",
      "Epoch 26/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0632 - acc: 0.9785 - precision_m: 0.8266 - recall_m: 0.5363 - f1_m: 0.6319\n",
      "Epoch 26: val_acc improved from 0.97373 to 0.97384, saving model to models/best_model_10_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0632 - acc: 0.9785 - precision_m: 0.8276 - recall_m: 0.5364 - f1_m: 0.6324 - val_loss: 0.0859 - val_acc: 0.9738 - val_precision_m: 0.7048 - val_recall_m: 0.5229 - val_f1_m: 0.5716\n",
      "Epoch 27/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.0633 - acc: 0.9784 - precision_m: 0.8297 - recall_m: 0.5483 - f1_m: 0.6364\n",
      "Epoch 27: val_acc did not improve from 0.97384\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0630 - acc: 0.9784 - precision_m: 0.8303 - recall_m: 0.5470 - f1_m: 0.6357 - val_loss: 0.0875 - val_acc: 0.9736 - val_precision_m: 0.7492 - val_recall_m: 0.4498 - val_f1_m: 0.5324\n",
      "Epoch 28/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0623 - acc: 0.9785 - precision_m: 0.8337 - recall_m: 0.5387 - f1_m: 0.6332\n",
      "Epoch 28: val_acc improved from 0.97384 to 0.97408, saving model to models/best_model_10_fold_1.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0626 - acc: 0.9784 - precision_m: 0.8330 - recall_m: 0.5411 - f1_m: 0.6348 - val_loss: 0.0877 - val_acc: 0.9741 - val_precision_m: 0.8068 - val_recall_m: 0.4047 - val_f1_m: 0.5102\n",
      "Epoch 29/30\n",
      "276/292 [===========================>..] - ETA: 0s - loss: 0.0632 - acc: 0.9779 - precision_m: 0.8298 - recall_m: 0.5225 - f1_m: 0.6155\n",
      "Epoch 29: val_acc did not improve from 0.97408\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0629 - acc: 0.9780 - precision_m: 0.8303 - recall_m: 0.5260 - f1_m: 0.6183 - val_loss: 0.0899 - val_acc: 0.9740 - val_precision_m: 0.7795 - val_recall_m: 0.4449 - val_f1_m: 0.5293\n",
      "Epoch 30/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0612 - acc: 0.9784 - precision_m: 0.8275 - recall_m: 0.5333 - f1_m: 0.6270\n",
      "Epoch 30: val_acc did not improve from 0.97408\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0616 - acc: 0.9783 - precision_m: 0.8262 - recall_m: 0.5336 - f1_m: 0.6272 - val_loss: 0.0933 - val_acc: 0.9738 - val_precision_m: 0.8055 - val_recall_m: 0.4058 - val_f1_m: 0.5119\n",
      "Score for fold 1: loss of 0.08767911046743393; acc of 97.40833640098572%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.0644063726067543; acc of 97.96389937400818%\n",
      "Test Precision: precision_m of 20.152580738067627%\n",
      "Test Recall: recall_m of 14.676252007484436%\n",
      "Test F1: f1_m of 16.206814348697662%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.1673 - acc: 0.9630 - precision_m: 0.0018 - recall_m: 0.0022 - f1_m: 0.0015\n",
      "Epoch 1: val_acc improved from -inf to 0.96336, saving model to models/best_model_10_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 3s 5ms/step - loss: 0.1673 - acc: 0.9630 - precision_m: 0.0018 - recall_m: 0.0022 - f1_m: 0.0015 - val_loss: 0.1337 - val_acc: 0.9634 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.1181 - acc: 0.9643 - precision_m: 0.1263 - recall_m: 0.0207 - f1_m: 0.0346\n",
      "Epoch 2: val_acc improved from 0.96336 to 0.96479, saving model to models/best_model_10_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.1172 - acc: 0.9644 - precision_m: 0.1323 - recall_m: 0.0212 - f1_m: 0.0356 - val_loss: 0.1084 - val_acc: 0.9648 - val_precision_m: 0.2121 - val_recall_m: 0.0311 - val_f1_m: 0.0531\n",
      "Epoch 3/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.1034 - acc: 0.9658 - precision_m: 0.4828 - recall_m: 0.1154 - f1_m: 0.1732\n",
      "Epoch 3: val_acc improved from 0.96479 to 0.96527, saving model to models/best_model_10_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.1029 - acc: 0.9660 - precision_m: 0.4817 - recall_m: 0.1154 - f1_m: 0.1733 - val_loss: 0.1111 - val_acc: 0.9653 - val_precision_m: 0.2576 - val_recall_m: 0.0526 - val_f1_m: 0.0840\n",
      "Epoch 4/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0937 - acc: 0.9686 - precision_m: 0.6349 - recall_m: 0.2076 - f1_m: 0.2904\n",
      "Epoch 4: val_acc improved from 0.96527 to 0.96994, saving model to models/best_model_10_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0942 - acc: 0.9685 - precision_m: 0.6374 - recall_m: 0.2111 - f1_m: 0.2944 - val_loss: 0.0953 - val_acc: 0.9699 - val_precision_m: 0.6527 - val_recall_m: 0.2462 - val_f1_m: 0.3256\n",
      "Epoch 5/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.0898 - acc: 0.9701 - precision_m: 0.6666 - recall_m: 0.2625 - f1_m: 0.3559\n",
      "Epoch 5: val_acc improved from 0.96994 to 0.97054, saving model to models/best_model_10_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0896 - acc: 0.9701 - precision_m: 0.6661 - recall_m: 0.2636 - f1_m: 0.3571 - val_loss: 0.0943 - val_acc: 0.9705 - val_precision_m: 0.6789 - val_recall_m: 0.2801 - val_f1_m: 0.3628\n",
      "Epoch 6/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.0858 - acc: 0.9705 - precision_m: 0.6798 - recall_m: 0.2820 - f1_m: 0.3785\n",
      "Epoch 6: val_acc did not improve from 0.97054\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0856 - acc: 0.9706 - precision_m: 0.6843 - recall_m: 0.2873 - f1_m: 0.3841 - val_loss: 0.0926 - val_acc: 0.9701 - val_precision_m: 0.6483 - val_recall_m: 0.3968 - val_f1_m: 0.4528\n",
      "Epoch 7/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0834 - acc: 0.9708 - precision_m: 0.7114 - recall_m: 0.3290 - f1_m: 0.4251\n",
      "Epoch 7: val_acc did not improve from 0.97054\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0832 - acc: 0.9709 - precision_m: 0.7091 - recall_m: 0.3277 - f1_m: 0.4237 - val_loss: 0.0969 - val_acc: 0.9705 - val_precision_m: 0.6774 - val_recall_m: 0.2432 - val_f1_m: 0.3270\n",
      "Epoch 8/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.0818 - acc: 0.9713 - precision_m: 0.7206 - recall_m: 0.3366 - f1_m: 0.4291\n",
      "Epoch 8: val_acc improved from 0.97054 to 0.97174, saving model to models/best_model_10_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0816 - acc: 0.9713 - precision_m: 0.7211 - recall_m: 0.3354 - f1_m: 0.4287 - val_loss: 0.0918 - val_acc: 0.9717 - val_precision_m: 0.6913 - val_recall_m: 0.2923 - val_f1_m: 0.3808\n",
      "Epoch 9/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0783 - acc: 0.9724 - precision_m: 0.7261 - recall_m: 0.3694 - f1_m: 0.4644\n",
      "Epoch 9: val_acc did not improve from 0.97174\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0782 - acc: 0.9724 - precision_m: 0.7277 - recall_m: 0.3708 - f1_m: 0.4658 - val_loss: 0.0903 - val_acc: 0.9701 - val_precision_m: 0.6556 - val_recall_m: 0.4008 - val_f1_m: 0.4547\n",
      "Epoch 10/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.0770 - acc: 0.9731 - precision_m: 0.7395 - recall_m: 0.3795 - f1_m: 0.4761\n",
      "Epoch 10: val_acc improved from 0.97174 to 0.97258, saving model to models/best_model_10_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0767 - acc: 0.9731 - precision_m: 0.7373 - recall_m: 0.3811 - f1_m: 0.4766 - val_loss: 0.0868 - val_acc: 0.9726 - val_precision_m: 0.7204 - val_recall_m: 0.4371 - val_f1_m: 0.5106\n",
      "Epoch 11/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.0750 - acc: 0.9739 - precision_m: 0.7438 - recall_m: 0.4158 - f1_m: 0.5065\n",
      "Epoch 11: val_acc did not improve from 0.97258\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0750 - acc: 0.9739 - precision_m: 0.7413 - recall_m: 0.4144 - f1_m: 0.5047 - val_loss: 0.0880 - val_acc: 0.9713 - val_precision_m: 0.7006 - val_recall_m: 0.2692 - val_f1_m: 0.3661\n",
      "Epoch 12/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0748 - acc: 0.9739 - precision_m: 0.7540 - recall_m: 0.4032 - f1_m: 0.4989\n",
      "Epoch 12: val_acc improved from 0.97258 to 0.97270, saving model to models/best_model_10_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0748 - acc: 0.9739 - precision_m: 0.7524 - recall_m: 0.4023 - f1_m: 0.4982 - val_loss: 0.0864 - val_acc: 0.9727 - val_precision_m: 0.7217 - val_recall_m: 0.3138 - val_f1_m: 0.4039\n",
      "Epoch 13/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0719 - acc: 0.9749 - precision_m: 0.7540 - recall_m: 0.4270 - f1_m: 0.5208\n",
      "Epoch 13: val_acc did not improve from 0.97270\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0718 - acc: 0.9749 - precision_m: 0.7547 - recall_m: 0.4278 - f1_m: 0.5217 - val_loss: 0.0866 - val_acc: 0.9721 - val_precision_m: 0.7063 - val_recall_m: 0.4764 - val_f1_m: 0.5330\n",
      "Epoch 14/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.0724 - acc: 0.9754 - precision_m: 0.7809 - recall_m: 0.4483 - f1_m: 0.5436\n",
      "Epoch 14: val_acc improved from 0.97270 to 0.97425, saving model to models/best_model_10_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0722 - acc: 0.9755 - precision_m: 0.7827 - recall_m: 0.4500 - f1_m: 0.5444 - val_loss: 0.0894 - val_acc: 0.9743 - val_precision_m: 0.7459 - val_recall_m: 0.3712 - val_f1_m: 0.4696\n",
      "Epoch 15/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.0716 - acc: 0.9752 - precision_m: 0.7872 - recall_m: 0.4402 - f1_m: 0.5366\n",
      "Epoch 15: val_acc did not improve from 0.97425\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0712 - acc: 0.9753 - precision_m: 0.7856 - recall_m: 0.4422 - f1_m: 0.5383 - val_loss: 0.0853 - val_acc: 0.9741 - val_precision_m: 0.7934 - val_recall_m: 0.4243 - val_f1_m: 0.5124\n",
      "Epoch 16/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0691 - acc: 0.9766 - precision_m: 0.7953 - recall_m: 0.4741 - f1_m: 0.5713\n",
      "Epoch 16: val_acc did not improve from 0.97425\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0692 - acc: 0.9766 - precision_m: 0.7944 - recall_m: 0.4733 - f1_m: 0.5706 - val_loss: 0.0846 - val_acc: 0.9720 - val_precision_m: 0.6635 - val_recall_m: 0.5045 - val_f1_m: 0.5438\n",
      "Epoch 17/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.0687 - acc: 0.9765 - precision_m: 0.7935 - recall_m: 0.4719 - f1_m: 0.5663\n",
      "Epoch 17: val_acc did not improve from 0.97425\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0687 - acc: 0.9765 - precision_m: 0.7935 - recall_m: 0.4719 - f1_m: 0.5663 - val_loss: 0.0880 - val_acc: 0.9699 - val_precision_m: 0.5944 - val_recall_m: 0.5025 - val_f1_m: 0.5150\n",
      "Epoch 18/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0677 - acc: 0.9765 - precision_m: 0.7780 - recall_m: 0.4795 - f1_m: 0.5694\n",
      "Epoch 18: val_acc improved from 0.97425 to 0.97461, saving model to models/best_model_10_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0677 - acc: 0.9765 - precision_m: 0.7802 - recall_m: 0.4759 - f1_m: 0.5673 - val_loss: 0.0826 - val_acc: 0.9746 - val_precision_m: 0.7848 - val_recall_m: 0.4343 - val_f1_m: 0.5258\n",
      "Epoch 19/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.0659 - acc: 0.9769 - precision_m: 0.8011 - recall_m: 0.4751 - f1_m: 0.5707\n",
      "Epoch 19: val_acc did not improve from 0.97461\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0665 - acc: 0.9769 - precision_m: 0.8013 - recall_m: 0.4769 - f1_m: 0.5717 - val_loss: 0.0859 - val_acc: 0.9729 - val_precision_m: 0.6672 - val_recall_m: 0.5154 - val_f1_m: 0.5456\n",
      "Epoch 20/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.0657 - acc: 0.9772 - precision_m: 0.8090 - recall_m: 0.4983 - f1_m: 0.5936\n",
      "Epoch 20: val_acc improved from 0.97461 to 0.97473, saving model to models/best_model_10_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0654 - acc: 0.9773 - precision_m: 0.8101 - recall_m: 0.4991 - f1_m: 0.5944 - val_loss: 0.0907 - val_acc: 0.9747 - val_precision_m: 0.7631 - val_recall_m: 0.4673 - val_f1_m: 0.5390\n",
      "Epoch 21/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.0663 - acc: 0.9769 - precision_m: 0.8079 - recall_m: 0.4777 - f1_m: 0.5750\n",
      "Epoch 21: val_acc did not improve from 0.97473\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0663 - acc: 0.9769 - precision_m: 0.8079 - recall_m: 0.4777 - f1_m: 0.5750 - val_loss: 0.0877 - val_acc: 0.9729 - val_precision_m: 0.7778 - val_recall_m: 0.3637 - val_f1_m: 0.4504\n",
      "Epoch 22/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0636 - acc: 0.9780 - precision_m: 0.8236 - recall_m: 0.5152 - f1_m: 0.6093\n",
      "Epoch 22: val_acc did not improve from 0.97473\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0635 - acc: 0.9780 - precision_m: 0.8180 - recall_m: 0.5131 - f1_m: 0.6057 - val_loss: 0.0856 - val_acc: 0.9747 - val_precision_m: 0.7555 - val_recall_m: 0.4522 - val_f1_m: 0.5199\n",
      "Epoch 23/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9777 - precision_m: 0.8119 - recall_m: 0.4981 - f1_m: 0.5955\n",
      "Epoch 23: val_acc did not improve from 0.97473\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0637 - acc: 0.9777 - precision_m: 0.8092 - recall_m: 0.4964 - f1_m: 0.5935 - val_loss: 0.1213 - val_acc: 0.9695 - val_precision_m: 0.6869 - val_recall_m: 0.2008 - val_f1_m: 0.2897\n",
      "Epoch 24/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0621 - acc: 0.9782 - precision_m: 0.8066 - recall_m: 0.5009 - f1_m: 0.5977\n",
      "Epoch 24: val_acc did not improve from 0.97473\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0628 - acc: 0.9779 - precision_m: 0.8023 - recall_m: 0.5031 - f1_m: 0.5969 - val_loss: 0.0864 - val_acc: 0.9732 - val_precision_m: 0.7452 - val_recall_m: 0.3929 - val_f1_m: 0.4688\n",
      "Epoch 25/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.0618 - acc: 0.9778 - precision_m: 0.8352 - recall_m: 0.4873 - f1_m: 0.5916\n",
      "Epoch 25: val_acc did not improve from 0.97473\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0618 - acc: 0.9778 - precision_m: 0.8344 - recall_m: 0.4877 - f1_m: 0.5916 - val_loss: 0.0834 - val_acc: 0.9743 - val_precision_m: 0.6869 - val_recall_m: 0.5420 - val_f1_m: 0.5685\n",
      "Epoch 26/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0606 - acc: 0.9790 - precision_m: 0.8278 - recall_m: 0.5238 - f1_m: 0.6194\n",
      "Epoch 26: val_acc improved from 0.97473 to 0.97569, saving model to models/best_model_10_fold_2.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0609 - acc: 0.9789 - precision_m: 0.8268 - recall_m: 0.5243 - f1_m: 0.6195 - val_loss: 0.0871 - val_acc: 0.9757 - val_precision_m: 0.7151 - val_recall_m: 0.5272 - val_f1_m: 0.5785\n",
      "Epoch 27/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.0611 - acc: 0.9787 - precision_m: 0.8137 - recall_m: 0.5148 - f1_m: 0.6075\n",
      "Epoch 27: val_acc did not improve from 0.97569\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0612 - acc: 0.9786 - precision_m: 0.8157 - recall_m: 0.5140 - f1_m: 0.6071 - val_loss: 0.0823 - val_acc: 0.9751 - val_precision_m: 0.7491 - val_recall_m: 0.4851 - val_f1_m: 0.5497\n",
      "Epoch 28/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.0593 - acc: 0.9793 - precision_m: 0.8186 - recall_m: 0.5421 - f1_m: 0.6311\n",
      "Epoch 28: val_acc did not improve from 0.97569\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0598 - acc: 0.9791 - precision_m: 0.8173 - recall_m: 0.5383 - f1_m: 0.6283 - val_loss: 0.0821 - val_acc: 0.9755 - val_precision_m: 0.7779 - val_recall_m: 0.4726 - val_f1_m: 0.5482\n",
      "Epoch 29/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0591 - acc: 0.9791 - precision_m: 0.8293 - recall_m: 0.5337 - f1_m: 0.6238\n",
      "Epoch 29: val_acc did not improve from 0.97569\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0588 - acc: 0.9792 - precision_m: 0.8301 - recall_m: 0.5365 - f1_m: 0.6266 - val_loss: 0.0870 - val_acc: 0.9740 - val_precision_m: 0.6634 - val_recall_m: 0.5376 - val_f1_m: 0.5651\n",
      "Epoch 30/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9794 - precision_m: 0.8238 - recall_m: 0.5328 - f1_m: 0.6258\n",
      "Epoch 30: val_acc did not improve from 0.97569\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0590 - acc: 0.9794 - precision_m: 0.8244 - recall_m: 0.5333 - f1_m: 0.6264 - val_loss: 0.0849 - val_acc: 0.9744 - val_precision_m: 0.7634 - val_recall_m: 0.4195 - val_f1_m: 0.5058\n",
      "Score for fold 2: loss of 0.08707863092422485; acc of 97.5691556930542%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.0819297656416893; acc of 97.39354252815247%\n",
      "Test Precision: precision_m of 27.799251675605774%\n",
      "Test Recall: recall_m of 21.618828177452087%\n",
      "Test F1: f1_m of 23.25579524040222%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.2023 - acc: 0.9476 - precision_m: 0.0072 - recall_m: 0.0170 - f1_m: 0.0060\n",
      "Epoch 1: val_acc improved from -inf to 0.96299, saving model to models/best_model_10_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 3s 5ms/step - loss: 0.2023 - acc: 0.9476 - precision_m: 0.0072 - recall_m: 0.0170 - f1_m: 0.0060 - val_loss: 0.1475 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.1352 - acc: 0.9631 - precision_m: 0.1475 - recall_m: 0.0242 - f1_m: 0.0405 \n",
      "Epoch 2: val_acc improved from 0.96299 to 0.96466, saving model to models/best_model_10_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.1334 - acc: 0.9634 - precision_m: 0.1545 - recall_m: 0.0257 - f1_m: 0.0428 - val_loss: 0.1130 - val_acc: 0.9647 - val_precision_m: 0.3441 - val_recall_m: 0.1019 - val_f1_m: 0.1490\n",
      "Epoch 3/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.1081 - acc: 0.9657 - precision_m: 0.5433 - recall_m: 0.1832 - f1_m: 0.2519\n",
      "Epoch 3: val_acc improved from 0.96466 to 0.96622, saving model to models/best_model_10_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.1077 - acc: 0.9658 - precision_m: 0.5358 - recall_m: 0.1810 - f1_m: 0.2494 - val_loss: 0.1024 - val_acc: 0.9662 - val_precision_m: 0.4293 - val_recall_m: 0.0859 - val_f1_m: 0.1371\n",
      "Epoch 4/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.0992 - acc: 0.9678 - precision_m: 0.6290 - recall_m: 0.2424 - f1_m: 0.3274\n",
      "Epoch 4: val_acc improved from 0.96622 to 0.96802, saving model to models/best_model_10_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0990 - acc: 0.9679 - precision_m: 0.6293 - recall_m: 0.2450 - f1_m: 0.3305 - val_loss: 0.0944 - val_acc: 0.9680 - val_precision_m: 0.4921 - val_recall_m: 0.2316 - val_f1_m: 0.3002\n",
      "Epoch 5/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.0919 - acc: 0.9696 - precision_m: 0.6854 - recall_m: 0.3232 - f1_m: 0.4120\n",
      "Epoch 5: val_acc improved from 0.96802 to 0.96945, saving model to models/best_model_10_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0920 - acc: 0.9697 - precision_m: 0.6894 - recall_m: 0.3238 - f1_m: 0.4131 - val_loss: 0.0951 - val_acc: 0.9695 - val_precision_m: 0.5209 - val_recall_m: 0.2759 - val_f1_m: 0.3513\n",
      "Epoch 6/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.0887 - acc: 0.9713 - precision_m: 0.7096 - recall_m: 0.3644 - f1_m: 0.4579\n",
      "Epoch 6: val_acc improved from 0.96945 to 0.97125, saving model to models/best_model_10_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0887 - acc: 0.9715 - precision_m: 0.7128 - recall_m: 0.3656 - f1_m: 0.4596 - val_loss: 0.0856 - val_acc: 0.9713 - val_precision_m: 0.6268 - val_recall_m: 0.3119 - val_f1_m: 0.3972\n",
      "Epoch 7/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.0841 - acc: 0.9725 - precision_m: 0.7260 - recall_m: 0.4140 - f1_m: 0.5043\n",
      "Epoch 7: val_acc did not improve from 0.97125\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0846 - acc: 0.9724 - precision_m: 0.7242 - recall_m: 0.4127 - f1_m: 0.5020 - val_loss: 0.0855 - val_acc: 0.9711 - val_precision_m: 0.5910 - val_recall_m: 0.3062 - val_f1_m: 0.3844\n",
      "Epoch 8/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.0814 - acc: 0.9736 - precision_m: 0.7351 - recall_m: 0.4306 - f1_m: 0.5203\n",
      "Epoch 8: val_acc improved from 0.97125 to 0.97197, saving model to models/best_model_10_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0814 - acc: 0.9735 - precision_m: 0.7352 - recall_m: 0.4303 - f1_m: 0.5201 - val_loss: 0.0837 - val_acc: 0.9720 - val_precision_m: 0.6272 - val_recall_m: 0.3436 - val_f1_m: 0.4308\n",
      "Epoch 9/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0798 - acc: 0.9746 - precision_m: 0.7689 - recall_m: 0.4633 - f1_m: 0.5515\n",
      "Epoch 9: val_acc improved from 0.97197 to 0.97377, saving model to models/best_model_10_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0798 - acc: 0.9746 - precision_m: 0.7679 - recall_m: 0.4632 - f1_m: 0.5513 - val_loss: 0.0820 - val_acc: 0.9738 - val_precision_m: 0.7152 - val_recall_m: 0.3528 - val_f1_m: 0.4516\n",
      "Epoch 10/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0771 - acc: 0.9756 - precision_m: 0.7813 - recall_m: 0.4674 - f1_m: 0.5591\n",
      "Epoch 10: val_acc improved from 0.97377 to 0.97460, saving model to models/best_model_10_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0767 - acc: 0.9756 - precision_m: 0.7833 - recall_m: 0.4678 - f1_m: 0.5597 - val_loss: 0.0799 - val_acc: 0.9746 - val_precision_m: 0.7028 - val_recall_m: 0.3795 - val_f1_m: 0.4789\n",
      "Epoch 11/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.0755 - acc: 0.9760 - precision_m: 0.7924 - recall_m: 0.4914 - f1_m: 0.5823\n",
      "Epoch 11: val_acc improved from 0.97460 to 0.97520, saving model to models/best_model_10_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0752 - acc: 0.9761 - precision_m: 0.7943 - recall_m: 0.4932 - f1_m: 0.5841 - val_loss: 0.0801 - val_acc: 0.9752 - val_precision_m: 0.7586 - val_recall_m: 0.3584 - val_f1_m: 0.4686\n",
      "Epoch 12/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.0737 - acc: 0.9762 - precision_m: 0.7998 - recall_m: 0.4936 - f1_m: 0.5849\n",
      "Epoch 12: val_acc did not improve from 0.97520\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0737 - acc: 0.9763 - precision_m: 0.7974 - recall_m: 0.4946 - f1_m: 0.5842 - val_loss: 0.0787 - val_acc: 0.9734 - val_precision_m: 0.6169 - val_recall_m: 0.4835 - val_f1_m: 0.5198\n",
      "Epoch 13/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0720 - acc: 0.9768 - precision_m: 0.8077 - recall_m: 0.4972 - f1_m: 0.5889\n",
      "Epoch 13: val_acc improved from 0.97520 to 0.97616, saving model to models/best_model_10_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0723 - acc: 0.9767 - precision_m: 0.8075 - recall_m: 0.4987 - f1_m: 0.5901 - val_loss: 0.0759 - val_acc: 0.9762 - val_precision_m: 0.7377 - val_recall_m: 0.4610 - val_f1_m: 0.5414\n",
      "Epoch 14/30\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 0.0701 - acc: 0.9774 - precision_m: 0.8012 - recall_m: 0.5169 - f1_m: 0.6030\n",
      "Epoch 14: val_acc did not improve from 0.97616\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0702 - acc: 0.9776 - precision_m: 0.8062 - recall_m: 0.5173 - f1_m: 0.6047 - val_loss: 0.0774 - val_acc: 0.9746 - val_precision_m: 0.6713 - val_recall_m: 0.5284 - val_f1_m: 0.5696\n",
      "Epoch 15/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.0683 - acc: 0.9777 - precision_m: 0.8145 - recall_m: 0.5123 - f1_m: 0.6067\n",
      "Epoch 15: val_acc did not improve from 0.97616\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0683 - acc: 0.9777 - precision_m: 0.8145 - recall_m: 0.5123 - f1_m: 0.6067 - val_loss: 0.0779 - val_acc: 0.9747 - val_precision_m: 0.7207 - val_recall_m: 0.3695 - val_f1_m: 0.4690\n",
      "Epoch 16/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0673 - acc: 0.9776 - precision_m: 0.7999 - recall_m: 0.5253 - f1_m: 0.6106\n",
      "Epoch 16: val_acc did not improve from 0.97616\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0675 - acc: 0.9775 - precision_m: 0.8030 - recall_m: 0.5248 - f1_m: 0.6113 - val_loss: 0.0760 - val_acc: 0.9734 - val_precision_m: 0.6178 - val_recall_m: 0.4956 - val_f1_m: 0.5281\n",
      "Epoch 17/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0650 - acc: 0.9786 - precision_m: 0.8242 - recall_m: 0.5265 - f1_m: 0.6190\n",
      "Epoch 17: val_acc did not improve from 0.97616\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0654 - acc: 0.9785 - precision_m: 0.8265 - recall_m: 0.5261 - f1_m: 0.6193 - val_loss: 0.0768 - val_acc: 0.9741 - val_precision_m: 0.6395 - val_recall_m: 0.5008 - val_f1_m: 0.5382\n",
      "Epoch 18/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0650 - acc: 0.9785 - precision_m: 0.8089 - recall_m: 0.5390 - f1_m: 0.6241\n",
      "Epoch 18: val_acc did not improve from 0.97616\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0651 - acc: 0.9785 - precision_m: 0.8101 - recall_m: 0.5357 - f1_m: 0.6220 - val_loss: 0.0732 - val_acc: 0.9754 - val_precision_m: 0.7159 - val_recall_m: 0.4224 - val_f1_m: 0.5096\n",
      "Epoch 19/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0629 - acc: 0.9792 - precision_m: 0.8349 - recall_m: 0.5490 - f1_m: 0.6433\n",
      "Epoch 19: val_acc did not improve from 0.97616\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0630 - acc: 0.9791 - precision_m: 0.8316 - recall_m: 0.5454 - f1_m: 0.6394 - val_loss: 0.0704 - val_acc: 0.9748 - val_precision_m: 0.6752 - val_recall_m: 0.4264 - val_f1_m: 0.5080\n",
      "Epoch 20/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9796 - precision_m: 0.8324 - recall_m: 0.5627 - f1_m: 0.6552\n",
      "Epoch 20: val_acc did not improve from 0.97616\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0627 - acc: 0.9796 - precision_m: 0.8321 - recall_m: 0.5624 - f1_m: 0.6550 - val_loss: 0.0758 - val_acc: 0.9757 - val_precision_m: 0.7474 - val_recall_m: 0.3611 - val_f1_m: 0.4722\n",
      "Epoch 21/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0616 - acc: 0.9799 - precision_m: 0.8462 - recall_m: 0.5643 - f1_m: 0.6548\n",
      "Epoch 21: val_acc did not improve from 0.97616\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0621 - acc: 0.9797 - precision_m: 0.8425 - recall_m: 0.5580 - f1_m: 0.6491 - val_loss: 0.0737 - val_acc: 0.9759 - val_precision_m: 0.7569 - val_recall_m: 0.4098 - val_f1_m: 0.5114\n",
      "Epoch 22/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9802 - precision_m: 0.8502 - recall_m: 0.5651 - f1_m: 0.6589\n",
      "Epoch 22: val_acc did not improve from 0.97616\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0604 - acc: 0.9801 - precision_m: 0.8489 - recall_m: 0.5648 - f1_m: 0.6584 - val_loss: 0.0748 - val_acc: 0.9748 - val_precision_m: 0.6112 - val_recall_m: 0.5669 - val_f1_m: 0.5720\n",
      "Epoch 23/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0595 - acc: 0.9805 - precision_m: 0.8584 - recall_m: 0.5692 - f1_m: 0.6684\n",
      "Epoch 23: val_acc did not improve from 0.97616\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0594 - acc: 0.9806 - precision_m: 0.8577 - recall_m: 0.5714 - f1_m: 0.6698 - val_loss: 0.0781 - val_acc: 0.9757 - val_precision_m: 0.7571 - val_recall_m: 0.3590 - val_f1_m: 0.4712\n",
      "Epoch 24/30\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 0.0590 - acc: 0.9807 - precision_m: 0.8514 - recall_m: 0.5763 - f1_m: 0.6695\n",
      "Epoch 24: val_acc did not improve from 0.97616\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0588 - acc: 0.9806 - precision_m: 0.8505 - recall_m: 0.5777 - f1_m: 0.6705 - val_loss: 0.0736 - val_acc: 0.9762 - val_precision_m: 0.7471 - val_recall_m: 0.3898 - val_f1_m: 0.4928\n",
      "Epoch 25/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9806 - precision_m: 0.8618 - recall_m: 0.5769 - f1_m: 0.6672\n",
      "Epoch 25: val_acc improved from 0.97616 to 0.97688, saving model to models/best_model_10_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0598 - acc: 0.9806 - precision_m: 0.8648 - recall_m: 0.5745 - f1_m: 0.6660 - val_loss: 0.0726 - val_acc: 0.9769 - val_precision_m: 0.7282 - val_recall_m: 0.4348 - val_f1_m: 0.5279\n",
      "Epoch 26/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0574 - acc: 0.9811 - precision_m: 0.8516 - recall_m: 0.5907 - f1_m: 0.6779\n",
      "Epoch 26: val_acc did not improve from 0.97688\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0572 - acc: 0.9812 - precision_m: 0.8517 - recall_m: 0.5929 - f1_m: 0.6793 - val_loss: 0.0696 - val_acc: 0.9769 - val_precision_m: 0.6813 - val_recall_m: 0.5059 - val_f1_m: 0.5613\n",
      "Epoch 27/30\n",
      "279/291 [===========================>..] - ETA: 0s - loss: 0.0551 - acc: 0.9818 - precision_m: 0.8527 - recall_m: 0.6059 - f1_m: 0.6924\n",
      "Epoch 27: val_acc did not improve from 0.97688\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0552 - acc: 0.9819 - precision_m: 0.8546 - recall_m: 0.6076 - f1_m: 0.6944 - val_loss: 0.0765 - val_acc: 0.9751 - val_precision_m: 0.7485 - val_recall_m: 0.3548 - val_f1_m: 0.4649\n",
      "Epoch 28/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.0561 - acc: 0.9814 - precision_m: 0.8608 - recall_m: 0.5982 - f1_m: 0.6848\n",
      "Epoch 28: val_acc did not improve from 0.97688\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0561 - acc: 0.9814 - precision_m: 0.8601 - recall_m: 0.5985 - f1_m: 0.6847 - val_loss: 0.0803 - val_acc: 0.9752 - val_precision_m: 0.7225 - val_recall_m: 0.3582 - val_f1_m: 0.4626\n",
      "Epoch 29/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0556 - acc: 0.9814 - precision_m: 0.8642 - recall_m: 0.5928 - f1_m: 0.6835\n",
      "Epoch 29: val_acc improved from 0.97688 to 0.97712, saving model to models/best_model_10_fold_3.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0554 - acc: 0.9815 - precision_m: 0.8671 - recall_m: 0.5934 - f1_m: 0.6853 - val_loss: 0.0707 - val_acc: 0.9771 - val_precision_m: 0.6702 - val_recall_m: 0.5807 - val_f1_m: 0.6049\n",
      "Epoch 30/30\n",
      "278/291 [===========================>..] - ETA: 0s - loss: 0.0553 - acc: 0.9815 - precision_m: 0.8618 - recall_m: 0.6015 - f1_m: 0.6856\n",
      "Epoch 30: val_acc did not improve from 0.97712\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0552 - acc: 0.9817 - precision_m: 0.8626 - recall_m: 0.5994 - f1_m: 0.6840 - val_loss: 0.0729 - val_acc: 0.9771 - val_precision_m: 0.7540 - val_recall_m: 0.4204 - val_f1_m: 0.5249\n",
      "Score for fold 3: loss of 0.07068116217851639; acc of 97.71202802658081%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.07247267663478851; acc of 97.76048064231873%\n",
      "Test Precision: precision_m of 25.577422976493835%\n",
      "Test Recall: recall_m of 22.26392775774002%\n",
      "Test F1: f1_m of 22.62873202562332%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1816 - acc: 0.9600 - precision_m: 0.0049 - recall_m: 0.0067 - f1_m: 0.0035\n",
      "Epoch 1: val_acc improved from -inf to 0.96143, saving model to models/best_model_10_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 3s 5ms/step - loss: 0.1816 - acc: 0.9600 - precision_m: 0.0049 - recall_m: 0.0067 - f1_m: 0.0035 - val_loss: 0.1469 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.1331 - acc: 0.9646 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 2: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1330 - acc: 0.9646 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1261 - val_acc: 0.9614 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 3/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.1098 - acc: 0.9651 - precision_m: 0.1370 - recall_m: 0.0204 - f1_m: 0.0344\n",
      "Epoch 3: val_acc did not improve from 0.96143\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1097 - acc: 0.9651 - precision_m: 0.1416 - recall_m: 0.0208 - f1_m: 0.0352 - val_loss: 0.1178 - val_acc: 0.9613 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 4/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0987 - acc: 0.9664 - precision_m: 0.4799 - recall_m: 0.1080 - f1_m: 0.1654\n",
      "Epoch 4: val_acc improved from 0.96143 to 0.96406, saving model to models/best_model_10_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0987 - acc: 0.9664 - precision_m: 0.4844 - recall_m: 0.1117 - f1_m: 0.1701 - val_loss: 0.1184 - val_acc: 0.9641 - val_precision_m: 0.2879 - val_recall_m: 0.0646 - val_f1_m: 0.0986\n",
      "Epoch 5/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.0922 - acc: 0.9681 - precision_m: 0.6169 - recall_m: 0.2039 - f1_m: 0.2887\n",
      "Epoch 5: val_acc improved from 0.96406 to 0.96597, saving model to models/best_model_10_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0922 - acc: 0.9681 - precision_m: 0.6148 - recall_m: 0.2032 - f1_m: 0.2877 - val_loss: 0.1087 - val_acc: 0.9660 - val_precision_m: 0.5428 - val_recall_m: 0.1566 - val_f1_m: 0.2258\n",
      "Epoch 6/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0873 - acc: 0.9693 - precision_m: 0.6555 - recall_m: 0.2742 - f1_m: 0.3639\n",
      "Epoch 6: val_acc improved from 0.96597 to 0.96836, saving model to models/best_model_10_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0868 - acc: 0.9695 - precision_m: 0.6524 - recall_m: 0.2731 - f1_m: 0.3625 - val_loss: 0.0988 - val_acc: 0.9684 - val_precision_m: 0.5914 - val_recall_m: 0.3492 - val_f1_m: 0.4102\n",
      "Epoch 7/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9693 - precision_m: 0.6589 - recall_m: 0.2777 - f1_m: 0.3646\n",
      "Epoch 7: val_acc did not improve from 0.96836\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0884 - acc: 0.9694 - precision_m: 0.6545 - recall_m: 0.2769 - f1_m: 0.3631 - val_loss: 0.1034 - val_acc: 0.9684 - val_precision_m: 0.6354 - val_recall_m: 0.2305 - val_f1_m: 0.3096\n",
      "Epoch 8/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0850 - acc: 0.9707 - precision_m: 0.6944 - recall_m: 0.3261 - f1_m: 0.4137\n",
      "Epoch 8: val_acc improved from 0.96836 to 0.96955, saving model to models/best_model_10_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0849 - acc: 0.9708 - precision_m: 0.6951 - recall_m: 0.3236 - f1_m: 0.4116 - val_loss: 0.0959 - val_acc: 0.9696 - val_precision_m: 0.6594 - val_recall_m: 0.3117 - val_f1_m: 0.3870\n",
      "Epoch 9/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0807 - acc: 0.9717 - precision_m: 0.7033 - recall_m: 0.3481 - f1_m: 0.4435\n",
      "Epoch 9: val_acc did not improve from 0.96955\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0807 - acc: 0.9716 - precision_m: 0.6981 - recall_m: 0.3453 - f1_m: 0.4402 - val_loss: 0.0960 - val_acc: 0.9684 - val_precision_m: 0.5998 - val_recall_m: 0.4945 - val_f1_m: 0.5133\n",
      "Epoch 10/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0785 - acc: 0.9723 - precision_m: 0.7241 - recall_m: 0.3777 - f1_m: 0.4677\n",
      "Epoch 10: val_acc improved from 0.96955 to 0.96979, saving model to models/best_model_10_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0785 - acc: 0.9723 - precision_m: 0.7210 - recall_m: 0.3757 - f1_m: 0.4656 - val_loss: 0.0926 - val_acc: 0.9698 - val_precision_m: 0.6545 - val_recall_m: 0.3150 - val_f1_m: 0.3923\n",
      "Epoch 11/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0765 - acc: 0.9731 - precision_m: 0.7313 - recall_m: 0.3946 - f1_m: 0.4843\n",
      "Epoch 11: val_acc improved from 0.96979 to 0.97063, saving model to models/best_model_10_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0770 - acc: 0.9730 - precision_m: 0.7288 - recall_m: 0.3924 - f1_m: 0.4819 - val_loss: 0.0935 - val_acc: 0.9706 - val_precision_m: 0.6789 - val_recall_m: 0.3433 - val_f1_m: 0.4306\n",
      "Epoch 12/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0742 - acc: 0.9734 - precision_m: 0.7184 - recall_m: 0.3983 - f1_m: 0.4912\n",
      "Epoch 12: val_acc improved from 0.97063 to 0.97134, saving model to models/best_model_10_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0745 - acc: 0.9732 - precision_m: 0.7153 - recall_m: 0.3978 - f1_m: 0.4894 - val_loss: 0.0974 - val_acc: 0.9713 - val_precision_m: 0.7103 - val_recall_m: 0.3322 - val_f1_m: 0.4251\n",
      "Epoch 13/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0756 - acc: 0.9726 - precision_m: 0.7245 - recall_m: 0.3946 - f1_m: 0.4793\n",
      "Epoch 13: val_acc did not improve from 0.97134\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0753 - acc: 0.9727 - precision_m: 0.7223 - recall_m: 0.3930 - f1_m: 0.4780 - val_loss: 0.1016 - val_acc: 0.9706 - val_precision_m: 0.7247 - val_recall_m: 0.2940 - val_f1_m: 0.3861\n",
      "Epoch 14/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0717 - acc: 0.9743 - precision_m: 0.7294 - recall_m: 0.4367 - f1_m: 0.5215\n",
      "Epoch 14: val_acc did not improve from 0.97134\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0720 - acc: 0.9743 - precision_m: 0.7298 - recall_m: 0.4359 - f1_m: 0.5205 - val_loss: 0.0907 - val_acc: 0.9691 - val_precision_m: 0.6089 - val_recall_m: 0.4787 - val_f1_m: 0.5025\n",
      "Epoch 15/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0695 - acc: 0.9748 - precision_m: 0.7428 - recall_m: 0.4488 - f1_m: 0.5361\n",
      "Epoch 15: val_acc improved from 0.97134 to 0.97146, saving model to models/best_model_10_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0698 - acc: 0.9748 - precision_m: 0.7407 - recall_m: 0.4482 - f1_m: 0.5353 - val_loss: 0.0905 - val_acc: 0.9715 - val_precision_m: 0.6193 - val_recall_m: 0.4439 - val_f1_m: 0.4933\n",
      "Epoch 16/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0684 - acc: 0.9758 - precision_m: 0.7554 - recall_m: 0.4680 - f1_m: 0.5537\n",
      "Epoch 16: val_acc did not improve from 0.97146\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0687 - acc: 0.9757 - precision_m: 0.7513 - recall_m: 0.4680 - f1_m: 0.5525 - val_loss: 0.0877 - val_acc: 0.9715 - val_precision_m: 0.6487 - val_recall_m: 0.4343 - val_f1_m: 0.4924\n",
      "Epoch 17/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0692 - acc: 0.9755 - precision_m: 0.7481 - recall_m: 0.4698 - f1_m: 0.5504\n",
      "Epoch 17: val_acc improved from 0.97146 to 0.97242, saving model to models/best_model_10_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0691 - acc: 0.9755 - precision_m: 0.7456 - recall_m: 0.4683 - f1_m: 0.5488 - val_loss: 0.0888 - val_acc: 0.9724 - val_precision_m: 0.7239 - val_recall_m: 0.4062 - val_f1_m: 0.4829\n",
      "Epoch 18/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 0.9759 - precision_m: 0.7676 - recall_m: 0.4714 - f1_m: 0.5566\n",
      "Epoch 18: val_acc improved from 0.97242 to 0.97254, saving model to models/best_model_10_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0679 - acc: 0.9759 - precision_m: 0.7658 - recall_m: 0.4695 - f1_m: 0.5550 - val_loss: 0.0897 - val_acc: 0.9725 - val_precision_m: 0.6913 - val_recall_m: 0.4432 - val_f1_m: 0.5108\n",
      "Epoch 19/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0653 - acc: 0.9770 - precision_m: 0.7792 - recall_m: 0.5062 - f1_m: 0.5877\n",
      "Epoch 19: val_acc did not improve from 0.97254\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0659 - acc: 0.9768 - precision_m: 0.7816 - recall_m: 0.5072 - f1_m: 0.5893 - val_loss: 0.0915 - val_acc: 0.9673 - val_precision_m: 0.5350 - val_recall_m: 0.5440 - val_f1_m: 0.5232\n",
      "Epoch 20/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0657 - acc: 0.9775 - precision_m: 0.7781 - recall_m: 0.5141 - f1_m: 0.5952\n",
      "Epoch 20: val_acc did not improve from 0.97254\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0656 - acc: 0.9775 - precision_m: 0.7726 - recall_m: 0.5135 - f1_m: 0.5934 - val_loss: 0.1067 - val_acc: 0.9712 - val_precision_m: 0.7420 - val_recall_m: 0.3129 - val_f1_m: 0.4060\n",
      "Epoch 21/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0653 - acc: 0.9772 - precision_m: 0.7894 - recall_m: 0.4971 - f1_m: 0.5851\n",
      "Epoch 21: val_acc did not improve from 0.97254\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0651 - acc: 0.9773 - precision_m: 0.7864 - recall_m: 0.4952 - f1_m: 0.5830 - val_loss: 0.1006 - val_acc: 0.9723 - val_precision_m: 0.7298 - val_recall_m: 0.3539 - val_f1_m: 0.4425\n",
      "Epoch 22/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0633 - acc: 0.9780 - precision_m: 0.7920 - recall_m: 0.5169 - f1_m: 0.6041\n",
      "Epoch 22: val_acc improved from 0.97254 to 0.97266, saving model to models/best_model_10_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0629 - acc: 0.9780 - precision_m: 0.7902 - recall_m: 0.5184 - f1_m: 0.6046 - val_loss: 0.1038 - val_acc: 0.9727 - val_precision_m: 0.7447 - val_recall_m: 0.3798 - val_f1_m: 0.4738\n",
      "Epoch 23/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0627 - acc: 0.9783 - precision_m: 0.8006 - recall_m: 0.5357 - f1_m: 0.6172\n",
      "Epoch 23: val_acc did not improve from 0.97266\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0627 - acc: 0.9783 - precision_m: 0.7992 - recall_m: 0.5326 - f1_m: 0.6144 - val_loss: 0.0909 - val_acc: 0.9682 - val_precision_m: 0.5488 - val_recall_m: 0.5158 - val_f1_m: 0.5064\n",
      "Epoch 24/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0651 - acc: 0.9774 - precision_m: 0.7928 - recall_m: 0.4975 - f1_m: 0.5887\n",
      "Epoch 24: val_acc did not improve from 0.97266\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0652 - acc: 0.9774 - precision_m: 0.7902 - recall_m: 0.4952 - f1_m: 0.5860 - val_loss: 0.0965 - val_acc: 0.9654 - val_precision_m: 0.5043 - val_recall_m: 0.6132 - val_f1_m: 0.5269\n",
      "Epoch 25/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0658 - acc: 0.9770 - precision_m: 0.7897 - recall_m: 0.5064 - f1_m: 0.5880\n",
      "Epoch 25: val_acc did not improve from 0.97266\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0654 - acc: 0.9772 - precision_m: 0.7894 - recall_m: 0.5124 - f1_m: 0.5912 - val_loss: 0.1015 - val_acc: 0.9727 - val_precision_m: 0.7796 - val_recall_m: 0.3671 - val_f1_m: 0.4663\n",
      "Epoch 26/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9786 - precision_m: 0.8083 - recall_m: 0.5256 - f1_m: 0.6124\n",
      "Epoch 26: val_acc did not improve from 0.97266\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0605 - acc: 0.9788 - precision_m: 0.8071 - recall_m: 0.5255 - f1_m: 0.6119 - val_loss: 0.0872 - val_acc: 0.9722 - val_precision_m: 0.6910 - val_recall_m: 0.4561 - val_f1_m: 0.5139\n",
      "Epoch 27/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9790 - precision_m: 0.8148 - recall_m: 0.5465 - f1_m: 0.6280\n",
      "Epoch 27: val_acc improved from 0.97266 to 0.97349, saving model to models/best_model_10_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0606 - acc: 0.9790 - precision_m: 0.8128 - recall_m: 0.5455 - f1_m: 0.6267 - val_loss: 0.0895 - val_acc: 0.9735 - val_precision_m: 0.7739 - val_recall_m: 0.3969 - val_f1_m: 0.4865\n",
      "Epoch 28/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0637 - acc: 0.9769 - precision_m: 0.8163 - recall_m: 0.4553 - f1_m: 0.5520\n",
      "Epoch 28: val_acc did not improve from 0.97349\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0639 - acc: 0.9770 - precision_m: 0.8129 - recall_m: 0.4561 - f1_m: 0.5528 - val_loss: 0.0871 - val_acc: 0.9730 - val_precision_m: 0.7418 - val_recall_m: 0.4325 - val_f1_m: 0.5076\n",
      "Epoch 29/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9792 - precision_m: 0.8109 - recall_m: 0.5301 - f1_m: 0.6222\n",
      "Epoch 29: val_acc improved from 0.97349 to 0.97421, saving model to models/best_model_10_fold_4.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0590 - acc: 0.9793 - precision_m: 0.8094 - recall_m: 0.5279 - f1_m: 0.6202 - val_loss: 0.0890 - val_acc: 0.9742 - val_precision_m: 0.7618 - val_recall_m: 0.4356 - val_f1_m: 0.5183\n",
      "Epoch 30/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0583 - acc: 0.9800 - precision_m: 0.8260 - recall_m: 0.5618 - f1_m: 0.6447\n",
      "Epoch 30: val_acc did not improve from 0.97421\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0585 - acc: 0.9799 - precision_m: 0.8226 - recall_m: 0.5581 - f1_m: 0.6410 - val_loss: 0.0854 - val_acc: 0.9727 - val_precision_m: 0.6972 - val_recall_m: 0.4371 - val_f1_m: 0.5067\n",
      "Score for fold 4: loss of 0.08899437636137009; acc of 97.42089509963989%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.08929432183504105; acc of 97.08968997001648%\n",
      "Test Precision: precision_m of 25.565168261528015%\n",
      "Test Recall: recall_m of 17.845584452152252%\n",
      "Test F1: f1_m of 19.894495606422424%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.1760 - acc: 0.9602 - precision_m: 0.0271 - recall_m: 0.0080 - f1_m: 0.0065\n",
      "Epoch 1: val_acc improved from -inf to 0.96211, saving model to models/best_model_10_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 3s 5ms/step - loss: 0.1760 - acc: 0.9602 - precision_m: 0.0271 - recall_m: 0.0080 - f1_m: 0.0065 - val_loss: 0.1275 - val_acc: 0.9621 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.1263 - acc: 0.9637 - precision_m: 0.1338 - recall_m: 0.0172 - f1_m: 0.0300\n",
      "Epoch 2: val_acc did not improve from 0.96211\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.1263 - acc: 0.9636 - precision_m: 0.1380 - recall_m: 0.0181 - f1_m: 0.0313 - val_loss: 0.1148 - val_acc: 0.9621 - val_precision_m: 0.1061 - val_recall_m: 0.0187 - val_f1_m: 0.0310\n",
      "Epoch 3/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.1123 - acc: 0.9644 - precision_m: 0.3601 - recall_m: 0.0736 - f1_m: 0.1163\n",
      "Epoch 3: val_acc improved from 0.96211 to 0.96271, saving model to models/best_model_10_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.1122 - acc: 0.9644 - precision_m: 0.3623 - recall_m: 0.0740 - f1_m: 0.1169 - val_loss: 0.1148 - val_acc: 0.9627 - val_precision_m: 0.1212 - val_recall_m: 0.0156 - val_f1_m: 0.0270\n",
      "Epoch 4/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.1035 - acc: 0.9658 - precision_m: 0.5083 - recall_m: 0.1329 - f1_m: 0.1981\n",
      "Epoch 4: val_acc improved from 0.96271 to 0.96654, saving model to models/best_model_10_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.1036 - acc: 0.9657 - precision_m: 0.5071 - recall_m: 0.1325 - f1_m: 0.1977 - val_loss: 0.1055 - val_acc: 0.9665 - val_precision_m: 0.5962 - val_recall_m: 0.1906 - val_f1_m: 0.2729\n",
      "Epoch 5/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0969 - acc: 0.9670 - precision_m: 0.6054 - recall_m: 0.2050 - f1_m: 0.2828\n",
      "Epoch 5: val_acc did not improve from 0.96654\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0975 - acc: 0.9668 - precision_m: 0.6050 - recall_m: 0.2085 - f1_m: 0.2857 - val_loss: 0.1010 - val_acc: 0.9659 - val_precision_m: 0.5585 - val_recall_m: 0.3210 - val_f1_m: 0.3797\n",
      "Epoch 6/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0915 - acc: 0.9685 - precision_m: 0.6371 - recall_m: 0.2619 - f1_m: 0.3498\n",
      "Epoch 6: val_acc improved from 0.96654 to 0.96881, saving model to models/best_model_10_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0915 - acc: 0.9684 - precision_m: 0.6356 - recall_m: 0.2621 - f1_m: 0.3496 - val_loss: 0.0948 - val_acc: 0.9688 - val_precision_m: 0.6789 - val_recall_m: 0.2987 - val_f1_m: 0.3904\n",
      "Epoch 7/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0869 - acc: 0.9704 - precision_m: 0.7054 - recall_m: 0.3211 - f1_m: 0.4181\n",
      "Epoch 7: val_acc improved from 0.96881 to 0.96988, saving model to models/best_model_10_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0869 - acc: 0.9703 - precision_m: 0.7084 - recall_m: 0.3188 - f1_m: 0.4156 - val_loss: 0.0914 - val_acc: 0.9699 - val_precision_m: 0.6301 - val_recall_m: 0.3055 - val_f1_m: 0.3917\n",
      "Epoch 8/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0842 - acc: 0.9713 - precision_m: 0.7246 - recall_m: 0.3442 - f1_m: 0.4427\n",
      "Epoch 8: val_acc did not improve from 0.96988\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0844 - acc: 0.9712 - precision_m: 0.7218 - recall_m: 0.3439 - f1_m: 0.4419 - val_loss: 0.0949 - val_acc: 0.9699 - val_precision_m: 0.6801 - val_recall_m: 0.2629 - val_f1_m: 0.3584\n",
      "Epoch 9/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0815 - acc: 0.9718 - precision_m: 0.7183 - recall_m: 0.3569 - f1_m: 0.4529\n",
      "Epoch 9: val_acc did not improve from 0.96988\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0814 - acc: 0.9718 - precision_m: 0.7196 - recall_m: 0.3590 - f1_m: 0.4550 - val_loss: 0.0898 - val_acc: 0.9695 - val_precision_m: 0.6228 - val_recall_m: 0.3016 - val_f1_m: 0.3815\n",
      "Epoch 10/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0798 - acc: 0.9731 - precision_m: 0.7399 - recall_m: 0.4064 - f1_m: 0.4968\n",
      "Epoch 10: val_acc improved from 0.96988 to 0.97000, saving model to models/best_model_10_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0798 - acc: 0.9730 - precision_m: 0.7413 - recall_m: 0.4067 - f1_m: 0.4973 - val_loss: 0.0898 - val_acc: 0.9700 - val_precision_m: 0.6668 - val_recall_m: 0.3058 - val_f1_m: 0.3957\n",
      "Epoch 11/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0786 - acc: 0.9734 - precision_m: 0.7639 - recall_m: 0.3843 - f1_m: 0.4843\n",
      "Epoch 11: val_acc did not improve from 0.97000\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0784 - acc: 0.9734 - precision_m: 0.7667 - recall_m: 0.3845 - f1_m: 0.4856 - val_loss: 0.0859 - val_acc: 0.9699 - val_precision_m: 0.6245 - val_recall_m: 0.4006 - val_f1_m: 0.4641\n",
      "Epoch 12/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0755 - acc: 0.9742 - precision_m: 0.7641 - recall_m: 0.4356 - f1_m: 0.5250\n",
      "Epoch 12: val_acc improved from 0.97000 to 0.97144, saving model to models/best_model_10_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0753 - acc: 0.9743 - precision_m: 0.7663 - recall_m: 0.4341 - f1_m: 0.5245 - val_loss: 0.0834 - val_acc: 0.9714 - val_precision_m: 0.6532 - val_recall_m: 0.4352 - val_f1_m: 0.5000\n",
      "Epoch 13/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0751 - acc: 0.9747 - precision_m: 0.7686 - recall_m: 0.4339 - f1_m: 0.5263\n",
      "Epoch 13: val_acc did not improve from 0.97144\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0751 - acc: 0.9746 - precision_m: 0.7684 - recall_m: 0.4324 - f1_m: 0.5251 - val_loss: 0.0909 - val_acc: 0.9711 - val_precision_m: 0.7306 - val_recall_m: 0.3016 - val_f1_m: 0.3984\n",
      "Epoch 14/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0734 - acc: 0.9749 - precision_m: 0.7772 - recall_m: 0.4342 - f1_m: 0.5325\n",
      "Epoch 14: val_acc did not improve from 0.97144\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0735 - acc: 0.9748 - precision_m: 0.7760 - recall_m: 0.4332 - f1_m: 0.5318 - val_loss: 0.0830 - val_acc: 0.9707 - val_precision_m: 0.7146 - val_recall_m: 0.2750 - val_f1_m: 0.3716\n",
      "Epoch 15/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0713 - acc: 0.9757 - precision_m: 0.7823 - recall_m: 0.4595 - f1_m: 0.5541\n",
      "Epoch 15: val_acc did not improve from 0.97144\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0712 - acc: 0.9758 - precision_m: 0.7851 - recall_m: 0.4596 - f1_m: 0.5553 - val_loss: 0.0823 - val_acc: 0.9714 - val_precision_m: 0.6648 - val_recall_m: 0.4592 - val_f1_m: 0.5199\n",
      "Epoch 16/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0707 - acc: 0.9758 - precision_m: 0.7795 - recall_m: 0.4688 - f1_m: 0.5603\n",
      "Epoch 16: val_acc improved from 0.97144 to 0.97263, saving model to models/best_model_10_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0707 - acc: 0.9759 - precision_m: 0.7822 - recall_m: 0.4699 - f1_m: 0.5616 - val_loss: 0.0832 - val_acc: 0.9726 - val_precision_m: 0.7161 - val_recall_m: 0.3838 - val_f1_m: 0.4725\n",
      "Epoch 17/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0699 - acc: 0.9757 - precision_m: 0.7776 - recall_m: 0.4583 - f1_m: 0.5550\n",
      "Epoch 17: val_acc improved from 0.97263 to 0.97275, saving model to models/best_model_10_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0693 - acc: 0.9758 - precision_m: 0.7831 - recall_m: 0.4574 - f1_m: 0.5560 - val_loss: 0.0836 - val_acc: 0.9728 - val_precision_m: 0.7084 - val_recall_m: 0.4010 - val_f1_m: 0.4720\n",
      "Epoch 18/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0684 - acc: 0.9764 - precision_m: 0.7945 - recall_m: 0.4728 - f1_m: 0.5669\n",
      "Epoch 18: val_acc improved from 0.97275 to 0.97299, saving model to models/best_model_10_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0682 - acc: 0.9764 - precision_m: 0.7930 - recall_m: 0.4735 - f1_m: 0.5671 - val_loss: 0.0837 - val_acc: 0.9730 - val_precision_m: 0.7025 - val_recall_m: 0.4494 - val_f1_m: 0.5240\n",
      "Epoch 19/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0676 - acc: 0.9771 - precision_m: 0.8032 - recall_m: 0.4985 - f1_m: 0.5921\n",
      "Epoch 19: val_acc did not improve from 0.97299\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0674 - acc: 0.9771 - precision_m: 0.8052 - recall_m: 0.4964 - f1_m: 0.5906 - val_loss: 0.0827 - val_acc: 0.9729 - val_precision_m: 0.7156 - val_recall_m: 0.4335 - val_f1_m: 0.5174\n",
      "Epoch 20/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9770 - precision_m: 0.7976 - recall_m: 0.4927 - f1_m: 0.5860\n",
      "Epoch 20: val_acc improved from 0.97299 to 0.97359, saving model to models/best_model_10_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0663 - acc: 0.9769 - precision_m: 0.7951 - recall_m: 0.4906 - f1_m: 0.5840 - val_loss: 0.0814 - val_acc: 0.9736 - val_precision_m: 0.7198 - val_recall_m: 0.4471 - val_f1_m: 0.5261\n",
      "Epoch 21/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0659 - acc: 0.9774 - precision_m: 0.8005 - recall_m: 0.5075 - f1_m: 0.5982\n",
      "Epoch 21: val_acc did not improve from 0.97359\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0656 - acc: 0.9775 - precision_m: 0.8017 - recall_m: 0.5094 - f1_m: 0.6001 - val_loss: 0.0863 - val_acc: 0.9724 - val_precision_m: 0.7312 - val_recall_m: 0.3998 - val_f1_m: 0.4867\n",
      "Epoch 22/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0641 - acc: 0.9782 - precision_m: 0.7996 - recall_m: 0.5084 - f1_m: 0.5992\n",
      "Epoch 22: val_acc did not improve from 0.97359\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0643 - acc: 0.9782 - precision_m: 0.8006 - recall_m: 0.5114 - f1_m: 0.6017 - val_loss: 0.0802 - val_acc: 0.9736 - val_precision_m: 0.6723 - val_recall_m: 0.4976 - val_f1_m: 0.5469\n",
      "Epoch 23/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0641 - acc: 0.9778 - precision_m: 0.8125 - recall_m: 0.5172 - f1_m: 0.6108\n",
      "Epoch 23: val_acc did not improve from 0.97359\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0639 - acc: 0.9778 - precision_m: 0.8106 - recall_m: 0.5152 - f1_m: 0.6086 - val_loss: 0.0838 - val_acc: 0.9733 - val_precision_m: 0.7133 - val_recall_m: 0.4732 - val_f1_m: 0.5434\n",
      "Epoch 24/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0617 - acc: 0.9785 - precision_m: 0.8215 - recall_m: 0.5257 - f1_m: 0.6231\n",
      "Epoch 24: val_acc did not improve from 0.97359\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0619 - acc: 0.9785 - precision_m: 0.8206 - recall_m: 0.5241 - f1_m: 0.6218 - val_loss: 0.0797 - val_acc: 0.9725 - val_precision_m: 0.6581 - val_recall_m: 0.5477 - val_f1_m: 0.5719\n",
      "Epoch 25/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.0628 - acc: 0.9786 - precision_m: 0.8232 - recall_m: 0.5294 - f1_m: 0.6202\n",
      "Epoch 25: val_acc did not improve from 0.97359\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0628 - acc: 0.9786 - precision_m: 0.8232 - recall_m: 0.5294 - f1_m: 0.6202 - val_loss: 0.0813 - val_acc: 0.9735 - val_precision_m: 0.7431 - val_recall_m: 0.4325 - val_f1_m: 0.5179\n",
      "Epoch 26/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0611 - acc: 0.9790 - precision_m: 0.8230 - recall_m: 0.5365 - f1_m: 0.6294\n",
      "Epoch 26: val_acc improved from 0.97359 to 0.97454, saving model to models/best_model_10_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0614 - acc: 0.9788 - precision_m: 0.8179 - recall_m: 0.5273 - f1_m: 0.6207 - val_loss: 0.0779 - val_acc: 0.9745 - val_precision_m: 0.7459 - val_recall_m: 0.4755 - val_f1_m: 0.5569\n",
      "Epoch 27/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0610 - acc: 0.9790 - precision_m: 0.8304 - recall_m: 0.5431 - f1_m: 0.6365\n",
      "Epoch 27: val_acc did not improve from 0.97454\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0609 - acc: 0.9790 - precision_m: 0.8328 - recall_m: 0.5409 - f1_m: 0.6351 - val_loss: 0.0800 - val_acc: 0.9729 - val_precision_m: 0.6557 - val_recall_m: 0.5460 - val_f1_m: 0.5654\n",
      "Epoch 28/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9786 - precision_m: 0.8249 - recall_m: 0.5309 - f1_m: 0.6258\n",
      "Epoch 28: val_acc improved from 0.97454 to 0.97526, saving model to models/best_model_10_fold_5.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0608 - acc: 0.9787 - precision_m: 0.8244 - recall_m: 0.5283 - f1_m: 0.6235 - val_loss: 0.0814 - val_acc: 0.9753 - val_precision_m: 0.7249 - val_recall_m: 0.4906 - val_f1_m: 0.5587\n",
      "Epoch 29/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9792 - precision_m: 0.8283 - recall_m: 0.5504 - f1_m: 0.6382\n",
      "Epoch 29: val_acc did not improve from 0.97526\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0600 - acc: 0.9791 - precision_m: 0.8283 - recall_m: 0.5485 - f1_m: 0.6367 - val_loss: 0.0808 - val_acc: 0.9751 - val_precision_m: 0.7264 - val_recall_m: 0.4725 - val_f1_m: 0.5428\n",
      "Epoch 30/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9793 - precision_m: 0.8328 - recall_m: 0.5491 - f1_m: 0.6383\n",
      "Epoch 30: val_acc did not improve from 0.97526\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0593 - acc: 0.9794 - precision_m: 0.8357 - recall_m: 0.5489 - f1_m: 0.6393 - val_loss: 0.0825 - val_acc: 0.9749 - val_precision_m: 0.7597 - val_recall_m: 0.4886 - val_f1_m: 0.5661\n",
      "Score for fold 5: loss of 0.08144097775220871; acc of 97.52599596977234%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.07708431780338287; acc of 97.51228094100952%\n",
      "Test Precision: precision_m of 28.04323136806488%\n",
      "Test Recall: recall_m of 22.05350250005722%\n",
      "Test F1: f1_m of 23.677964508533478%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1851 - acc: 0.9564 - precision_m: 0.0091 - recall_m: 0.0080 - f1_m: 0.0032\n",
      "Epoch 1: val_acc improved from -inf to 0.96059, saving model to models/best_model_10_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 3s 5ms/step - loss: 0.1851 - acc: 0.9564 - precision_m: 0.0091 - recall_m: 0.0080 - f1_m: 0.0032 - val_loss: 0.1557 - val_acc: 0.9606 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.1294 - acc: 0.9638 - precision_m: 0.1632 - recall_m: 0.0254 - f1_m: 0.0420\n",
      "Epoch 2: val_acc did not improve from 0.96059\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1291 - acc: 0.9638 - precision_m: 0.1627 - recall_m: 0.0251 - f1_m: 0.0416 - val_loss: 0.1213 - val_acc: 0.9605 - val_precision_m: 0.0303 - val_recall_m: 0.0030 - val_f1_m: 0.0055\n",
      "Epoch 3/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.1143 - acc: 0.9648 - precision_m: 0.4028 - recall_m: 0.0881 - f1_m: 0.1374\n",
      "Epoch 3: val_acc improved from 0.96059 to 0.96203, saving model to models/best_model_10_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1143 - acc: 0.9648 - precision_m: 0.4027 - recall_m: 0.0878 - f1_m: 0.1370 - val_loss: 0.1125 - val_acc: 0.9620 - val_precision_m: 0.4284 - val_recall_m: 0.1156 - val_f1_m: 0.1739\n",
      "Epoch 4/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.1047 - acc: 0.9663 - precision_m: 0.5444 - recall_m: 0.1504 - f1_m: 0.2206\n",
      "Epoch 4: val_acc improved from 0.96203 to 0.96481, saving model to models/best_model_10_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1049 - acc: 0.9662 - precision_m: 0.5475 - recall_m: 0.1514 - f1_m: 0.2223 - val_loss: 0.1040 - val_acc: 0.9648 - val_precision_m: 0.6023 - val_recall_m: 0.1658 - val_f1_m: 0.2450\n",
      "Epoch 5/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0964 - acc: 0.9682 - precision_m: 0.6434 - recall_m: 0.2462 - f1_m: 0.3334\n",
      "Epoch 5: val_acc improved from 0.96481 to 0.96589, saving model to models/best_model_10_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0968 - acc: 0.9684 - precision_m: 0.6411 - recall_m: 0.2509 - f1_m: 0.3374 - val_loss: 0.0975 - val_acc: 0.9659 - val_precision_m: 0.6117 - val_recall_m: 0.3013 - val_f1_m: 0.3788\n",
      "Epoch 6/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0925 - acc: 0.9696 - precision_m: 0.6848 - recall_m: 0.2950 - f1_m: 0.3850\n",
      "Epoch 6: val_acc improved from 0.96589 to 0.96866, saving model to models/best_model_10_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0924 - acc: 0.9697 - precision_m: 0.6820 - recall_m: 0.2963 - f1_m: 0.3856 - val_loss: 0.0946 - val_acc: 0.9687 - val_precision_m: 0.6754 - val_recall_m: 0.2804 - val_f1_m: 0.3763\n",
      "Epoch 7/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0883 - acc: 0.9704 - precision_m: 0.6696 - recall_m: 0.3279 - f1_m: 0.4156\n",
      "Epoch 7: val_acc improved from 0.96866 to 0.96915, saving model to models/best_model_10_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0884 - acc: 0.9703 - precision_m: 0.6684 - recall_m: 0.3297 - f1_m: 0.4164 - val_loss: 0.0890 - val_acc: 0.9691 - val_precision_m: 0.6443 - val_recall_m: 0.4001 - val_f1_m: 0.4655\n",
      "Epoch 8/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0857 - acc: 0.9714 - precision_m: 0.6963 - recall_m: 0.3563 - f1_m: 0.4449\n",
      "Epoch 8: val_acc improved from 0.96915 to 0.96987, saving model to models/best_model_10_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0856 - acc: 0.9715 - precision_m: 0.6945 - recall_m: 0.3569 - f1_m: 0.4452 - val_loss: 0.0900 - val_acc: 0.9699 - val_precision_m: 0.6912 - val_recall_m: 0.3838 - val_f1_m: 0.4614\n",
      "Epoch 9/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0831 - acc: 0.9719 - precision_m: 0.7127 - recall_m: 0.3855 - f1_m: 0.4725\n",
      "Epoch 9: val_acc did not improve from 0.96987\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0828 - acc: 0.9719 - precision_m: 0.7126 - recall_m: 0.3854 - f1_m: 0.4722 - val_loss: 0.0902 - val_acc: 0.9696 - val_precision_m: 0.6972 - val_recall_m: 0.3798 - val_f1_m: 0.4561\n",
      "Epoch 10/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0789 - acc: 0.9737 - precision_m: 0.7392 - recall_m: 0.4189 - f1_m: 0.5096\n",
      "Epoch 10: val_acc improved from 0.96987 to 0.97023, saving model to models/best_model_10_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0793 - acc: 0.9736 - precision_m: 0.7368 - recall_m: 0.4182 - f1_m: 0.5091 - val_loss: 0.0840 - val_acc: 0.9702 - val_precision_m: 0.6544 - val_recall_m: 0.4474 - val_f1_m: 0.4993\n",
      "Epoch 11/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0788 - acc: 0.9736 - precision_m: 0.7522 - recall_m: 0.4085 - f1_m: 0.5033\n",
      "Epoch 11: val_acc did not improve from 0.97023\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0786 - acc: 0.9737 - precision_m: 0.7532 - recall_m: 0.4119 - f1_m: 0.5065 - val_loss: 0.0926 - val_acc: 0.9699 - val_precision_m: 0.7131 - val_recall_m: 0.3127 - val_f1_m: 0.4106\n",
      "Epoch 12/30\n",
      "279/292 [===========================>..] - ETA: 0s - loss: 0.0757 - acc: 0.9746 - precision_m: 0.7573 - recall_m: 0.4383 - f1_m: 0.5313\n",
      "Epoch 12: val_acc improved from 0.97023 to 0.97119, saving model to models/best_model_10_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0758 - acc: 0.9745 - precision_m: 0.7585 - recall_m: 0.4383 - f1_m: 0.5318 - val_loss: 0.0864 - val_acc: 0.9712 - val_precision_m: 0.7395 - val_recall_m: 0.3841 - val_f1_m: 0.4686\n",
      "Epoch 13/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0746 - acc: 0.9745 - precision_m: 0.7501 - recall_m: 0.4412 - f1_m: 0.5334\n",
      "Epoch 13: val_acc improved from 0.97119 to 0.97204, saving model to models/best_model_10_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0743 - acc: 0.9746 - precision_m: 0.7478 - recall_m: 0.4422 - f1_m: 0.5340 - val_loss: 0.0854 - val_acc: 0.9720 - val_precision_m: 0.7083 - val_recall_m: 0.5227 - val_f1_m: 0.5634\n",
      "Epoch 14/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0736 - acc: 0.9752 - precision_m: 0.7653 - recall_m: 0.4474 - f1_m: 0.5413\n",
      "Epoch 14: val_acc did not improve from 0.97204\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0739 - acc: 0.9750 - precision_m: 0.7599 - recall_m: 0.4451 - f1_m: 0.5382 - val_loss: 0.0836 - val_acc: 0.9717 - val_precision_m: 0.7410 - val_recall_m: 0.4107 - val_f1_m: 0.4856\n",
      "Epoch 15/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.0714 - acc: 0.9755 - precision_m: 0.7697 - recall_m: 0.4710 - f1_m: 0.5597\n",
      "Epoch 15: val_acc did not improve from 0.97204\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0716 - acc: 0.9755 - precision_m: 0.7672 - recall_m: 0.4688 - f1_m: 0.5575 - val_loss: 0.0839 - val_acc: 0.9699 - val_precision_m: 0.6400 - val_recall_m: 0.5684 - val_f1_m: 0.5610\n",
      "Epoch 16/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0724 - acc: 0.9757 - precision_m: 0.7834 - recall_m: 0.4594 - f1_m: 0.5537\n",
      "Epoch 16: val_acc did not improve from 0.97204\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0723 - acc: 0.9757 - precision_m: 0.7808 - recall_m: 0.4576 - f1_m: 0.5519 - val_loss: 0.0814 - val_acc: 0.9716 - val_precision_m: 0.6755 - val_recall_m: 0.4751 - val_f1_m: 0.5287\n",
      "Epoch 17/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0695 - acc: 0.9763 - precision_m: 0.7749 - recall_m: 0.4862 - f1_m: 0.5762\n",
      "Epoch 17: val_acc improved from 0.97204 to 0.97276, saving model to models/best_model_10_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0699 - acc: 0.9762 - precision_m: 0.7767 - recall_m: 0.4815 - f1_m: 0.5725 - val_loss: 0.0826 - val_acc: 0.9728 - val_precision_m: 0.7714 - val_recall_m: 0.4189 - val_f1_m: 0.5188\n",
      "Epoch 18/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.0687 - acc: 0.9758 - precision_m: 0.7716 - recall_m: 0.4706 - f1_m: 0.5630\n",
      "Epoch 18: val_acc improved from 0.97276 to 0.97336, saving model to models/best_model_10_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0687 - acc: 0.9758 - precision_m: 0.7724 - recall_m: 0.4705 - f1_m: 0.5632 - val_loss: 0.0862 - val_acc: 0.9734 - val_precision_m: 0.7695 - val_recall_m: 0.4544 - val_f1_m: 0.5472\n",
      "Epoch 19/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 0.9769 - precision_m: 0.8005 - recall_m: 0.5003 - f1_m: 0.5933\n",
      "Epoch 19: val_acc did not improve from 0.97336\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0681 - acc: 0.9768 - precision_m: 0.8024 - recall_m: 0.4988 - f1_m: 0.5926 - val_loss: 0.0824 - val_acc: 0.9725 - val_precision_m: 0.7442 - val_recall_m: 0.4407 - val_f1_m: 0.5319\n",
      "Epoch 20/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0673 - acc: 0.9767 - precision_m: 0.7953 - recall_m: 0.4939 - f1_m: 0.5852\n",
      "Epoch 20: val_acc did not improve from 0.97336\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0668 - acc: 0.9768 - precision_m: 0.7933 - recall_m: 0.4911 - f1_m: 0.5827 - val_loss: 0.0809 - val_acc: 0.9724 - val_precision_m: 0.7275 - val_recall_m: 0.4454 - val_f1_m: 0.5308\n",
      "Epoch 21/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.0665 - acc: 0.9769 - precision_m: 0.7841 - recall_m: 0.4835 - f1_m: 0.5745\n",
      "Epoch 21: val_acc did not improve from 0.97336\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0665 - acc: 0.9768 - precision_m: 0.7837 - recall_m: 0.4830 - f1_m: 0.5740 - val_loss: 0.0834 - val_acc: 0.9728 - val_precision_m: 0.7569 - val_recall_m: 0.4078 - val_f1_m: 0.5078\n",
      "Epoch 22/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9771 - precision_m: 0.7945 - recall_m: 0.5003 - f1_m: 0.5922\n",
      "Epoch 22: val_acc did not improve from 0.97336\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0661 - acc: 0.9772 - precision_m: 0.7920 - recall_m: 0.4952 - f1_m: 0.5876 - val_loss: 0.0831 - val_acc: 0.9734 - val_precision_m: 0.7606 - val_recall_m: 0.4538 - val_f1_m: 0.5453\n",
      "Epoch 23/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0651 - acc: 0.9775 - precision_m: 0.8023 - recall_m: 0.4937 - f1_m: 0.5896\n",
      "Epoch 23: val_acc did not improve from 0.97336\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0655 - acc: 0.9773 - precision_m: 0.8024 - recall_m: 0.4934 - f1_m: 0.5891 - val_loss: 0.0808 - val_acc: 0.9728 - val_precision_m: 0.7216 - val_recall_m: 0.4912 - val_f1_m: 0.5542\n",
      "Epoch 24/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9780 - precision_m: 0.8112 - recall_m: 0.5222 - f1_m: 0.6155\n",
      "Epoch 24: val_acc did not improve from 0.97336\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0633 - acc: 0.9780 - precision_m: 0.8118 - recall_m: 0.5233 - f1_m: 0.6166 - val_loss: 0.0811 - val_acc: 0.9722 - val_precision_m: 0.6732 - val_recall_m: 0.5984 - val_f1_m: 0.5840\n",
      "Epoch 25/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0641 - acc: 0.9778 - precision_m: 0.8221 - recall_m: 0.5034 - f1_m: 0.5984\n",
      "Epoch 25: val_acc improved from 0.97336 to 0.97373, saving model to models/best_model_10_fold_6.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0643 - acc: 0.9778 - precision_m: 0.8213 - recall_m: 0.5039 - f1_m: 0.5987 - val_loss: 0.0820 - val_acc: 0.9737 - val_precision_m: 0.7017 - val_recall_m: 0.5880 - val_f1_m: 0.6007\n",
      "Epoch 26/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.0634 - acc: 0.9783 - precision_m: 0.8305 - recall_m: 0.5208 - f1_m: 0.6178\n",
      "Epoch 26: val_acc did not improve from 0.97373\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0634 - acc: 0.9783 - precision_m: 0.8302 - recall_m: 0.5216 - f1_m: 0.6182 - val_loss: 0.0848 - val_acc: 0.9723 - val_precision_m: 0.7247 - val_recall_m: 0.4534 - val_f1_m: 0.5319\n",
      "Epoch 27/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0618 - acc: 0.9790 - precision_m: 0.8362 - recall_m: 0.5255 - f1_m: 0.6233\n",
      "Epoch 27: val_acc did not improve from 0.97373\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0615 - acc: 0.9790 - precision_m: 0.8368 - recall_m: 0.5271 - f1_m: 0.6249 - val_loss: 0.0883 - val_acc: 0.9731 - val_precision_m: 0.7412 - val_recall_m: 0.4630 - val_f1_m: 0.5401\n",
      "Epoch 28/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0618 - acc: 0.9785 - precision_m: 0.8214 - recall_m: 0.5154 - f1_m: 0.6141\n",
      "Epoch 28: val_acc did not improve from 0.97373\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0619 - acc: 0.9786 - precision_m: 0.8246 - recall_m: 0.5134 - f1_m: 0.6132 - val_loss: 0.0814 - val_acc: 0.9725 - val_precision_m: 0.7103 - val_recall_m: 0.5429 - val_f1_m: 0.5727\n",
      "Epoch 29/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0606 - acc: 0.9791 - precision_m: 0.8329 - recall_m: 0.5339 - f1_m: 0.6280\n",
      "Epoch 29: val_acc did not improve from 0.97373\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0606 - acc: 0.9790 - precision_m: 0.8300 - recall_m: 0.5361 - f1_m: 0.6283 - val_loss: 0.0831 - val_acc: 0.9726 - val_precision_m: 0.6755 - val_recall_m: 0.6005 - val_f1_m: 0.5959\n",
      "Epoch 30/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9792 - precision_m: 0.8301 - recall_m: 0.5332 - f1_m: 0.6266\n",
      "Epoch 30: val_acc did not improve from 0.97373\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0602 - acc: 0.9792 - precision_m: 0.8290 - recall_m: 0.5311 - f1_m: 0.6248 - val_loss: 0.0810 - val_acc: 0.9729 - val_precision_m: 0.7399 - val_recall_m: 0.4714 - val_f1_m: 0.5437\n",
      "Score for fold 6: loss of 0.08200610429048538; acc of 97.3725438117981%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.08635763078927994; acc of 97.09435105323792%\n",
      "Test Precision: precision_m of 25.636574625968933%\n",
      "Test Recall: recall_m of 21.11676037311554%\n",
      "Test F1: f1_m of 22.12269902229309%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1970 - acc: 0.9556 - precision_m: 0.0023 - recall_m: 0.0083 - f1_m: 0.0031\n",
      "Epoch 1: val_acc improved from -inf to 0.96249, saving model to models/best_model_10_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 3s 5ms/step - loss: 0.1970 - acc: 0.9556 - precision_m: 0.0023 - recall_m: 0.0083 - f1_m: 0.0031 - val_loss: 0.1462 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.1376 - acc: 0.9630 - precision_m: 0.0598 - recall_m: 0.0070 - f1_m: 0.0123\n",
      "Epoch 2: val_acc did not improve from 0.96249\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1377 - acc: 0.9630 - precision_m: 0.0628 - recall_m: 0.0074 - f1_m: 0.0130 - val_loss: 0.1212 - val_acc: 0.9625 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 3/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.1165 - acc: 0.9636 - precision_m: 0.2871 - recall_m: 0.0541 - f1_m: 0.0866\n",
      "Epoch 3: val_acc improved from 0.96249 to 0.96260, saving model to models/best_model_10_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1167 - acc: 0.9635 - precision_m: 0.2918 - recall_m: 0.0548 - f1_m: 0.0880 - val_loss: 0.1109 - val_acc: 0.9626 - val_precision_m: 0.0303 - val_recall_m: 0.0043 - val_f1_m: 0.0076\n",
      "Epoch 4/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.1070 - acc: 0.9643 - precision_m: 0.4897 - recall_m: 0.1061 - f1_m: 0.1635\n",
      "Epoch 4: val_acc improved from 0.96260 to 0.96476, saving model to models/best_model_10_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1066 - acc: 0.9644 - precision_m: 0.4897 - recall_m: 0.1064 - f1_m: 0.1640 - val_loss: 0.1049 - val_acc: 0.9648 - val_precision_m: 0.3694 - val_recall_m: 0.0755 - val_f1_m: 0.1176\n",
      "Epoch 5/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.1021 - acc: 0.9651 - precision_m: 0.5105 - recall_m: 0.1390 - f1_m: 0.2049\n",
      "Epoch 5: val_acc did not improve from 0.96476\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1016 - acc: 0.9652 - precision_m: 0.5155 - recall_m: 0.1407 - f1_m: 0.2075 - val_loss: 0.1069 - val_acc: 0.9646 - val_precision_m: 0.3636 - val_recall_m: 0.0677 - val_f1_m: 0.1054\n",
      "Epoch 6/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0941 - acc: 0.9668 - precision_m: 0.6437 - recall_m: 0.2069 - f1_m: 0.2928\n",
      "Epoch 6: val_acc improved from 0.96476 to 0.96798, saving model to models/best_model_10_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0943 - acc: 0.9667 - precision_m: 0.6385 - recall_m: 0.2061 - f1_m: 0.2915 - val_loss: 0.0975 - val_acc: 0.9680 - val_precision_m: 0.5704 - val_recall_m: 0.2346 - val_f1_m: 0.3051\n",
      "Epoch 7/30\n",
      "278/292 [===========================>..] - ETA: 0s - loss: 0.0923 - acc: 0.9670 - precision_m: 0.6146 - recall_m: 0.2135 - f1_m: 0.2974\n",
      "Epoch 7: val_acc did not improve from 0.96798\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0923 - acc: 0.9670 - precision_m: 0.6203 - recall_m: 0.2118 - f1_m: 0.2964 - val_loss: 0.0995 - val_acc: 0.9679 - val_precision_m: 0.5678 - val_recall_m: 0.3351 - val_f1_m: 0.3884\n",
      "Epoch 8/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0881 - acc: 0.9684 - precision_m: 0.6910 - recall_m: 0.2709 - f1_m: 0.3656\n",
      "Epoch 8: val_acc improved from 0.96798 to 0.97037, saving model to models/best_model_10_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0883 - acc: 0.9685 - precision_m: 0.6946 - recall_m: 0.2704 - f1_m: 0.3657 - val_loss: 0.0917 - val_acc: 0.9704 - val_precision_m: 0.6483 - val_recall_m: 0.3563 - val_f1_m: 0.4269\n",
      "Epoch 9/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0851 - acc: 0.9690 - precision_m: 0.6826 - recall_m: 0.2846 - f1_m: 0.3803\n",
      "Epoch 9: val_acc did not improve from 0.97037\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0854 - acc: 0.9689 - precision_m: 0.6808 - recall_m: 0.2846 - f1_m: 0.3801 - val_loss: 0.0972 - val_acc: 0.9694 - val_precision_m: 0.6783 - val_recall_m: 0.2203 - val_f1_m: 0.3091\n",
      "Epoch 10/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0836 - acc: 0.9695 - precision_m: 0.7072 - recall_m: 0.2994 - f1_m: 0.3985\n",
      "Epoch 10: val_acc did not improve from 0.97037\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0832 - acc: 0.9696 - precision_m: 0.7072 - recall_m: 0.2990 - f1_m: 0.3981 - val_loss: 0.0929 - val_acc: 0.9697 - val_precision_m: 0.6957 - val_recall_m: 0.2413 - val_f1_m: 0.3300\n",
      "Epoch 11/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0800 - acc: 0.9710 - precision_m: 0.7408 - recall_m: 0.3386 - f1_m: 0.4424\n",
      "Epoch 11: val_acc did not improve from 0.97037\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0801 - acc: 0.9709 - precision_m: 0.7383 - recall_m: 0.3412 - f1_m: 0.4432 - val_loss: 0.0947 - val_acc: 0.9703 - val_precision_m: 0.6972 - val_recall_m: 0.2441 - val_f1_m: 0.3360\n",
      "Epoch 12/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0796 - acc: 0.9710 - precision_m: 0.7426 - recall_m: 0.3483 - f1_m: 0.4475\n",
      "Epoch 12: val_acc improved from 0.97037 to 0.97085, saving model to models/best_model_10_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0798 - acc: 0.9710 - precision_m: 0.7430 - recall_m: 0.3481 - f1_m: 0.4475 - val_loss: 0.0862 - val_acc: 0.9708 - val_precision_m: 0.6179 - val_recall_m: 0.4668 - val_f1_m: 0.5053\n",
      "Epoch 13/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0767 - acc: 0.9724 - precision_m: 0.7504 - recall_m: 0.3883 - f1_m: 0.4870\n",
      "Epoch 13: val_acc improved from 0.97085 to 0.97145, saving model to models/best_model_10_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0769 - acc: 0.9723 - precision_m: 0.7524 - recall_m: 0.3889 - f1_m: 0.4880 - val_loss: 0.0859 - val_acc: 0.9714 - val_precision_m: 0.6953 - val_recall_m: 0.3726 - val_f1_m: 0.4552\n",
      "Epoch 14/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0753 - acc: 0.9719 - precision_m: 0.7564 - recall_m: 0.3808 - f1_m: 0.4851\n",
      "Epoch 14: val_acc did not improve from 0.97145\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0752 - acc: 0.9719 - precision_m: 0.7581 - recall_m: 0.3820 - f1_m: 0.4868 - val_loss: 0.0862 - val_acc: 0.9695 - val_precision_m: 0.5933 - val_recall_m: 0.4517 - val_f1_m: 0.4905\n",
      "Epoch 15/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0742 - acc: 0.9723 - precision_m: 0.7419 - recall_m: 0.3814 - f1_m: 0.4822\n",
      "Epoch 15: val_acc did not improve from 0.97145\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0741 - acc: 0.9724 - precision_m: 0.7425 - recall_m: 0.3828 - f1_m: 0.4839 - val_loss: 0.0903 - val_acc: 0.9713 - val_precision_m: 0.7184 - val_recall_m: 0.3471 - val_f1_m: 0.4360\n",
      "Epoch 16/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0725 - acc: 0.9735 - precision_m: 0.7652 - recall_m: 0.4189 - f1_m: 0.5188\n",
      "Epoch 16: val_acc did not improve from 0.97145\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0728 - acc: 0.9735 - precision_m: 0.7644 - recall_m: 0.4180 - f1_m: 0.5183 - val_loss: 0.0835 - val_acc: 0.9710 - val_precision_m: 0.6868 - val_recall_m: 0.3747 - val_f1_m: 0.4483\n",
      "Epoch 17/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0716 - acc: 0.9731 - precision_m: 0.7713 - recall_m: 0.3976 - f1_m: 0.4993\n",
      "Epoch 17: val_acc improved from 0.97145 to 0.97264, saving model to models/best_model_10_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0715 - acc: 0.9731 - precision_m: 0.7712 - recall_m: 0.3968 - f1_m: 0.4987 - val_loss: 0.0835 - val_acc: 0.9726 - val_precision_m: 0.6527 - val_recall_m: 0.4437 - val_f1_m: 0.5018\n",
      "Epoch 18/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0709 - acc: 0.9736 - precision_m: 0.7728 - recall_m: 0.4066 - f1_m: 0.5074\n",
      "Epoch 18: val_acc did not improve from 0.97264\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0708 - acc: 0.9737 - precision_m: 0.7730 - recall_m: 0.4074 - f1_m: 0.5083 - val_loss: 0.0839 - val_acc: 0.9723 - val_precision_m: 0.6927 - val_recall_m: 0.4425 - val_f1_m: 0.5011\n",
      "Epoch 19/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0694 - acc: 0.9738 - precision_m: 0.7798 - recall_m: 0.4176 - f1_m: 0.5213\n",
      "Epoch 19: val_acc improved from 0.97264 to 0.97324, saving model to models/best_model_10_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0695 - acc: 0.9738 - precision_m: 0.7796 - recall_m: 0.4166 - f1_m: 0.5202 - val_loss: 0.0817 - val_acc: 0.9732 - val_precision_m: 0.7128 - val_recall_m: 0.4463 - val_f1_m: 0.5121\n",
      "Epoch 20/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0690 - acc: 0.9741 - precision_m: 0.7651 - recall_m: 0.4267 - f1_m: 0.5250\n",
      "Epoch 20: val_acc did not improve from 0.97324\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0688 - acc: 0.9741 - precision_m: 0.7643 - recall_m: 0.4291 - f1_m: 0.5264 - val_loss: 0.0827 - val_acc: 0.9725 - val_precision_m: 0.6929 - val_recall_m: 0.4376 - val_f1_m: 0.5023\n",
      "Epoch 21/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0677 - acc: 0.9754 - precision_m: 0.7810 - recall_m: 0.4707 - f1_m: 0.5645\n",
      "Epoch 21: val_acc did not improve from 0.97324\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0677 - acc: 0.9754 - precision_m: 0.7820 - recall_m: 0.4715 - f1_m: 0.5655 - val_loss: 0.0829 - val_acc: 0.9717 - val_precision_m: 0.6227 - val_recall_m: 0.4888 - val_f1_m: 0.5257\n",
      "Epoch 22/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0662 - acc: 0.9768 - precision_m: 0.7973 - recall_m: 0.5129 - f1_m: 0.6011\n",
      "Epoch 22: val_acc improved from 0.97324 to 0.97372, saving model to models/best_model_10_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0665 - acc: 0.9766 - precision_m: 0.7955 - recall_m: 0.5069 - f1_m: 0.5959 - val_loss: 0.0839 - val_acc: 0.9737 - val_precision_m: 0.6519 - val_recall_m: 0.5281 - val_f1_m: 0.5553\n",
      "Epoch 23/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0651 - acc: 0.9771 - precision_m: 0.7987 - recall_m: 0.5205 - f1_m: 0.6077\n",
      "Epoch 23: val_acc did not improve from 0.97372\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0648 - acc: 0.9773 - precision_m: 0.8022 - recall_m: 0.5186 - f1_m: 0.6067 - val_loss: 0.0834 - val_acc: 0.9732 - val_precision_m: 0.6821 - val_recall_m: 0.4568 - val_f1_m: 0.5154\n",
      "Epoch 24/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0662 - acc: 0.9770 - precision_m: 0.7947 - recall_m: 0.5144 - f1_m: 0.6025\n",
      "Epoch 24: val_acc did not improve from 0.97372\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0659 - acc: 0.9771 - precision_m: 0.7967 - recall_m: 0.5150 - f1_m: 0.6037 - val_loss: 0.0853 - val_acc: 0.9723 - val_precision_m: 0.7395 - val_recall_m: 0.3616 - val_f1_m: 0.4536\n",
      "Epoch 25/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.0638 - acc: 0.9776 - precision_m: 0.8127 - recall_m: 0.5376 - f1_m: 0.6240\n",
      "Epoch 25: val_acc improved from 0.97372 to 0.97384, saving model to models/best_model_10_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0638 - acc: 0.9776 - precision_m: 0.8125 - recall_m: 0.5375 - f1_m: 0.6239 - val_loss: 0.0822 - val_acc: 0.9738 - val_precision_m: 0.6925 - val_recall_m: 0.5163 - val_f1_m: 0.5579\n",
      "Epoch 26/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0639 - acc: 0.9773 - precision_m: 0.7913 - recall_m: 0.5243 - f1_m: 0.6072\n",
      "Epoch 26: val_acc did not improve from 0.97384\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0639 - acc: 0.9774 - precision_m: 0.7938 - recall_m: 0.5243 - f1_m: 0.6081 - val_loss: 0.0848 - val_acc: 0.9735 - val_precision_m: 0.7455 - val_recall_m: 0.4233 - val_f1_m: 0.5076\n",
      "Epoch 27/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0618 - acc: 0.9780 - precision_m: 0.7962 - recall_m: 0.5584 - f1_m: 0.6359\n",
      "Epoch 27: val_acc did not improve from 0.97384\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0618 - acc: 0.9780 - precision_m: 0.7944 - recall_m: 0.5557 - f1_m: 0.6335 - val_loss: 0.0895 - val_acc: 0.9725 - val_precision_m: 0.7830 - val_recall_m: 0.3447 - val_f1_m: 0.4416\n",
      "Epoch 28/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0621 - acc: 0.9783 - precision_m: 0.8249 - recall_m: 0.5378 - f1_m: 0.6271\n",
      "Epoch 28: val_acc did not improve from 0.97384\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0619 - acc: 0.9783 - precision_m: 0.8256 - recall_m: 0.5393 - f1_m: 0.6287 - val_loss: 0.0846 - val_acc: 0.9722 - val_precision_m: 0.6821 - val_recall_m: 0.3699 - val_f1_m: 0.4501\n",
      "Epoch 29/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.0609 - acc: 0.9787 - precision_m: 0.8201 - recall_m: 0.5457 - f1_m: 0.6334\n",
      "Epoch 29: val_acc did not improve from 0.97384\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0610 - acc: 0.9787 - precision_m: 0.8195 - recall_m: 0.5456 - f1_m: 0.6332 - val_loss: 0.0906 - val_acc: 0.9682 - val_precision_m: 0.5325 - val_recall_m: 0.6175 - val_f1_m: 0.5536\n",
      "Epoch 30/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0598 - acc: 0.9788 - precision_m: 0.8188 - recall_m: 0.5506 - f1_m: 0.6347\n",
      "Epoch 30: val_acc improved from 0.97384 to 0.97527, saving model to models/best_model_10_fold_7.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0599 - acc: 0.9787 - precision_m: 0.8213 - recall_m: 0.5481 - f1_m: 0.6332 - val_loss: 0.0792 - val_acc: 0.9753 - val_precision_m: 0.7326 - val_recall_m: 0.4809 - val_f1_m: 0.5437\n",
      "Score for fold 7: loss of 0.07924289256334305; acc of 97.52688407897949%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.06263136118650436; acc of 97.935551404953%\n",
      "Test Precision: precision_m of 23.417121171951294%\n",
      "Test Recall: recall_m of 17.946740984916687%\n",
      "Test F1: f1_m of 19.022291898727417%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1850 - acc: 0.9592 - precision_m: 0.0027 - recall_m: 0.0034 - f1_m: 0.0019\n",
      "Epoch 1: val_acc improved from -inf to 0.96299, saving model to models/best_model_10_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 3s 5ms/step - loss: 0.1850 - acc: 0.9592 - precision_m: 0.0027 - recall_m: 0.0034 - f1_m: 0.0019 - val_loss: 0.1393 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.1341 - acc: 0.9636 - precision_m: 0.0035 - recall_m: 2.9138e-04 - f1_m: 5.3792e-04   \n",
      "Epoch 2: val_acc did not improve from 0.96299\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1340 - acc: 0.9634 - precision_m: 0.0034 - recall_m: 2.8539e-04 - f1_m: 5.2687e-04 - val_loss: 0.1161 - val_acc: 0.9630 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 3/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.1126 - acc: 0.9635 - precision_m: 0.0631 - recall_m: 0.0090 - f1_m: 0.0150\n",
      "Epoch 3: val_acc improved from 0.96299 to 0.96334, saving model to models/best_model_10_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1124 - acc: 0.9635 - precision_m: 0.0691 - recall_m: 0.0096 - f1_m: 0.0161 - val_loss: 0.1054 - val_acc: 0.9633 - val_precision_m: 0.0909 - val_recall_m: 0.0069 - val_f1_m: 0.0127\n",
      "Epoch 4/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.1019 - acc: 0.9648 - precision_m: 0.3089 - recall_m: 0.0554 - f1_m: 0.0908\n",
      "Epoch 4: val_acc improved from 0.96334 to 0.96358, saving model to models/best_model_10_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1017 - acc: 0.9648 - precision_m: 0.3096 - recall_m: 0.0552 - f1_m: 0.0904 - val_loss: 0.0992 - val_acc: 0.9636 - val_precision_m: 0.1212 - val_recall_m: 0.0129 - val_f1_m: 0.0228\n",
      "Epoch 5/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0955 - acc: 0.9662 - precision_m: 0.5482 - recall_m: 0.1299 - f1_m: 0.1985\n",
      "Epoch 5: val_acc improved from 0.96358 to 0.96718, saving model to models/best_model_10_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0957 - acc: 0.9662 - precision_m: 0.5510 - recall_m: 0.1301 - f1_m: 0.1991 - val_loss: 0.0971 - val_acc: 0.9672 - val_precision_m: 0.4609 - val_recall_m: 0.1330 - val_f1_m: 0.1922\n",
      "Epoch 6/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0927 - acc: 0.9679 - precision_m: 0.6809 - recall_m: 0.2186 - f1_m: 0.3135\n",
      "Epoch 6: val_acc improved from 0.96718 to 0.96778, saving model to models/best_model_10_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0924 - acc: 0.9680 - precision_m: 0.6816 - recall_m: 0.2204 - f1_m: 0.3150 - val_loss: 0.0956 - val_acc: 0.9678 - val_precision_m: 0.6281 - val_recall_m: 0.2138 - val_f1_m: 0.2914\n",
      "Epoch 7/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0906 - acc: 0.9682 - precision_m: 0.6529 - recall_m: 0.2690 - f1_m: 0.3571\n",
      "Epoch 7: val_acc improved from 0.96778 to 0.96993, saving model to models/best_model_10_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0904 - acc: 0.9682 - precision_m: 0.6550 - recall_m: 0.2681 - f1_m: 0.3567 - val_loss: 0.0919 - val_acc: 0.9699 - val_precision_m: 0.5626 - val_recall_m: 0.3403 - val_f1_m: 0.3969\n",
      "Epoch 8/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0872 - acc: 0.9694 - precision_m: 0.6725 - recall_m: 0.2926 - f1_m: 0.3854\n",
      "Epoch 8: val_acc did not improve from 0.96993\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0875 - acc: 0.9693 - precision_m: 0.6762 - recall_m: 0.2919 - f1_m: 0.3850 - val_loss: 0.0908 - val_acc: 0.9699 - val_precision_m: 0.5997 - val_recall_m: 0.2839 - val_f1_m: 0.3519\n",
      "Epoch 9/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0847 - acc: 0.9698 - precision_m: 0.6934 - recall_m: 0.3124 - f1_m: 0.4062\n",
      "Epoch 9: val_acc did not improve from 0.96993\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0848 - acc: 0.9699 - precision_m: 0.6946 - recall_m: 0.3140 - f1_m: 0.4080 - val_loss: 0.0945 - val_acc: 0.9697 - val_precision_m: 0.6142 - val_recall_m: 0.2308 - val_f1_m: 0.3034\n",
      "Epoch 10/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0817 - acc: 0.9711 - precision_m: 0.7241 - recall_m: 0.3514 - f1_m: 0.4457\n",
      "Epoch 10: val_acc did not improve from 0.96993\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0819 - acc: 0.9710 - precision_m: 0.7239 - recall_m: 0.3528 - f1_m: 0.4470 - val_loss: 0.1030 - val_acc: 0.9631 - val_precision_m: 0.4524 - val_recall_m: 0.5152 - val_f1_m: 0.4542\n",
      "Epoch 11/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0806 - acc: 0.9720 - precision_m: 0.7293 - recall_m: 0.3870 - f1_m: 0.4772\n",
      "Epoch 11: val_acc improved from 0.96993 to 0.97125, saving model to models/best_model_10_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0806 - acc: 0.9721 - precision_m: 0.7311 - recall_m: 0.3900 - f1_m: 0.4799 - val_loss: 0.0895 - val_acc: 0.9713 - val_precision_m: 0.6490 - val_recall_m: 0.3090 - val_f1_m: 0.3841\n",
      "Epoch 12/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0771 - acc: 0.9730 - precision_m: 0.7309 - recall_m: 0.4204 - f1_m: 0.5090\n",
      "Epoch 12: val_acc improved from 0.97125 to 0.97161, saving model to models/best_model_10_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0768 - acc: 0.9731 - precision_m: 0.7332 - recall_m: 0.4209 - f1_m: 0.5095 - val_loss: 0.0898 - val_acc: 0.9716 - val_precision_m: 0.6567 - val_recall_m: 0.3211 - val_f1_m: 0.4013\n",
      "Epoch 13/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0749 - acc: 0.9742 - precision_m: 0.7584 - recall_m: 0.4452 - f1_m: 0.5355\n",
      "Epoch 13: val_acc improved from 0.97161 to 0.97305, saving model to models/best_model_10_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0750 - acc: 0.9741 - precision_m: 0.7563 - recall_m: 0.4450 - f1_m: 0.5349 - val_loss: 0.0862 - val_acc: 0.9730 - val_precision_m: 0.6048 - val_recall_m: 0.4813 - val_f1_m: 0.4966\n",
      "Epoch 14/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0741 - acc: 0.9746 - precision_m: 0.7655 - recall_m: 0.4515 - f1_m: 0.5400\n",
      "Epoch 14: val_acc did not improve from 0.97305\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0741 - acc: 0.9744 - precision_m: 0.7626 - recall_m: 0.4489 - f1_m: 0.5373 - val_loss: 0.0868 - val_acc: 0.9714 - val_precision_m: 0.6208 - val_recall_m: 0.3531 - val_f1_m: 0.4163\n",
      "Epoch 15/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0726 - acc: 0.9745 - precision_m: 0.7738 - recall_m: 0.4451 - f1_m: 0.5403\n",
      "Epoch 15: val_acc did not improve from 0.97305\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0727 - acc: 0.9745 - precision_m: 0.7733 - recall_m: 0.4448 - f1_m: 0.5400 - val_loss: 0.0867 - val_acc: 0.9724 - val_precision_m: 0.6505 - val_recall_m: 0.4030 - val_f1_m: 0.4594\n",
      "Epoch 16/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0702 - acc: 0.9756 - precision_m: 0.7667 - recall_m: 0.4780 - f1_m: 0.5672\n",
      "Epoch 16: val_acc did not improve from 0.97305\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0704 - acc: 0.9756 - precision_m: 0.7698 - recall_m: 0.4760 - f1_m: 0.5662 - val_loss: 0.0857 - val_acc: 0.9727 - val_precision_m: 0.6697 - val_recall_m: 0.3623 - val_f1_m: 0.4336\n",
      "Epoch 17/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0700 - acc: 0.9759 - precision_m: 0.7802 - recall_m: 0.4842 - f1_m: 0.5742\n",
      "Epoch 17: val_acc did not improve from 0.97305\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0700 - acc: 0.9759 - precision_m: 0.7784 - recall_m: 0.4831 - f1_m: 0.5728 - val_loss: 0.0916 - val_acc: 0.9707 - val_precision_m: 0.6650 - val_recall_m: 0.2803 - val_f1_m: 0.3590\n",
      "Epoch 18/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0695 - acc: 0.9760 - precision_m: 0.7958 - recall_m: 0.4891 - f1_m: 0.5761\n",
      "Epoch 18: val_acc improved from 0.97305 to 0.97353, saving model to models/best_model_10_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0697 - acc: 0.9760 - precision_m: 0.7933 - recall_m: 0.4911 - f1_m: 0.5769 - val_loss: 0.0841 - val_acc: 0.9735 - val_precision_m: 0.6553 - val_recall_m: 0.4452 - val_f1_m: 0.4935\n",
      "Epoch 19/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0691 - acc: 0.9761 - precision_m: 0.7914 - recall_m: 0.4852 - f1_m: 0.5775\n",
      "Epoch 19: val_acc did not improve from 0.97353\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0691 - acc: 0.9762 - precision_m: 0.7936 - recall_m: 0.4871 - f1_m: 0.5787 - val_loss: 0.0866 - val_acc: 0.9720 - val_precision_m: 0.5992 - val_recall_m: 0.5456 - val_f1_m: 0.5368\n",
      "Epoch 20/30\n",
      "280/292 [===========================>..] - ETA: 0s - loss: 0.0665 - acc: 0.9766 - precision_m: 0.7906 - recall_m: 0.4970 - f1_m: 0.5890\n",
      "Epoch 20: val_acc did not improve from 0.97353\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0669 - acc: 0.9765 - precision_m: 0.7889 - recall_m: 0.4959 - f1_m: 0.5866 - val_loss: 0.0893 - val_acc: 0.9722 - val_precision_m: 0.6534 - val_recall_m: 0.3357 - val_f1_m: 0.4155\n",
      "Epoch 21/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0649 - acc: 0.9775 - precision_m: 0.8056 - recall_m: 0.5137 - f1_m: 0.6043\n",
      "Epoch 21: val_acc improved from 0.97353 to 0.97377, saving model to models/best_model_10_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0650 - acc: 0.9775 - precision_m: 0.8043 - recall_m: 0.5165 - f1_m: 0.6052 - val_loss: 0.0812 - val_acc: 0.9738 - val_precision_m: 0.6208 - val_recall_m: 0.4486 - val_f1_m: 0.4907\n",
      "Epoch 22/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0648 - acc: 0.9777 - precision_m: 0.8093 - recall_m: 0.5305 - f1_m: 0.6178\n",
      "Epoch 22: val_acc did not improve from 0.97377\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0647 - acc: 0.9777 - precision_m: 0.8125 - recall_m: 0.5294 - f1_m: 0.6173 - val_loss: 0.0825 - val_acc: 0.9732 - val_precision_m: 0.6079 - val_recall_m: 0.3924 - val_f1_m: 0.4517\n",
      "Epoch 23/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0645 - acc: 0.9775 - precision_m: 0.8070 - recall_m: 0.5224 - f1_m: 0.6105\n",
      "Epoch 23: val_acc did not improve from 0.97377\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0641 - acc: 0.9776 - precision_m: 0.8089 - recall_m: 0.5227 - f1_m: 0.6112 - val_loss: 0.0917 - val_acc: 0.9730 - val_precision_m: 0.6447 - val_recall_m: 0.3676 - val_f1_m: 0.4379\n",
      "Epoch 24/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0640 - acc: 0.9778 - precision_m: 0.8071 - recall_m: 0.5238 - f1_m: 0.6165\n",
      "Epoch 24: val_acc did not improve from 0.97377\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0641 - acc: 0.9777 - precision_m: 0.8022 - recall_m: 0.5233 - f1_m: 0.6147 - val_loss: 0.0870 - val_acc: 0.9732 - val_precision_m: 0.6493 - val_recall_m: 0.3711 - val_f1_m: 0.4415\n",
      "Epoch 25/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0635 - acc: 0.9780 - precision_m: 0.8062 - recall_m: 0.5262 - f1_m: 0.6139\n",
      "Epoch 25: val_acc did not improve from 0.97377\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0636 - acc: 0.9780 - precision_m: 0.8072 - recall_m: 0.5241 - f1_m: 0.6122 - val_loss: 0.0814 - val_acc: 0.9728 - val_precision_m: 0.6304 - val_recall_m: 0.3810 - val_f1_m: 0.4486\n",
      "Epoch 26/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0610 - acc: 0.9785 - precision_m: 0.8181 - recall_m: 0.5448 - f1_m: 0.6309\n",
      "Epoch 26: val_acc improved from 0.97377 to 0.97413, saving model to models/best_model_10_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0611 - acc: 0.9786 - precision_m: 0.8179 - recall_m: 0.5476 - f1_m: 0.6330 - val_loss: 0.0815 - val_acc: 0.9741 - val_precision_m: 0.6336 - val_recall_m: 0.4958 - val_f1_m: 0.5228\n",
      "Epoch 27/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0621 - acc: 0.9783 - precision_m: 0.8083 - recall_m: 0.5332 - f1_m: 0.6185\n",
      "Epoch 27: val_acc improved from 0.97413 to 0.97437, saving model to models/best_model_10_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0622 - acc: 0.9783 - precision_m: 0.8075 - recall_m: 0.5329 - f1_m: 0.6181 - val_loss: 0.0810 - val_acc: 0.9744 - val_precision_m: 0.6737 - val_recall_m: 0.4529 - val_f1_m: 0.5060\n",
      "Epoch 28/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0598 - acc: 0.9788 - precision_m: 0.8162 - recall_m: 0.5439 - f1_m: 0.6334\n",
      "Epoch 28: val_acc did not improve from 0.97437\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0598 - acc: 0.9788 - precision_m: 0.8129 - recall_m: 0.5425 - f1_m: 0.6310 - val_loss: 0.1064 - val_acc: 0.9701 - val_precision_m: 0.6724 - val_recall_m: 0.2213 - val_f1_m: 0.3125\n",
      "Epoch 29/30\n",
      "282/292 [===========================>..] - ETA: 0s - loss: 0.0591 - acc: 0.9794 - precision_m: 0.8167 - recall_m: 0.5544 - f1_m: 0.6408\n",
      "Epoch 29: val_acc did not improve from 0.97437\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0592 - acc: 0.9794 - precision_m: 0.8181 - recall_m: 0.5542 - f1_m: 0.6405 - val_loss: 0.0840 - val_acc: 0.9728 - val_precision_m: 0.6106 - val_recall_m: 0.5268 - val_f1_m: 0.5389\n",
      "Epoch 30/30\n",
      "277/292 [===========================>..] - ETA: 0s - loss: 0.0592 - acc: 0.9796 - precision_m: 0.8383 - recall_m: 0.5539 - f1_m: 0.6445\n",
      "Epoch 30: val_acc improved from 0.97437 to 0.97520, saving model to models/best_model_10_fold_8.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0592 - acc: 0.9796 - precision_m: 0.8388 - recall_m: 0.5550 - f1_m: 0.6461 - val_loss: 0.0823 - val_acc: 0.9752 - val_precision_m: 0.6733 - val_recall_m: 0.5025 - val_f1_m: 0.5365\n",
      "Score for fold 8: loss of 0.08227130770683289; acc of 97.52036333084106%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.07450316846370697; acc of 97.72098660469055%\n",
      "Test Precision: precision_m of 24.643699824810028%\n",
      "Test Recall: recall_m of 19.135217368602753%\n",
      "Test F1: f1_m of 20.579752326011658%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "Epoch 1/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.1870 - acc: 0.9564 - precision_m: 0.0375 - recall_m: 0.0110 - f1_m: 0.0098\n",
      "Epoch 1: val_acc improved from -inf to 0.96151, saving model to models/best_model_10_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 3s 5ms/step - loss: 0.1870 - acc: 0.9564 - precision_m: 0.0375 - recall_m: 0.0110 - f1_m: 0.0098 - val_loss: 0.1335 - val_acc: 0.9615 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.1258 - acc: 0.9638 - precision_m: 0.3115 - recall_m: 0.0576 - f1_m: 0.0928\n",
      "Epoch 2: val_acc improved from 0.96151 to 0.96199, saving model to models/best_model_10_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.1253 - acc: 0.9639 - precision_m: 0.3099 - recall_m: 0.0568 - f1_m: 0.0916 - val_loss: 0.1175 - val_acc: 0.9620 - val_precision_m: 0.1818 - val_recall_m: 0.0186 - val_f1_m: 0.0336\n",
      "Epoch 3/30\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.1062 - acc: 0.9658 - precision_m: 0.5199 - recall_m: 0.1530 - f1_m: 0.2194\n",
      "Epoch 3: val_acc improved from 0.96199 to 0.96520, saving model to models/best_model_10_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.1062 - acc: 0.9658 - precision_m: 0.5199 - recall_m: 0.1530 - f1_m: 0.2194 - val_loss: 0.0991 - val_acc: 0.9652 - val_precision_m: 0.5444 - val_recall_m: 0.1419 - val_f1_m: 0.2119\n",
      "Epoch 4/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0979 - acc: 0.9675 - precision_m: 0.6163 - recall_m: 0.2321 - f1_m: 0.3155\n",
      "Epoch 4: val_acc improved from 0.96520 to 0.96878, saving model to models/best_model_10_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0979 - acc: 0.9676 - precision_m: 0.6199 - recall_m: 0.2325 - f1_m: 0.3162 - val_loss: 0.0944 - val_acc: 0.9688 - val_precision_m: 0.7578 - val_recall_m: 0.2114 - val_f1_m: 0.3058\n",
      "Epoch 5/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0909 - acc: 0.9694 - precision_m: 0.6534 - recall_m: 0.2853 - f1_m: 0.3741\n",
      "Epoch 5: val_acc did not improve from 0.96878\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0909 - acc: 0.9693 - precision_m: 0.6543 - recall_m: 0.2874 - f1_m: 0.3765 - val_loss: 0.0947 - val_acc: 0.9679 - val_precision_m: 0.5844 - val_recall_m: 0.4238 - val_f1_m: 0.4571\n",
      "Epoch 6/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0889 - acc: 0.9699 - precision_m: 0.6663 - recall_m: 0.2974 - f1_m: 0.3879\n",
      "Epoch 6: val_acc improved from 0.96878 to 0.97128, saving model to models/best_model_10_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0888 - acc: 0.9700 - precision_m: 0.6705 - recall_m: 0.3004 - f1_m: 0.3918 - val_loss: 0.0889 - val_acc: 0.9713 - val_precision_m: 0.6857 - val_recall_m: 0.3209 - val_f1_m: 0.4060\n",
      "Epoch 7/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0853 - acc: 0.9710 - precision_m: 0.6847 - recall_m: 0.3431 - f1_m: 0.4313\n",
      "Epoch 7: val_acc did not improve from 0.97128\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0851 - acc: 0.9710 - precision_m: 0.6858 - recall_m: 0.3446 - f1_m: 0.4322 - val_loss: 0.0906 - val_acc: 0.9707 - val_precision_m: 0.7218 - val_recall_m: 0.2702 - val_f1_m: 0.3691\n",
      "Epoch 8/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0825 - acc: 0.9718 - precision_m: 0.6994 - recall_m: 0.3743 - f1_m: 0.4634\n",
      "Epoch 8: val_acc did not improve from 0.97128\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0825 - acc: 0.9718 - precision_m: 0.6981 - recall_m: 0.3731 - f1_m: 0.4624 - val_loss: 0.0880 - val_acc: 0.9710 - val_precision_m: 0.7245 - val_recall_m: 0.3521 - val_f1_m: 0.4371\n",
      "Epoch 9/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0823 - acc: 0.9722 - precision_m: 0.7290 - recall_m: 0.3796 - f1_m: 0.4703\n",
      "Epoch 9: val_acc did not improve from 0.97128\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0822 - acc: 0.9722 - precision_m: 0.7293 - recall_m: 0.3790 - f1_m: 0.4698 - val_loss: 0.0840 - val_acc: 0.9713 - val_precision_m: 0.6562 - val_recall_m: 0.3738 - val_f1_m: 0.4496\n",
      "Epoch 10/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0801 - acc: 0.9729 - precision_m: 0.7438 - recall_m: 0.3926 - f1_m: 0.4881\n",
      "Epoch 10: val_acc did not improve from 0.97128\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0802 - acc: 0.9729 - precision_m: 0.7386 - recall_m: 0.3911 - f1_m: 0.4859 - val_loss: 0.0906 - val_acc: 0.9696 - val_precision_m: 0.6922 - val_recall_m: 0.2912 - val_f1_m: 0.3825\n",
      "Epoch 11/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0780 - acc: 0.9738 - precision_m: 0.7435 - recall_m: 0.4189 - f1_m: 0.5110\n",
      "Epoch 11: val_acc did not improve from 0.97128\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0780 - acc: 0.9738 - precision_m: 0.7400 - recall_m: 0.4207 - f1_m: 0.5113 - val_loss: 0.0959 - val_acc: 0.9704 - val_precision_m: 0.7289 - val_recall_m: 0.3173 - val_f1_m: 0.4053\n",
      "Epoch 12/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0765 - acc: 0.9742 - precision_m: 0.7526 - recall_m: 0.4204 - f1_m: 0.5124\n",
      "Epoch 12: val_acc improved from 0.97128 to 0.97176, saving model to models/best_model_10_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0768 - acc: 0.9741 - precision_m: 0.7529 - recall_m: 0.4223 - f1_m: 0.5138 - val_loss: 0.0845 - val_acc: 0.9718 - val_precision_m: 0.6449 - val_recall_m: 0.4639 - val_f1_m: 0.5097\n",
      "Epoch 13/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0758 - acc: 0.9739 - precision_m: 0.7578 - recall_m: 0.4118 - f1_m: 0.5083\n",
      "Epoch 13: val_acc did not improve from 0.97176\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0761 - acc: 0.9738 - precision_m: 0.7563 - recall_m: 0.4121 - f1_m: 0.5082 - val_loss: 0.0868 - val_acc: 0.9707 - val_precision_m: 0.5921 - val_recall_m: 0.5619 - val_f1_m: 0.5457\n",
      "Epoch 14/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0751 - acc: 0.9750 - precision_m: 0.7682 - recall_m: 0.4311 - f1_m: 0.5222\n",
      "Epoch 14: val_acc improved from 0.97176 to 0.97319, saving model to models/best_model_10_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0750 - acc: 0.9750 - precision_m: 0.7717 - recall_m: 0.4318 - f1_m: 0.5239 - val_loss: 0.0817 - val_acc: 0.9732 - val_precision_m: 0.6882 - val_recall_m: 0.4684 - val_f1_m: 0.5223\n",
      "Epoch 15/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0738 - acc: 0.9746 - precision_m: 0.7524 - recall_m: 0.4282 - f1_m: 0.5219\n",
      "Epoch 15: val_acc did not improve from 0.97319\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0737 - acc: 0.9746 - precision_m: 0.7529 - recall_m: 0.4276 - f1_m: 0.5216 - val_loss: 0.0973 - val_acc: 0.9702 - val_precision_m: 0.6990 - val_recall_m: 0.2718 - val_f1_m: 0.3646\n",
      "Epoch 16/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0722 - acc: 0.9753 - precision_m: 0.7774 - recall_m: 0.4438 - f1_m: 0.5387\n",
      "Epoch 16: val_acc did not improve from 0.97319\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0722 - acc: 0.9753 - precision_m: 0.7790 - recall_m: 0.4450 - f1_m: 0.5401 - val_loss: 0.0847 - val_acc: 0.9725 - val_precision_m: 0.6941 - val_recall_m: 0.3817 - val_f1_m: 0.4616\n",
      "Epoch 17/30\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.0726 - acc: 0.9751 - precision_m: 0.7713 - recall_m: 0.4421 - f1_m: 0.5369\n",
      "Epoch 17: val_acc did not improve from 0.97319\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0729 - acc: 0.9750 - precision_m: 0.7666 - recall_m: 0.4359 - f1_m: 0.5305 - val_loss: 0.0861 - val_acc: 0.9710 - val_precision_m: 0.6907 - val_recall_m: 0.3202 - val_f1_m: 0.4034\n",
      "Epoch 18/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0710 - acc: 0.9760 - precision_m: 0.7924 - recall_m: 0.4500 - f1_m: 0.5494\n",
      "Epoch 18: val_acc did not improve from 0.97319\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0709 - acc: 0.9760 - precision_m: 0.7943 - recall_m: 0.4509 - f1_m: 0.5507 - val_loss: 0.0881 - val_acc: 0.9701 - val_precision_m: 0.7082 - val_recall_m: 0.3034 - val_f1_m: 0.3875\n",
      "Epoch 19/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0699 - acc: 0.9765 - precision_m: 0.7792 - recall_m: 0.4681 - f1_m: 0.5658\n",
      "Epoch 19: val_acc improved from 0.97319 to 0.97331, saving model to models/best_model_10_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0697 - acc: 0.9766 - precision_m: 0.7801 - recall_m: 0.4689 - f1_m: 0.5666 - val_loss: 0.0839 - val_acc: 0.9733 - val_precision_m: 0.6918 - val_recall_m: 0.4371 - val_f1_m: 0.5024\n",
      "Epoch 20/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0686 - acc: 0.9761 - precision_m: 0.7813 - recall_m: 0.4670 - f1_m: 0.5609\n",
      "Epoch 20: val_acc improved from 0.97331 to 0.97355, saving model to models/best_model_10_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0690 - acc: 0.9760 - precision_m: 0.7838 - recall_m: 0.4640 - f1_m: 0.5590 - val_loss: 0.0836 - val_acc: 0.9735 - val_precision_m: 0.7149 - val_recall_m: 0.4420 - val_f1_m: 0.5147\n",
      "Epoch 21/30\n",
      "287/291 [============================>.] - ETA: 0s - loss: 0.0689 - acc: 0.9764 - precision_m: 0.8029 - recall_m: 0.4593 - f1_m: 0.5598\n",
      "Epoch 21: val_acc did not improve from 0.97355\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0688 - acc: 0.9764 - precision_m: 0.8024 - recall_m: 0.4611 - f1_m: 0.5611 - val_loss: 0.0791 - val_acc: 0.9733 - val_precision_m: 0.7253 - val_recall_m: 0.4197 - val_f1_m: 0.4971\n",
      "Epoch 22/30\n",
      "285/291 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9772 - precision_m: 0.8101 - recall_m: 0.4796 - f1_m: 0.5808\n",
      "Epoch 22: val_acc did not improve from 0.97355\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0682 - acc: 0.9772 - precision_m: 0.8120 - recall_m: 0.4804 - f1_m: 0.5820 - val_loss: 0.0838 - val_acc: 0.9732 - val_precision_m: 0.7279 - val_recall_m: 0.4034 - val_f1_m: 0.4843\n",
      "Epoch 23/30\n",
      "286/291 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 0.9764 - precision_m: 0.8070 - recall_m: 0.4634 - f1_m: 0.5644\n",
      "Epoch 23: val_acc did not improve from 0.97355\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0679 - acc: 0.9764 - precision_m: 0.8081 - recall_m: 0.4623 - f1_m: 0.5634 - val_loss: 0.0851 - val_acc: 0.9726 - val_precision_m: 0.6421 - val_recall_m: 0.5383 - val_f1_m: 0.5548\n",
      "Epoch 24/30\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.0675 - acc: 0.9769 - precision_m: 0.8124 - recall_m: 0.4778 - f1_m: 0.5770\n",
      "Epoch 24: val_acc did not improve from 0.97355\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0676 - acc: 0.9769 - precision_m: 0.8124 - recall_m: 0.4793 - f1_m: 0.5781 - val_loss: 0.0834 - val_acc: 0.9734 - val_precision_m: 0.6147 - val_recall_m: 0.5339 - val_f1_m: 0.5449\n",
      "Epoch 25/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0656 - acc: 0.9775 - precision_m: 0.8056 - recall_m: 0.4931 - f1_m: 0.5893\n",
      "Epoch 25: val_acc did not improve from 0.97355\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0659 - acc: 0.9773 - precision_m: 0.8031 - recall_m: 0.4898 - f1_m: 0.5863 - val_loss: 0.0914 - val_acc: 0.9722 - val_precision_m: 0.7273 - val_recall_m: 0.3734 - val_f1_m: 0.4573\n",
      "Epoch 26/30\n",
      "284/291 [============================>.] - ETA: 0s - loss: 0.0650 - acc: 0.9778 - precision_m: 0.8042 - recall_m: 0.5080 - f1_m: 0.6026\n",
      "Epoch 26: val_acc improved from 0.97355 to 0.97367, saving model to models/best_model_10_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0650 - acc: 0.9778 - precision_m: 0.8079 - recall_m: 0.5070 - f1_m: 0.6029 - val_loss: 0.0817 - val_acc: 0.9737 - val_precision_m: 0.6956 - val_recall_m: 0.4628 - val_f1_m: 0.5217\n",
      "Epoch 27/30\n",
      "288/291 [============================>.] - ETA: 0s - loss: 0.0657 - acc: 0.9772 - precision_m: 0.7969 - recall_m: 0.4830 - f1_m: 0.5792\n",
      "Epoch 27: val_acc improved from 0.97367 to 0.97402, saving model to models/best_model_10_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0659 - acc: 0.9771 - precision_m: 0.7944 - recall_m: 0.4838 - f1_m: 0.5788 - val_loss: 0.0834 - val_acc: 0.9740 - val_precision_m: 0.6925 - val_recall_m: 0.4558 - val_f1_m: 0.5190\n",
      "Epoch 28/30\n",
      "290/291 [============================>.] - ETA: 0s - loss: 0.0636 - acc: 0.9786 - precision_m: 0.8202 - recall_m: 0.5160 - f1_m: 0.6122\n",
      "Epoch 28: val_acc did not improve from 0.97402\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0636 - acc: 0.9785 - precision_m: 0.8191 - recall_m: 0.5153 - f1_m: 0.6114 - val_loss: 0.0957 - val_acc: 0.9722 - val_precision_m: 0.7860 - val_recall_m: 0.3268 - val_f1_m: 0.4308\n",
      "Epoch 29/30\n",
      "281/291 [===========================>..] - ETA: 0s - loss: 0.0645 - acc: 0.9774 - precision_m: 0.8141 - recall_m: 0.4816 - f1_m: 0.5798\n",
      "Epoch 29: val_acc improved from 0.97402 to 0.97438, saving model to models/best_model_10_fold_9.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0642 - acc: 0.9774 - precision_m: 0.8150 - recall_m: 0.4847 - f1_m: 0.5830 - val_loss: 0.0830 - val_acc: 0.9744 - val_precision_m: 0.6776 - val_recall_m: 0.5196 - val_f1_m: 0.5568\n",
      "Epoch 30/30\n",
      "282/291 [============================>.] - ETA: 0s - loss: 0.0624 - acc: 0.9789 - precision_m: 0.8174 - recall_m: 0.5256 - f1_m: 0.6223\n",
      "Epoch 30: val_acc did not improve from 0.97438\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.0624 - acc: 0.9789 - precision_m: 0.8185 - recall_m: 0.5272 - f1_m: 0.6236 - val_loss: 0.0875 - val_acc: 0.9731 - val_precision_m: 0.6757 - val_recall_m: 0.4511 - val_f1_m: 0.5105\n",
      "Score for fold 9: loss of 0.08300593495368958; acc of 97.4380373954773%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.07600522041320801; acc of 97.5094735622406%\n",
      "Test Precision: precision_m of 26.26517415046692%\n",
      "Test Recall: recall_m of 21.599659323692322%\n",
      "Test F1: f1_m of 22.738616168498993%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.1791 - acc: 0.9603 - precision_m: 7.8461e-04 - recall_m: 0.0029 - f1_m: 0.0012\n",
      "Epoch 1: val_acc improved from -inf to 0.96034, saving model to models/best_model_10_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 3s 5ms/step - loss: 0.1791 - acc: 0.9603 - precision_m: 7.8461e-04 - recall_m: 0.0029 - f1_m: 0.0012 - val_loss: 0.1450 - val_acc: 0.9603 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1225 - acc: 0.9652 - precision_m: 0.3784 - recall_m: 0.0785 - f1_m: 0.1227\n",
      "Epoch 2: val_acc improved from 0.96034 to 0.96238, saving model to models/best_model_10_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1220 - acc: 0.9654 - precision_m: 0.3813 - recall_m: 0.0799 - f1_m: 0.1248 - val_loss: 0.1214 - val_acc: 0.9624 - val_precision_m: 0.2525 - val_recall_m: 0.0690 - val_f1_m: 0.1026\n",
      "Epoch 3/30\n",
      "289/292 [============================>.] - ETA: 0s - loss: 0.1055 - acc: 0.9663 - precision_m: 0.5100 - recall_m: 0.1572 - f1_m: 0.2274\n",
      "Epoch 3: val_acc improved from 0.96238 to 0.96418, saving model to models/best_model_10_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.1054 - acc: 0.9664 - precision_m: 0.5097 - recall_m: 0.1585 - f1_m: 0.2287 - val_loss: 0.1095 - val_acc: 0.9642 - val_precision_m: 0.4167 - val_recall_m: 0.1126 - val_f1_m: 0.1699\n",
      "Epoch 4/30\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.0957 - acc: 0.9696 - precision_m: 0.6888 - recall_m: 0.2830 - f1_m: 0.3755\n",
      "Epoch 4: val_acc improved from 0.96418 to 0.96611, saving model to models/best_model_10_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0957 - acc: 0.9696 - precision_m: 0.6888 - recall_m: 0.2830 - f1_m: 0.3755 - val_loss: 0.1018 - val_acc: 0.9661 - val_precision_m: 0.5225 - val_recall_m: 0.2276 - val_f1_m: 0.2929\n",
      "Epoch 5/30\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.0901 - acc: 0.9711 - precision_m: 0.6903 - recall_m: 0.3313 - f1_m: 0.4244\n",
      "Epoch 5: val_acc improved from 0.96611 to 0.96695, saving model to models/best_model_10_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0901 - acc: 0.9710 - precision_m: 0.6891 - recall_m: 0.3305 - f1_m: 0.4236 - val_loss: 0.0968 - val_acc: 0.9669 - val_precision_m: 0.6878 - val_recall_m: 0.3259 - val_f1_m: 0.4083\n",
      "Epoch 6/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0872 - acc: 0.9717 - precision_m: 0.7107 - recall_m: 0.3553 - f1_m: 0.4473\n",
      "Epoch 6: val_acc improved from 0.96695 to 0.96887, saving model to models/best_model_10_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0871 - acc: 0.9717 - precision_m: 0.7126 - recall_m: 0.3564 - f1_m: 0.4489 - val_loss: 0.0937 - val_acc: 0.9689 - val_precision_m: 0.7105 - val_recall_m: 0.3762 - val_f1_m: 0.4589\n",
      "Epoch 7/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0849 - acc: 0.9723 - precision_m: 0.7140 - recall_m: 0.3794 - f1_m: 0.4646\n",
      "Epoch 7: val_acc improved from 0.96887 to 0.96923, saving model to models/best_model_10_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0846 - acc: 0.9724 - precision_m: 0.7160 - recall_m: 0.3803 - f1_m: 0.4661 - val_loss: 0.0959 - val_acc: 0.9692 - val_precision_m: 0.7424 - val_recall_m: 0.2976 - val_f1_m: 0.3923\n",
      "Epoch 8/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0810 - acc: 0.9738 - precision_m: 0.7370 - recall_m: 0.4246 - f1_m: 0.5136\n",
      "Epoch 8: val_acc improved from 0.96923 to 0.96935, saving model to models/best_model_10_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0809 - acc: 0.9737 - precision_m: 0.7334 - recall_m: 0.4226 - f1_m: 0.5116 - val_loss: 0.0966 - val_acc: 0.9694 - val_precision_m: 0.7727 - val_recall_m: 0.2838 - val_f1_m: 0.3885\n",
      "Epoch 9/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0807 - acc: 0.9733 - precision_m: 0.7296 - recall_m: 0.4133 - f1_m: 0.4970\n",
      "Epoch 9: val_acc improved from 0.96935 to 0.97019, saving model to models/best_model_10_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0807 - acc: 0.9733 - precision_m: 0.7285 - recall_m: 0.4133 - f1_m: 0.4965 - val_loss: 0.0901 - val_acc: 0.9702 - val_precision_m: 0.6941 - val_recall_m: 0.4720 - val_f1_m: 0.5238\n",
      "Epoch 10/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0782 - acc: 0.9753 - precision_m: 0.7738 - recall_m: 0.4463 - f1_m: 0.5424\n",
      "Epoch 10: val_acc improved from 0.97019 to 0.97043, saving model to models/best_model_10_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0780 - acc: 0.9752 - precision_m: 0.7717 - recall_m: 0.4460 - f1_m: 0.5419 - val_loss: 0.0928 - val_acc: 0.9704 - val_precision_m: 0.7987 - val_recall_m: 0.3785 - val_f1_m: 0.4783\n",
      "Epoch 11/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0759 - acc: 0.9754 - precision_m: 0.7735 - recall_m: 0.4413 - f1_m: 0.5409\n",
      "Epoch 11: val_acc did not improve from 0.97043\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0755 - acc: 0.9755 - precision_m: 0.7733 - recall_m: 0.4433 - f1_m: 0.5415 - val_loss: 0.1059 - val_acc: 0.9696 - val_precision_m: 0.7852 - val_recall_m: 0.2990 - val_f1_m: 0.4064\n",
      "Epoch 12/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0743 - acc: 0.9759 - precision_m: 0.7928 - recall_m: 0.4456 - f1_m: 0.5435\n",
      "Epoch 12: val_acc improved from 0.97043 to 0.97115, saving model to models/best_model_10_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0745 - acc: 0.9757 - precision_m: 0.7923 - recall_m: 0.4427 - f1_m: 0.5412 - val_loss: 0.0907 - val_acc: 0.9712 - val_precision_m: 0.6803 - val_recall_m: 0.5479 - val_f1_m: 0.5762\n",
      "Epoch 13/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0733 - acc: 0.9756 - precision_m: 0.7827 - recall_m: 0.4520 - f1_m: 0.5476\n",
      "Epoch 13: val_acc improved from 0.97115 to 0.97127, saving model to models/best_model_10_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0732 - acc: 0.9756 - precision_m: 0.7768 - recall_m: 0.4501 - f1_m: 0.5448 - val_loss: 0.0971 - val_acc: 0.9713 - val_precision_m: 0.8188 - val_recall_m: 0.3793 - val_f1_m: 0.4847\n",
      "Epoch 14/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9765 - precision_m: 0.7909 - recall_m: 0.4694 - f1_m: 0.5686\n",
      "Epoch 14: val_acc did not improve from 0.97127\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0705 - acc: 0.9765 - precision_m: 0.7921 - recall_m: 0.4699 - f1_m: 0.5692 - val_loss: 0.0926 - val_acc: 0.9703 - val_precision_m: 0.6653 - val_recall_m: 0.5268 - val_f1_m: 0.5516\n",
      "Epoch 15/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0699 - acc: 0.9766 - precision_m: 0.7987 - recall_m: 0.4794 - f1_m: 0.5754\n",
      "Epoch 15: val_acc did not improve from 0.97127\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0698 - acc: 0.9766 - precision_m: 0.7986 - recall_m: 0.4838 - f1_m: 0.5786 - val_loss: 0.0891 - val_acc: 0.9706 - val_precision_m: 0.6330 - val_recall_m: 0.6139 - val_f1_m: 0.5998\n",
      "Epoch 16/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0683 - acc: 0.9772 - precision_m: 0.7958 - recall_m: 0.4988 - f1_m: 0.5906\n",
      "Epoch 16: val_acc improved from 0.97127 to 0.97296, saving model to models/best_model_10_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0684 - acc: 0.9772 - precision_m: 0.7945 - recall_m: 0.4971 - f1_m: 0.5886 - val_loss: 0.0872 - val_acc: 0.9730 - val_precision_m: 0.7185 - val_recall_m: 0.5494 - val_f1_m: 0.5872\n",
      "Epoch 17/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0665 - acc: 0.9773 - precision_m: 0.7881 - recall_m: 0.5015 - f1_m: 0.5930\n",
      "Epoch 17: val_acc improved from 0.97296 to 0.97344, saving model to models/best_model_10_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0667 - acc: 0.9772 - precision_m: 0.7886 - recall_m: 0.5003 - f1_m: 0.5919 - val_loss: 0.0873 - val_acc: 0.9734 - val_precision_m: 0.8402 - val_recall_m: 0.4495 - val_f1_m: 0.5475\n",
      "Epoch 18/30\n",
      "288/292 [============================>.] - ETA: 0s - loss: 0.0664 - acc: 0.9773 - precision_m: 0.8077 - recall_m: 0.4912 - f1_m: 0.5863\n",
      "Epoch 18: val_acc did not improve from 0.97344\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0664 - acc: 0.9773 - precision_m: 0.8072 - recall_m: 0.4898 - f1_m: 0.5847 - val_loss: 0.0929 - val_acc: 0.9712 - val_precision_m: 0.8274 - val_recall_m: 0.3262 - val_f1_m: 0.4395\n",
      "Epoch 19/30\n",
      "290/292 [============================>.] - ETA: 0s - loss: 0.0657 - acc: 0.9776 - precision_m: 0.8035 - recall_m: 0.4966 - f1_m: 0.5897\n",
      "Epoch 19: val_acc improved from 0.97344 to 0.97392, saving model to models/best_model_10_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0657 - acc: 0.9776 - precision_m: 0.8033 - recall_m: 0.4966 - f1_m: 0.5895 - val_loss: 0.0863 - val_acc: 0.9739 - val_precision_m: 0.8004 - val_recall_m: 0.4756 - val_f1_m: 0.5660\n",
      "Epoch 20/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0641 - acc: 0.9779 - precision_m: 0.8057 - recall_m: 0.5114 - f1_m: 0.6020\n",
      "Epoch 20: val_acc improved from 0.97392 to 0.97440, saving model to models/best_model_10_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0639 - acc: 0.9779 - precision_m: 0.8050 - recall_m: 0.5121 - f1_m: 0.6027 - val_loss: 0.0871 - val_acc: 0.9744 - val_precision_m: 0.8040 - val_recall_m: 0.4825 - val_f1_m: 0.5632\n",
      "Epoch 21/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0627 - acc: 0.9785 - precision_m: 0.8069 - recall_m: 0.5334 - f1_m: 0.6234\n",
      "Epoch 21: val_acc did not improve from 0.97440\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0628 - acc: 0.9784 - precision_m: 0.8063 - recall_m: 0.5360 - f1_m: 0.6248 - val_loss: 0.0989 - val_acc: 0.9719 - val_precision_m: 0.8704 - val_recall_m: 0.3753 - val_f1_m: 0.4912\n",
      "Epoch 22/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9782 - precision_m: 0.8046 - recall_m: 0.5166 - f1_m: 0.6049\n",
      "Epoch 22: val_acc did not improve from 0.97440\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0635 - acc: 0.9782 - precision_m: 0.8066 - recall_m: 0.5179 - f1_m: 0.6066 - val_loss: 0.0884 - val_acc: 0.9733 - val_precision_m: 0.8352 - val_recall_m: 0.4077 - val_f1_m: 0.5157\n",
      "Epoch 23/30\n",
      "287/292 [============================>.] - ETA: 0s - loss: 0.0606 - acc: 0.9793 - precision_m: 0.8181 - recall_m: 0.5408 - f1_m: 0.6295\n",
      "Epoch 23: val_acc did not improve from 0.97440\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0607 - acc: 0.9793 - precision_m: 0.8176 - recall_m: 0.5406 - f1_m: 0.6290 - val_loss: 0.0890 - val_acc: 0.9740 - val_precision_m: 0.8477 - val_recall_m: 0.4534 - val_f1_m: 0.5510\n",
      "Epoch 24/30\n",
      "283/292 [============================>.] - ETA: 0s - loss: 0.0599 - acc: 0.9797 - precision_m: 0.8375 - recall_m: 0.5512 - f1_m: 0.6423\n",
      "Epoch 24: val_acc did not improve from 0.97440\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0600 - acc: 0.9797 - precision_m: 0.8325 - recall_m: 0.5515 - f1_m: 0.6406 - val_loss: 0.0990 - val_acc: 0.9718 - val_precision_m: 0.8295 - val_recall_m: 0.3694 - val_f1_m: 0.4839\n",
      "Epoch 25/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0610 - acc: 0.9793 - precision_m: 0.8369 - recall_m: 0.5368 - f1_m: 0.6297\n",
      "Epoch 25: val_acc did not improve from 0.97440\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0610 - acc: 0.9792 - precision_m: 0.8362 - recall_m: 0.5380 - f1_m: 0.6305 - val_loss: 0.0899 - val_acc: 0.9736 - val_precision_m: 0.7720 - val_recall_m: 0.4765 - val_f1_m: 0.5594\n",
      "Epoch 26/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0605 - acc: 0.9790 - precision_m: 0.8191 - recall_m: 0.5416 - f1_m: 0.6278\n",
      "Epoch 26: val_acc improved from 0.97440 to 0.97524, saving model to models/best_model_10_fold_10.h5\n",
      "----------------------------------------------------------------------------\n",
      "NAJBOLJA METRIKA\n",
      "----------------------------------------------------------------------------\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0605 - acc: 0.9790 - precision_m: 0.8204 - recall_m: 0.5427 - f1_m: 0.6290 - val_loss: 0.0866 - val_acc: 0.9752 - val_precision_m: 0.8264 - val_recall_m: 0.4831 - val_f1_m: 0.5783\n",
      "Epoch 27/30\n",
      "286/292 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9799 - precision_m: 0.8293 - recall_m: 0.5558 - f1_m: 0.6402\n",
      "Epoch 27: val_acc did not improve from 0.97524\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0591 - acc: 0.9799 - precision_m: 0.8272 - recall_m: 0.5569 - f1_m: 0.6404 - val_loss: 0.0861 - val_acc: 0.9736 - val_precision_m: 0.7155 - val_recall_m: 0.5416 - val_f1_m: 0.5830\n",
      "Epoch 28/30\n",
      "284/292 [============================>.] - ETA: 0s - loss: 0.0581 - acc: 0.9800 - precision_m: 0.8199 - recall_m: 0.5588 - f1_m: 0.6449\n",
      "Epoch 28: val_acc did not improve from 0.97524\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0581 - acc: 0.9800 - precision_m: 0.8205 - recall_m: 0.5589 - f1_m: 0.6452 - val_loss: 0.0887 - val_acc: 0.9738 - val_precision_m: 0.8230 - val_recall_m: 0.4331 - val_f1_m: 0.5403\n",
      "Epoch 29/30\n",
      "281/292 [===========================>..] - ETA: 0s - loss: 0.0565 - acc: 0.9806 - precision_m: 0.8541 - recall_m: 0.5621 - f1_m: 0.6550\n",
      "Epoch 29: val_acc did not improve from 0.97524\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0566 - acc: 0.9806 - precision_m: 0.8512 - recall_m: 0.5653 - f1_m: 0.6567 - val_loss: 0.1016 - val_acc: 0.9740 - val_precision_m: 0.8655 - val_recall_m: 0.4244 - val_f1_m: 0.5418\n",
      "Epoch 30/30\n",
      "285/292 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9805 - precision_m: 0.8384 - recall_m: 0.5795 - f1_m: 0.6602\n",
      "Epoch 30: val_acc did not improve from 0.97524\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.0574 - acc: 0.9805 - precision_m: 0.8373 - recall_m: 0.5785 - f1_m: 0.6596 - val_loss: 0.0946 - val_acc: 0.9725 - val_precision_m: 0.8400 - val_recall_m: 0.3735 - val_f1_m: 0.4882\n",
      "Score for fold 10: loss of 0.08660221099853516; acc of 97.5240409374237%\n",
      "------------------------------------------------------------------------\n",
      "Final test score: loss of 0.073390893638134; acc of 97.60623574256897%\n",
      "Test Precision: precision_m of 29.116958379745483%\n",
      "Test Recall: recall_m of 22.598300874233246%\n",
      "Test F1: f1_m of 24.40764307975769%\n",
      "------------------------------------------------------------------------\n",
      "Validation score per fold\n",
      "> Fold 1 - Loss: 0.08767911046743393 - Accuracy: 97.40833640098572%\n",
      "> Fold 2 - Loss: 0.08707863092422485 - Accuracy: 97.5691556930542%\n",
      "> Fold 3 - Loss: 0.07068116217851639 - Accuracy: 97.71202802658081%\n",
      "> Fold 4 - Loss: 0.08899437636137009 - Accuracy: 97.42089509963989%\n",
      "> Fold 5 - Loss: 0.08144097775220871 - Accuracy: 97.52599596977234%\n",
      "> Fold 6 - Loss: 0.08200610429048538 - Accuracy: 97.3725438117981%\n",
      "> Fold 7 - Loss: 0.07924289256334305 - Accuracy: 97.52688407897949%\n",
      "> Fold 8 - Loss: 0.08227130770683289 - Accuracy: 97.52036333084106%\n",
      "> Fold 9 - Loss: 0.08300593495368958 - Accuracy: 97.4380373954773%\n",
      "> Fold 10 - Loss: 0.08660221099853516 - Accuracy: 97.5240409374237%\n",
      "------------------------------------------------------------------------\n",
      "Testing score per fold\n",
      "> Fold 1 - Accuracy: 97.96389937400818 - Precision: 20.152580738067627 - Recall: 14.676252007484436 - F1: 16.206814348697662%\n",
      "> Fold 2 - Accuracy: 97.39354252815247 - Precision: 27.799251675605774 - Recall: 21.618828177452087 - F1: 23.25579524040222%\n",
      "> Fold 3 - Accuracy: 97.76048064231873 - Precision: 25.577422976493835 - Recall: 22.26392775774002 - F1: 22.62873202562332%\n",
      "> Fold 4 - Accuracy: 97.08968997001648 - Precision: 25.565168261528015 - Recall: 17.845584452152252 - F1: 19.894495606422424%\n",
      "> Fold 5 - Accuracy: 97.51228094100952 - Precision: 28.04323136806488 - Recall: 22.05350250005722 - F1: 23.677964508533478%\n",
      "> Fold 6 - Accuracy: 97.09435105323792 - Precision: 25.636574625968933 - Recall: 21.11676037311554 - F1: 22.12269902229309%\n",
      "> Fold 7 - Accuracy: 97.935551404953 - Precision: 23.417121171951294 - Recall: 17.946740984916687 - F1: 19.022291898727417%\n",
      "> Fold 8 - Accuracy: 97.72098660469055 - Precision: 24.643699824810028 - Recall: 19.135217368602753 - F1: 20.579752326011658%\n",
      "> Fold 9 - Accuracy: 97.5094735622406 - Precision: 26.26517415046692 - Recall: 21.599659323692322 - F1: 22.738616168498993%\n",
      "> Fold 10 - Accuracy: 97.60623574256897 - Precision: 29.116958379745483 - Recall: 22.598300874233246 - F1: 24.40764307975769%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Validation Accuracy: 97.50182807445526 (+- 0.0931881947206742)\n",
      "> Validation Loss: 0.082900270819664\n",
      "> Testing Accuracy: 97.55864918231964 (+- 0.2903378754294288)\n",
      "> Testing Precision: 25.62171831727028\n",
      "> Testing Recall: 20.085477381944656\n",
      "> Testing F1: 21.453480422496796\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Lists to hold cross-validation results\n",
    "acc_10_per_fold = []\n",
    "loss_10_per_fold = []\n",
    "precision_10_per_fold = []\n",
    "recall_10_per_fold = []\n",
    "f1_10_per_fold = []\n",
    "\n",
    "testing_acc_10_per_fold = []\n",
    "testing_precision_10_per_fold = []\n",
    "testing_recall_10_per_fold = []\n",
    "testing_f1_10_per_fold = []\n",
    "\n",
    "# Load data from .npz files\n",
    "for fold_no in range(1, 11):\n",
    "    with np.load(f'fold_{fold_no}.npz') as data:\n",
    "        x_train = data['x_train_fold.npy']\n",
    "        y_train = data['y_train_fold.npy']\n",
    "        x_val = data['x_val_fold.npy']\n",
    "        y_val = data['y_val_fold.npy']\n",
    "        x_test = data['x_test_fold.npy']\n",
    "        y_test = data['y_test_fold.npy']\n",
    "        \n",
    "        # Converting ground truth arrays to one wake word (1) and 'other' (0)\n",
    "        wake_word_index = all_targets.index(wake_word)\n",
    "        y_train = np.equal(y_train, wake_word_index).astype('float64')\n",
    "        y_val = np.equal(y_val, wake_word_index).astype('float64')\n",
    "        y_test = np.equal(y_test, wake_word_index).astype('float64')\n",
    "        \n",
    "        # CNN for TF expects (batch, height, width, channels)\n",
    "        x_train = x_train.reshape(x_train.shape[0], \n",
    "                          x_train.shape[1], \n",
    "                          x_train.shape[2], \n",
    "                          1)\n",
    "        x_val = x_val.reshape(x_val.shape[0], \n",
    "                          x_val.shape[1], \n",
    "                          x_val.shape[2], \n",
    "                          1)\n",
    "        x_test = x_test.reshape(x_test.shape[0], \n",
    "                          x_test.shape[1], \n",
    "                          x_test.shape[2], \n",
    "                          1)\n",
    "        sample_shape = x_test.shape[1:]\n",
    "\n",
    "    # CNN model\n",
    "    model_10 = models.Sequential()\n",
    "    model_10.add(layers.Conv2D(8, \n",
    "                            (4, 4), \n",
    "                            activation='relu',\n",
    "                            input_shape=sample_shape))\n",
    "    model_10.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model_10.add(layers.Conv2D(32, (2, 2), activation='relu'))\n",
    "    model_10.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model_10.add(layers.Conv2D(32, (1, 1), activation='relu'))\n",
    "    model_10.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Classifier\n",
    "    model_10.add(layers.Flatten())\n",
    "    model_10.add(layers.Dense(32, activation='relu'))\n",
    "    model_10.add(layers.Dropout(0.5))\n",
    "    model_10.add(layers.Dense(1, activation='sigmoid'))\n",
    "    # Compile the model\n",
    "\n",
    "    model_10.compile(loss='binary_crossentropy', \n",
    "              optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "              metrics=['acc', precision_m, recall_m, f1_m])\n",
    "\n",
    "    checkpoint_filepath = f'models/best_model_10_fold_{fold_no}.h5'\n",
    "    model_checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=False,\n",
    "        monitor='val_acc',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "        save_freq='epoch'\n",
    "    )\n",
    "\n",
    "    # Instantiate the custom callback\n",
    "    metrics_history = MetricsHistory()\n",
    "\n",
    "    # Print fold number\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Train\n",
    "    history_10 = model_10.fit(x_train, \n",
    "                    y_train, \n",
    "                    epochs=30, \n",
    "                    batch_size=256, \n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[model_checkpoint_callback, metrics_history])\n",
    "\n",
    "    model_10.load_weights(checkpoint_filepath)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    scores = model_10.evaluate(x_val, y_val, verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model_10.metrics_names[0]} of {scores[0]}; {model_10.metrics_names[1]} of {scores[1] * 100}%')\n",
    "    acc_10_per_fold.append(scores[1] * 100)\n",
    "    loss_10_per_fold.append(scores[0])\n",
    "    precision_10_per_fold.append(metrics_history.best_metrics['precision_m'] * 100)\n",
    "    recall_10_per_fold.append(metrics_history.best_metrics['recall_m'] * 100)\n",
    "    f1_10_per_fold.append(metrics_history.best_metrics['f1_m'] * 100)\n",
    "\n",
    "    # Final evaluation on test set\n",
    "    final_scores = model_10.evaluate(x_test, y_test, verbose=0)\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Final test score: {model_10.metrics_names[0]} of {final_scores[0]}; {model_10.metrics_names[1]} of {final_scores[1] * 100}%')\n",
    "    print(f'Test Precision: {model_10.metrics_names[2]} of {final_scores[2] * 100}%')\n",
    "    print(f'Test Recall: {model_10.metrics_names[3]} of {final_scores[3] * 100}%')\n",
    "    print(f'Test F1: {model_10.metrics_names[4]} of {final_scores[4] * 100}%')\n",
    "\n",
    "    # Append test metrics to lists\n",
    "    testing_acc_10_per_fold.append(final_scores[1] * 100)\n",
    "    testing_precision_10_per_fold.append(final_scores[2] * 100)\n",
    "    testing_recall_10_per_fold.append(final_scores[3] * 100)\n",
    "    testing_f1_10_per_fold.append(final_scores[4] * 100)\n",
    "\n",
    "# Print the results\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Validation score per fold')\n",
    "for i in range(0, len(acc_10_per_fold)):\n",
    "    print(f'> Fold {i+1} - Loss: {loss_10_per_fold[i]} - Accuracy: {acc_10_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Testing score per fold')\n",
    "for i in range(0, len(testing_acc_10_per_fold)):\n",
    "    print(f'> Fold {i+1} - Accuracy: {testing_acc_10_per_fold[i]} - Precision: {testing_precision_10_per_fold[i]} - Recall: {testing_recall_10_per_fold[i]} - F1: {testing_f1_10_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Validation Accuracy: {np.mean(acc_10_per_fold)} (+- {np.std(acc_10_per_fold)})')\n",
    "print(f'> Validation Loss: {np.mean(loss_10_per_fold)}')\n",
    "print(f'> Testing Accuracy: {np.mean(testing_acc_10_per_fold)} (+- {np.std(testing_acc_10_per_fold)})')\n",
    "print(f'> Testing Precision: {np.mean(testing_precision_10_per_fold)}')\n",
    "print(f'> Testing Recall: {np.mean(testing_recall_10_per_fold)}')\n",
    "print(f'> Testing F1: {np.mean(testing_f1_10_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model\n",
    "model_1 = models.Sequential()\n",
    "model_1.add(layers.Conv2D(32, \n",
    "                        (2, 2), \n",
    "                        activation='relu',\n",
    "                        input_shape=sample_shape))\n",
    "model_1.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model_1.add(layers.Conv2D(32, (2, 2), activation='relu'))\n",
    "model_1.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model_1.add(layers.Conv2D(64, (2, 2), activation='relu'))\n",
    "model_1.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Classifier\n",
    "model_1.add(layers.Flatten())\n",
    "model_1.add(layers.Dense(64, activation='relu'))\n",
    "model_1.add(layers.Dropout(0.5))\n",
    "model_1.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = models.Sequential()\n",
    "model_2.add(layers.Conv2D(16,\n",
    "                          (3,3),\n",
    "                          activation=\"relu\",\n",
    "                          input_shape=sample_shape))\n",
    "model_2.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model_2.add(layers.Conv2D(32,\n",
    "                          (3,3),\n",
    "                          activation=\"relu\",\n",
    "                          ))\n",
    "model_2.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model_2.add(layers.Flatten())\n",
    "model_2.add(layers.Dense(32, activation='relu'))\n",
    "model_2.add(layers.Dropout(0.5))\n",
    "model_2.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = models.Sequential()\n",
    "model_3.add(layers.Conv2D(16,\n",
    "                          (3,3),\n",
    "                          activation=\"relu\",\n",
    "                          input_shape=sample_shape))\n",
    "model_3.add(layers.MaxPooling2D(pool_size=(8, 8)))\n",
    "\n",
    "model_3.add(layers.Flatten())\n",
    "model_3.add(layers.Dense(16, activation='relu'))\n",
    "model_3.add(layers.Dropout(0.3))\n",
    "model_3.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = models.Sequential()\n",
    "model_4.add(layers.Conv2D(64,\n",
    "                          (5,5),\n",
    "                          activation=\"relu\",\n",
    "                          input_shape=sample_shape))\n",
    "model_4.add(layers.MaxPooling2D(pool_size=(5, 5)))\n",
    "\n",
    "model_4.add(layers.Flatten())\n",
    "model_4.add(layers.Dense(32, activation='relu'))\n",
    "model_4.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = models.Sequential()\n",
    "model_5.add(layers.Conv2D(8,\n",
    "                          (4,4),\n",
    "                          activation=\"tanh\",\n",
    "                          input_shape=sample_shape))\n",
    "model_5.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model_5.add(layers.Flatten())\n",
    "model_5.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model\n",
    "model_6 = models.Sequential()\n",
    "model_6.add(layers.Conv2D(64, \n",
    "                        (2, 2), \n",
    "                        activation='relu',\n",
    "                        input_shape=sample_shape))\n",
    "model_6.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model_6.add(layers.Conv2D(64, (2, 2), activation='relu'))\n",
    "model_6.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model_6.add(layers.Conv2D(128, (2, 2), activation='relu'))\n",
    "model_6.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Classifier\n",
    "model_6.add(layers.Flatten())\n",
    "model_6.add(layers.Dense(128, activation='relu'))\n",
    "model_6.add(layers.Dropout(0.5))\n",
    "model_6.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model\n",
    "model_7 = models.Sequential()\n",
    "model_7.add(layers.Conv2D(64, \n",
    "                        (1, 1), \n",
    "                        activation='relu',\n",
    "                        input_shape=sample_shape))\n",
    "model_7.add(layers.Conv2D(64, (1, 1), activation='relu'))\n",
    "model_7.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model_7.add(layers.Conv2D(128, (1, 1), activation='relu'))\n",
    "model_7.add(layers.Conv2D(128, (1, 1), activation='relu'))\n",
    "model_7.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model_7.add(layers.Conv2D(256, (1, 1), activation='relu'))\n",
    "model_7.add(layers.Conv2D(256, (1, 1), activation='relu'))\n",
    "model_7.add(layers.Conv2D(256, (1, 1), activation='relu'))\n",
    "model_7.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model_7.add(layers.Conv2D(512, (1, 1), activation='relu'))\n",
    "model_7.add(layers.Conv2D(512, (1, 1), activation='relu'))\n",
    "model_7.add(layers.Conv2D(512, (1, 1), activation='relu'))\n",
    "model_7.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model_7.add(layers.Conv2D(512, (1, 1), activation='relu'))\n",
    "model_7.add(layers.Conv2D(512, (1, 1), activation='relu'))\n",
    "model_7.add(layers.Conv2D(512, (1, 1), activation='relu'))\n",
    "#model_7.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Classifier\n",
    "model_7.add(layers.Flatten())\n",
    "model_7.add(layers.Dense(512, activation='relu'))\n",
    "model_7.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model\n",
    "model_8 = models.Sequential()\n",
    "model_8.add(layers.Conv2D(16, \n",
    "                        (1, 1), \n",
    "                        activation='relu',\n",
    "                        input_shape=sample_shape))\n",
    "model_8.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model_8.add(layers.Conv2D(32, (2, 2), activation='relu'))\n",
    "model_8.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model_8.add(layers.Conv2D(64, (2, 2), activation='relu'))\n",
    "model_8.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Classifier\n",
    "model_8.add(layers.Flatten())\n",
    "model_8.add(layers.Dense(64, activation='relu'))\n",
    "model_8.add(layers.Dropout(0.5))\n",
    "model_8.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model\n",
    "model_9 = models.Sequential()\n",
    "model_9.add(layers.Conv2D(16, \n",
    "                        (16, 16), \n",
    "                        activation='relu',\n",
    "                        input_shape=sample_shape))\n",
    "\n",
    "# Classifier\n",
    "model_9.add(layers.Flatten())\n",
    "model_9.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model\n",
    "model_10 = models.Sequential()\n",
    "model_10.add(layers.Conv2D(8, \n",
    "                        (4, 4), \n",
    "                        activation='relu',\n",
    "                        input_shape=sample_shape))\n",
    "model_10.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model_10.add(layers.Conv2D(32, (2, 2), activation='relu'))\n",
    "model_10.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model_10.add(layers.Conv2D(32, (1, 1), activation='relu'))\n",
    "model_10.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Classifier\n",
    "model_10.add(layers.Flatten())\n",
    "model_10.add(layers.Dense(32, activation='relu'))\n",
    "model_10.add(layers.Dropout(0.5))\n",
    "model_10.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 15, 15, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 7, 7, 32)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 6, 6, 32)          4128      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 3, 3, 32)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 2, 2, 64)          8256      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 1, 1, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16769 (65.50 KB)\n",
      "Trainable params: 16769 (65.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Display model\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_53 (Conv2D)          (None, 14, 14, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPooli  (None, 7, 7, 16)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_54 (Conv2D)          (None, 5, 5, 32)          4640      \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPooli  (None, 2, 2, 32)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 32)                4128      \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8961 (35.00 KB)\n",
      "Trainable params: 8961 (35.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_55 (Conv2D)          (None, 14, 14, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d_35 (MaxPooli  (None, 1, 1, 16)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 449 (1.75 KB)\n",
      "Trainable params: 449 (1.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_56 (Conv2D)          (None, 12, 12, 64)        1664      \n",
      "                                                                 \n",
      " max_pooling2d_36 (MaxPooli  (None, 2, 2, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 32)                8224      \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9921 (38.75 KB)\n",
      "Trainable params: 9921 (38.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_57 (Conv2D)          (None, 13, 13, 8)         136       \n",
      "                                                                 \n",
      " average_pooling2d_1 (Avera  (None, 6, 6, 8)           0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 288)               0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 1)                 289       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 425 (1.66 KB)\n",
      "Trainable params: 425 (1.66 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_58 (Conv2D)          (None, 15, 15, 64)        320       \n",
      "                                                                 \n",
      " max_pooling2d_37 (MaxPooli  (None, 7, 7, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_59 (Conv2D)          (None, 6, 6, 64)          16448     \n",
      "                                                                 \n",
      " max_pooling2d_38 (MaxPooli  (None, 3, 3, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_60 (Conv2D)          (None, 2, 2, 128)         32896     \n",
      "                                                                 \n",
      " max_pooling2d_39 (MaxPooli  (None, 1, 1, 128)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66305 (259.00 KB)\n",
      "Trainable params: 66305 (259.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_61 (Conv2D)          (None, 16, 16, 64)        128       \n",
      "                                                                 \n",
      " conv2d_62 (Conv2D)          (None, 16, 16, 64)        4160      \n",
      "                                                                 \n",
      " max_pooling2d_40 (MaxPooli  (None, 8, 8, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_63 (Conv2D)          (None, 8, 8, 128)         8320      \n",
      "                                                                 \n",
      " conv2d_64 (Conv2D)          (None, 8, 8, 128)         16512     \n",
      "                                                                 \n",
      " max_pooling2d_41 (MaxPooli  (None, 4, 4, 128)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_65 (Conv2D)          (None, 4, 4, 256)         33024     \n",
      "                                                                 \n",
      " conv2d_66 (Conv2D)          (None, 4, 4, 256)         65792     \n",
      "                                                                 \n",
      " conv2d_67 (Conv2D)          (None, 4, 4, 256)         65792     \n",
      "                                                                 \n",
      " max_pooling2d_42 (MaxPooli  (None, 2, 2, 256)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_68 (Conv2D)          (None, 2, 2, 512)         131584    \n",
      "                                                                 \n",
      " conv2d_69 (Conv2D)          (None, 2, 2, 512)         262656    \n",
      "                                                                 \n",
      " conv2d_70 (Conv2D)          (None, 2, 2, 512)         262656    \n",
      "                                                                 \n",
      " max_pooling2d_43 (MaxPooli  (None, 1, 1, 512)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_71 (Conv2D)          (None, 1, 1, 512)         262656    \n",
      "                                                                 \n",
      " conv2d_72 (Conv2D)          (None, 1, 1, 512)         262656    \n",
      "                                                                 \n",
      " conv2d_73 (Conv2D)          (None, 1, 1, 512)         262656    \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1901761 (7.25 MB)\n",
      "Trainable params: 1901761 (7.25 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_82\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_272 (Conv2D)         (None, 1, 1, 16)          4112      \n",
      "                                                                 \n",
      " flatten_80 (Flatten)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_152 (Dense)           (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4129 (16.13 KB)\n",
      "Trainable params: 4129 (16.13 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_9.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_78 (Conv2D)          (None, 13, 13, 8)         136       \n",
      "                                                                 \n",
      " max_pooling2d_47 (MaxPooli  (None, 6, 6, 8)           0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_79 (Conv2D)          (None, 5, 5, 32)          1056      \n",
      "                                                                 \n",
      " max_pooling2d_48 (MaxPooli  (None, 2, 2, 32)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_80 (Conv2D)          (None, 2, 2, 32)          1056      \n",
      "                                                                 \n",
      " max_pooling2d_49 (MaxPooli  (None, 1, 1, 32)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_19 (Flatten)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3337 (13.04 KB)\n",
      "Trainable params: 3337 (13.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add training parameters to model\n",
    "model_1.compile(loss='binary_crossentropy', \n",
    "              optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "              metrics=['acc'])\n",
    "\n",
    "model_2.compile(loss='binary_crossentropy', \n",
    "              optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "              metrics=['acc'])\n",
    "\n",
    "model_3.compile(loss='binary_crossentropy', \n",
    "              optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "              metrics=['acc'])\n",
    "\n",
    "model_4.compile(loss='binary_crossentropy', \n",
    "              optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "              metrics=['acc'])\n",
    "\n",
    "model_5.compile(loss='binary_crossentropy', \n",
    "              optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "              metrics=['acc'])\n",
    "\n",
    "model_6.compile(loss='binary_crossentropy', \n",
    "              optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "              metrics=['acc'])\n",
    "\n",
    "model_7.compile(loss='binary_crossentropy', \n",
    "              optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "              metrics=['acc'])\n",
    "\n",
    "model_8.compile(loss='binary_crossentropy', \n",
    "              optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "              metrics=['acc'])\n",
    "\n",
    "model_9.compile(loss='binary_crossentropy', \n",
    "              optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "              metrics=['acc'])\n",
    "\n",
    "model_10.compile(loss='binary_crossentropy', \n",
    "              optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "303/303 [==============================] - 3s 5ms/step - loss: 0.1515 - acc: 0.9625 - val_loss: 0.1076 - val_acc: 0.9646\n",
      "Epoch 2/30\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.0980 - acc: 0.9669 - val_loss: 0.0843 - val_acc: 0.9717\n",
      "Epoch 3/30\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.0846 - acc: 0.9711 - val_loss: 0.0774 - val_acc: 0.9743\n",
      "Epoch 4/30\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.0763 - acc: 0.9735 - val_loss: 0.0701 - val_acc: 0.9774\n",
      "Epoch 5/30\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.0725 - acc: 0.9754 - val_loss: 0.0673 - val_acc: 0.9763\n",
      "Epoch 6/30\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.0687 - acc: 0.9763 - val_loss: 0.0628 - val_acc: 0.9785\n",
      "Epoch 7/30\n",
      "162/303 [===============>..............] - ETA: 0s - loss: 0.0628 - acc: 0.9785"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history_1 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/strojnoUcenje/env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/strojnoUcenje/env/lib/python3.10/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/strojnoUcenje/env/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/strojnoUcenje/env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/strojnoUcenje/env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/strojnoUcenje/env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/strojnoUcenje/env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/strojnoUcenje/env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/strojnoUcenje/env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:249\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m InterpolateRuntimeError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    243\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcontrol_dependencies(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_options\u001b[38;5;241m.\u001b[39mcontrol_captures):\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;66;03m# The caller must use record_operation to record this operation in the\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;66;03m# eager case, so we enforce the same requirement for the non-eager\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;66;03m# case by explicitly pausing recording. We don't have a gradient\u001b[39;00m\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;66;03m# registered for PartitionedCall, so recording this operation confuses\u001b[39;00m\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;66;03m# forwardprop code (GradientTape manages to ignore it).\u001b[39;00m\n\u001b[0;32m--> 249\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mrecord\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop_recording\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    250\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m    251\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m             \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m             \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m         )\n",
      "File \u001b[0;32m/usr/lib/python3.10/contextlib.py:279\u001b[0m, in \u001b[0;36mcontextmanager.<locals>.helper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontextmanager\u001b[39m(func):\n\u001b[1;32m    253\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"@contextmanager decorator.\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \n\u001b[1;32m    255\u001b[0m \u001b[38;5;124;03m    Typical usage:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m            <cleanup>\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhelper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _GeneratorContextManager(func, args, kwds)\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m helper\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train\n",
    "history_1 = model_1.fit(x_train, \n",
    "                    y_train, \n",
    "                    epochs=30, \n",
    "                    batch_size=256, \n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "303/303 [==============================] - 2s 4ms/step - loss: 0.1680 - acc: 0.9596 - val_loss: 0.1106 - val_acc: 0.9631\n",
      "Epoch 2/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.1100 - acc: 0.9655 - val_loss: 0.0911 - val_acc: 0.9682\n",
      "Epoch 3/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0943 - acc: 0.9678 - val_loss: 0.0851 - val_acc: 0.9696\n",
      "Epoch 4/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0866 - acc: 0.9700 - val_loss: 0.0852 - val_acc: 0.9708\n",
      "Epoch 5/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0803 - acc: 0.9721 - val_loss: 0.0768 - val_acc: 0.9732\n",
      "Epoch 6/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0760 - acc: 0.9730 - val_loss: 0.0722 - val_acc: 0.9743\n",
      "Epoch 7/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0719 - acc: 0.9743 - val_loss: 0.0692 - val_acc: 0.9757\n",
      "Epoch 8/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0680 - acc: 0.9764 - val_loss: 0.0661 - val_acc: 0.9785\n",
      "Epoch 9/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0649 - acc: 0.9777 - val_loss: 0.0652 - val_acc: 0.9766\n",
      "Epoch 10/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0629 - acc: 0.9776 - val_loss: 0.0644 - val_acc: 0.9774\n",
      "Epoch 11/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0589 - acc: 0.9797 - val_loss: 0.0613 - val_acc: 0.9781\n",
      "Epoch 12/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0572 - acc: 0.9801 - val_loss: 0.0617 - val_acc: 0.9790\n",
      "Epoch 13/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0565 - acc: 0.9806 - val_loss: 0.0646 - val_acc: 0.9774\n",
      "Epoch 14/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0534 - acc: 0.9814 - val_loss: 0.0616 - val_acc: 0.9796\n",
      "Epoch 15/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0527 - acc: 0.9817 - val_loss: 0.0674 - val_acc: 0.9804\n",
      "Epoch 16/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0498 - acc: 0.9823 - val_loss: 0.0573 - val_acc: 0.9813\n",
      "Epoch 17/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0483 - acc: 0.9829 - val_loss: 0.0622 - val_acc: 0.9807\n",
      "Epoch 18/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0461 - acc: 0.9833 - val_loss: 0.0580 - val_acc: 0.9811\n",
      "Epoch 19/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0461 - acc: 0.9836 - val_loss: 0.0577 - val_acc: 0.9813\n",
      "Epoch 20/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0445 - acc: 0.9843 - val_loss: 0.0596 - val_acc: 0.9811\n",
      "Epoch 21/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0434 - acc: 0.9848 - val_loss: 0.0610 - val_acc: 0.9781\n",
      "Epoch 22/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0416 - acc: 0.9852 - val_loss: 0.0574 - val_acc: 0.9811\n",
      "Epoch 23/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0415 - acc: 0.9855 - val_loss: 0.0560 - val_acc: 0.9823\n",
      "Epoch 24/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0399 - acc: 0.9856 - val_loss: 0.0606 - val_acc: 0.9819\n",
      "Epoch 25/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0392 - acc: 0.9860 - val_loss: 0.0619 - val_acc: 0.9829\n",
      "Epoch 26/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0390 - acc: 0.9859 - val_loss: 0.0565 - val_acc: 0.9832\n",
      "Epoch 27/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0381 - acc: 0.9864 - val_loss: 0.0634 - val_acc: 0.9827\n",
      "Epoch 28/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0371 - acc: 0.9865 - val_loss: 0.0650 - val_acc: 0.9819\n",
      "Epoch 29/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0357 - acc: 0.9865 - val_loss: 0.0616 - val_acc: 0.9823\n",
      "Epoch 30/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0350 - acc: 0.9871 - val_loss: 0.0629 - val_acc: 0.9822\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "history_2 = model_2.fit(x_train, \n",
    "                    y_train, \n",
    "                    epochs=30, \n",
    "                    batch_size=256, \n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "303/303 [==============================] - 2s 3ms/step - loss: 0.2816 - acc: 0.9263 - val_loss: 0.1725 - val_acc: 0.9630\n",
      "Epoch 2/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.1827 - acc: 0.9631 - val_loss: 0.1615 - val_acc: 0.9630\n",
      "Epoch 3/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.1685 - acc: 0.9637 - val_loss: 0.1544 - val_acc: 0.9630\n",
      "Epoch 4/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.1615 - acc: 0.9638 - val_loss: 0.1500 - val_acc: 0.9630\n",
      "Epoch 5/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.1571 - acc: 0.9638 - val_loss: 0.1473 - val_acc: 0.9630\n",
      "Epoch 6/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.1536 - acc: 0.9638 - val_loss: 0.1437 - val_acc: 0.9630\n",
      "Epoch 7/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.1496 - acc: 0.9639 - val_loss: 0.1409 - val_acc: 0.9630\n",
      "Epoch 8/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.1458 - acc: 0.9639 - val_loss: 0.1390 - val_acc: 0.9630\n",
      "Epoch 9/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.1428 - acc: 0.9639 - val_loss: 0.1370 - val_acc: 0.9630\n",
      "Epoch 10/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.1421 - acc: 0.9639 - val_loss: 0.1353 - val_acc: 0.9630\n",
      "Epoch 11/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.1394 - acc: 0.9639 - val_loss: 0.1359 - val_acc: 0.9630\n",
      "Epoch 12/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.1380 - acc: 0.9639 - val_loss: 0.1336 - val_acc: 0.9630\n",
      "Epoch 13/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.1361 - acc: 0.9639 - val_loss: 0.1331 - val_acc: 0.9630\n",
      "Epoch 14/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.1351 - acc: 0.9639 - val_loss: 0.1325 - val_acc: 0.9630\n",
      "Epoch 15/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.1341 - acc: 0.9639 - val_loss: 0.1313 - val_acc: 0.9630\n",
      "Epoch 16/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.1339 - acc: 0.9639 - val_loss: 0.1341 - val_acc: 0.9630\n",
      "Epoch 17/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.1326 - acc: 0.9639 - val_loss: 0.1310 - val_acc: 0.9630\n",
      "Epoch 18/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.1316 - acc: 0.9638 - val_loss: 0.1299 - val_acc: 0.9630\n",
      "Epoch 19/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.1305 - acc: 0.9638 - val_loss: 0.1285 - val_acc: 0.9629\n",
      "Epoch 20/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.1306 - acc: 0.9639 - val_loss: 0.1286 - val_acc: 0.9630\n",
      "Epoch 21/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.1309 - acc: 0.9639 - val_loss: 0.1293 - val_acc: 0.9629\n",
      "Epoch 22/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.1304 - acc: 0.9639 - val_loss: 0.1283 - val_acc: 0.9630\n",
      "Epoch 23/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.1287 - acc: 0.9638 - val_loss: 0.1281 - val_acc: 0.9630\n",
      "Epoch 24/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.1285 - acc: 0.9638 - val_loss: 0.1272 - val_acc: 0.9630\n",
      "Epoch 25/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.1281 - acc: 0.9639 - val_loss: 0.1260 - val_acc: 0.9629\n",
      "Epoch 26/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.1278 - acc: 0.9639 - val_loss: 0.1265 - val_acc: 0.9630\n",
      "Epoch 27/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.1269 - acc: 0.9639 - val_loss: 0.1251 - val_acc: 0.9629\n",
      "Epoch 28/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.1274 - acc: 0.9640 - val_loss: 0.1251 - val_acc: 0.9628\n",
      "Epoch 29/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.1272 - acc: 0.9641 - val_loss: 0.1259 - val_acc: 0.9628\n",
      "Epoch 30/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.1267 - acc: 0.9641 - val_loss: 0.1247 - val_acc: 0.9628\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "history_3 = model_3.fit(x_train, \n",
    "                    y_train, \n",
    "                    epochs=30, \n",
    "                    batch_size=256, \n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "303/303 [==============================] - 2s 4ms/step - loss: 0.1488 - acc: 0.9597 - val_loss: 0.1091 - val_acc: 0.9646\n",
      "Epoch 2/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0931 - acc: 0.9692 - val_loss: 0.0934 - val_acc: 0.9706\n",
      "Epoch 3/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0829 - acc: 0.9724 - val_loss: 0.0898 - val_acc: 0.9701\n",
      "Epoch 4/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0743 - acc: 0.9747 - val_loss: 0.0766 - val_acc: 0.9748\n",
      "Epoch 5/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0706 - acc: 0.9757 - val_loss: 0.0720 - val_acc: 0.9757\n",
      "Epoch 6/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0694 - acc: 0.9764 - val_loss: 0.0763 - val_acc: 0.9746\n",
      "Epoch 7/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0664 - acc: 0.9772 - val_loss: 0.0770 - val_acc: 0.9740\n",
      "Epoch 8/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0633 - acc: 0.9784 - val_loss: 0.0681 - val_acc: 0.9782\n",
      "Epoch 9/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0605 - acc: 0.9794 - val_loss: 0.0735 - val_acc: 0.9757\n",
      "Epoch 10/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0586 - acc: 0.9805 - val_loss: 0.0672 - val_acc: 0.9765\n",
      "Epoch 11/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0580 - acc: 0.9799 - val_loss: 0.0660 - val_acc: 0.9776\n",
      "Epoch 12/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0551 - acc: 0.9810 - val_loss: 0.0624 - val_acc: 0.9790\n",
      "Epoch 13/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0546 - acc: 0.9814 - val_loss: 0.0668 - val_acc: 0.9766\n",
      "Epoch 14/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0540 - acc: 0.9817 - val_loss: 0.0666 - val_acc: 0.9772\n",
      "Epoch 15/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0520 - acc: 0.9823 - val_loss: 0.0612 - val_acc: 0.9803\n",
      "Epoch 16/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0502 - acc: 0.9825 - val_loss: 0.0682 - val_acc: 0.9782\n",
      "Epoch 17/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0513 - acc: 0.9824 - val_loss: 0.0666 - val_acc: 0.9790\n",
      "Epoch 18/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0500 - acc: 0.9823 - val_loss: 0.0630 - val_acc: 0.9796\n",
      "Epoch 19/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0483 - acc: 0.9829 - val_loss: 0.0631 - val_acc: 0.9795\n",
      "Epoch 20/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0483 - acc: 0.9832 - val_loss: 0.0621 - val_acc: 0.9796\n",
      "Epoch 21/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0490 - acc: 0.9828 - val_loss: 0.0606 - val_acc: 0.9807\n",
      "Epoch 22/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0475 - acc: 0.9835 - val_loss: 0.0578 - val_acc: 0.9795\n",
      "Epoch 23/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0469 - acc: 0.9835 - val_loss: 0.0647 - val_acc: 0.9792\n",
      "Epoch 24/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0438 - acc: 0.9847 - val_loss: 0.0586 - val_acc: 0.9802\n",
      "Epoch 25/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0462 - acc: 0.9836 - val_loss: 0.0593 - val_acc: 0.9814\n",
      "Epoch 26/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0433 - acc: 0.9846 - val_loss: 0.0617 - val_acc: 0.9803\n",
      "Epoch 27/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0426 - acc: 0.9853 - val_loss: 0.0588 - val_acc: 0.9797\n",
      "Epoch 28/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0422 - acc: 0.9852 - val_loss: 0.0659 - val_acc: 0.9772\n",
      "Epoch 29/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0419 - acc: 0.9855 - val_loss: 0.0636 - val_acc: 0.9780\n",
      "Epoch 30/30\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 0.0414 - acc: 0.9853 - val_loss: 0.0649 - val_acc: 0.9801\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "history_4 = model_4.fit(x_train, \n",
    "                    y_train, \n",
    "                    epochs=30, \n",
    "                    batch_size=256, \n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "303/303 [==============================] - 2s 3ms/step - loss: 0.2087 - acc: 0.9410 - val_loss: 0.1438 - val_acc: 0.9630\n",
      "Epoch 2/30\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.1322 - acc: 0.9640 - val_loss: 0.1297 - val_acc: 0.9631\n",
      "Epoch 3/30\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.1251 - acc: 0.9642 - val_loss: 0.1263 - val_acc: 0.9632\n",
      "Epoch 4/30\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.1215 - acc: 0.9644 - val_loss: 0.1222 - val_acc: 0.9634\n",
      "Epoch 5/30\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.1178 - acc: 0.9649 - val_loss: 0.1191 - val_acc: 0.9637\n",
      "Epoch 6/30\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.1145 - acc: 0.9650 - val_loss: 0.1160 - val_acc: 0.9640\n",
      "Epoch 7/30\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.1113 - acc: 0.9652 - val_loss: 0.1128 - val_acc: 0.9644\n",
      "Epoch 8/30\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.1087 - acc: 0.9657 - val_loss: 0.1109 - val_acc: 0.9644\n",
      "Epoch 9/30\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.1059 - acc: 0.9658 - val_loss: 0.1082 - val_acc: 0.9652\n",
      "Epoch 10/30\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.1028 - acc: 0.9665 - val_loss: 0.1055 - val_acc: 0.9657\n",
      "Epoch 11/30\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.1005 - acc: 0.9670 - val_loss: 0.1028 - val_acc: 0.9668\n",
      "Epoch 12/30\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.0983 - acc: 0.9672 - val_loss: 0.1012 - val_acc: 0.9673\n",
      "Epoch 13/30\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.0967 - acc: 0.9676 - val_loss: 0.1003 - val_acc: 0.9661\n",
      "Epoch 14/30\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.0952 - acc: 0.9682 - val_loss: 0.1001 - val_acc: 0.9671\n",
      "Epoch 15/30\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.0939 - acc: 0.9685 - val_loss: 0.0978 - val_acc: 0.9694\n",
      "Epoch 16/30\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.0926 - acc: 0.9687 - val_loss: 0.0971 - val_acc: 0.9675\n",
      "Epoch 17/30\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.0916 - acc: 0.9692 - val_loss: 0.0959 - val_acc: 0.9682\n",
      "Epoch 18/30\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.0907 - acc: 0.9691 - val_loss: 0.0966 - val_acc: 0.9702\n",
      "Epoch 19/30\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.0900 - acc: 0.9694 - val_loss: 0.0945 - val_acc: 0.9684\n",
      "Epoch 20/30\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.0892 - acc: 0.9695 - val_loss: 0.0959 - val_acc: 0.9679\n",
      "Epoch 21/30\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.0886 - acc: 0.9698 - val_loss: 0.0933 - val_acc: 0.9699\n",
      "Epoch 22/30\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.0879 - acc: 0.9699 - val_loss: 0.0945 - val_acc: 0.9685\n",
      "Epoch 23/30\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.0873 - acc: 0.9701 - val_loss: 0.0944 - val_acc: 0.9683\n",
      "Epoch 24/30\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.0865 - acc: 0.9702 - val_loss: 0.0924 - val_acc: 0.9690\n",
      "Epoch 25/30\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.0865 - acc: 0.9703 - val_loss: 0.0925 - val_acc: 0.9686\n",
      "Epoch 26/30\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.0856 - acc: 0.9706 - val_loss: 0.0912 - val_acc: 0.9693\n",
      "Epoch 27/30\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.0855 - acc: 0.9707 - val_loss: 0.0914 - val_acc: 0.9691\n",
      "Epoch 28/30\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.0853 - acc: 0.9705 - val_loss: 0.0919 - val_acc: 0.9686\n",
      "Epoch 29/30\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.0849 - acc: 0.9707 - val_loss: 0.0908 - val_acc: 0.9689\n",
      "Epoch 30/30\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.0846 - acc: 0.9708 - val_loss: 0.0920 - val_acc: 0.9684\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "history_5 = model_5.fit(x_train, \n",
    "                    y_train, \n",
    "                    epochs=30, \n",
    "                    batch_size=256, \n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwQAAAHBCAYAAADXQXzMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd3gUVdvA4d/uppPeK0RCLyIiWDCIDbCiASkWiu9nV4oVXxWx4mtBULArFgRRiGKlGiSCKAoihBoIAiGN9JC+e74/hmyyyW6yyQaWwHNf115hZ+fMnJkNmfPMPOccnVJKIYQQQgghhDgj6Z1dASGEEEIIIYTzSEAghBBCCCHEGUwCAiGEEEIIIc5gEhAIIYQQQghxBpOAQAghhBBCiDOYBARCCCGEEEKcwSQgEEIIIYQQ4gwmAYEQQgghhBBnMAkIhBBCCCGEOINJQCDOSBMmTCA2NrZFZWfMmIFOp2vdCp1iDhw4gE6n4+OPPz6p+127di06nY61a9eal9n7XZ2oOsfGxjJhwoRW3aYQQghxKpGAQJxSdDqdXa+6DUYhHLVhwwZmzJhBQUGBs6sihBBCnHQuzq6AEHV99tlnFu8//fRTVq1a1WB59+7dHdrP+++/j8lkalHZJ598kmnTpjm0f2E/R74re23YsIFnnnmGCRMm4O/vb/HZ7t270evl3okQQojTlwQE4pRy6623WrzfuHEjq1atarC8vtLSUry8vOzej6ura4vqB+Di4oKLi/zXOVkc+a5ag7u7u1P331YcO3aMdu3aObsaQgghWkBue4k2Z/DgwfTq1Yu//vqLQYMG4eXlxX//+18Ali1bxjXXXENkZCTu7u7ExcXx3HPPYTQaLbZRPy+9Jv/81Vdf5b333iMuLg53d3f69+/Ppk2bLMpa60Og0+m4//77+eabb+jVqxfu7u707NmT5cuXN6j/2rVrOe+88/Dw8CAuLo53333X7n4JycnJ3HTTTbRv3x53d3diYmKYOnUqZWVlDY7P29ub9PR0brjhBry9vQkJCeHhhx9ucC4KCgqYMGECfn5++Pv7M378eLtSZ/788090Oh2ffPJJg89WrFiBTqfj+++/B+Dff//l3nvvpWvXrnh6ehIUFMRNN93EgQMHmtyPtT4E9tb5n3/+YcKECXTs2BEPDw/Cw8O5/fbbyc3NNa8zY8YMHnnkEQDOOussc1paTd2s9SHYv38/N910E4GBgXh5eXHBBRfwww8/WKxT0x/iyy+/5IUXXiA6OhoPDw8uv/xyUlNTmzzu5pyzgoICpk6dSmxsLO7u7kRHRzNu3DiOHj1qXqe8vJwZM2bQpUsXPDw8iIiIICEhgX379lnUt346nrW+GTW/X/v27ePqq6/Gx8eHW265BbD/dxRg165djBo1ipCQEDw9PenatStPPPEEAElJSeh0Or7++usG5RYuXIhOp+O3335r8jwKIYRomtzmFG1Sbm4uV111FWPGjOHWW28lLCwMgI8//hhvb28efPBBvL29+fnnn5k+fTpFRUW88sorTW534cKFFBcXc9ddd6HT6Xj55ZdJSEhg//79Td6p/vXXX0lMTOTee+/Fx8eHN954gxEjRnDw4EGCgoIA2LJlC8OGDSMiIoJnnnkGo9HIs88+S0hIiF3H/dVXX1FaWso999xDUFAQf/zxB2+++SaHDx/mq6++sljXaDQydOhQzj//fF599VVWr17Na6+9RlxcHPfccw8ASimGDx/Or7/+yt1330337t35+uuvGT9+fJN1Oe+88+jYsSNffvllg/UXL15MQEAAQ4cOBWDTpk1s2LCBMWPGEB0dzYEDB3j77bcZPHgwO3bsaNbTnebUedWqVezfv5+JEycSHh5OSkoK7733HikpKWzcuBGdTkdCQgJ79uxh0aJFvP766wQHBwPY/E6ysrK46KKLKC0tZdKkSQQFBfHJJ59w/fXXs2TJEm688UaL9V966SX0ej0PP/wwhYWFvPzyy9xyyy38/vvvjR6nveespKSE+Ph4du7cye233865557L0aNH+fbbbzl8+DDBwcEYjUauvfZa1qxZw5gxY5g8eTLFxcWsWrWK7du3ExcXZ/f5r1FdXc3QoUO5+OKLefXVV831sfd39J9//iE+Ph5XV1fuvPNOYmNj2bdvH9999x0vvPACgwcPJiYmhs8//7zBOf3888+Ji4vjwgsvbHa9hRBCWKGEOIXdd999qv6v6SWXXKIA9c477zRYv7S0tMGyu+66S3l5eany8nLzsvHjx6sOHTqY36elpSlABQUFqby8PPPyZcuWKUB999135mVPP/10gzoBys3NTaWmppqXbd26VQHqzTffNC+77rrrlJeXl0pPTzcv27t3r3JxcWmwTWusHd/MmTOVTqdT//77r8XxAerZZ5+1WLdv376qX79+5vfffPONAtTLL79sXlZdXa3i4+MVoObPn99ofR5//HHl6upqcc4qKiqUv7+/uv322xut92+//aYA9emnn5qXJSUlKUAlJSVZHEvd76o5dba230WLFilArVu3zrzslVdeUYBKS0trsH6HDh3U+PHjze+nTJmiAJWcnGxeVlxcrM466ywVGxurjEajxbF0795dVVRUmNedM2eOAtS2bdsa7Ksue8/Z9OnTFaASExMbrG8ymZRSSn300UcKULNmzbK5jrVzr1Tt/42657Xm92vatGl21dva7+igQYOUj4+PxbK69VFK+/1yd3dXBQUF5mXZ2dnKxcVFPf300w32I4QQomUkZUi0Se7u7kycOLHBck9PT/O/i4uLOXr0KPHx8ZSWlrJr164mtzt69GgCAgLM7+Pj4wEtRaQpV1xxhcWd1rPPPhtfX19zWaPRyOrVq7nhhhuIjIw0r9epUyeuuuqqJrcPlsd37Ngxjh49ykUXXYRSii1btjRY/+6777Z4Hx8fb3EsP/74Iy4uLuYnBgAGg4EHHnjArvqMHj2aqqoqEhMTzctWrlxJQUEBo0ePtlrvqqoqcnNz6dSpE/7+/mzevNmufbWkznX3W15eztGjR7ngggsAmr3fuvsfMGAAF198sXmZt7c3d955JwcOHGDHjh0W60+cOBE3Nzfze3t/p+w9Z0uXLqVPnz4N7qID5jS0pUuXEhwcbPUcOTKEbt3vwFq9bf2O5uTksG7dOm6//Xbat29vsz7jxo2joqKCJUuWmJctXryY6urqJvsVCSGEsJ8EBKJNioqKsmhk1UhJSeHGG2/Ez88PX19fQkJCzA2HwsLCJrdbv3FSExzk5+c3u2xN+Zqy2dnZlJWV0alTpwbrWVtmzcGDB5kwYQKBgYHmfgGXXHIJ0PD4PDw8GqS91K0PaHnqEREReHt7W6zXtWtXu+rTp08funXrxuLFi83LFi9eTHBwMJdddpl5WVlZGdOnTycmJgZ3d3eCg4MJCQmhoKDAru+lrubUOS8vj8mTJxMWFoanpychISGcddZZgH2/D7b2b21fNSNf/fvvvxbLW/o7Ze8527dvH7169Wp0W/v27aNr166t2hnexcWF6OjoBsvt+R2tCYaaqne3bt3o378/n3/+uXnZ559/zgUXXGD3/xkhhBBNkz4Eok2qexeyRkFBAZdccgm+vr48++yzxMXF4eHhwebNm3nsscfsGrrSYDBYXa6UOqFl7WE0GrnyyivJy8vjscceo1u3brRr14709HQmTJjQ4Phs1ae1jR49mhdeeIGjR4/i4+PDt99+y9ixYy0anw888ADz589nypQpXHjhhfj5+aHT6RgzZswJHVJ01KhRbNiwgUceeYRzzjkHb29vTCYTw4YNO+FDmdZo6e/FyT5ntp4U1O+EXsPd3b3BcKzN/R21x7hx45g8eTKHDx+moqKCjRs3Mnfu3GZvRwghhG0SEIjTxtq1a8nNzSUxMZFBgwaZl6elpTmxVrVCQ0Px8PCwOsKMPaPObNu2jT179vDJJ58wbtw48/JVq1a1uE4dOnRgzZo1lJSUWNxx3717t93bGD16NM888wxLly4lLCyMoqIixowZY7HOkiVLGD9+PK+99pp5WXl5eYsmArO3zvn5+axZs4ZnnnmG6dOnm5fv3bu3wTabkzbToUMHq+enJiWtQ4cOdm+rMfaes7i4OLZv397otuLi4vj999+pqqqy2Tm+5slF/e3Xf+LRGHt/Rzt27AjQZL0BxowZw4MPPsiiRYsoKyvD1dXVIh1NCCGE4yRlSJw2au7E1r3zWllZyVtvveWsKlkwGAxcccUVfPPNNxw5csS8PDU1lZ9++smu8mB5fEop5syZ0+I6XX311VRXV/P222+blxmNRt588027t9G9e3d69+7N4sWLWbx4MRERERYBWU3d698Rf/PNN23efW6NOls7XwCzZ89usM2a8fPtCVCuvvpq/vjjD4shL48dO8Z7771HbGwsPXr0sPdQGmXvORsxYgRbt261OjxnTfkRI0Zw9OhRq3fWa9bp0KEDBoOBdevWWXzenP8/9v6OhoSEMGjQID766CMOHjxotT41goODueqqq1iwYAGff/45w4YNM48EJYQQonXIEwJx2rjooosICAhg/PjxTJo0CZ1Ox2effdZqKTutYcaMGaxcuZKBAwdyzz33YDQamTt3Lr169eLvv/9utGy3bt2Ii4vj4YcfJj09HV9fX5YuXWpX/wZbrrvuOgYOHMi0adM4cOAAPXr0IDExsdn59aNHj2b69Ol4eHjwn//8p0EqybXXXstnn32Gn58fPXr04LfffmP16tXm4VhPRJ19fX0ZNGgQL7/8MlVVVURFRbFy5UqrT4z69esHwBNPPMGYMWNwdXXluuuuszrR1rRp01i0aBFXXXUVkyZNIjAwkE8++YS0tDSWLl3aarMa23vOHnnkEZYsWcJNN93E7bffTr9+/cjLy+Pbb7/lnXfeoU+fPowbN45PP/2UBx98kD/++IP4+HiOHTvG6tWruffeexk+fDh+fn7cdNNNvPnmm+h0OuLi4vj+++/Jzs62u87N+R194403uPjiizn33HO58847Oeusszhw4AA//PBDg/8L48aNY+TIkQA899xzzT+ZQgghGiUBgThtBAUF8f333/PQQw/x5JNPEhAQwK233srll19uHg/f2fr168dPP/3Eww8/zFNPPUVMTAzPPvssO3fubHIUJFdXV7777jsmTZrEzJkz8fDw4MYbb+T++++nT58+LaqPXq/n22+/ZcqUKSxYsACdTsf111/Pa6+9Rt++fe3ezujRo3nyyScpLS21ms4xZ84cDAYDn3/+OeXl5QwcOJDVq1e36HtpTp0XLlzIAw88wLx581BKMWTIEH766SeLUZ4A+vfvz3PPPcc777zD8uXLMZlMpKWlWQ0IwsLC2LBhA4899hhvvvkm5eXlnH322Xz33Xdcc801zT4eW+w9Z97e3iQnJ/P000/z9ddf88knnxAaGsrll19u7vRrMBj48ccfeeGFF1i4cCFLly4lKCiIiy++mN69e5u39eabb1JVVcU777yDu7s7o0aN4pVXXmmy82+N5vyO9unTh40bN/LUU0/x9ttvU15eTocOHRg1alSD7V533XUEBARgMpm4/vrrm3sqhRBCNEGnTqXbp0KcoW644QZSUlKs5rcLcaarrq4mMjKS6667jg8//NDZ1RFCiNOO9CEQ4iQrKyuzeL93715+/PFHBg8e7JwKCXGK++abb8jJybHoqCyEEKL1yBMCIU6yiIgIJkyYQMeOHfn33395++23qaioYMuWLXTu3NnZ1RPilPH777/zzz//8NxzzxEcHNziyeSEEEI0TvoQCHGSDRs2jEWLFpGZmYm7uzsXXnghL774ogQDQtTz9ttvs2DBAs455xw+/vhjZ1dHCCFOW/KEQAghhBBCiDOY9CEQQgghhBDiDCYBgRBCCCGEEGew06YPgclk4siRI/j4+KDT6ZxdHSGEEELYQSlFcXExkZGRrTaxnxCieU6bgODIkSPExMQ4uxpCCCGEaIFDhw6ZJ9MTQpxcp01A4OPjA2h/UHx9fZ1cGyGEEELYo6ioiJiYGPN1XAhx8p02AUFNmpCvr68EBEIIIUQbI+m+QjiPJOsJIYQQQghxBpOAQAghhBBCiDOYBARCCCGEEEKcwSQgEEIIIYQQ4gwmAYEQQgghhBBnMAkIhBBCCCGEOINJQCCEEEIIIcQZTAICIYQQQgghzmASEAghhBBCCHEGO21mKhZCCCGEdUYjJCdDRgZEREB8PBgMJ76sEKJtkIBACCGEOMGc2ahOTITJk+Hw4dpl0dEwZw4kJJy4skKItkNShoQQQogTKDERYmPh0kvh5pu1n7Gx2vKTse+RIy0b9ADp6dryxurgSFkhRNuiU0opZ1eiNRQVFeHn50dhYSG+vr7Oro4QQghhblTXv9LqdNrPJUvsu9PekicMRqMWeNRv0NetQ3Q0pKU13JYjZZtLrt9COJ88IRBCCCHsYDTC2rWwaJH202hsev3JkxsGA1C7bMqUprfT0icMycm2G/Q1dTh0SFuvNcsKIdqeFgUE8+bNIzY2Fg8PD84//3z++OMPm+tWVVXx7LPPEhcXh4eHB3369GH58uUW6xQXFzNlyhQ6dOiAp6cnF110EZs2bWpJ1YQQQohW15JGeWs0qh1J28nIsP1ZU+s5UlYI0fY0OyBYvHgxDz74IE8//TSbN2+mT58+DB06lOzsbKvrP/nkk7z77ru8+eab7Nixg7vvvpsbb7yRLVu2mNf5v//7P1atWsVnn33Gtm3bGDJkCFdccQXp6ektPzIhhBCiFbS0Ue5oo9rRJwwREfbt39p6jpQVQrQ9ze5DcP7559O/f3/mzp0LgMlkIiYmhgceeIBp06Y1WD8yMpInnniC++67z7xsxIgReHp6smDBAsrKyvDx8WHZsmVcc8015nX69evHVVddxfPPP29XvSQHUQghRGtzJJd+7VrtSUJTkpJg8OCGyx0tX1P39HTrQYU9fQhaUra55PothPM16wlBZWUlf/31F1dccUXtBvR6rrjiCn777TerZSoqKvDw8LBY5unpya+//gpAdXU1RqOx0XWEEEIIZ3Ak7Sc+Xms013Qgrk+ng5gYbT1rHH3CYDBow4PW7Kv+vgFmz7beoHekrBCi7WlWQHD06FGMRiNhYWEWy8PCwsjMzLRaZujQocyaNYu9e/diMplYtWoViYmJZBz/C+bj48OFF17Ic889x5EjRzAajSxYsIDffvvNvI41FRUVFBUVWbyEEEKI1uRIo9zRRnVrpO0kJGgjGUVFWS6Pjm56hCNHygoh2pYTPsrQnDlz6Ny5M926dcPNzY3777+fiRMnotfX7vqzzz5DKUVUVBTu7u688cYbjB071mKd+mbOnImfn5/5FRMTc6IPRQghhJM1d6QfR8s62ih3pFHt6BOGunU4cEBLLVq4UPuZlmZfg96RskKItqNZfQgqKyvx8vJiyZIl3HDDDebl48ePp6CggGXLltksW15eTm5uLpGRkUybNo3vv/+elJQUi3WOHTtGUVERERERjB49mpKSEn744Qer26uoqKCiosL8vqioiJiYGMlBFEKI05QzZtxtrVz6ls5UXNOhGSz339x5DE5l0odACOdr1hMCNzc3+vXrx5o1a8zLTCYTa9as4cILL2y0rIeHB1FRUVRXV7N06VKGDx/eYJ127doRERFBfn4+K1assLpODXd3d3x9fS1eQgghTk/OmnG3tXLpDQat4+/YsdpPe3PvJW1HCHEyNHuUocWLFzN+/HjeffddBgwYwOzZs/nyyy/ZtWsXYWFhjBs3jqioKGbOnAnA77//Tnp6Oueccw7p6enMmDGDtLQ0Nm/ejL+/PwArVqxAKUXXrl1JTU3lkUcewcPDg+TkZFxdXe2ql9xhEEKI09OpMOOutScMMTFaMHAyGuUtfcLQFsj1Wwjnc2lugdGjR5OTk8P06dPJzMzknHPOYfny5eaOxgcPHrTI/S8vL+fJJ59k//79eHt7c/XVV/PZZ5+ZgwGAwsJCHn/8cQ4fPkxgYCAjRozghRdesDsYEEIIcfpqzkg/9YffdKRsXQkJMHy48xrlNU8YhBDiRGj2E4JTldxhEEKIU19L7nQvWqTNDtyUhQu1lJzWKitODrl+C+F8zX5CIIQQQrRESzv2yoy7QghxYskTAiGEEM3Skrv8NR17619x7Bktp63MuCtaRq7fQjjfCZ+HQAghxKnFkbH8ExO1Bvall2qpOJdeqr1vbKQeo1F7MmCtQV6zbMoU2/WQGXeFEOLEkoBACCHOIC1p0Nct25LhO5vTsdcWmXFXCCFOHEkZEkKIM0RrpO20ZPjO1uzY68jwm6fz0J0n1Ak+cXL9FsL5pFOxEEKcAZpK29HptLSd4cOtt/UcGb6zNTv2OjL8pgzd2QKOTA8thGgzJGVICCHOAI6m7WRk2Lcfa+vFx2ttyPo5/DV0Om2Sr/h4+/YhThJHpngWQrQpEhAIIcQZwJEGPTh2l1869uJYT25nlHe0J7gQok2RgEAIIc4AjqbtOHqX/4zu2OtIT25nlW+NnuBCiDZDOhULIYQTONpPs7nlW2M8/poMErDchj2dklta71bljJ070pPbmeVP4hTPcv0WwvkkIBBCiBZwpG3paD/NlpZvjQa9tX3HxGgpP6f0Xf7W6Bzb0iisJUMzObv82rXak4SmJCU53FNbrt9CnALUaaKwsFABqrCw0NlVEUKc5pYuVSo6WimtWa29oqO15faU1eksy4K2TKdrehutUb5+3WNi7Kt7jepqpZKSlFq4UPtZXW1/Wadw9KTVbKO5X3pSUsN9WnslJZ165aurteOzdt5qzl1MTKt8+XL9FsL5pA+BEEI0gyMDrzjaT7M1+nkmJMCBA9qN3YULtZ9pac27u18zfOfYsdrPZmXdtMXOsS390h3tyd2K5ZUe8vtA1mXaT4urv7Xy0hNciDOKzEMghBB2cuZY/q1RvobTxuN3Rq6UoyfNkS+9Tg9tpYeC3lAZBG654L8NdKaG652I8jnxkHo/VITWfuSeDZ3mQkhyI+WP9wRXUyZREJheu+/8KHSvyzwEQpxOJCAQQpyxmpsS7mjb0tk3jFtNSzpQ2OrcWnOXvaWdY5sq7+hJc+RLPz40U07Hw6TeZ6VBPg9C0hoZmqkVyufcEETKpNwGH1UEQ8oz0PPNIEIamQAiJx5Sv9BRUVln327QqTOE2CwlhGhrJGVICNFmOZJ90pKRGJ05ln9rlG8VLTlxzsyVcvSkOfKlGwzkvDWWlBlQUa/1XBEMKTMgZ94Y28GUg+WVXnsyAED94WL1gILU++qlD9WRk5NISspIKiotA6KKynRSUkaSkyMTkwlxupCAQAjRJjkyNHtLU8KdPZZ/q83429JIqqUnztEx7euUt5oL31h5R0+aA1+6UkZSgxcd30+9D49ffVODv0Ap6+ff0fIFBclUGHIblq2zjQpDLgUFDc+bUkZSUycD1gYi1Jalpk6xuW8hRNsiAYEQos1xVsdeR9uWjvbTbJV+ni2NpBw5ca2UK5UTDxsXwdbZsPMp7efGRdpym+UdPWl1vnSrwUgjX3pBQTIVFYdtN8h1UFFxyGqDvDXKV1bad96trWfet02q0X0LIdoWCQiEEG2Ko9knjtysbo0GuaMz9taUj4k0cglrGcMiLmEt7aOMTZd3JJJy5MS1Qq5UTryW8241deaZ40FBE51jW3TSj3/pOfHKRjCibH7pjjTIW6O8m5t9593aeo7uWwjRtkinYiGEU7W1jr01bUtrg93YOzlXQoI2KE1LJzZLIJEbdZPRUVsBRTQ65gA2KuDoEEmOnLiau+xNTZNs49GKuvgiUicbAKP11BkTpE42EHzxRTZvpjty0nPiISWg4fKaPP6evax3sHWkQd4a5f3943F3j6aiIh3rqT863N2j8fdveN4d3bcQom2RJwRCCKdpix17wclj+R+/y6+rFxXpTnQevyMnzsFHKwXFG6gIshIM1NBDRZCRguINjdetBSfdnEuvw3owotPZzKWvaZA3lvPj7h5jtUHeGuV1OgOdOs0xr1u/LECnTrPR6RqeB0f3LYRoWyQgEEI4RVvt2FvDocm5WsqZefyOnjgH0nacmb7iSC69Iw3y1igPEBKSQM+eS3B3tzzv7u7R9Oy5hJAQ6+e9NfYthGg7JCAQQjikJQPWtOWOva2mJSfOmXn8dU6cMtTrXFtzruzoQKHS9pGf9DpZifeTn/Q6an9qk49WWit9RSkj+flrycpaRH7+WrtGyHE0GGlpg7y1ytds44ILDtCnTxLduy+kT58kLrgg7aTsWwjRNkgfAiFEi7V04llH+gHUtEtHjtQa8HWDiuZ27HWkH0CLJueq0dIT58Q8fgASEshZ9jCplbO0FJ7j3HMNdHJ7kJDrGj9xOTmJpKZOpoLDcDwn333Ta3TqNKfRxqUjufAN9l3nbr+7e3ST+26NYCQkJIHg4OEUFCRTWZmBm1sE/v7xdt9dd7Q8aHf8AwIG271+a+5bCHHq0yll7crQ9hQVFeHn50dhYSG+vr7Oro4Qpz1bE8fWNMobywJZtEjrM9CUhQu1lBxb+6/fpo6JaUaDHgfa9C1t0NeUbemJW7tW62iBNuRlQW+oDAK3XPDfBjrT8fWSkqz3qK7ZN1iPpJpI3amZqKpho1wr39hdY0fKWpan3jZO7L6VMrJxY2yTwcgFF6RJI7mF5PothPNJQCCEaDajUev8a+suf83N5rQ06w3sOu3aRtlq19atR0tv0reYIw16R0/c8fI5HQ+Teh9UhNZ+5J4NneZBSFqM7fI19W9BJFXbMLb1aMd2w9iRsnVZv8sfQ6dOs+1o0Ld8344EI6Jpcv0WwvkkIBBCNLth7WiDvqZd3FT2SmPt2lbR3ANvxUioRXf4gZzvHiXF+5Xj+6vzgUl737PkEUKue9n2MQCqupKCX9+iMn8fbgFx+F98LzoXt0bL5OevZevWpr/0Pn2SGqSmOFK2PqWMzUpfaa19tyQYEfaR67cQzid9CIQ4w7Uk+8XRAWtaox+Aw1py4K00CUJOPKTeb+UO/1wIScbmiVPKSGrwIijH+hCYClKDvyBYzWz0bndL8vgd6VzbmqMENTcXvrX2Lbn0QojTmQQEQpzBbGW/1Az9aSv7pbXG8ne0Y29z7xabHT9wpVMU9Klzl377YXSNHXgrTIJQM+NufTUz7vZ8GkJsnDjzEJi2h4Y3D4FprdFsK5e+oiKdlJSRjaa+ONK51pmTXDVr30pBXp72H+DIkQY/denpBGRkgL8/9OoFvdZpP3v3ho4dLSJYpaCoSNtcXh7k52s/q6thyBAIDm71Q23UkSPw118wcCAEBp7cfQshTn2SMiTEGcqR7JfWTPmprjby66/J5OdnEBAQwcUXx+PiYsfssTmJpO6dTEVlnRQOt2g6dW78Trc5D/+sw9bv0jeWh+9gyo+qrmTjMi8qAm1MsmUC93wDFwwvtZrCk5W1iJ07m+6N3b37QsLCLHtjO5pL70jnWmd2zG1y3wrcC9244KFIdOkZUFHRov1U6D1I8+jBTkMvthp7samsF1tVb9KJov6X7eoK118PEyfC0KHgcoJuzVVUwHffwfz5sHw5mEzg6wsPPaQN63uqXCrl+i2E80lAIMQZytF+AA4OWAO0fCjInJxEUraPOL7DOh/U5NH3Wmq7/Nq15Ey/tPYuvbXyT0PIs1YO3MFOvY7mszs7j791RvppflmHKEXOptdIOfZI3d1p6n7fdaZuKPEI5qh7JBm6SP6timJfWSQHTVEcIZIMIgjmKL3Ybn71JAVPyq3uvgA/9rj14kC7XhwJ7MU2erNoX3/K8AK0p2i33aYFB926tc4hb9miBQGff649lagRHg6Zmdq/g4LgscfgvvvAy6t19ttScv0WwvkkZUiI00BLRttxNPvF0ZSflqavKGUk9Z87tZx5a3n0Jkj9506CLxtu/U53Rjqp9x9/Y6v8fRCckd7wJr7BQM5bY2s79datdzCkzICeJWMIsXHyHc1nd2Q8fnv3nZaWgb+/9Ynfaiaqsh7ENd651pGyzVZVRdXPyZR98Q3uPy0jJOsgPa3026g86sOWuSOZl3wVR4gknSgyiKCy3J367XudDkJDITISCIUjgcMoC4B9gfCrv5GY6jRiCrYRlrMd/8Pb8Urbjsu+3fgbCxlQuZ4BleshX9vW+y6u/BtyHt8VDGJ5xiDeeXkgL7/sxwUXaIHB6NHg59e8Qz56VAsA5s+HrVtrl0dFwbhxMGECdOoEX30FTz8Nu3fDo4/CrFnwxBNwxx3g7t6Sky2EOB3IEwIh2riWDonfWkN/tiTlx5H0lfzcNWzddkWT9e7TezUBQZc3WJ6/djZbmdp0eV4nYPAU6/Uut5HHr8DdI8Zm6osz7tJXVsIXX8CyZWt54IGm9z1lShLHjg3mhhvghhvgggsaBpct7rtRUzZvLZUF+3EL7IS//6BmpwkVF8O+fZYp/rn/lhCxdTlnH1jGwIIfCFD55vVL8WQFQ1mmv5603oG4BJWSmxvBtm3xmEwGfH21hn5UlO2f4eFaqk+zVFTAnj2wbRts3669/vpLq3QdJnRspQ/rGMQ6BvGnRzyDRoYycaL2f0+vt7756motFWj+fC01qKpKW+7mpn13EyfClVce//6qqrTHBa6uVLt48PlSD2Y8q+fAAa1M+/YwfTqMH3/iUphskeu3EM4nAYEQbVhrDInvSD+AlubxO9Iwzlr7FDt5vsmy3XmSsMHPNVielfE5O3ff2nT5rgsIi7jFYpmjDfrWyqW3ZwjMvDx49114803tKY9eb+SLL2IJDk5Hp2u4b6V0FBdHM3p0GuXltfsOCYHrrtMamFdcAZ6eTR6+bbt3a63Xzz7TGsVubtojrcZa4pGR4O1t3sTy5XDTTVBSAmFkch3fcQPfcDlr8KA2/z+HYL7XXc/64OHsO+sKgtt7Ndi0lc2feErBgQOwbl3tKzW1wWo76cY6BrEzeBAdbo3nxsntiY3VPtu1SzuNn34KmZmKQPKIIp1BcUe48fx0LuxwBK+8OtFSejpkZzf4j67c3anUe5Jf4ckxkydleKLcPQiL9SQkxhOdl6f2hde8PDzgqacgIKBVT4lcv4VwPgkIhGijHB0SH2oDCr3eSK9eyQQFZZCbG8H27dqd08YCCkfy+B3pHJu/9Cm2BjUdEPTJfZKAEQ0DAoeCEQfqXaO1cult3aXft09L2froIygt1daNjIQHHoDRoxP599/G9+3hkcDy5fDNN/DDD1BYWLuWl5fWCXb4cLj2Wi0PvUlFRfDll1oLdsMGOwpY4esLUVEUeEXy/d9RZBmDiXf5jfOqN6KvcxyFIXHkXnwDxutuwP+qCwkKNdi8u35KycjQcv7WrUOtW4du27YGqxygA3vCBpGrC0afmU4U6URyhEiOWARCJ6Wu4eGtukm5fgvhfBIQCHGKONmTg9X47rtEKisnExRUG1nk5kbj5jaH665rZPbXn8Oo0OfaHi1HBXHBZVnWU2ccSPtRa9ewMfsKKoLRcv6t7TsHLghbjW5ww5QhR9J+TtVJrpTS2tqzZsHXX9feCD77bG1EmTFjtJvxzd13VRX88gssW6YFCHWDT4NB2/bMmVZSWkwmreD8+bB0aW1kotfDVVfVDq9ja4jPuv8uKWn84AcM0CKU4cOhRw/rnR/amrw8+PVXqpKSKfxuHQH7/8KgjI2XCQ5uOu8pJET7bsrKGr7KyynLK+PbxWX8uLQMU2kZnpTROaac668oo0tMGbryMq0DQiv3QpbrtxDOJwGBEKeAlvQDWLQIbj5+s1qvN9K7d+0d/prcaICFC2Gs9ZvVNjv2NnW32tE8foca9UYjOSPDSJmUq1Vbb1kOHfR8M4iQr7JsRlTZ2Yns2DESpbBInzGZdOh08OabS/jzz4bHrdMZmTUrloCAdPR662k3paXR/PJLGgEBBgIDtTHfAwIw/zswEHx8AFqeh1+juloLAF57DX7/vXb5VVdpjfXLLrPePm5JHwCltNFraoKDf/7Rlk+YAO+/fzzv/N9/4ZNP4OOPtUdTNbp104KA226zfxKLGsXFpP2azkNjj9CuMJ2BsUf4zzWZuPbsoo3dGRXVvO21RSUlZH3zG6kf/4q7qZQug6Pw7V6noR8R0ao9ggsKtN+p2bNr47GLL4bnn4dLLmm13ZjJ9VsI55OAQAgna2k/gJonBPHxidx//2RCQ2ujiezsaObOnUNycoLNJwSOdOx1NI+fRYvIeftmbehPW436pyHkHhvRTGIiOXNG2B76c/LSBietulp7AlPToG3fvuF5y8qKYd682SQn275LHx+fyDPPaMFE3aCgJph4+ukljZb3oIwQfR4dfPNp752HuzsUuwRQaAik2CWAcp2n3Xe5s7Nr+6e6uWnt7alToWdPu4o75NNP4fbbwdVYxov9EpnkOx/D2p9rf5F9fLTvbuJEOP/8Ft+5P3hQa4weOgTnngs//9z8EXhqlJbuJj39bUpLdxIUdDWhobfg5naSZwhrQ3Jy4H//g3nzoPz4qEs//2zfk8nmkOu3EM4nAYEQraQld10dnRxs5MhEJk3S7vDXbW/VvdP91VcJVm+UOzSmvYN5/DXRTI6VoSDds4436pOxne904AA8+yzqi88p6FJZOznYTgO6ARdqwcB553Gs67ms+LWdOR++7pjsnp4wdKiRUaOSiY3NQK+PwGCw7y59VVUiFRWTUarOF1cahC45AbWpPbqCfAyFebiW5OFRmo9XRR4+VXn4mfJtjldfoxx38ggknwDyCLT4d/1lmYSTHtSHe+/Tce+9EBbWZNVbz59/kvbkBwSuWIQfRbXLL7tMCwISEhxOLcnO1lLn9uzRHjKsW6dlvTSHyVRNbu63pKe/RUHBGovPdDpXgoKuIzx8IoGBw9DrZSRua44cgRdegM2bYf1626MetZRcv4VwPgkIhGgFOTmJ7N07mco6o+24uUXTuYnRdhzpB6CUkZ9/jkWvP2z15qvJpEOpaC67zPqINQ7NeutgHn/dIY6UTjWc8VfVi4SUgr//1m7tL1tmOdA6aLeM6/Z+rdkNenbQg030ZxP92evXn7OGn821CW5ceaUd7VWTSctjT03VxrmseaWmotJSKehQbH2m4iYogwGjXyCV7QJQClyL83EpzkNvaiJP3IrqG0bg8uWiFoyJ6YCXXoLHHze/PaCLZb6awNY+4/lwTax9nY2bUFCg/d/4+29tSMxff4WYGPvLV1QcISPjA44ceY/KyvTjS/UEBV2Ln99AsrO/pKTkL/P6bm7hhIWNIzx8Iu3atdIMYacZo7Hp+U1aQq7fQjifBARCOCgnJ5Ht223fpe/Vy/aoMXX7ATTGWj8AZ8562xp5/E1OdfzFF9owNsuWaa+DB2vX0eu1W8fHO5Puqe7IikV57P/yT9rt2MR5x0OAKCzHewe03Jo+faB//9qXq6u5oV+30U9amjaWfGMiIrQZq+p2FKjfaaD+Zz4+DVNolNIStvPytFd+vvV/132/Y4fW8zchQTtfJyMomDkT/vtf7d+jR8Odd7Kp3WCGXa0nL09LV1q58vgEXi1UWgpDhmh3o8PCtFSvzp2bLqeUoqDgF44ceYujR79GqWoAXF1DiIi4g8jIO/Hw6GBev6TkHzIz55OVtYCqqqPm5b6+FxAePpHQ0NG4uLQwP0nYTa7fQjhfiwKCefPm8corr5CZmUmfPn148803GTBggNV1q6qqmDlzJp988gnp6el07dqV//3vfwwbNsy8jtFoZMaMGSxYsIDMzEwiIyOZMGECTz75JDo7807lD4pwBkfv0td9QtBYx2BrTwgcHQJTVVeycZkXFQFG23f58w1cMLwUnYtbw89bkMdvbRsNelMHBWmtyn/+0W4T1/D0hGHDtCDgmmsgOJgDB7ThNL//3nKz552nrTbyoiN0LdqE7s9NsOn4Kz+fZnFx0Z5mdOoEcXHaq+bfZ53l4MD8DvrpJ22CgMpKu4OC0tK9ZGZ+TFbWpxiNJYSF3UZk5D20a9e96f3VDQaef16b4va4HTu0SbCOHNFO1+rV2ilqrspK7btbvhz8/bX/I336NF6murqQzMzPOHLkLUpLd5qX+/ldTGTkvYSEJKDX2+50azJVkpv7A5mZ88nN/RHQntTo9Z6EhIwgPHwi/v6D0enawhimbY9cv4VwvmYHBIsXL2bcuHG88847nH/++cyePZuvvvqK3bt3Exoa2mD9xx57jAULFvD+++/TrVs3VqxYwYMPPsiGDRvo27cvAC+++CKzZs3ik08+oWfPnvz5559MnDiRF154gUmTJtlVL/mDIpwhN3ct27Y1fZe9d+8kgoIGN1hekznTsWMi993XsGPwvHlzSEtLsNqHwOEhMNeuJWf6pU137H22kXFLExMxTppEUXB6bepMfjS615uYJrmu/fth7lwt6klJqZ1uFWzOilVVBa+/DjNmaCMmurhogdUNN2gDz0RH29iXUtr+NtUJEDZv1pbXb+zX/Dsm5uRP3docdgQF1dXF5OR8RWbmfAoLf7W6GX//S4mMvJfg4OHo9VaCikaCgRoHDmhf07592lD1K1ZoQ5/ay2jUnoR99ZWWzrVqFVx0ke31S0q2kp7+NllZCzCZjgGg17cjPFwLcry9m7Hz4yoqMsnKWkBm5nxKS3eYl3t4xBIWNp7w8Al4esY2e7vCNrl+C+F8zQ4Izj//fPr378/cuXMBMJlMxMTE8MADDzBt2rQG60dGRvLEE09w3333mZeNGDECT09PFixYAMC1115LWFgYH374oc11miJ/UIQzrF27CLAj54eFDB5sfezP775LxNt7hDbQZ70JvpQOSkqWWp0PwOE7/MfzlZrs2FsvXyk72zyHEuvWwba/jVxMMhFkUBEQwWVPx3PH3QbboyCWlGhj1K9YAStWUFa0h51PgOcRiJsHbiFxWgP3hhvgwgsbREIbNsDdd0PN3E2XXAJvvw3d7bjBbVXNn8C2PH69laBAubhQWJhMZuZ8srO/MjeYQU9g4BDCwydiMPhy5Mg75OZ+hxYFgptbBBERdxIZeQfu7seH9LQjGKiRmalNMfDPP9od/h9/1L7GpigFd9wBH36oxTPff6+lDdVnNB4jJ+drjhx5h6Ki9eblXl49iIq6l7Cw23BxcfwaoJSiuPgPMjLmk539BUZjbR8Vb+9z8fHpj69vf3x8+uPl1eO075CslKK6ugBX19adpRjk+i3EqaBZf8EqKyv566+/eLxOZzK9Xs8VV1zBb7/9ZrVMRUUFHh4eFss8PT359dfau1QXXXQR7733Hnv27KFLly5s3bqVX3/9lVmzZjWnekI4rLrayK+/JpOfn0FAQAQXXxyPi4vtXnS5uRF2daDMzbU+9rpSRoK97tTmGa3fHtVrnVSDve5EqeENUo50v26g0xyjdoffhNU7/J3mGNEFbbB+h//4ePAhyRC8noYde493kM3SR7BqQW0AsHt3/Q0ZONJ5MAcqtWHov54CL78G06fD+PHgajBpnYBXrtSCgF9/NT8FKA+BrXOgPAKKekH+sGC69phNUPC1Daqbnw/TpsF772nvg4Lg1Ve1fTjUlm/LgUCNq67SOlzfcAPlyYlkvnoOmZdWUF6+z7yKp2dnwsMnEh4+rrahDwQFDaO8/CBHjrxHRsb7VFZm8O+/z/Dvv88THHwDUb/44//fD7VfzyaCAdCeDKxdq81kvGGD9sTgm2+0dCJblIJHH9WCAb1ei1XrBgMmUwW5uT+Rnf0FubnfYTJpE53pdC4EBycQFXUvfn6D7E4xtYdOp8PX93x8fc+nU6fXOXr0azIz55Ofv4aSks2UlGwmI+NdAPR6L7y9+5oDBB+f/nh6dmrV+jhTZWUOe/bcRXl5Guee+zt6vZUbDEKINq1ZAcHRo0cxGo2E1RvbLiwsjF27dlktM3ToUGbNmsWgQYOIi4tjzZo1JCYmYjTWjqYxbdo0ioqK6NatGwaDAaPRyAsvvMAtt9xisy4VFRVU1OnsV1RUZHNdIexRd8begOM3wZYta3zG3qCgeLKzowkOtj5RlcmkIycnmrCweKvlC/LWUmHItV0pPVSQS0He2oYTfGVkEJKspfU0uMOfU+cOf0aG9W3Hx2u5Nenp6EyKgHoD95jQkWmIJmZMPPUHzzn7bK34oEHaz4gI7eb0/Pnw3HNQcSiLX+5YScjUFQzRr8KzKNtyA7GxVAy/mK3XrabckHm88eRKaelOtm2/joiIO4mLew0XF2+U0h5SPPig9nQCtFEtX35Zm5xVgNFYztFzC8n8sRf5us2g3wHlYNB7ExI6ioiI2/H1vchmA9XDoz0dOz5PbOx0cnISOXLkLQoLkzl6dClHe4LXxxBpvIaw2+7Dnm7LAQFa/JeQoP285hqtkT9ihPX1Z87UgjvQJjkbMUIbLrSgYA3Z2V+Qk/O1xR16D484wsPHERFxB+7uzZzorAUMBk/Cwm4mLOxmKirSKSz8jeLiTcdff2I0FlNUtN7iiYWLiz8+PueZAwQfn/64u0e1uSDh6NFv2b37DqqqstHpXCkq+g1//xMwO5kQwqlO+DPOOXPmcMcdd9CtWzd0Oh1xcXFMnDiRjz76yLzOl19+yeeff87ChQvp2bMnf//9N1OmTCEyMpLx48db3e7MmTN55plnTnT1xRlCS9tpOGNvQEA6Ot1IvvtuidWgID7ewMiRc5g0aSQmk87qRFWLF8/mq6+sP2Wo3LbWrvpVblsL9YfvtPMOv82ZYQ0GbSrkkSNROh26OtmDpuOPK+43zkZnMDCgn9b4HzQIBg7UBsuxUF2N26/ruGv/Cu4IWoE+/Xh0cXyW01J9Owr7Xkr4+KHohg6hsoM/W7deSllpJh4esfTp8zOursGkpf2Xw4dnk5HxHvn5q/H2/pSpUweyerW2ne7d4Z13tHqcCkymKioqDqLTuaDXex5/eVjPwW+l/ZlMZZhM5ZhMZVRUpJOVtYDs7EVUVxfA8V8zv606In5ShPhdhmHBO3aPPqTXuxEWNoawsDGUzJnCkQNzyLoSSjtAKj+w/7cowsJuITLyXnx8zml0W+3awbffapOlffUVjBqlNfZvv91yvXnzah86zJplIiHhV/bs+YKcnK8sRv5xc4siNHQ0oaFj8fHp57SGtbt7FKGhIwkN1UbIUspEaeluc4BQVLSJkpK/qa4uID9/Nfn5q+scQzi+vhdx1lkvnPJDm1ZXF5GaOpXMTO1a3a5dL7p1+6zJ710I0TY1qw9BZWUlXl5eLFmyhBtuuMG8fPz48RQUFLBs2TKbZcvLy8nNzSUyMpJp06bx/fffk5KSAkBMTAzTpk2z6Gfw/PPPs2DBAptPHqw9IYiJiZEcxDOc0ajlt2dkaO3g+Pimx82urjaybFksgYG2RwrKz49m+PA0q+lDiYkwZ461TsHarLeTJyfY7F/r0ARfdcbybzDNMTQ+q1kdW55KJPTFyUSZ6szY6x7Dz9fNJuSuBC64ALy9G6nczp1aH4N6cwMY+/Tld/+hvPjnUFYeu4gq3Dj3XHjuuTxCQi7j2LGtuLtHc8456/D0PMtcLj8/iZ07x1NZeQijUc8XXzzK4sUzmDbNnYcf1kYNdQalTJSV7aWoaJO58VdSsgWTydpEYwYMBs86QYIWKNRfZjBonaSNxrLjDX3tpb0vb7CsZvQba9zdYwgPn0B4+Hg81+6p7VMwYoR2e745Q5LWmWegeuaTZN0WQXr6W5SWpphX8fW9AD+/eNzcInF3j8LdPRI3tyjc3SMsRvQxGrU+Hx98oL1/9VV46CHt3wsWwG23Kbp2/ZP//vcLOnVaXGfOAHB1DSYk5CZCQ8fi5zewzYzyYzJVcuzYdnOAUFy8iWPHUqj5/gwGP3r0+IKgoGGNb8hJCgrWsWvXeMrLDwA6YmIeIjb2OQwGj6aKtoj0IRDC+VrUqXjAgAG8+eabgNapuH379tx///1WOxXXV1VVRffu3Rk1ahQvvvgiAEFBQTz//PPcc8895vVmzpzJ/Pnz2bNnj131kj8owtoIltHR2k3wxga8Wbt2LWDH7GAkMdjGaDuJiTBlipHAwNphQ/Pz43n9dUOj+3Z4gq+mxvJfssTmwRuN2ig9L7wAOmXk9k7JTB2bQaeLI3C73I5ISimtlTd5sjbUj7+/NiLQ0KFawvjxUccKCmDWLG1UIKUKefXVK+jW7U+UCuf883/By6uLxWaTkmDq1EKuumoSQ4d+CoCr69n06bMAb+/ejdeplSilqKg4ZNGgKy7+yyJtpYZerzWSrAcGJ45O547B4G3uIBwQcJllP5O6HY2bExTUnXSsTp8BpRSFhcmkp7/F0aNLzWP8W+PqGmwOFGp+fv99JAsXRpGbG8ktt0TRr18Oy5Z9weDBXxAVVdvXwWDwJSQkgdDQsfj7X3badNY1GkspKdnC/v3Tjo/0pCcu7jWioyefMmlERmM5aWlPcvjwLEDh4RFLt26f4O9/Yh/JyfVbCOdr0bCj48eP591332XAgAHMnj2bL7/8kl27dhEWFsa4ceOIiopi5syZAPz++++kp6dzzjnnkJ6ezowZM0hLS2Pz5s34+/sDMGHCBFavXs27775Lz5492bJlC3feeSe33347//vf/+yql/xBObPVtIt1Osux/Ldv18byb6RdzNdfLyIgoOmRgvLzF3LjjdZHCoKWPZ1otQm+6kdCMTEwe7bNg87M1CZES0rS3t9zj9Zo97D3BmB+Ptx5pxZwgNZz9NNPbacnAVlZJaxfP5TAwA0UFAQzdepa4uJ68vzzcMEFkJMDDz+sbQa0zqlvv51ISMhdVFUdRadz46yznicm5kGrczo4orIyxyLlo7h4E1VV2Q3W0+s98Pbua84J9/Xtj6dnZ3Q6PUqZMJkqLFJ6LO/8W18GqsFTAy3tqLGnC+723S1vblBQNxh47jl48kmrq1VUZJKT8xXl5fupqDhCRUU6lZXaT6Uqm65Xg/PqSVDQ9YSFjSUgYOgJuxN9KjCZKtmz5x5zKk54+H/o0uUtp3fULS7+m127buPYse3menXqNKtVRmxqily/hXC+Fk1MNnfuXPPEZOeccw5vvPEG559/PgCDBw8mNjaWjz/+GIBffvmFe+65h/379+Pt7c3VV1/NSy+9RGSdaSyLi4t56qmn+Prrr8nOziYyMpKxY8cyffp03OzMD5A/KGeumsyZs85K5P77mzeWP7TOEwKHJCaSPXsEqfdDZb2hP+PegtDGJviqqkL9toG8P9/isMcPVHpX0vXgKHwf+RBb436uXatl+GRmanne771n32zJZr/+Crfcos0c7OKiPWJ4+GFteBgbjMZStm27hoKCtej1/qxYkcQrr5xjnnLgiiu06QDy8rSHG/fco23W319rfO7Zcwe5udrsY35+8XTr9olFmlFzKKUoK0ulsDCZgoJ1FBauo7w8zcqaBry9e1t0Cm3XrucJ6x9wwtgbFNgZDDRGG5oyj4qKdCoqjlBZmd4gYCgoOIJen4XR6MLBg1dx9dVjCQm5FheXxvLSTi9KKQ4fnsO+fQ8BJvz84unZcylubiEnvS4mUzWHDr3MgQMzUKoKV9dQunZ9n+Dg609aHeT6LYTztSggOBXJH5TTQ0vusq9dC9OnJ/LMM1qn4LpP32s69j799BKefTbB6uibNX0IAgJsjxTUWB8CR61cCR9ck8irpkn49K6d4KtoWzQzg+Yw9N0EbrihzuiY+/bBypUYV/9IFqs4fF0FpbG129NVQpdFoURc+TqMGWNuqJtMWpvvqae0f/fsqd3g72Zv38bqaq2V/uyz2gbi4rTGZf/+jRYzmSrYtu168vNXYjD40KfPGnx9+/Pvv9qmPvlE+95Bm5H23Xfh+P0FM6UUmZkfkZo6BaOxBIPBm06dZhMefnuT6RZKmTh2LIXCwnXmAKCyMrPBep6eXS2GjfT2Psec49/mNRUUtEIw0BwrV1axebOJKVPc7X8qdRrKzV3Ojh2jMRqLcHfvQO/e3520tDiA0tJUdu0aR1GRNmx4cPANdOny3kkPTOT6LYTzSUAgThkt7QOwaJERgyGWkBDbnYJzcqIxmdIYO9Z6g37JkkSCgkaiFFZHCiopsT7KkKN++UUbQr6sDEbcYOSL+5IxZGeQtCuCiR/FczDdgDfFTO2TxJTuKwjctILKo/s4MhzSh0PV8dF+DJUuRJRdTpk6TK6/1vEzchl0SuqB/unnyY2/gdvG6fjpJ239cePgrbe0JwR2OXgQbr1Vi9ZAGzpm3jzw8Wm0mMlUSUrKSHJzv0Ov9+Lss1fg73+xxTp79mjfcbdu2pOBxiYFLitLY9eu8RQWavUICrqOrl3fx82tdihkk6mKkpIt5sZ/YeGvVFfnW2xHp3PD13cAfn6D8POLx9f3Alxd/e08GW2UraDgJAcDwtKxYzvZvv16yspSMRi86d798xN+d14pxZEj77Jv30OYTKUYDD507vwmYWHjnNKfQa7fQjifBATilFDTB6D+b6MdfWMdSvnJy4M33tBe/+n1KNffPwtjaO1ILi7ZBnSHHmTgQy83vflmPt7YsEGbfOnYMW2c9sTE4yPomEyweTOV368kff4Kog9uwJVqSmPg0E2QNQRMx7OB3HVhRJ/1MBGRd+Di4odSJv7d+zQH0l8AncJ3O/ScAbuKzuPRqudZ5z6EeW/pmDixGfNxLV0K//d/Wu9gb29tWuBbb22ymMlUzc6dY8nJWYJe70Hv3j8QEHCZnTu1TSkjhw69TlraEyhViatrMGed9TyVldkUFiZTWLihzqy8Gr2+HX5+F+LnNwh//0H4+Aw4fe7+N0f9oODcc2vH/JRgwGmqqvJISRlFQcEaQMdZZ71A+/bTTkjjvKIig927/0NennZ3wN9/MN26fYyHR4dW35e95PothPNJQCCcrqYPQN0nA3U1NXpmRsYidu9uOgm+a9eFRERonYKzsrRRb+bNg5ISuJFEljAS9IrCOuP5+24DvUmHbmkjEQk0+/HGn3/C5ZdDURFccbni+1d34f77Oi3/afVqOKqNv66Agj6QerMXxwaUmsuXl5/HOec8RGjoCKs57bm5P7IjZSxGUxGuuTp6zVD4bYeSc+Pxfv15+wbyLy2FqVNrpwYeMECbISwursmiShnZtWsCWVkL0Onc6NVrWasPsVhSso2dO2/j2LGtDT5zcQnAz+9icwDg7d237eX+nyh1g4IaEgw4nclURWrqVI4cmQdAaOgtdO36Qat1sFZKkZPzFXv23EN1dR46nTsdO848PsqRc4dzleu3EM4nAYFodc3tB7B2LVx6/Aa/Xm85StC2bdooQaCNiGOtD0D+oe/Yuq/pR+x9Mh/j2MCZvPKqjvfeg/Ljo0Se09vI+vRYPPMOY+1+nAkdpYHReGfbiEia+Xjjny1GJl2ylXOK15EQtI54ktHlHrUoavL3Jueurhy6JJsSz0MAKKXjn3+u46OPHuKff+I57zwdb76pjdBTX0EBTJ2aSnz8jXTsuB1l1NP5bT1RS6u1Y7zySm1IyQEDrJ+sf/7R+h/s3Kkdx2OPaQn/dgxbqZSJPXvuIiPjA3Q6F3r2XEJw8PAmy7WEyVTBgQPPkZu7DC+vHvj7D8LPbxDt2vV0eiPnlFY3KJBg4JSSnv42e/c+ABjx8RlAr17ftHg25qqqAgoKfiYvbwV5eSuoqPgXAG/vvnTv/hnt2vVsxZq3nFy/hXA+CQhEq2pJP4BFi7RRbuLjrY8SNHfuHJKTE1i4UBsdx8LRo6ghV7Bx2tZGx/J3y4ELb4aVaih3qPc4RHsGDNDaQdd6r0V3WdMpRx/emsTtnw62TLWx5/FGVBR8/jmsX0/JT8mYfl2PryqyXM/TEy64gKpL+5MxqJh01++oqNS2qdd7Eh4+nujoqbi4dGHuXG3+gOJirej48VoaeHi49n7zZrjpJti/H3x8Svjss//g5/clAOFpXel8XyqGsuNpUddfrzUIzz5be68UzJ0LjzwCFRXaRj/7TBsGyA5KKfbufeD4XU49PXosIjR0lF1lxUm2fbsWtV95pbNrIurJz/+ZlJSRVFfn4+YWRe/ey/Dx6ddkOaWMFBVtIj9/JXl5Kygq+p26k9npdO60b/8IHTo85fRhTuuS67cQzicBgWg1Le0H0OJRgjIztYZqSgoHJ7Zj/zjLvPG6jm6O4+rHDuFVXUmpwZt/732Zbq/fhc6gr41ImjCWhejGjmX+/DojetZ9vNEMxQY/PC4biOvlg1Dx8RR1qSTj6AJychZjNJYA4OoaRlTU/URG3o2bW7BF+cxM+O9/Yf587b2PD0yfrnUSnjpVa8t36ABffQXnnac4dOg19u9/DDDh7daLXgu74fF2otZfAWD0aC2SmzkTvvtOW3bNNdoOQuwbcUQpxf79j3Lo0KuAjm7dPiE8/LZmnxshhDYC0Pbt11NauhO93pNu3T4hNPSmBuuVlx8iL28F+fkryc9f3aADvadnVwIDhxIYOBR//0swGOwdSeDkkeu3EM4nAYFoFY70A6gZ9jMw0PYoQQ2G/Tx8WEvC37MHY4cI/vrMi1LjPvR6D4sZY4uLA2jXrhC93kTGvgsY8p4i6I/ftQ8vuUSbaffwYbsa9Zfrk/jZNJiLL4ZvvoGgIOwOJkzeviw3XsnyskEciRvEuxt64+2XSWbmp2RmfkxZWe2M3F5ePYmJeZDQ0JubzB/+/XeYNAn++MNy+XXXwccfQ2Bg7bK8vNXs2DGG6upcXF2D6eH9KgEzf4LFiy0Lu7nBq6/C/fc3o+cxpKVN599/nwOgS5f3iIy8w+6yQoiGqqsL2bFjrLkDcIcOT9O+/SMUFKwzBwGlpTstyhgMfgQEXHE8CBji1M7C9pLrtxDOJwGBaBWO9APIz1/L1q1NN8j79EkiIGAwHDiA6dLL0B9Iozy0Pb+8eQnuoZ9RXh7OogV/0b7wS1TpPg7nxvH5tnu574E13HDDKKAEL68e9N4yCs+HXtGG9/H01FJmXn8djhxp+HgDzNHM6vfTGDHKQFERxMceYskdKwhduUAbO7QJN4f/zKLMS+nZs4Kvv/6WsrL55OWtQJuOWBsFJzT0JsLDJ+LnF9+s0UVMJm0s/2nTIDdXu8n/8MPW2/JlZQdISUmgpGQLYCAu7mWicy9D9/TT8O232tifX3yhTQjQhKqqfIqL/6S4eBOFhevJy/sRgE6d3iA6+gG76y+EsE0pI/v2Pcbhw68dX6Kn5u9GzXtf3/MJCBhCYOBQfHz6o9c3MnbvKUiu30I4nwQEolU40g8gK2sRO3c2fZc9MXEhu78/jw8OXE6MOkQqcUwd8CQP/W8iAN88+iQPbfqYGGr3XRkWjdtbcyi+siPbtl1LZWU6rq5h9A56B9/758KaNdqKXbpoA+LrdJZBQU2resECCAggd+EK8r9YQafqXXadF6XTkWGI5tLYRG4a/SlDhnyOyZRn/tzP72LCw28nJGQkLi6Nj+nflLIybdSisLDG1zMay9iz526ysj4FIDR0jDaayZE8rc+AlY7DRmMpJSVbKCraRHHxHxQXb6KsLLXBeh07vkz79o84dBxCiIYyMuazZ89dKFWFu3t7AgOHEhAwhICAy3F1DXB29Rwi128hnE8CAtEqHJkt2N4nBK9Pmc/bW/9LJBnspBu3RX7BU28Nxc8vi6Mbr2bE4z9p+65bqE4HhvKrB7Bt27UcO7YVvd6T7t0XELIsDx56SGtJu7iAl5f27xp+ftC+PezebTFMoxE9v3M+qw1DGX6TO32+eLxBMFHpB1lXwMZhsYR0OmBe7uYWRXj4eMLDJ+Dl1bnJ4z4RlFKkp89l374HUaqadu3OplevRDw94zCZqjh2bBvFxZuOBwCbOHYshbqdE2t4eHTEx6c/vr798fcfbFfHRyFEy5SVpaFUFZ6enZ0ygdiJItdvIZxPAgLRKlrUD+A4pYxs3BhLRUU62sj71Ptch7EslIE3G/EsPEpFl95U/rCSA2V3kpv7HV5ePek3pgBDWrr1ytXpwFCtStmxY/TxnFwdcXGvEc1IdPfcAz/8oK0fE6MN4VNQYLmd9u1h6FAYOpRjF1zOLff5s2yZ9tGSmxNJWDcZdeQw+QMgYxgcvQgw32x3IyTkBsLDJxIYeCU6XSPjsJ5EBQXJpKTcRFVVFi4uAXh6dqGk5G+UqmiwrptbBD4+/c0BgI/Pebi6Bjmh1kKI04lcv4VwPgkIRANKGSkoSKayMgM3twj8/eObbMA2ux9APTk5iaSkjMRkAr2+7q+kDlD0/F87QpYf02ZWXbmSIxVL2LPnbnQ6N/qpt/C+9P+aPrDjHRhMpmpSUydx5MjbAERG3kenTq+jX/Sl1kM373hKj5eX1jFiyBAtEOjSxSIx32jUcvU///wQ/fuvYNRNK4jrsIJqXbF5nX37+nHOORM5++yxuLoGciqqqEhn+/YRFBf/bl7m4hKAj895FgGAu3uUE2sphDhdyfVbCOdrWz2PxAmXk5NIaupkKipq8/Dd3aPp1GkOISG2Z+qtrMywa/u21gsKSmDp0iXEx1v2P3AnhE4ziwlZeUybgeunnyh1yyI1ZSoAHTvOxPtXL7v2TYa2b73ehc6d5+Hp2Yl9+x7myJF5lJcfoMfoL3C54gqtc21cHAwcWGd80VpGYykFBb+Ql7eCsWNXMnx47Sgf1cCxY8H8+OOt/PbbRD755Gx697aves7i7h5F376/kJ39FTqdAR+f/nh6xp1WKQlCCCGEsE0CAmFWc5e+ftpORUU6KSkj6dlzic2gwM3Nvpk0ba33xhswd24CH300nA0bkgkPz8BtZxb+1z+BrrgMBg2C77/H1M6dHZtvwWQqIyDgCqKjp0DEOvsOMKJ23zqdjpiYB/HwiGXnzlvJy/uBv/+Op3fv73G/w3K4TKUUx479Q16eNtlPYWEySlXWWUOP0Xg+X3wxlPXrh7J7d398fAz8/DOnfDBQQ693Jzz8VmdXQwghhBBOIClDAqibx29jIgF0uLtHc8EFaVbTh5rqB9BY+W3boH9/bTKtefPg3nuBlSth+HAoL9cmH1u2DLy82L//vxw8OBMXl0D69/9HS2OpmQQhPb3RYUOtToIAFBX9wbZt11FVlY2bWxRnn/0Dbm4R5OevIi9vJfn5K6mszLQoUzPKhzbZz+W4uvqzebM28W9JCSxfrj3QEEII0Ti5fgvhfPKEQABa51LbwQCAoqLiEAUFyVb7AOh0Bjp1mnP8CYOW91/nUwA6dZrdIBgoL9eGK62o0CbGvefmQnjlPXjySW1Un2uu0aY49vCgoGAdBw++BEDXru/V5rQbDDBnjjZNsq1hQ2fPthoMAPj6DuDcczeybds1lJbu5K+/BtR7AgB6vRf+/pcSGKiN9e3p2aVBSs2558L+/dqx+Dg2gqgQQgghxEkjAcFpyt6OwUqZKCnZwsGDb9u13bKyvVYDAoCQkAR69lxiow/CbKvpRo8/Dtu3Q9/Af1kcPQdd+w+0EX4AEhK0CQ7c3KiqKmDnztsARXj4REJCRlhuKCFBCxwmT7acLjk6WgsGEmz3fwDw9DyLvn3Xk5IygoKCJAC8vc8xT/bj5zcQvb5hf4L63Ny0lxBCCCFEWyEpQ6chax2D3dyiCQ+fQ05OAmlpRygsXIWLywrCw1fRrt3RZmzdQGDgMEJDxxAcPNzqZFr2BiMrV8KTQ//gIV7jJv1S9Kbj49z37AkPPgjjxmlzAwA7dtxCdvZCPDziOO+8LbYn8TIaITlZ60AcEQHx8TafDFhjMlVRWJiMl1cP3N3D7S4nhBCiZeT6LYTzSUBwmrHVMdhk0rJnsrLaEx5+0OKzY8d8+PvvSzn77HW0a1eAXt9wuyYTmEyuuLhUmZfp9R4EBV1LaOgYAgOvxmDwtK+SRiNFn3/Hzv97jfOrfq1dfuWV2h1+Ly/IzDQ36LOOLmbnzlsAA337/oqfnyTnCyHE6UKu30I4n6QMnUaUMpKaOhlrnXprGvnh4QdRSkdubj/KyobSrt1QYmIu4OyzXXnlFW2m4fpzAdTMNPzss1/w7LPd6dBhMdnZiygr20NOzhJycpZgMPgQHHwDoaFjCAi4Er3etUEdOHYMPv4YNXs2vqmpnA9U4or+lptxefRBSE2Fu++2SPkp7xPOnllFoIfY2KckGBBCCCGEaGXyhOA0Yu/kYD17fkNIyHCLZYsWaZ174+MTuf9+y7kAsrJimDdvNsnJCTzyCLz8sjYUZ0nJ32Rnf0F29hdUVNQ+dXBxCSQkZCRBQdfi49Mf9zwFc+fCO++YJ/3KI4D39Xdz9Y/303toJCQmap2C6/w6Kj38/ToUng2+VV055/Lt6PUSwwohxOlErt9COJ+0rk4j//5r3+RgJlNpg2U1Q/QnJyewfv1wevdOJigog9zcCLZti8dk0vLwZ82Cvn1h7FgdPj598fHpS8eOMykq2ng8OPiSqqosMjLeIyPjPQDcc8DHHXyGgWdeOK/9PpW5+ffx9Mx29B6Klvc/eXKDIUMPjtGCAUMpdH+qCP0fMlGWEEIIIURrkycEp4nff4dHH13LM880/YSgT5+kBiMFNTWUP2ip/aWlWl+EefPgnnsarqPKjlHw00yyD3xMYUA6pe0BK316c3M7061bf3x9++O7z4D3sEkYKmo/L+oCW+aBcoGuL0HECiApCQYPbrgxIYQQbdaZfv0W4lQgTwhOAz/+CDfdBOXl8ZSUBOHtnWtjTW1yMH//+Aaf2DOU/yefaG3yt97SJg/Lz9eGDdWh4M8/Yf58dIsWEVBQQACAXk/16OGU3D+E4phjbNiwierqTURF7ScoaC85OXvJyVmobfwHaHcAfHaB7244NFILBkLWQviK4xXJsO8JiBBCCCGEsJ8EBG3c/Plwxx3aHf5rry3D319HdbW1NW1PDlbDnqH8R4yAwEB4/nmY/UQ2vVct4Nqj89Ft315boH17GD8ebr8dl9hY/IGU9VofBZMJFi/O5Yor/qSoaBPFxZsozl1PpSGXY3FwLA4yr9E245YDXWbV1JzavCYhhBBCCNFqJGWojVIKXnxRm9AXtCH7//vfqWRkzMbVNRRwoarqiHl9d/cYm5OD1dfoUP5VVfDjj6Q+MZ8OKT/gihZ9KA8PdAkJMHEiXHIJrF9v3kBRn3j6nGvgwAG47Tb49NOGO6zoG0ORXwbFXaG4K1SEaMGA/za0RxTR0ZCW1qw5BYQQQpz6zrTrtxCnInlC0AYZjTBpkpa6AzBtGjz++F9s3vwGAHl5n3LffVcQGFjbMTgvL57Zsw1NTdgLaG3uBqn6KSna44jPPoPsbDodX/w7A/iI2ym7cjTvf+SP+w+J0LGjxSOGKq9o+pbOgdgE5s61vkP3GXMJGTmSkPVYz1eaPVuCASGEEEKIE0CeELQx5eVwyy3aKJ06nZb3f9991WzePICSki1UVIzlqqsWNugYXNOuXrIEu4ICAAoKtPFI58+HTZtql4eFabf6J05k6c4e3HwzVFbCM30Seeqfkejq7dx0POln9wtL6P7fRnaemNgwXykmpjZfSQghxGnnTLl+C3Eqk4DgFKWUkYKCZCorM3Bzi8DfP56CAgM33ADr1oGbGyxYoHUmPnRoFvv2PYSLiz933bWLHTvCrG7T7swboxGeeUabcKDi+NA/Li5w3XVaStCwYeBaO/HYqlUw4gYjKaWxRHEYKxMdo9Chi7Fj543mKwkhhDjdnG7XbyHaIkkZOgXl5CSSmjqZioraO+UGQzTvvDOHdesS8PWFZcu0tJ6ysgOkpT0FQHX1qzaDAdAycQ4d0trbNkfvzMvTev+uOD60T+/eWhBwyy0QGmq1yJVXwsZXkom577DVz+H4SERN7hwb+UpCCCGEEOJEkYDgFJOTk0hKykjA8sFNVVU6//d/IykpWcJzzyVw9tnabMF7996HyVSKn98gdu263a592By9c+tWuPFG7S6+uzv83/9pwwoNGtTkXfoeAXYOCSpDhwohhBBCnFKsZXcIJ1HKSGrqZOoHAwB6vbbs4Yen0Lu3EYCcnK/Iy/sRnc6NLl3eJSLCvpl8rY7euWgRXHhhbUpPRYU2+9hll2kzliUmtmCjDqwnhBBCCCFOCgkITiEFBckWaUL16XQKo/EQBQXJVFXls3fvJAA6dPgv7dp1Iz5e6yOgsxEX6HRaH934uvOSVVfDgw9qaUJlZdoyo9GyYHq6NmNZY0FBi3YuhBBCCCGcTQKCU0hFhX3pNJWVGezfP42qqiy8vLrRvv00oHa2YWjYLrc6emd2ttYB4PXXtfc+PtZ3WNPvfMqUhsFCjWbvXAghhBBCnAokIDgFHDgAM2bAhAn2pdNUVh4lI+M9ALp0eRe93t38Wc1sw1FRlmWio+sNObppE/TrB2vXgre3NqpQcbHtndbtkWyL3TsXQgghhBCnCulU7CSlpbB0qTbEf1KStkyvj+f//i+aoKB0dDpro8HqcHOLIiPjbQDCw/+Dv/+gBmslJMDw4Y2M3vnRR3DvvVo/gS5d4OuvtQ7F9miqU3CTOxdCCCGEEKcSCQhOIqVg40YtCPjii9ob8jodXH45TJxo4MIL57Bnz0hMJp25IzGAyaRDpwM/v4vJyfkCV9dQ4uJetrkvq6N3VlZqE3+98472/vrr4dNPwc9PSx+yhz2dgmXoUCGEEEKINkMCgpPgyBH47DP4+GPYtat2+VlnaUP8jxsHHTpoyxITE5gzZwn33TeZ0NDaDsZHj0bzxReP8sADD6PTQadOs3F1DWxeJW66CTZs0CKQZ56BJ54A/fGssZpOwenpNJjmGGpnNZNOwUII0WxGo5Hk5GQyMjKIiIggPj4ew0l8curI/p1ddyHEiScBwQlUWAi33w7ffAMmk7bMy0sbsGfiRG14f32dXhxGo3YD//DhBH79dTi9eycTFJRBbm4E27ZdzKuvDkGnqyAgYCihoWPsr8j69dpOMzO1pwELF8LVV1uuU9MpeORIrfFfNyiQTsFCCNHihnFiYiKTJ0/m8OHamzzR0dHMmTOHBDv7VjnSKHdk/61RdyFEG6BOE4WFhQpQhYWFzq6K2SOPKKW1rJUaOFCpDz5QqqjI9vpJSbXr138NHTpfJSWhfvrJUyUl7bevAiaTUvPmKeXiom2kVy+l9u5tvMzSpUpFR1vuPCZGWy6EEG1YdXW1SkpKUgsXLlRJSUmqurra7rJLly5V0dHRCm2iGAWo6OhotbSJv41Lly5VOq1TmMVLp9MpnU7XZHlH9u3o/luj7vY4Fa/fQpxpJCA4QXJzlfL21trTS5bYV2bhQuvBgJ9ftvrmm0CVlIQaPfpltXChHRtLS1PqtttqNzJqlFLFxfZVpLpai04WLtR+NuOiKYQQjXGkUe5IeWc0qqurqxvss375mJiYRo/BkUa5I/tvjbrb61S7fgtxJmpRQDB37lzVoUMH5e7urgYMGKB+//13m+tWVlaqZ555RnXs2FG5u7urs88+W/30008W63To0MHqH5x7773X7jqdan9QnnlGKb2+Wt155/sqI+NTVVS0RVVXlzVaxtYTgscfv1UlJaHef7+PMhgqVVKSjQ0YjUr9+KNS116rlE6nFdbplLrrLqWqqlr7EIUQZyhnNModKe+sRnVSUpLNcnVfSTb+qDvaKHdk/47WvTlOteu3EGeiZgcEX3zxhXJzc1MfffSRSklJUXfccYfy9/dXWVlZVtd/9NFHVWRkpPrhhx/Uvn371FtvvaU8PDzU5s2bzetkZ2erjIwM82vVqlXN/kNzKv1BKS5WKjBQqZtuek0lJVHnpVcbN3ZV27aNUGlpM1R29hJ17NguZTRqjfXqai1bp6YtD0r167dSJSWh1qzRqe7df1cxMVZu2B89qtTLLyvVsaPtnKPoaEn7EUIopdpm6oyz7tI70jBeuHChXWUX2njs62ij3JH9O1r35jiVrt9CnKmaHRAMGDBA3Xfffeb3RqNRRUZGqpkzZ1pdPyIiQs2dO9diWUJCgrrlllts7mPy5MkqLi5OmUwmu+t1Kv1BmTVLKXf3Y2rZslCVlIT6449eKjk5oF5wUPtau9Zdbdp0jtqx41b1ww//Uxdc8IMKC/tXubsfUwsWdFRJSaj775+kdLo6bXqTSanff1dq/Hil3N1rG/5eXtYDAp1OWW5ACOGokpIStXLlSlVaWnrS930mpc448y69Iw1jZ+7b0f3LEwIhzizNCggqKiqUwWBQX3/9tcXycePGqeuvv95qmcDAQPXBBx9YLLvllltUhw4dbO4jKChIvfDCC82p2inzB6W8XKnIyNqnA7/9FquMxkplMplUeXm6ys1doQ4efE3t3DlR/flnf/XLL142A4UVK9xUUhJq8eJo1blzkdaWP3ZMqQ8/VKpfP8sGf9++Sr33nrZzawFBTVBg9RGDEKK5Vq9erc466ywFqNjYWJWYmNismxht7S69MxvlbfUufc05s3bO7QmEWivlqCX7d7TuzXGqXL+FOJM1KyBIT09XgNqwYYPF8kceeUQNGDDAapmxY8eqHj16qD179iij0ahWrlypPD09lZubm9X1Fy9erAwGg0pPT2+0LuXl5aqwsND8OnTo0CnxB+X997WnA998oz0d2Lv3YZWZuVDl5SUpk6nhH06TyahKS1NVTs436sCB51VKyhj1xx+91Nq1LnWCg2WqesdupaZOVcrfv7aB7+6u1LhxSm3cqD0xaGyYorqvVrijI8TpoCWN8oKCAnXnnXdaNIxq/n3llVeqHTt2NLmNtniX3pmNcmfepXe0YVzzfdUv35wgzJFGuSP7d6Rsc0hAIITznfCAIDs7Ww0fPlzp9XplMBhUly5d1L333qs8PDysrj9kyBB17bXXNlmXp59+2uofSGf+QamuVqpTp7p9BwwWd/w3bIhW2dn2/QE1GitUccEWVbzsdaWuvNKyQX/WWVqfgZwcy0K2himq/2qFnE8h2rqWNMq///57FRUV1WjD0sXFRU2dOlUVFBTY3G9bvEvvzEa5M+/SK+V4w9ja71pMTEyzAkBHGuWO7r+lZe0lAYEQznfCU4ZqlJWVqcOHDyuTyaQeffRR1aNHjwbrHDhwQOn1evXNN980WZdT8QnBF19oTwe+/97PRhqQTiUl6ZoOCoqKtI4IHTpYpvtce602ipDRaL2cPCEQbZTR1u90ExzJo29Oozw3N1fddtttdjVKa16hoaHqww8/tDg2Z96l/+ijj+wqO3HiRFVSUtKq+3a0Ue7Mu/R1t+FIw7i1U8Sa2yh3ZP+ODhXbFAkIhHC+FnUqvv/++83vjUajioqKstmpuL7KykoVFxenHn/88QafPf300yo8PFxVtWCITGf/QTGZlDr7bKVGjXrFZp+AmqBgw4YYq+lD6uBBpR5+WClf39rGe3CwUtOmafMKNMXaMEV1X9KHQJyCvv76axUcHKwGDBig/vzzT7vLtTTtprmN8iVLlqiwsDDzZ97e3o2WDQ4OVl27djUv69+/v9q4caNSynl36VevXq0iIiLsDmYCAwPVf//7X3XkyJEG581ZjXJn3qVXSrvGrFq1St19991q5MiR6q677lJz5sxRH3zwgfr888/V0qVL1Y8//qiSkpLUxo0b1datW9WePXvUwYMHVU5OjiopKWlx4KvUiW+UO5Ozr99CiBYOO+ru7q4+/vhjtWPHDnXnnXcqf39/lZmZqZRS6rbbblPTpk0zr79x40a1dOlStW/fPrVu3Tp12WWXqbPOOkvl5+dbbNdoNKr27durxx57rEUH4uw/KN9/rz0d+PZb26MJ1X3l5SXVFv7zT6Vuvrl2RmFQqls3rZNwc0cvWbq0dkSh+sGAjDIkTiGVlZXqwQcftGig6fV69cADDzT5/9iRtBt7G+VLly5VI0eONL/v3r27mjdvnl1lV65cqV599VXl4+NjXjZhwgT11ltvtahB39y61wQU9fs7GAyGRsv5+/urjh07mt+7ubmpCRMmqH/++cfivDurUV43OKt5RUZGtvpd+rKyMvXbb7+pN954Q912222qW7duNgOh5r68vLzUueeeq8aNG6defvll9eOPP6pDhw41q0P66cbZ128hhFI6pZSimebOncsrr7xCZmYm55xzDm+88Qbnn38+AIMHDyY2NpaPP/4YgF9++YV77rmH/fv34+3tzdVXX81LL71EZGSkxTZXrlzJ0KFD2b17N126dGlulSgqKsLPz4/CwkJ8fX2bXd4RSsHFF0NU1Czuvfchu8p077aAsD98YNYs+OWX2g8uvRQeegiuugr0+pZVKDERJk+Gw4drl8XEwOzZkJDQsm0KYYPRaCQ5OZmMjAwiIiKIj4/HYDA0WubQoUOMHj2a3377zerngYGBvPfeeyQkJKDT6RrsLzY2lsN1f7/r0Ol0REdHk5aWZrUeixYt4uabb27yuLy9vSkpKcFgMDBt2jSeeuopEhMT7Sq7cOFCxo4dS2ZmJo8//rj576GXlxelpaVNlk9KSmLw4MENltcce3p6Otb+dNc99uXLl3PXXXeRnp4OwL333stFF13EbbfdBmBRvuYcL1myhOHDh7Ns2TJee+01NmzYYF5nyJAhPPTQQxQXFzNlyhSL8x8TE8Ps2bNJsOPvS3N+X4xGI1u3bmXdunWsW7eO5ORkjh492mA9f39/OnXqRFxcHHFxcRb/joiIQN/I39Lq6mpSUlLYtGmT+bVt2zaqq6sbrNu+fXv69+9PUFAQZWVllJWVUV5ebv53/VfNZ1VVVU2eFz8/P3r16tXgFRwc3GRZ0L7Po0ePcuTIEdLT063+zMvLo2PHjhbb79mzJ35+fnbt40Rx5vVbCKFpUUBwKnLmH5R162DIkFIWLTqLgIBsu8r0eS2agO+PX1BdXGDMGHjwQejbt3UqZTRCcjJkZEBEBMTHQxONNCGaKzExkcmTJ1s0DqOjo5kzZ47NxuFPP/3EbbfdRm5ubpPbv/rqq5k3bx6xsbHmZWvXruXSSy9tsqytRrW95QH69OnD/Pnz6Xv8/2VL9/3777/zwAMPsGnTpkbLNRXMgHbOR44cCVhv1M+fP581a9bw2WefARAXF8eHH37IJZdcYi5f/zuz1aDfuHEjr732GomJiZhMJgB69erFlClTiImJITc31+4g0B4VFRX8+eef5gBg/fr1FBcXW6zj6enJ+eefj9FoJDU1lYyMjEa36enpSceOHS0CBW9vbzZv3symTZvYsmULZWVlDcqFhITQv39/i1doaGiLjqu6utocHOTl5bFjxw62b99ufu3evRuj0Wi1bHh4uEUD3sPDw2qDPyMjg8rKyhbVr3379g0Cke7du+Ph4dGi7TWXBARCOJ8EBK1g2DDw9dWeDnh4xGIyVVFZeQTtCXE9JnDPgQtuBp2PH9x1FzzwAERHW64nDXpxiqtpmNb/E1L3bnPdBmZ1dTUzZszghRdeAMDV1dWuO6eenp7MmDGDqVOn4urqavcd/pq79PU1dZe9xjPPPMPjjz+Oq6ur3WUba9CbTCY++eQTpk6dSmFhodWy0PC8WWOrUT969Gg+++wzsrKy0Ol0TJ06leeeew4vL68G56A5T3XS0tKYM2cOH3zwAceOHQMgLCyM/v37ExAQQGBgIIGBgTb/7e/vj4uLS4PtHjt2jN9++43k5GTWrVvHxo0bKS8vt1jHz8+Piy++mEGDBhEfH0+/fv1wc3Mzf15aWsr+/ftJTU1l37597Nu3z/zvf//912ZDuy5fX1/69etn0fhv3759g6dTJ0pFRQV79uxh+/btbNu2zRwopKWlNXtbISEhREVFERkZafEzKioKf39/UlNTLfZj60mbXq+nc+fODQKFTp06Wf0uHSEBgRDOJwGBgzZvhosuKmXhwo4EBmbRtesHuLgEkJIy8vgadU6vCdBBz3khhMQ/AbffDj4+DTdqLeUnOhrmzJGUH3FCNLeB2Ny0nYyMDG6++WbWrl0LYE5LaUqfPn3YunUrAL179+add96hsrLSoScEYPsue43XX3+dKVOmNKusvQ36wsJCbr31Vr7//nuL5a6urlx00UVcffXV5sZXTEyMzUZp3e/M3d2dhQsXsnTpUgC6d+/ORx99xAUXXGCzHi1RUFDAe++9xxtvvGFORbKXr6+vRbBQXFzM5s2bG6TmhISEMGjQIPOrd+/eLX76UFVVxb///msRJOzbt4+CggL69Oljbvx36dKl0bQiZykpKWnwNKGqqsrcwK/f8I+IiLAIluxRUFBASkqKRZCwbds28vLyrK6fkpJCjx49WuPwzCQgEML5JCBw0E03AbzOffc9iIdHLAMG7EGvdyUnJ5G92++iUleb7+pe4EYn3QOEXPOSliZkTWIijBypdUyoq6ZRsGSJBAWiVbUk7ac5qTNKKcaOHUtWVhbe3t68//77KKXsusv/+eefU1VVxUMPPWROMbrjjjv44YcfyMjIaPZdeoDDhw+zbt06PvnkE37++WeLBqmfnx/vv/8+N2n/sW1qTtqNLdu2beOuu+7ir7/+spnq4evrazWvPCQkBNACkkWLFjFp0iRyc3Mt+ju4u7vbVY+WqKqqYvXq1aSnp5Ofn09eXh55eXnmf9ddVlRU1Oi2YmJiuOSSS8wBQJcuXU7anXlhnVKKrKwscxBSEyjs3buXrKwsi6dmrUECAiGcTwICB+zaBX37lvL557VPByIi/gPA14sr6T2uF0Hd97IlqAcf5t5Dct49zJ5tsN2eNxohNtbyyUBdOp32pCAtTdKHhIWWdOyF5qf91LA3bWfUqFEsWbIEk8lEr169WLJkCV27dm12Ln5ubi6PPvooH330EaA1lK01NOvXWylFamqqOSVl3bp1VtMwevbsybRp0xg7dqzdd6Nbes7rM5lMpKWlNWh87d6922rHVoDQ0FB69eqFyWQyP3Wp39/hVFFdXU1BQUGDgEGn03HRRRfRoUMHZ1dR2EkpdUKCNQkIhHA+CQgccPvtUFzc8OlAYiKsHzGL13iILELpwh6K8Gv6Jv/atdooQ01JSgIbqRCi7XKkUd/cO/w1+2vpaD3N6ZgLMGHCBObNm2fOZW9pLv66deu4++672blzJwDu7u5UVFRYHPeDDz6Im5ubOQDIzMy02LZer+fcc88135G++OKLCQoKsvtYTpbKykpzXnndQGH//v0W67m5uTF9+nQeffTRVr9zK8TJIAGBEKeAEz+y6clxsscx/vdfpdq1O6aWLg1TSUmoI0c+UEppc371ichSBWiTi93OBw2mA7A5N9jChfbNNGxjjHLRdrV0kq2TMR5/S2aerXl5enqqjz76qNG6N3dM+4qKCvXCCy8oDw8PBShXV1d15ZVXqosuukgFBAQ0qIObm5uKj49XTzzxhFq+fLkqKipq9Jye6oqLi9Uff/yhPvroI/Xcc8+plJQUZ1dJCIfIPARCOJ8EBC30wANKjRw5SyUloX77LVYZjZVKKaWSkpR6j/9TCtSfnKv0VFtt01udiDQpyb6AwMYspqJtammjvrkz7tbX0llv69fbVlAQGRlpntCqsWNv6URVqampasiQIQ32265dO3XllVeq5557Tv3yyy+qrKysyW0JIZxHAgIhnE9ShlogOxu6di3lww+1vgNdurxPZOT/AbD8xc0MeeI89CgG8isbGGh1GwsXQoMREWv6EKSnN+xUDNKH4BTXkpSf5qbtVFRUsGvXLrZv386PP/7IwoULm6yXo+PxNzVaT/10JYCBAwfy008/4WNtFK16HMnFV0rx1VdfsXz5cnr27MmgQYM455xzJHVGiDZEUoaEcL7WHUz4DDFnDlxxxbsEBmbh4RFLePg47QOluHDRJPQoFjLWZjAA2tQCDRgM2sZHjtQa/3WDgpoOCLNnSzBwCmppHn9ycrLNYAC0Bu+hQ4e4/PLLyc7OZs+ePXaNq17X+vXrrTbo4+PjiY6ObjKPPz4+3up2S0pKKC8v55xzziEzM5Pq6mpcXV2ZNWsW9913n92dDw0Gg82Aoyk6nY5Ro0YxatSoFpUXQgghBNKHoLkKCpQKCantO5Ce/n7th4sWKQXqmM5LRXPIarZPo30IaixdqlR0tGXBmBhtuTjlOJLHb2/aTt2Xn5+fuvjii9X1119vd5kBAwaojz/+WJWWllqtu715/GVlZSoxMVGNGjVKeXp6WpTp27ev2rRp0wk5x0KI05ekDAnhfJIy1EwvvQR//aWNLOTuHsv55+9Gr3eD0lLo2hUOH2bHmGfptfgpwPpNfrumEpCZip3iRE/QVVd1dTWvv/46jz76aJP1uvvuuxk+fDi9e/cmMjISnU5n14y7Xl5eVFdXm8e5DwwM5Pbbb+fuu+8mLi4OaHpM/aqqKtasWcMXX3zB119/bTHcZ6dOnRg7dixjxoxp9cmKhBBnBkkZEuIU4OSApNWcjDsMpaVKRUfbeDowfbp2J79DB6VKS+Umv5NUV1erpKQktXDhQpWUlGSzQ601LRnpp7kj9RiNRrVu3Tp17733qpCQkCbLNdUx2J47/FlZWWrmzJmqQ4cOFusMGzZMffvtt6q6urrBeausrFS//PKLuvvuu1VwcHCDc/Lwww+rP//8U5lMpmZ9P0IIUZ88IRDC+SQgaIa5c5UaMeJ1lZSE2rAhVhmNFdoHBw4o5eGhtfq/+sq8fnVFtdryepJaf/9CteX1JFVdYX/jVDRfS4furCnbkrQfe1N+nn/+efXQQw81qF9wcLAaOnSozWCgqZQjW8dtbaSe6upq9d1336mrrrrK4lg7dOigXnzxRZWVlaX++OMPNXXqVBUVFWWxvZCQEHXvvfeq5ORkZTQa7f9ShBCiCRIQCOF8EhDYqbJSqbi4UrVkSXjDpwM33aQFA5dcolTNHVNrjwiio+URwQniSB6/I8N32vuEoO7L19dXTZgwQS1fvlxVVlaa69/S4TdrjqE5T0ZSU1PVI488ogIDAxvtqzBx4kS1cuVKVVVVZVc9hBCiuSQgEML5pA+BnT75BL77bjb33z/Vsu/AL79oswbr9bB5M/TpA4mJ2khB9U9tszoRnJlOxtCd9Tky/KY9efwAnp6eXH/99YwZM4Zhw4bh4eFh9ThaOvxmS5WVlfHVV1/x1ltv8fvvv+Pl5cX111/P2LFjGTp0KO7u7id0/0IIIX0IhHA+GXbUDiYTvPZaGU8//T8AOnR4QgsGjEaYPFlb6c47tWCgZpm1xqFSWlAwZQoMH37KdhJ2tGHa0vIneujO5ORkq8NbZmRkNFm3uusZjUZSU1PZvn0727dvJyYmptH9T5kyheeeew5vb+9Gt+/I8Jst5enpybhx4xg3bhyHDh0iMDCQdu3andQ6CCGEEMK5JCCwwzffQJcu7xIUlImbW515Bz74ALZuBX9/eO45bVlyMjTSOEQpOHRIW+8kN/7s0dJGuaPlExMTGTlyZIO77Onp6YwcOZIlS5bYLN/cBn19EVYnhWho/vz5vPLKK+zYsYOKioom14+KiuKNN96w67ydCmJiYpxdBSGEEEI4gQQETVAKXn65jEce0Z4OxMYefzqQnw9PPKGt9MwzEBys/dvOxqnd651EjjTKHSlvNBqZPHmy1ZQbpRQ6nY4pU6YwfPhwq08a7G3Q21qvZoKuxu7yA6xatcr8by8vL3r27EmvXr3o1asXvXv3pnv37uzdu5fMzMyTlvIjhBBCCOEoCQiasHo1REdrTwdcXes8HXjmGcjNhR494J57agvY2Ti1e70Wasl4+o40yh0p72jKT0tn3K2qquK3335jxYoVTebKDxw4kKuuuorevXvTq1cvYmNj0ev1DdaLjo5udDtCCCGEEKcaCQia8PLLZdx9t/Z04Kyzjj8d2LED5s7VVpg9G1xdawvEx0N0NKSnW+9HoNNpn9drnNbnSB5/S9J2HG2UO1Le0ZQfg8HAnDlzGDlyJDqdziIo0B3vyD179mwMBgOpqamsXLmSFStW8PPPP1NSUmKxLVdXV6qqqszvm5MuJYQQpyOjyUjywWQyijOI8Ikgvn08Br08/RTidCIBQSNycqB9e+3pgIvL8acDSsHUqVrn4euvhyuvtCxkMMCcOTByJEYgGcgAIoB4wABaENFI496RPP6Wpu042ih3pLyjKT8ACQkJLFmypMF5i4iM4NZbbmX16tU88sgj7N+/36JccHAwV155JUOHDmXIkCEEBQfx1tK32PfvPuI6xHHviHtxc3Wzq35n6kXT0eN2pLwz9+1sct5OvrZ8zltaPnFnIpOXT+ZwUZ3rkW80c4bNIaG73CgR4nQhw442wmgsY+PGjlRVZdKly/tERv4ffPedFgi4uUFKCnTqZLVs4qOPMnnWLA4bjeZl0QYDcx58kISXX7a5T1sN+po73Y3l8Tsy/KYjQ286Wt5c7/TD2gj4VgQHB/PBBx80+pRkw6ENvPvnu+QdyIMsIAc4Cphq13FxcWHgwIEMGTKEoUOH0rdvX3PqjyMXvta4aLbFxoajx+3Mc+5oeWc28OS8nfz/J235nLe0fOLOREZ+ORJV7w+zjuPXo1FLWiUokGFHhXA+CQgaUV1dzMGD/yM39zv69duEvkpBr16QmgqPPQYvvWS1XEsb9U016NFBTHTMCR1P32ajvIl921t+//79FBYWsm/fPlJTU9m3bx/79u1j9brVpKelN1n3FgmEYcOGcc/oe7j00kvx8fFpsIojF77WuGi2xcaGo8ftzHPeGuWdGQjJeTu5/0/a+jlvSXmjyUjsnFiL81W/fLRvNGmT0xx+OiQBgRDOJwGBHZQyodPp4eWXtUAgPBz27AErDUtn3qVftGgRN998c5PlFy5cyNixYxssf/SNR3ll8is2yz0y5xFenmT76UZT5cNiwigvKqewsLDJOprpAX9wa+fG2eFnmy9idSkUWzO3UmWszf3HF4jTXrrAxi9cjlz4WuOi2RYbG44etzPPuaPlndnAk/N28v+ftOVz7kj5tQfWcukndlyPxicxOHZwk+s1RgICIZyv4TApogGdTg+ZmbVzDbz0ktVgAJrXuba+9HT77pDbWi80LNSu8tbWM5qMLDIuglFojem6fIFRsKhqEZlZmWzdupUff/yRDz74gGeeeYa77rqLa665htkvz4ZGBuvJOpRlDgaioqIYNGgQEydO5D8P/wdGAncAjwDjgRHHfz4JTILK/1Tyypev8McffzR4vfLlK1T9pwrupPY1BugPBGoBw6GiQyQfbHjOAZIPJtu8YELj5R0pC9p5n7x8coOGSk1ZgCnLp2A0GRt87khZR8s7etzOPOeOlHfmOXe07mfqeTtTz7mj5TOK7ewXZud6QohTm3Qqttd//wslJTBgANx2m83VHOlcm2PIsauszfU6oDXeixop7Ht8vXpW7lzJ4f2HwRO4DDgEFADVgBFYAYeXHCbiYTuHS9WjbcsPiAQCtddHEz9i9MWj8fLyMq+6aNsiPkz8sLbsWdY3aevC4+iFy5Hyju67ORfs+nfhHCnraPm2fM4dKe/Mc+5o3c/U83amnnNHy0f42DnYg53rCSFObRIQ2GPTJpg/X/v3nDlgZfz5Go6MmBPSLcSuBn1ItxCrH2WXZsMw4MtGysfBnBfn8EnVJ6Snp3PkyBHS09MpLi62q94AoaGhREVFERkZaf6ZrtJ5f+/7Wv190IIBK6fJI8LDIhgAxy88zizv6L7bamOjLZ9zR8o7u4En56355c/Uc+5o+fj28UT7RpNelG716UpNulF8+8aH0BZCtA0SEDRFKZg0Sfv3bbfBBRc0uvpFAy/C4GfAWGj98TOAwd/ARQMvarA8yj+q6Qb9RZC/L58f0n8gLy+PvLw88vPzycvLY9ehXZACBAH5WIyuY7YFvtvynfVtu1HboK951Xu/8p6VXNnlygZF1x5Yy/ufvN9IxTUn4sLjzPKO7rutNjba8jl3pLyzG3hy3ppf/kw9546WN+gNzBk2h5FfjkSHzqJ8Td+L2cNmnxHDzQpxJpA+BI0wGmHnk5/Dxo0YPdphfOGlep8bOXbsGEePHuXQoUPs2bOHT1d9ivE828EAgDHKyMTJE5k6dSp3330348ePZ9SoUbx6/6u4/+0Owdj+ZpbDAyMf4Nprr2XcuHFMmTKFZ555hjfffJNV36yCvUAulsGAHi11Jxo8+3jywAMP8L///Y/PPvuMn3/+mV27dpFfkE/0S9Ho7tdpufsJwJXA+UAP0MXoiGkfw2WdLrNarZoLj7VOv6BdQGJ8Yxq98NSsV78cNH7hcWZ5R/ftyHlzpKyj5dvyOXekvDPPuaN1P1PP25l6zlujfEL3BJaMWkKUb5TF8mjf6FYbclQIcWqQUYZsSEyExx8oIVf5UVZpotLoQrVRj0EpMJowVZpQxpN/6vReelzbueLi5YKhnQGXdi64tHPB4KX9u8K1gmxjtpay4wl4Y5G+0zmwMwGeAVa3nV+Wz968vTb33VjZ1ip/oOAAVaba0YLc9G508O/QaLlTobyjZVt63s7k78xZ+27qnA2MGUiXoC54unji6epp/unh4oGniycpOSnM2zTPZvk7z72TbsHdKKsuo6yqjLLqMsqry83/Lqsu40DBAXbk7KDSWGku5+niybkR59IlqIt5X9b2vy17G59u/ZTcslxz2SDPIMb2HkvPkJ6W+6rzs9yoLT9QcICUnBSLfbfGeXP0d3Vw7GC6BXXTjrPOcdec87f/fNtm2bv63UX34O7asdc77przn1aQRkp2ChXGCnM5DxcP+ob3pXNQZ21/dfZZtx7bs7fz2T+fWZzzsHZhPDnoSW7odoPFd6TXNbwbZG3I1BjfGGYPm93i4VqbU/5ET0QnowwJ4XwSEFiRmAgjR0I7Vcwxbz9UiR2nyICWgOUCuNb5WfOwoCYdx7XeOvXXr7/MDa1B73H8Jc90hBDitOVmcLMaWHi4eFBRXUG1qRoPFw8CPANsPvWwRqHIL8unvLq8ReVrLEhYQKBnYLPLNUYCAiGcT/oQ1GM0wuTJWteBEnzA+wX0fqWYdF6gcwO9GwGBbrz8mhuenm64e7jj6u5qnlPAaDLyn2//Y3EnqL5gz2A+uP6DRu+wGE1GduTsIK8sj0DPQHqE9Gj2bJ4tLe/MfZ/J5DtrW2rOWW5pLt7u3sT6xVJhrGj0zn79O89HS49SZayinVs7QtuF4uXq1bAxWO9Of92fbgY3qkxV1u/o17/bbeVzozJa3369pwrW9u9ucG/R70hr/K6m5KSQcywHL1cvOvh3oKK6wuad/brvS6tKOVp6lPLqctq5tiOkXUijx1//Tn/NOTEpk/VzXP+nre+i3u9H3adUlcZKKo2VFFY0Y76Wk6jukyEhxOlDnhDUs3YtXNr0XCwkJYGVucGA2klwAKsdsST3UgghRI1qU7U5OLAWPNRdVm2qdmpdR/UchaerZ6tuU54QCOF88oSgHjunEWh0vZqOWPVzNqN9o+3O2RRCCHFmcNG74O3mjbebt7OrIoQ4Q0lAUI+d0wg0uV5C9wSGdx1+QjtiCSGEEEII4SgJCOqJj4foaEhP1/oR1KfTaZ/H2zEXi0FvsDrzpRBCCCGEEKcKGbOmHoNBm4wYtMZ/XTXvZ8/W1hNCCCGEEKKtk4DAioQEWLIEoiznYiE6WlueIF0AhBBCCCHEaUJShmxISIDhwyE5WetAHBGhpQnJkwEhhBBCCHE6kYCgEQaD7aFFhRBCCCGEOB1IypAQQgghhBBnsBYFBPPmzSM2NhYPDw/OP/98/vjjD5vrVlVV8eyzzxIXF4eHhwd9+vRh+fLlDdZLT0/n1ltvJSgoCE9PT3r37s2ff/7ZkuoJIYQQQggh7NTsgGDx4sU8+OCDPP3002zevJk+ffowdOhQsrOzra7/5JNP8u677/Lmm2+yY8cO7r77bm688Ua2bNliXic/P5+BAwfi6urKTz/9xI4dO3jttdcICAho+ZG1AqWM5OevJStrEfn5a1HK6NT6CCGEEEII0dp0Slkbbd+2888/n/79+zN37lwATCYTMTExPPDAA0ybNq3B+pGRkTzxxBPcd9995mUjRozA09OTBQsWADBt2jTWr19PcnJyiw+ktac+z8lJJHXvZCoqa2cadneLplPnOYSEyDBDQgghRGto7eu3EKL5mvWEoLKykr/++osrrriidgN6PVdccQW//fab1TIVFRV4eHhYLPP09OTXX381v//2228577zzuOmmmwgNDaVv3768//77zalaq8rJSSRl+wgqKg5bLK8oP0zK9hHk5CQ6qWZCCCGEEEK0rmYFBEePHsVoNBIWFmaxPCwsjMzMTKtlhg4dyqxZs9i7dy8mk4lVq1aRmJhIRkaGeZ39+/fz9ttv07lzZ1asWME999zDpEmT+OSTT2zWpaKigqKiIotXa1DKSOo/d2pv6k1Mhh5QkPrPnZI+JIQQQgghTgsnfJShOXPm0LlzZ7p164abmxv3338/EydORK+v3bXJZOLcc8/lxRdfpG/fvtx5553ccccdvPPOOza3O3PmTPz8/MyvmJiYVqlvQd5aKgy5DYOBGnqoMORSkLe2VfYnhBBCCCGEMzUrIAgODsZgMJCVlWWxPCsri/DwcKtlQkJC+Oabbzh27Bj//vsvu3btwtvbm44dO5rXiYiIoEePHhblunfvzsGDB23W5fHHH6ewsND8OnToUHMOxabKbWtbdT0hhBBCCCFOZc0KCNzc3OjXrx9r1qwxLzOZTKxZs4YLL7yw0bIeHh5ERUVRXV3N0qVLGT58uPmzgQMHsnv3bov19+zZQ4cOHWxuz93dHV9fX4tXa3DLbd31hBBCCCGEOJU1O2XowQcf5P333+eTTz5h586d3HPPPRw7doyJEycCMG7cOB5//HHz+r///juJiYns37+f5ORkhg0bhslk4tFHHzWvM3XqVDZu3MiLL75IamoqCxcu5L333rMYmehk8Q8ajHs2YLKxggncs7T1hBBCCCGEaOtcmltg9OjR5OTkMH36dDIzMznnnHNYvny5uaPxwYMHLfoHlJeX8+STT7J//368vb25+uqr+eyzz/D39zev079/f77++msef/xxnn32Wc466yxmz57NLbfc4vgRNpMufjCdRgaRMilXCwrqhkwmQAedFgeh+2rwSa+bEEIIIYQQra3Z8xCcqlp1HOPERHLmjCD1PqgIrV3sng2d5kHI5KWQIHMRCCGEEI6SeQiEcL5mPyE4IyQkEMJSgqdMoiAwncogrc+Af340utfnSDAghBBCCCFOGxIQ2JKQgG74cAKSkyEjAyIiID4eDAZn10wIIYQQQohWIwFBYwwGGDzY2bUQQgghhBDihDnhE5MJIYQQQgghTl0SEAghhBBCCHEGk4BACCGEEEKIM5gEBEIIIYQQQpzBpFOxEEIIIU5ZRqORqqoqZ1dDiDbH1dUVg52jY0pAIIQQQohTjlKKzMxMCgoKnF0VIdosf39/wsPD0el0ja4nAYEQQgghTjk1wUBoaCheXl5NNmiEELWUUpSWlpKdnQ1AREREo+tLQCCEEEKIU4rRaDQHA0FBQc6ujhBtkqenJwDZ2dmEhoY2mj4knYqFEEIIcUqp6TPg5eXl5JoI0bbV/B9qqh+OBARCCCGEOCVJmpAQjrH3/5AEBEIIIYQQQpzBJCAQQgghhDiFxcbGMnv2bLvXX7t2LTqdTkZocsCBAwfQ6XT8/fffdpcZPHgwU6ZMOWF1OpEkIBBCCCHEactohLVrYdEi7afReOL2pdPpGn3NmDGjRdvdtGkTd955p93rX3TRRWRkZODn59ei/YkTLzExkSFDhhAUFNTswONEkFGGhBBCCHFaSkyEyZPh8OHaZdHRMGcOJCS0/v4yMjLM/168eDHTp09n9+7d5mXe3t7mfyulMBqNuLg03RQLCQlpVj3c3NwIDw9vVhlxch07doyLL76YUaNGcccddzi7OvKEQAghhBCnn8REGDnSMhgASE/Xlicmtv4+w8PDzS8/Pz90Op35/a5du/Dx8eGnn36iX79+uLu78+uvv7Jv3z6GDx9OWFgY3t7e9O/fn9WrV1tst37KkE6n44MPPuDGG2/Ey8uLzp078+2335o/r58y9PHHH+Pv78+KFSvo3r073t7eDBs2zCKAqa6uZtKkSfj7+xMUFMRjjz3G+PHjueGGG2web25uLmPHjiUqKgovLy969+7NokWLLNYxmUy8/PLLdOrUCXd3d9q3b88LL7xg/vzw4cOMHTuWwMBA2rVrx3nnncfvv/9udX81aTxffvkl8fHxeHp60r9/f/bs2cOmTZs477zz8Pb25qqrriInJ8eiDs8++yzR0dG4u7tzzjnnsHz5cott//HHH/Tt2xcPDw/OO+88tmzZ0mD/27dv56qrrsLb25uwsDBuu+02jh49avP8NOa2225j+vTpXHHFFS0q39okIBBCCCHEacVo1J4MKNXws5plU6ac2PQhW6ZNm8ZLL73Ezp07OfvssykpKeHqq69mzZo1bNmyhWHDhnHddddx8ODBRrfzzDPPMGrUKP755x+uvvpqbrnlFvLy8myuX1payquvvspnn33GunXrOHjwIA8//LD58//97398/vnnzJ8/n/Xr11NUVMQ333zTaB3Ky8vp168fP/zwA9u3b+fOO+/ktttu448//jCv8/jjj/PSSy/x1FNPsWPHDhYuXEhYWBgAJSUlXHLJJaSnp/Ptt9+ydetWHn30UUwmU6P7ffrpp3nyySfZvHkzLi4u3HzzzTz66KPMmTOH5ORkUlNTmT59unn9OXPm8Nprr/Hqq6/yzz//MHToUK6//nr27t1rrse1115Ljx49+Ouvv5gxY4bFuQEoKCjgsssuo2/fvvz5558sX76crKwsRo0a1Whd2wx1migsLFSAKiwsdHZVhBBCCGEna9fvsrIytWPHDlVWVtaibSYlKaU1/Rt/JSW1zjFYM3/+fOXn51enTkkKUN98802TZXv27KnefPNN8/sOHTqo119/3fweUE8++aT5fUlJiQLUTz/9ZLGv/Px8c10AlZqaai4zb948FRYWZn4fFhamXnnlFfP76upq1b59ezV8+HB7D1kppdQ111yjHnroIaWUUkVFRcrd3V29//77Vtd99913lY+Pj8rNzbVr22lpaQpQH3zwgXnZokWLFKDWrFljXjZz5kzVtWtX8/vIyEj1wgsvWGyrf//+6t577zXXIygoyOL37e2331aA2rJli1JKqeeee04NGTLEYhuHDh1SgNq9e7dSSqlLLrlETZ482a5jqX9MNftpbfb+X5I+BEIIIYQ4rdTJhGmV9VrTeeedZ/G+pKSEGTNm8MMPP5CRkUF1dTVlZWVNPiE4++yzzf9u164dvr6+ZGdn21zfy8uLuLg48/uIiAjz+oWFhWRlZTFgwADz5waDgX79+jV6t95oNPLiiy/y5Zdfkp6eTmVlJRUVFebJsHbu3ElFRQWXX3651fJ///03ffv2JTAwsNFjra/usdc8bejdu7fFsppjKyoq4siRIwwcONBiGwMHDmTr1q3mep599tl4eHiYP7/wwgst1t+6dStJSUkW/UBq7Nu3jy5dujTrGE41EhAIIYQQ4rQSEdG667Wmdu3aWbx/+OGHWbVqFa+++iqdOnXC09OTkSNHUllZ2eh2XF1dLd7rdLpGG+/W1lfWcqqa4ZVXXmHOnDnMnj2b3r17065dO6ZMmWKuu6enZ6Plm/rclrrHUjPxVv1lTaUdNVdJSQnXXXcd//vf/xp8FuGMX6RWJn0IhBBCCHFaiY/XRhOyNUmrTgcxMdp6zrZ+/XomTJjAjTfeSO/evQkPD+fAgQMntQ5+fn6EhYWxadMm8zKj0cjmzZsbLbd+/XqGDx/OrbfeSp8+fejYsSN79uwxf965c2c8PT1Zs2aN1fJnn302f//9d6N9Hxzl6+tLZGQk69evb1D3Hj16ANC9e3f++ecfysvLzZ9v3LjRYv1zzz2XlJQUYmNj6dSpk8WrfpDXFklAIIQQQojTisGgDS0KDYOCmvezZ2vrOVvnzp1JTEzk77//ZuvWrdx8882tfnfbHg888AAzZ85k2bJl7N69m8mTJ5Ofn2++A29N586dWbVqFRs2bGDnzp3cddddZGVlmT/38PDgscce49FHH+XTTz9l3759bNy4kQ8//BCAsWPHEh4ezg033MD69evZv38/S5cu5bfffmvVY3vkkUf43//+x+LFi9m9ezfTpk3j77//ZvLkyQDcfPPN6HQ67rjjDnbs2MGPP/7Iq6++arGN++67j7y8PMaOHcumTZvYt28fK1asYOLEiRhb0Ds9Ly+Pv//+mx07dgCwe/du/v77bzIzMx0/4BaQgEAIIYQQp52EBFiyBKKiLJdHR2vLT8Q8BC0xa9YsAgICuOiii7juuusYOnQo55577kmvx2OPPcbYsWMZN24cF154Id7e3gwdOtQir76+J598knPPPZehQ4cyePBgc+O+rqeeeoqHHnqI6dOn0717d0aPHm3O73dzc2PlypWEhoZy9dVX07t3b1566SUMrRypTZo0iQcffJCHHnqI3r17s3z5cr799ls6d+4MaPNDfPfdd2zbto2+ffvyxBNPNEgNqnnKYDQaGTJkCL1792bKlCn4+/uj1ze/Of3tt9/St29frrnmGgDGjBlD3759eeeddxw/4BbQKUcTyE4RRUVF+Pn5UVhYiK+vr7OrI4QQQgg7WLt+l5eXk5aWxllnndVog9QeRiMkJ2sdiCMitDShU+HJwKnOZDLRvXt3Ro0axXPPPefs6ogWsvf/knQqFkIIIcRpy2CAwYOdXYtT37///svKlSu55JJLqKioYO7cuaSlpXHzzTc7u2riJJCUISGEEEKIM5xer+fjjz+mf//+DBw4kG3btrF69Wq6d+/u7Kq1OcnJyXh7e9t8nYrkCYEQQgghxBkuJiamwUg8omXOO+88/v77b2dXo1kkIBBCCCGEEKKVeHp60qlTJ2dXo1kkZUgIIYQQQogzmAQEQgghhBBCnMEkIBBCCCGEEOIMJgGBEEIIIYQQZzAJCIQQQgghhDiDSUAghBBCCHEKGTx4MFOmTDG/j42NZfbs2Y2W0el0fPPNNw7vu7W2c6Zau3YtOp2OgoICu8vY8/2eaBIQCCGEEEK0guuuu45hw4ZZ/Sw5ORmdTsc///zT7O1u2rSJO++88//bu/OwKI61b8C/AVkGhk2DLIqggApkQBY1ShBcjoMkiAuBgAsaAmpEIS6gERXjMZpIFFy+mJhEoq+4RTTmNYKo4EFwwWVQA0GYoCLBXSGDrDP1/eFLH4YdRCH63NfVV+yq6qqne3pC13R114uGpyAqKgqDBg1qkF5cXIxx48Z1aFuk43z33Xdwc3ODtrZ2mzsezaEOASGEEEJIBwgMDERycjLu3LnTIG/Hjh1wcnKCra1tm+vV19eHhoZGR4TYIkNDQ6ipqb2StkjbPXv2DO7u7vjss886tF7qEBBCCCGEdID3338f+vr6iIuLU0iXSqU4cOAAAgMD8ejRI/j5+aFXr17Q0NCAUCjEnj17mq23/pCSvLw8jBgxAurq6rC2tkZycnKDbSIiItC/f39oaGigX79+WL58OaqrqwEAcXFxWLVqFbKyssDj8cDj8biY6w8ZunbtGkaNGgU+n48ePXogODgYUqmUy58xYwYmTJiA6OhoGBkZoUePHpg7dy7XVmMkEgm8vLxgYGAAgUCAwYMH48SJEwplKisrERERARMTE6ipqcHCwgI//PADl//777/j/fffh7a2NrS0tODi4gKJRNJoe7XDeJKSkmBvbw8+n49Ro0bh/v37OHbsGKysrKCtrQ1/f388e/ZMIYb58+ejZ8+eUFdXx7vvvovMzEyFun/77Tf0798ffD4fI0eOxM2bNxu0f+bMGbi4uIDP58PExATz589HWVlZk8enOWFhYViyZAneeeeddm3fFOoQEEIIIaTLYwwoK+uchbHWxditWzdMnz4dcXFxYHU2OnDgAGQyGfz8/FBRUQFHR0ccPXoU169fR3BwMKZNm4YLFy60qg25XI5JkyZBVVUV58+fx7Zt2xAREdGgnJaWFuLi4pCdnY3Y2Fhs374dGzduBAD4+vpi4cKFsLGxQXFxMYqLi+Hr69ugjrKyMohEIujp6SEzMxMHDhzAiRMnEBISolAuJSUFEokEKSkp+OmnnxAXF9egU1SXVCqFh4cHTp48iStXrsDd3R2enp64ffs2V2b69OnYs2cPNm3ahJycHHz77bcQCAQAgKKiIowYMQJqamo4deoULl26hI8++gg1NTXNHruoqChs2bIFGRkZKCwshI+PD2JiYhAfH4+jR4/i+PHj2Lx5M1c+PDwcBw8exE8//YTLly/DwsICIpEIjx8/BgAUFhZi0qRJ8PT0hFgsxscff4wlS5YotCmRSODu7o7Jkyfj6tWr2LdvH86cOdPgGHY69pooKSlhAFhJSUlnh0IIIYSQVmrs73d5eTnLzs5m5eXlXJpUytjzS/NXv0ilrd+fnJwcBoClpKRwaS4uLmzq1KlNbvPee++xhQsXcuuurq4sNDSUWzc1NWUbN25kjDGWlJTEunXrxoqKirj8Y8eOMQDs0KFDTbaxfv165ujoyK2vXLmS2dnZNShXt57vvvuO6enpMWmdA3D06FGmpKTE7t69yxhjLCAggJmamrKamhquzAcffMB8fX2bjKUxNjY2bPPmzYwxxnJzcxkAlpyc3GjZpUuXsr59+7KqqqpW1Z2SksIAsBMnTnBpa9euZQCYRCLh0mbNmsVEIhFjjDGpVMpUVFTY7t27ufyqqipmbGzMvvrqKy4Oa2trhbYiIiIYAPbkyRPGGGOBgYEsODhYoUxaWhpTUlLizu+6n29r1e5TbTtNaey71Jh23SHYunUrzMzMoK6ujqFDhzbbq62ursbnn38Oc3NzqKurw87ODomJiQploqKiuFtWtcvAgQPbExohhBBCSKcZOHAghg8fjh9//BEAkJ+fj7S0NAQGBgIAZDIZVq9eDaFQiO7du0MgECApKUnh1/Hm5OTkwMTEBMbGxlzasGHDGpTbt28fnJ2dYWhoCIFAgMjIyFa3UbctOzs7aGpqcmnOzs6Qy+XIzc3l0mxsbKCsrMytGxkZ4f79+03WK5VKsWjRIlhZWUFXVxcCgQA5OTlcfGKxGMrKynB1dW10e7FYDBcXF6ioqLRpf+o+v2FgYMANp6qbVhu3RCJBdXU1nJ2duXwVFRUMGTIEOTk5AJ4fn6FDhyq0Uf+zyMrKQlxcHAQCAbeIRCLI5XIUFBS0Kf6XqVtbN9i3bx8WLFiAbdu2YejQoYiJiYFIJEJubi569uzZoHxkZCT+53/+B9u3b8fAgQORlJSEiRMnIiMjA/b29lw5GxsbhfFj3bq1OTRCCCGEvKY0NIA6Q9dfedttERgYiHnz5mHr1q3YsWMHzM3NuYvb9evXIzY2FjExMRAKhdDU1ERYWBiqqqo6LN6zZ89iypQpWLVqFUQiEXR0dLB37158/fXXHdZGXfUvzHk8HuRyeZPlFy1ahOTkZERHR8PCwgJ8Ph/e3t7cMeDz+c2211J+a+Lk8Xhtjrs9pFIpZs2ahfnz5zfI69OnT4e29SLafIdgw4YNCAoKwsyZM2FtbY1t27ZBQ0OD6wnXt2vXLnz22Wfw8PBAv379MGfOHHh4eDQ4Kbt16wZDQ0Nueeutt9q3R4QQQgh57fB4gKZm5yw8Xtti9fHxgZKSEuLj47Fz50589NFH4P1fJenp6fDy8sLUqVNhZ2eHfv364caNG62u28rKCoWFhSguLubSzp07p1AmIyMDpqamWLZsGZycnGBpaYlbt24plFFVVYVMJmuxraysLIUHYNPT06GkpIQBAwa0Oub60tPTMWPGDEycOBFCoRCGhoYKD+MKhULI5XKcPn260e1tbW2RlpbW7IPLL8rc3ByqqqpIT0/n0qqrq5GZmQlra2sAz49P/VEy9T8LBwcHZGdnw8LCosGiqqr60uJvqzZ1CKqqqnDp0iWMGTPmvxUoKWHMmDE4e/Zso9tUVlZCXV1dIY3P5+PMmTMKaXl5eTA2Nka/fv0wZcqUNt/WIoQQQgjpCgQCAXx9fbF06VIUFxdjxowZXJ6lpSWSk5ORkZGBnJwczJo1C/fu3Wt13WPGjEH//v0REBCArKwspKWlYdmyZQplLC0tcfv2bezduxcSiQSbNm3CoUOHFMqYmZmhoKAAYrEYDx8+RGVlZYO2pkyZAnV1dQQEBOD69etISUnBvHnzMG3aNBgYGLTtoNSLLyEhAWKxGFlZWfD391f4Zd7MzAwBAQH46KOPcPjwYRQUFCA1NRX79+8HAISEhKC0tBQffvghLl68iLy8POzatUthGNOL0tTUxJw5c7B48WIkJiYiOzsbQUFBePbsGTf8a/bs2cjLy8PixYuRm5uL+Pj4Bg9TR0REICMjAyEhIRCLxcjLy8Mvv/zS7oeK7969C7FYjPz8fADP3wIlFou5B53bq00dgocPH0ImkzU4CQwMDHD37t1GtxGJRNiwYQPy8vIgl8uRnJyMhIQEhZ7t0KFDERcXh8TERHzzzTcoKCiAi4sL/v777yZjqaysRGlpqcJCCCGEENIVBAYG4smTJxCJRArj/SMjI+Hg4ACRSAQ3NzcYGhpiwoQJra5XSUkJhw4dQnl5OYYMGYKPP/4Ya9asUSgzfvx4fPrppwgJCcGgQYOQkZGB5cuXK5SZPHky3N3dMXLkSOjr6zf66lMNDQ0kJSXh8ePHGDx4MLy9vTF69Ghs2bKlbQejng0bNkBPTw/Dhw+Hp6cnRCIRHBwcFMp888038Pb2xieffIKBAwciKCiIu1PRo0cPnDp1ClKpFK6urnB0dMT27dvb/ExBS9atW4fJkydj2rRpcHBwQH5+PpKSkqCnpwfg+ZCfgwcP4vDhw7Czs8O2bdvwxRdfKNRha2uL06dP48aNG3BxcYG9vT1WrFihcE60xbZt22Bvb4+goCAAwIgRI2Bvb48jR4680L7yGGvty7SAv/76C7169UJGRobCQxPh4eE4ffo0zp8/32CbBw8eICgoCL/++it4PB7Mzc0xZswY/PjjjygvL2+0nadPn8LU1BQbNmzgemH1RUVFYdWqVQ3SS0pKoK2t3dpdIoQQQkgnKi0thY6OjsLf74qKChQUFKBv374NRhkQQlqvtd+lNt0heOutt6CsrNzg1ta9e/dgaGjY6Db6+vo4fPgwysrKcOvWLfzxxx8QCAQKT3XXp6uri/79+3O3QxqzdOlSlJSUcEthYWFbdoUQQgghhBCCNnYIVFVV4ejoiJMnT3JpcrkcJ0+ebPSVV3Wpq6ujV69eqKmpwcGDB+Hl5dVkWalUColEAiMjoybLqKmpQVtbW2EhhBBCCCHkn2j37t0Kryetu9jY2LzUttv8bs8FCxYgICAATk5OGDJkCGJiYlBWVoaZM2cCeD6zXK9evbB27VoAwPnz51FUVIRBgwahqKgIUVFRkMvlCA8P5+pctGgRPD09YWpqir/++gsrV66EsrIy/Pz8Omg3CSGEEEII6brGjx/fYF6DWh39fER9be4Q+Pr64sGDB1ixYgXu3r2LQYMGITExkXvQ+Pbt21BS+u+Nh4qKCkRGRuLPP/+EQCCAh4cHdu3aBV1dXa7MnTt34Ofnh0ePHkFfXx/vvvsuzp07B319/RffQ0IIIYQQQro4LS0taGlpdUrbbXqouCtr7KEkQgghhHRt9FAxIS/PS3momBBCCCGEEPJ6oQ4BIYQQQgghbzDqEBBCCCGEEPIGow4BIYQQQgghbzDqEBBCCCGEdGFmZmaIiYlpdfnU1FTweDw8ffr0pcX0urt58yZ4PB7EYnGrt3Fzc0NYWNhLi+llog4BIYQQQl5fMhmQmgrs2fP8vzLZS2uKx+M1u0RFRbWr3szMTAQHB7e6/PDhw1FcXAwdHZ12tUderurqakREREAoFEJTUxPGxsaYPn06/vrrr06Lqc3zEBBCCCGE/CMkJAChocCdO/9N690biI0FJk3q8OaKi4u5f+/btw8rVqxAbm4ulyYQCLh/M8Ygk8nQrVvLl2JtnZdJVVUVhoaGbdqGvDrPnj3D5cuXsXz5ctjZ2eHJkycIDQ3F+PHjcfHixU6Jie4QEEIIIeT1k5AAeHsrdgYAoKjoeXpCQoc3aWhoyC06Ojrg8Xjc+h9//AEtLS0cO3YMjo6OUFNTw5kzZyCRSODl5QUDAwMIBAIMHjwYJ06cUKi3/pAhHo+H77//HhMnToSGhgYsLS1x5MgRLr/+kKG4uDjo6uoiKSkJVlZWEAgEcHd3V+jA1NTUYP78+dDV1UWPHj0QERGBgIAATJgwocn9ffToEfz8/NCrVy9oaGhAKBRiz549CmXkcjm++uorWFhYQE1NDX369MGaNWu4/NrJabt37w5NTU04OTnh/PnzjbZXO4xn//79cHFxAZ/Px+DBg3Hjxg1kZmbCyckJAoEA48aNw4MHDxRi+Pzzz9G7d2+oqalxk+rWdeHCBdjb20NdXR1OTk64cuVKg/avX7+OcePGQSAQwMDAANOmTcPDhw+bPD5N0dHRQXJyMnx8fDBgwAC888472LJlCy5duoTbt2+3ub6OQB0CQgghhLxeZLLndwYam3u1Ni0s7KUOH2rKkiVLsG7dOuTk5MDW1hZSqRQeHh44efIkrly5And3d3h6erZ4Ybhq1Sr4+Pjg6tWr8PDwwJQpU/D48eMmyz979gzR0dHYtWsX/vOf/+D27dtYtGgRl//ll19i9+7d2LFjB9LT01FaWorDhw83G0NFRQUcHR1x9OhRXL9+HcHBwZg2bRouXLjAlVm6dCnWrVuH5cuXIzs7G/Hx8TAwMAAASKVSuLq6oqioCEeOHEFWVhbCw8Mhl8ubbXflypWIjIzE5cuX0a1bN/j7+yM8PByxsbFIS0tDfn4+VqxYwZWPjY3F119/jejoaFy9ehUikQjjx49HXl4eF8f7778Pa2trXLp0CVFRUQrHBgCePn2KUaNGwd7eHhcvXkRiYiLu3bsHHx+fZmNtrZKSEvB4POjq6nZIfW3GXhMlJSUMACspKensUAghhBDSSo39/S4vL2fZ2dmsvLy8fZWmpDD2/NK/+SUlpUP2oTE7duxgOjo6dUJKYQDY4cOHW9zWxsaGbd68mVs3NTVlGzdu5NYBsMjISG5dKpUyAOzYsWMKbT158oSLBQDLz8/nttm6dSszMDDg1g0MDNj69eu59ZqaGtanTx/m5eXV2l1mjDH23nvvsYULFzLGGCstLWVqamps+/btjZb99ttvmZaWFnv06FGr6i4oKGAA2Pfff8+l7dmzhwFgJ0+e5NLWrl3LBgwYwK0bGxuzNWvWKNQ1ePBg9sknn3Bx9OjRQ+F8++abbxgAduXKFcYYY6tXr2Zjx45VqKOwsJABYLm5uYwxxlxdXVloaGir9qWu8vJy5uDgwPz9/du8bWvqbs13iZ4hIIQQQsjrpc5QmA4p14GcnJwU1qVSKaKionD06FEUFxejpqYG5eXlLd4hsLW15f6tqakJbW1t3L9/v8nyGhoaMDc359aNjIy48iUlJbh37x6GDBnC5SsrK8PR0bHZX+tlMhm++OIL7N+/H0VFRaiqqkJlZSU0NDQAADk5OaisrMTo0aMb3V4sFsPe3h7du3dvdl/rq7vvtXcbhEKhQlrtvpWWluKvv/6Cs7OzQh3Ozs7Iysri4rS1tYW6ujqXP2zYMIXyWVlZSElJUXgOpJZEIkH//v3btA+1qqur4ePjA8YYvvnmm3bV0RGoQ0AIIYSQ14uRUceW60CampoK64sWLUJycjKio6NhYWEBPp8Pb29vVFVVNVuPioqKwjqPx2v24r2x8qyxIVVtsH79esTGxiImJoZ7Y05YWBgXO5/Pb3b7lvKbUndfeDxeo2ktDTtqK6lUCk9PT3z55ZcN8ozaeR7VdgZu3bqFU6dOQVtb+0XDbDd6hoAQQgghrxcXl+dvE/q/i8UGeDzAxOR5uU6Wnp6OGTNmYOLEiRAKhTA0NMTNmzdfaQw6OjowMDBAZmYmlyaTyXD58uVmt0tPT4eXlxemTp0KOzs79OvXDzdu3ODyLS0twefzcfLkyUa3t7W1hVgsbvbZhxelra0NY2NjpKenN4jd2toaAGBlZYWrV6+ioqKCyz937pxCeQcHB/z+++8wMzODhYWFwlK/k9catZ2BvLw8nDhxAj169GjH3nUc6hAQQggh5PWirPz81aJAw05B7XpMzPNynczS0hIJCQkQi8XIysqCv79/h/+63Rrz5s3D2rVr8csvvyA3NxehoaF48uQJ9wt8YywtLZGcnIyMjAzk5ORg1qxZuHfvHpevrq6OiIgIhIeHY+fOnZBIJDh37hx++OEHAICfnx8MDQ0xYcIEpKen488//8TBgwdx9uzZDt23xYsX48svv8S+ffuQm5uLJUuWQCwWIzQ0FADg7+8PHo+HoKAgZGdn47fffkN0dLRCHXPnzsXjx4/h5+eHzMxMSCQSJCUlYebMmZC18eH06upqeHt74+LFi9i9ezdkMhnu3r2Lu3fvtnhn6GWhDgEhhBBCXj+TJgE//wz06qWY3rv38/SXMA9Be2zYsAF6enoYPnw4PD09IRKJ4ODg8MrjiIiIgJ+fH6ZPn45hw4ZBIBBAJBIpjKuvLzIyEg4ODhCJRHBzc+Mu7utavnw5Fi5ciBUrVsDKygq+vr7c+H5VVVUcP34cPXv2hIeHB4RCIdatWwflDu6ozZ8/HwsWLMDChQshFAqRmJiII0eOwNLSEsDz+SF+/fVXXLt2Dfb29li2bFmDoUG1dxlkMhnGjh0LoVCIsLAw6OrqQkmpbZfTtW9VunPnDgYNGgQjIyNuycjI6LD9bgsee9EBZF1EaWkpdHR0UFJS0qljsAghhBDSeo39/a6oqEBBQQH69u3b7AVpq8hkQFra8weIjYyeDxPqAncGujq5XA4rKyv4+Phg9erVnR0OaafWfpfooWJCCCGEvL6UlQE3t86Oosu7desWjh8/DldXV1RWVmLLli0oKCiAv79/Z4dGXgEaMkQIIYQQ8oZTUlJCXFwcBg8eDGdnZ1y7dg0nTpyAlZVVZ4f2j5OWlgaBQNDk0hXRHQJCCCGEkDeciYlJgzfxkPZxcnKCWCzu7DDahDoEhBBCCCGEdBA+nw8LC4vODqNNaMgQIYQQQgghbzDqEBBCCCGEEPIGow4BIYQQQgghbzDqEBBCCCGEEPIGow4BIYQQQgghbzDqEBBCCCGEdCFubm4ICwvj1s3MzBATE9PsNjweD4cPH37htjuqnjdVamoqeDwenj592uptWvP5vmzUISCEEEII6QCenp5wd3dvNC8tLQ08Hg9Xr15tc72ZmZkIDg5+0fAUREVFYdCgQQ3Si4uLMW7cuA5ti3SMx48fY968eRgwYAD4fD769OmD+fPno6Sk5IXrpg4BIYQQQkgHCAwMRHJyMu7cudMgb8eOHXBycoKtrW2b69XX14eGhkZHhNgiQ0NDqKmpvZK2SNv89ddf+OuvvxAdHY3r168jLi4OiYmJCAwMfOG6qUNACCGEENIB3n//fejr6yMuLk4hXSqV4sCBAwgMDMSjR4/g5+eHXr16QUNDA0KhEHv27Gm23vpDSvLy8jBixAioq6vD2toaycnJDbaJiIhA//79oaGhgX79+mH58uWorq4GAMTFxWHVqlXIysoCj8cDj8fjYq4/ZOjatWsYNWoU+Hw+evTogeDgYEilUi5/xowZmDBhAqKjo2FkZIQePXpg7ty5XFuNkUgk8PLygoGBAQQCAQYPHowTJ04olKmsrERERARMTEygpqYGCwsL/PDDD1z+77//jvfffx/a2trQ0tKCi4sLJBJJo+3VDuNJSkqCvb09+Hw+Ro0ahfv37+PYsWOwsrKCtrY2/P398ezZM4UY5s+fj549e0JdXR3vvvsuMjMzFer+7bff0L9/f/D5fIwcORI3b95s0P6ZM2fg4uICPp8PExMTzJ8/H2VlZU0en6a8/fbbOHjwIDw9PWFubo5Ro0ZhzZo1+PXXX1FTU9Pm+uqiDgEhhBBCuj7GgLKyzlkYa1WI3bp1w/Tp0xEXFwdWZ5sDBw5AJpPBz88PFRUVcHR0xNGjR3H9+nUEBwdj2rRpuHDhQqvakMvlmDRpElRVVXH+/Hls27YNERERDcppaWkhLi4O2dnZiI2Nxfbt27Fx40YAgK+vLxYuXAgbGxsUFxejuLgYvr6+DeooKyuDSCSCnp4eMjMzceDAAZw4cQIhISEK5VJSUiCRSJCSkoKffvoJcXFxDTpFdUmlUnh4eODkyZO4cuUK3N3d4enpidu3b3Nlpk+fjj179mDTpk3IycnBt99+C4FAAAAoKirCiBEjoKamhlOnTuHSpUv46KOPWrwojoqKwpYtW5CRkYHCwkL4+PggJiYG8fHxOHr0KI4fP47Nmzdz5cPDw3Hw4EH89NNPuHz5MiwsLCASifD48WMAQGFhISZNmgRPT0+IxWJ8/PHHWLJkiUKbEokE7u7umDx5Mq5evYp9+/bhzJkzDY5he5WUlEBbWxvdunV7sYrYa6KkpIQBYCUlJZ0dCiGEEEJaqbG/3+Xl5Sw7O5uVl5f/t6BUytjzS/NXv0ilrd6fnJwcBoClpKRwaS4uLmzq1KlNbvPee++xhQsXcuuurq4sNDSUWzc1NWUbN25kjDGWlJTEunXrxoqKirj8Y8eOMQDs0KFDTbaxfv165ujoyK2vXLmS2dnZNShXt57vvvuO6enpMWmd/T969ChTUlJid+/eZYwxFhAQwExNTVlNTQ1X5oMPPmC+vr5NxtIYGxsbtnnzZsYYY7m5uQwAS05ObrTs0qVLWd++fVlVVVWr6k5JSWEA2IkTJ7i0tWvXMgBMIpFwabNmzWIikYgxxphUKmUqKips9+7dXH5VVRUzNjZmX331FReHtbW1QlsREREMAHvy5AljjLHAwEAWHBysUCYtLY0pKSlx53fdz7ctHjx4wPr06cM+++yzJss0+l1qBN0hIIQQQgjpIAMHDsTw4cPx448/AgDy8/ORlpbGjfOWyWRYvXo1hEIhunfvDoFAgKSkJIVfx5uTk5MDExMTGBsbc2nDhg1rUG7fvn1wdnaGoaEhBAIBIiMjW91G3bbs7OygqanJpTk7O0MulyM3N5dLs7GxgbKyMrduZGSE+/fvN1mvVCrFokWLYGVlBV1dXQgEAuTk5HDxicViKCsrw9XVtdHtxWIxXFxcoKKi0qb9qfv8hoGBATecqm5abdwSiQTV1dVwdnbm8lVUVDBkyBDk5OQAeH58hg4dqtBG/c8iKysLcXFxEAgE3CISiSCXy1FQUNCm+OsqLS3Fe++9B2tra0RFRbW7nloveH+BEEIIIeQV0NAA6oxdf+Vtt0FgYCDmzZuHrVu3YseOHTA3N+cubtevX4/Y2FjExMRAKBRCU1MTYWFhqKqq6rBwz549iylTpmDVqlUQiUTQ0dHB3r178fXXX3dYG3XVvzDn8XiQy+VNll+0aBGSk5MRHR0NCwsL8Pl8eHt7c8eAz+c3215L+a2Jk8fjtTnu9pBKpZg1axbmz5/fIK9Pnz7tqvPvv/+Gu7s7tLS0cOjQoTZ3jBpDHQJCCCGEdH08HlDnl+quzMfHB6GhoYiPj8fOnTsxZ84c8Hg8AEB6ejq8vLwwdepUAM+fCbhx4wasra1bVbeVlRUKCwtRXFwMIyMjAMC5c+cUymRkZMDU1BTLli3j0m7duqVQRlVVFTKZrMW24uLiUFZWxt0lSE9Ph5KSEgYMGNCqeBuTnp6OGTNmYOLEiQCeXzTXfRhXKBRCLpfj9OnTGDNmTIPtbW1t8dNPP6G6urpDLoYbY25uDlVVVaSnp8PU1BQAUF1djczMTG6OCCsrKxw5ckRhu/qfhYODA7Kzs2FhYdEhcZWWlkIkEkFNTQ1HjhyBurp6h9RLQ4YIIYQQQjqQQCCAr68vli5diuLiYsyYMYPLs7S0RHJyMjIyMpCTk4NZs2bh3r17ra57zJgx6N+/PwICApCVlYW0tDSFC//aNm7fvo29e/dCIpFg06ZNOHTokEIZMzMzFBQUQCwW4+HDh6isrGzQ1pQpU6Curo6AgABcv34dKSkpmDdvHqZNmwYDA4O2HZR68SUkJEAsFiMrKwv+/v4Kv8ybmZkhICAAH330EQ4fPoyCggKkpqZi//79AICQkBCUlpbiww8/xMWLF5GXl4ddu3YpDGN6UZqampgzZw4WL16MxMREZGdnIygoCM+ePeOGf82ePRt5eXlYvHgxcnNzER8f3+Bh6oiICGRkZCAkJARisRh5eXn45Zdf2vVQcWlpKcaOHYuysjL88MMPKC0txd27d3H37t0WO3ctoQ5BM2QyGVJTU7Fnzx6kpqa+8MEmhBBCyJshMDAQT548gUgkUhjvHxkZCQcHB4hEIri5ucHQ0BATJkxodb1KSko4dOgQysvLMWTIEHz88cdYs2aNQpnx48fj008/RUhICAYNGoSMjAwsX75coczkyZPh7u6OkSNHQl9fv9FXn2poaCApKQmPHz/G4MGD4e3tjdGjR2PLli1tOxj1bNiwAXp6ehg+fDg8PT0hEong4OCgUOabb76Bt7c3PvnkEwwcOBBBQUHcqzp79OiBU6dOQSqVwtXVFY6Ojti+fXuH3y1Yt24dJk+ejGnTpsHBwQH5+flISkqCnp4egOdDfg4ePIjDhw/Dzs4O27ZtwxdffKFQh62tLU6fPo0bN27AxcUF9vb2WLFihcI50VqXL1/G+fPnce3aNVhYWMDIyIhbCgsLX2hfeYy18l1aXVxpaSl0dHS41y+9qISEBISGhipMLtK7d2/ExsZi0qRJL1w/IYQQQhr/+11RUYGCggL07du3w4ZEEPImau13ie4QNCIhIQHe3t4NZhosKiqCt7c3EhISOikyQgghhBBCOhZ1COqRyWQIDQ1FYzdOatPCwsJo+BAhhBBCCOkwu3fvVng9ad3FxsbmpbZNbxmqJy0trcGdgboYYygsLERaWhrc3NxeXWCEEEIIIeS1NX78+AbzGtR6WW9TqkUdgnqKi4s7tBwhhBBCCCEt0dLSgpaWVqe03a4hQ1u3boWZmRnU1dUxdOhQXLhwocmy1dXV+Pzzz2Fubg51dXXY2dkhMTGxyfLr1q0Dj8fj3vH6qtW+07ejyhFCCCGEENKVtblDsG/fPixYsAArV67E5cuXYWdnB5FI1OQU1ZGRkfj222+xefNmZGdnY/bs2Zg4cSKuXLnSoGxmZia+/fZbhamlXzUXFxf07t2bm0CkPh6PBxMTE7i4uLziyAghhBBCCOl4be4QbNiwAUFBQZg5cyasra2xbds2aGho4Mcff2y0/K5du/DZZ5/Bw8MD/fr1w5w5c+Dh4dFg+mypVIopU6Zg+/bt3PtdO4OysjJiY2MBoEGnoHY9JiYGysrKrzw2QgghhBBCOlqbOgRVVVW4dOmSwjTSSkpKGDNmDM6ePdvoNpWVlQ3ee8rn83HmzBmFtLlz5+K9995rdIrqV23SpEn4+eef0atXL4X03r174+eff6Z5CAghhBBCyGujTQ8VP3z4EDKZrMF01QYGBvjjjz8a3UYkEmHDhg0YMWIEzM3NcfLkSSQkJCi8tnPv3r24fPkyMjMzWx1LZWWlwjTbpaWlbdmVFk2aNAleXl5IS0tDcXExjIyM4OLiQncGCCGEEELIa+Wlz0MQGxsLS0tLDBw4EKqqqggJCcHMmTOhpPS86cLCQoSGhmL37t1tmo1w7dq10NHR4RYTE5MOj11ZWRlubm7w8/ODm5sbdQYIIYQQ8sqZmZkhJiam1eVTU1PB4/Hw9OnTlxbT6+7mzZvg8XgQi8Wt3sbNza3TXorzotrUIXjrrbegrKyMe/fuKaTfu3cPhoaGjW6jr6+Pw4cPo6ysDLdu3cIff/wBgUCAfv36AQAuXbqE+/fvw8HBAd26dUO3bt1w+vRpbNq0Cd26dWtyArClS5eipKSEWwoLC9uyK4QQQgh5A8jkMqTeTMWea3uQejMVMvnLm1iUx+M1u0RFRbWr3szMTAQHB7e6/PDhw1FcXAwdHZ12tUdevqioKAwcOBCamprQ09PDmDFjcP78+U6Lp01DhlRVVeHo6IiTJ09iwoQJAAC5XI6TJ08iJCSk2W3V1dXRq1cvVFdX4+DBg/Dx8QEAjB49GteuXVMoO3PmTAwcOBARERFN/iqvpqYGNTW1toRPCCGEkDdIQk4CQhNDcaf0vxOO9tbujVj3WEyy6vjnAevOUbRv3z6sWLECubm5XJpAIOD+zRiDTCZDt24tX4rp6+u3KQ5VVdUmf6glXUP//v2xZcsW9OvXD+Xl5di4cSPGjh2L/Pz8Nn/eHaHNQ4YWLFiA7du346effkJOTg7mzJmDsrIyzJw5EwAwffp0LF26lCt//vx5JCQk4M8//0RaWhrc3d0hl8sRHh4O4PkkDG+//bbCoqmpiR49euDtt9/uoN0khBBCyJskIScB3vu9FToDAFBUWgTv/d5IyEno8DYNDQ25RUdHBzwej1v/448/oKWlhWPHjsHR0RFqamo4c+YMJBIJvLy8YGBgAIFAgMGDB+PEiRMK9dYfMsTj8fD9999j4sSJ0NDQgKWlJY4cOcLl1x8yFBcXB11dXSQlJcHKygoCgQDu7u4KHZiamhrMnz8furq66NGjByIiIhAQEMD9ANyYR48ewc/PD7169YKGhgaEQiH27NmjUEYul+Orr76ChYUF1NTU0KdPH6xZs4bLv3PnDvz8/NC9e3doamrCycmpyV/Ka4fx7N+/Hy4uLuDz+Rg8eDBu3LiBzMxMODk5QSAQYNy4cXjw4IFCDJ9//jl69+4NNTU1DBo0qMGcWBcuXIC9vT3U1dXh5OTU6Ovxr1+/jnHjxkEgEMDAwADTpk3Dw4cPmzw+zfH398eYMWPQr18/2NjYYMOGDSgtLcXVq1fbVd+LanOHwNfXF9HR0VixYgUGDRoEsViMxMRE7kHj27dvK5xgFRUViIyMhLW1NSZOnIhevXrhzJkz0NXV7bCdIIQQQgipJZPLEJoYCgbWIK82LSwx7KUOH2rKkiVLsG7dOuTk5MDW1hZSqRQeHh44efIkrly5And3d3h6euL27dvN1rNq1Sr4+Pjg6tWr8PDwwJQpU/D48eMmyz979gzR0dHYtWsX/vOf/+D27dtYtGgRl//ll19i9+7d2LFjB9LT01FaWorDhw83G0NFRQUcHR1x9OhRXL9+HcHBwZg2bZrChLVLly7FunXrsHz5cmRnZyM+Pp67ZpRKpXB1dUVRURGOHDmCrKwshIeHQy6XN9vuypUrERkZicuXL6Nbt27w9/dHeHg4YmNjkZaWhvz8fKxYsYIrHxsbi6+//hrR0dG4evUqRCIRxo8fj7y8PC6O999/H9bW1rh06RKioqIUjg0APH36FKNGjYK9vT0uXryIxMRE3Lt3jxvx8iKqqqrw3XffQUdHB3Z2di9cX7uw10RJSQkDwEpKSjo7FEIIIYS0UmN/v8vLy1l2djYrLy9vV50pBSkMUWhxSSlI6aC9aGjHjh1MR0fnvzGlpDAA7PDhwy1ua2NjwzZv3sytm5qaso0bN3LrAFhkZCS3LpVKGQB27NgxhbaePHnCxQKA5efnc9ts3bqVGRgYcOsGBgZs/fr13HpNTQ3r06cP8/Lyau0uM8YYe++999jChQsZY4yVlpYyNTU1tn379kbLfvvtt0xLS4s9evSoVXUXFBQwAOz777/n0vbs2cMAsJMnT3Jpa9euZQMGDODWjY2N2Zo1axTqGjx4MPvkk0+4OHr06KFwvn3zzTcMALty5QpjjLHVq1ezsWPHKtRRWFjIALDc3FzGGGOurq4sNDS0VfvCGGO//vor09TUZDwejxkbG7MLFy60etvWau136aW/ZYgQQggh5FUq/ru45UJtKNeRnJycFNalUikWLVoEKysr6OrqQiAQICcnp8U7BLa2tty/NTU1oa2tjfv37zdZXkNDA+bm5ty6kZERV76kpAT37t3DkCFDuHxlZWU4Ojo2G4NMJsPq1ashFArRvXt3CAQCJCUlcbHn5OSgsrISo0ePbnR7sVgMe3t7dO/evdl26qu777V3G4RCoUJa7b6Vlpbir7/+grOzs0Idzs7OyMnJ4eK0tbVVeNvlsGHDFMpnZWUhJSUFAoGAWwYOHAgAkEgkbYq/1siRIyEWi5GRkQF3d3f4+Pg0+xm+TG16qJgQQgghpKsz0jLq0HIdSVNTU2F90aJFSE5ORnR0NCwsLMDn8+Ht7Y2qqqpm61FRUVFY5/F4zQ61aaw8Yw2HVLXF+vXrERsbi5iYGAiFQmhqaiIsLIyLnc/nN7t9S/lNqbsvPB6v0bSWhh21lVQqhaenJ7788ssGeUZG7TuPNDU1YWFhAQsLC7zzzjuwtLTEDz/8oPAs7qtCdwgIIYQQ8lpx6eOC3tq9wQOv0XweeDDRNoFLH5dXHFlD6enpmDFjBiZOnAihUAhDQ0PcvHnzlcago6MDAwMDhQliZTIZLl++3Ox26enp8PLywtSpU2FnZ4d+/frhxo0bXL6lpSX4fD5OnjzZ6Pa2trYQi8XNPvvworS1tWFsbIz09PQGsVtbWwMArKyscPXqVVRUVHD5586dUyjv4OCA33//HWZmZtxFfO1Sv5PXXnK5XGHS3VeJOgSEEEIIea0oKykj1j0WABp0CmrXY9xjoKzU+ROOWlpaIiEhAWKxGFlZWfD39+/wX7dbY968eVi7di1++eUX5ObmIjQ0FE+ePOF+gW+MpaUlkpOTkZGRgZycHMyaNUthrip1dXVEREQgPDwcO3fuhEQiwblz5/DDDz8AAPz8/GBoaIgJEyYgPT0df/75Jw4ePIizZ8926L4tXrwYX375Jfbt24fc3FwsWbIEYrEYoaGhAJ6/8YfH4yEoKAjZ2dn47bffEB0drVDH3Llz8fjxY/j5+SEzMxMSiQRJSUmYOXNmk3NmNaWsrAyfffYZzp07h1u3buHSpUv46KOPUFRUhA8++KDD9rstqENACCGEkNfOJKtJ+NnnZ/TS7qWQ3lu7N372+fmlzEPQHhs2bICenh6GDx8OT09PiEQiODg4vPI4IiIi4Ofnh+nTp2PYsGEQCAQQiUQK4+rri4yMhIODA0QiEdzc3LiL+7qWL1+OhQsXYsWKFbCysoKvry83Tl5VVRXHjx9Hz5494eHhAaFQiHXr1jU5B1V7zZ8/HwsWLMDChQshFAqRmJiII0eOwNLSEsDz+SF+/fVXXLt2Dfb29li2bFmDoUG1dxlkMhnGjh0LoVCIsLAw6OrqQkmpbZfTysrK+OOPPzB58mT0798fnp6eePToEdLS0mBjY9Nh+90WPPaiA8i6iNLSUujo6KCkpATa2tqdHQ4hhBBCWqGxv98VFRUoKChA3759m70gbQ2ZXIa022ko/rsYRlpGcOnj0iXuDHR1crkcVlZW8PHxwerVqzs7HNJOrf0u0UPFhBBCCHltKSspw83MrbPD6PJu3bqF48ePw9XVFZWVldiyZQsKCgrg7+/f2aGRV4CGDBFCCCGEvOGUlJQQFxeHwYMHw9nZGdeuXcOJEydgZWXV2aH946SlpSm8nrT+0hXRHQJCCCGEkDeciYlJgzfxkPZxcnKCWCzu7DDahDoEhBBCCCGEdBA+nw8LC4vODqNNaMgQIYQQQgghbzDqEBBCCCGEEPIGow4BIYQQQgghbzDqEBBCCCGEEPIGow4BIYQQQgghbzDqEBBCCCGEdCFubm4ICwvj1s3MzBATE9PsNjweD4cPH37htjuqnjdVamoqeDwenj592uptWvP5vmzUISCEEEII6QCenp5wd3dvNC8tLQ08Hg9Xr15tc72ZmZkIDg5+0fAUREVFYdCgQQ3Si4uLMW7cuA5ti3ScWbNmwdzcHHw+H/r6+vDy8sIff/zxwvVSh4AQQgghpAMEBgYiOTkZd+7caZC3Y8cOODk5wdbWts316uvrQ0NDoyNCbJGhoSHU1NReSVuk7RwdHbFjxw7k5OQgKSkJjDGMHTsWMpnsheqlDgEhhBBCSAd4//33oa+vj7i4OIV0qVSKAwcOIDAwEI8ePYKfnx969eoFDQ0NCIVC7Nmzp9l66w8pycvLw4gRI6Curg5ra2skJyc32CYiIgL9+/eHhoYG+vXrh+XLl6O6uhoAEBcXh1WrViErKws8Hg88Ho+Luf6QoWvXrmHUqFHg8/no0aMHgoODIZVKufwZM2ZgwoQJiI6OhpGREXr06IG5c+dybTVGIpHAy8sLBgYGEAgEGDx4ME6cOKFQprKyEhERETAxMYGamhosLCzwww8/cPm///473n//fWhra0NLSwsuLi6QSCSNtlc7jCcpKQn29vbg8/kYNWoU7t+/j2PHjsHKygra2trw9/fHs2fPFGKYP38+evbsCXV1dbz77rvIzMxUqPu3335D//79wefzMXLkSNy8ebNB+2fOnIGLiwv4fD5MTEwwf/58lJWVNXl8mhMcHIwRI0bAzMwMDg4O+Pe//43CwsJG220LmqmYEEIIIV0eYwzPqp+1XPAl0FDRAI/Ha7Fct27dMH36dMTFxWHZsmXcNgcOHIBMJoOfnx+kUikcHR0REREBbW1tHD16FNOmTYO5uTmGDBnSYhtyuRyTJk2CgYEBzp8/j5KSEoXnDWppaWkhLi4OxsbGuHbtGoKCgqClpYXw8HD4+vri+vXrSExM5C7EdXR0GtRRVlYGkUiEYcOGITMzE/fv38fHH3+MkJAQhU5PSkoKjIyMkJKSgvz8fPj6+mLQoEEICgpqdB+kUik8PDywZs0aqKmpYefOnfD09ERubi769OkDAJg+fTrOnj2LTZs2wc7ODgUFBXj48CEAoKioCCNGjICbmxtOnToFbW1tpKeno6amptljFxUVhS1btkBDQwM+Pj7w8fGBmpoa4uPjIZVKMXHiRGzevBkREREAgPDwcBw8eBA//fQTTE1N8dVXX0EkEiE/Px/du3dHYWEhJk2ahLlz5yI4OBgXL17EwoULFdqUSCRwd3fHv//9b/z444948OABQkJCEBISgh07djQbb0vKysqwY8cO9O3bFyYmJi9UF9hroqSkhAFgJSUlnR0KIYQQQlqpsb/f5eXlLDs7m5WXl3Np0kopQxQ6ZZFWSlu9Pzk5OQwAS0lJ4dJcXFzY1KlTm9zmvffeYwsXLuTWXV1dWWhoKLduamrKNm7cyBhjLCkpiXXr1o0VFRVx+ceOHWMA2KFDh5psY/369czR0ZFbX7lyJbOzs2tQrm493333HdPT02NS6X/3/+jRo0xJSYndvXuXMcZYQEAAMzU1ZTU1NVyZDz74gPn6+jYZS2NsbGzY5s2bGWOM5ebmMgAsOTm50bJLly5lffv2ZVVVVa2qOyUlhQFgJ06c4NLWrl3LADCJRMKlzZo1i4lEIsYYY1KplKmoqLDdu3dz+VVVVczY2Jh99dVXXBzW1tYKbUVERDAA7MmTJ4wxxgIDA1lwcLBCmbS0NKakpMSd33U/39bYunUr09TUZADYgAEDWH5+fpNlG/suNYaGDBFCCCGEdJCBAwdi+PDh+PHHHwEA+fn5SEtLQ2BgIABAJpNh9erVEAqF6N69OwQCAZKSknD79u1W1Z+TkwMTExMYGxtzacOGDWtQbt++fXB2doahoSEEAgEiIyNb3Ubdtuzs7KCpqcmlOTs7Qy6XIzc3l0uzsbGBsrIyt25kZIT79+83Wa9UKsWiRYtgZWUFXV1dCAQC5OTkcPGJxWIoKyvD1dW10e3FYjFcXFygoqLSpv2p+/yGgYEBN5yqblpt3BKJBNXV1XB2dubyVVRUMGTIEOTk5AB4fnyGDh2q0Eb9zyIrKwtxcXEQCATcIhKJIJfLUVBQ0Kb4a02ZMgVXrlzB6dOn0b9/f/j4+KCioqJdddWiIUOEEEII6fI0VDQgXSptueBLarstAgMDMW/ePGzduhU7duyAubk5d3G7fv16xMbGIiYmBkKhEJqamggLC0NVVVWHxXv27FlMmTIFq1atgkgkgo6ODvbu3Yuvv/66w9qoq/6FOY/Hg1wub7L8okWLkJycjOjoaFhYWIDP58Pb25s7Bnw+v9n2WspvTZw8Hq/NcbeHVCrFrFmzMH/+/AZ5tcOj2kpHRwc6OjqwtLTEO++8Az09PRw6dAh+fn7tjpM6BIQQQgjp8ng8HjRVNVsu2AX4+PggNDQU8fHx2LlzJ+bMmcM9T5Ceng4vLy9MnToVwPNnAm7cuAFra+tW1W1lZYXCwkIUFxfDyMgIAHDu3DmFMhkZGTA1NcWyZcu4tFu3bimUUVVVbfHNNFZWVoiLi0NZWRl3lyA9PR1KSkoYMGBAq+JtTHp6OmbMmIGJEycCeH7RXPehWKFQCLlcjtOnT2PMmDENtre1tcVPP/2E6urqNt8laC1zc3OoqqoiPT0dpqamAIDq6mpkZmZyz2xYWVnhyJEjCtvV/ywcHByQnZ0NCwuLlxInYwyMMVRWVr5QPTRkiBBCCCGkAwkEAvj6+mLp0qUoLi7GjBkzuDxLS0skJycjIyMDOTk5mDVrFu7du9fquseMGYP+/fsjICAAWVlZSEtLU7jwr23j9u3b2Lt3LyQSCTZt2oRDhw4plDEzM0NBQQHEYjEePnzY6AXllClToK6ujoCAAFy/fh0pKSmYN28epk2bBgMDg7YdlHrxJSQkQCwWIysrC/7+/gq/zJuZmSEgIAAfffQRDh8+jIKCAqSmpmL//v0AgJCQEJSWluLDDz/ExYsXkZeXh127dikMY3pRmpqamDNnDhYvXozExERkZ2cjKCgIz54944Z/zZ49G3l5eVi8eDFyc3MRHx/f4A1TERERyMjIQEhICMRiMfLy8vDLL78gJCSkzTH9+eefWLt2LS5duoTbt28jIyMDH3zwAfh8Pjw8PF5of6lDQAghhBDSwQIDA/HkyROIRCKF8f6RkZFwcHCASCSCm5sbDA0NMWHChFbXq6SkhEOHDqG8vBxDhgzBxx9/jDVr1iiUGT9+PD799FOEhIRg0KBByMjIwPLlyxXKTJ48Ge7u7hg5ciT09fUbffWphoYGkpKS8PjxYwwePBje3t4YPXo0tmzZ0raDUc+GDRugp6eH4cOHw9PTEyKRCA4ODgplvvnmG3h7e+OTTz7BwIEDERQUxL2qs0ePHjh16hSkUilcXV3h6OiI7du3d/jdgnXr1mHy5MmYNm0aHBwckJ+fj6SkJOjp6QF4PuTn4MGDOHz4MOzs7LBt2zZ88cUXCnXY2tri9OnTuHHjBlxcXGBvb48VK1YonBOtpa6ujrS0NHh4eMDCwgK+vr7Q0tJCRkYGevbs+UL7ymOMsReqoYsoLS2Fjo4OSkpKoK2t3dnhEEIIIaQVGvv7XVFRgYKCAvTt2xfq6uqdHCEh/1yt/S7RHQJCCCGEEELeYNQhIIQQQgghpJPt3r1b4fWkdRcbG5uX2ja9ZYgQQgghhJBONn78+AbzGtR6WW9TqkUdAkIIIYQQQjqZlpYWtLS0OqVtGjJECCGEEELIG4w6BIQQQgghhLzBqENACCGEEELIG4w6BIQQQgghhLzBqENACCGEEELIG4w6BIQQQgghXZiZmRliYmJaXT41NRU8Hg9Pnz59aTG97m7evAkejwexWNzqbdzc3BAWFvbSYnqZqENACCGEkNcWYzI8eZKKe/f24MmTVDAme2lt8Xi8ZpeoqKh21ZuZmYng4OBWlx8+fDiKi4uho6PTrvbIqzV79mzweLw2dfo6Gs1DQAghhJDX0oMHCcjPD0Vl5R0uTU2tNywsYqGvP6nD2ysuLub+vW/fPqxYsQK5ublcmkAg4P7NGINMJkO3bi1fiunr67cpDlVVVRgaGrZpG9I5Dh06hHPnzsHY2LhT46A7BIQQQgh57Tx4kIDff/dW6AwAQGVlEX7/3RsPHiR0eJuGhobcoqOjAx6Px63/8ccf0NLSwrFjx+Do6Ag1NTWcOXMGEokEXl5eMDAwgEAgwODBg3HixAmFeusPGeLxePj+++8xceJEaGhowNLSEkeOHOHy6w8ZiouLg66uLpKSkmBlZQWBQAB3d3eFDkxNTQ3mz58PXV1d9OjRAxEREQgICMCECROa3N9Hjx7Bz88PvXr1goaGBoRCIfbs2aNQRi6X46uvvoKFhQXU1NTQp08frFmzhsu/c+cO/Pz80L17d2hqasLJyQnnz59vtL3aYTz79++Hi4sL+Hw+Bg8ejBs3biAzMxNOTk4QCAQYN24cHjx4oBDD559/jt69e0NNTQ2DBg1CYmKiQt0XLlyAvb091NXV4eTkhCtXrjRo//r16xg3bhwEAgEMDAwwbdo0PHz4sMnj05KioiLMmzcPu3fvfukzEbeEOgSEEEIIea0wJkN+figA1lguACA/P+ylDh9qypIlS7Bu3Trk5OTA1tYWUqkUHh4eOHnyJK5cuQJ3d3d4enri9u3bzdazatUq+Pj44OrVq/Dw8MCUKVPw+PHjJss/e/YM0dHR2LVrF/7zn//g9u3bWLRoEZf/5ZdfYvfu3dixYwfS09NRWlqKw4cPNxtDRUUFHB0dcfToUVy/fh3BwcGYNm0aLly4wJVZunQp1q1bh+XLlyM7Oxvx8fEwMDAAAEilUri6uqKoqAhHjhxBVlYWwsPDIZfLm2135cqViIyMxOXLl9GtWzf4+/sjPDwcsbGxSEtLQ35+PlasWMGVj42Nxddff43o6GhcvXoVIpEI48ePR15eHhfH+++/D2tra1y6dAlRUVEKxwYAnj59ilGjRsHe3h4XL15EYmIi7t27Bx8fn2ZjbYpcLse0adOwePFi2NjYtKuODsXaYcuWLczU1JSpqamxIUOGsPPnzzdZtqqqiq1atYr169ePqampMVtbW3bs2DGFMv/v//0/JhQKmZaWFtPS0mLvvPMO++2339oUU0lJCQPASkpK2rNLhBBCCOkEjf39Li8vZ9nZ2ay8vLxddT5+nMJSUtDi8vhxSofsQ2N27NjBdHR0uPWUlBQGgB0+fLjFbW1sbNjmzZu5dVNTU7Zx40ZuHQCLjIzk1qVSKQPAXV/VtvXkyRMuFgAsPz+f22br1q3MwMCAWzcwMGDr16/n1mtqalifPn2Yl5dXa3eZMcbYe++9xxYuXMgYY6y0tJSpqamx7du3N1r222+/ZVpaWuzRo0etqrugoIABYN9//z2XtmfPHgaAnTx5kktbu3YtGzBgALdubGzM1qxZo1DX4MGD2SeffMLF0aNHD4Xz7ZtvvmEA2JUrVxhjjK1evZqNHTtWoY7CwkIGgOXm5jLGGHN1dWWhoaGt2pcvvviC/etf/2JyuZwx1vAz7iit/S61+Q7Bvn37sGDBAqxcuRKXL1+GnZ0dRCIR7t+/32j5yMhIfPvtt9i8eTOys7Mxe/ZsTJw4UeFWTO/evbFu3TpcunQJFy9exKhRo+Dl5YXff/+9reERQggh5A1XVVXccqE2lOtITk5OCutSqRSLFi2ClZUVdHV1IRAIkJOT0+IdAltbW+7fmpqa0NbWbvJaDAA0NDRgbm7OrRsZGXHlS0pKcO/ePQwZMoTLV1ZWhqOjY7MxyGQyrF69GkKhEN27d4dAIEBSUhIXe05ODiorKzF69OhGtxeLxbC3t0f37t2bbae+uvtee7dBKBQqpNXuW2lpKf766y84Ozsr1OHs7IycnBwuTltbW6irq3P5w4YNUyiflZWFlJQUCAQCbhk4cCAAQCKRtCn+S5cuITY2FnFxceDxeG3a9mVpc4dgw4YNCAoKwsyZM2FtbY1t27ZBQ0MDP/74Y6Pld+3ahc8++wweHh7o168f5syZAw8PD3z99ddcGU9PT3h4eMDS0hL9+/fHmjVrIBAIcO7cufbvGSGEEELeSKqqRh1ariNpamoqrC9atAiHDh3CF198gbS0NIjFYgiFQlRVVTVbT/0x5zwer9mhNo2VZ6yxIVWtt379esTGxiIiIgIpKSkQi8UQiURc7Hw+v9ntW8pvSt19qb2grp/W0rCjtpJKpfD09IRYLFZY8vLyMGLEiDbVlZaWhvv376NPnz7o1q0bunXrhlu3bmHhwoUwMzPr0Lhbq00dgqqqKly6dAljxoz5bwVKShgzZgzOnj3b6DaVlZUKPS7g+Qlw5syZRsvLZDLs3bsXZWVlDXpnhBBCCCEt0dV1gZpabwBN/frKg5qaCXR1XV5lWI1KT0/HjBkzMHHiRAiFQhgaGuLmzZuvNAYdHR0YGBggMzOTS5PJZLh8+XKz26Wnp8PLywtTp06FnZ0d+vXrhxs3bnD5lpaW4PP5OHnyZKPb29raQiwWN/vsw4vS1taGsbEx0tPTG8RubW0NALCyssLVq1dRUVHB5df/UdrBwQG///47zMzMYGFhobDU7+S1ZNq0abh69apCx8LY2BiLFy9GUlJSO/f0xbSpQ/Dw4UPIZDLu9kwtAwMD3L17t9FtRCIRNmzYgLy8PMjlciQnJyMhIUHhyXYAuHbtGgQCAdTU1DB79mwcOnSI+6AaU1lZidLSUoWFEEIIIYTHU4aFRWztWv1cAICFRQx4POVXGldjLC0tkZCQALFYjKysLPj7+3f4r9utMW/ePKxduxa//PILcnNzERoaiidPnjQ7pMXS0hLJycnIyMhATk4OZs2ahXv37nH56urqiIiIQHh4OHbu3AmJRIJz587hhx9+AAD4+fnB0NAQEyZMQHp6Ov78808cPHiwyR+Z22vx4sX48ssvsW/fPuTm5mLJkiUQi8UIDQ0FAPj7+4PH4yEoKAjZ2dn47bffEB0drVDH3Llz8fjxY/j5+SEzMxMSiQRJSUmYOXMmZLK2PZzeo0cPvP322wqLiooKDA0NMWDAgA7b77Z46W8Zio2NhaWlJQYOHAhVVVWEhIRg5syZUFJSbHrAgAEQi8U4f/485syZg4CAAGRnZzdZ79q1a6Gjo8MtJiYmL3tXCCGEEPIPoa8/CTY2P0NNrZdCuppab9jY/PxS5iFojw0bNkBPTw/Dhw+Hp6cnRCIRHBwcXnkcERER8PPzw/Tp0zFs2DAIBAKIRKIGozzqioyMhIODA0QiEdzc3LiL+7qWL1+OhQsXYsWKFbCysoKvry83vl9VVRXHjx9Hz5494eHhAaFQiHXr1kFZuWM7avPnz8eCBQuwcOFCCIVCJCYm4siRI7C0tATwfH6IX3/9FdeuXYO9vT2WLVuGL7/8UqGO2rsMMpkMY8eOhVAoRFhYGHR1dRtc0/4T8VgbBpBVVVVBQ0MDP//8s8IHHhAQgKdPn+KXX35pctuKigo8evQIxsbGWLJkCf73f/+32YeGx4wZA3Nzc3z77beN5ldWVqKyspJbLy0thYmJCUpKSqCtrd3aXSKEEEJIJyotLYWOjo7C3++KigoUFBSgb9++zV6QtgZjMjx9moaqqmKoqhpBV9elS9wZ6OrkcjmsrKzg4+OD1atXd3Y4pJ1a+11q00zFqqqqcHR0xMmTJ7kOgVwux8mTJxESEtLsturq6ujVqxeqq6tx8ODBFt/bKpfLFS7461NTU4OamlpbwieEEELIG4bHU4aenltnh9Hl3bp1C8ePH4erqysqKyuxZcsWFBQUwN/fv7NDI69AmzoEALBgwQIEBATAyckJQ4YMQUxMDMrKyjBz5kwAwPTp09GrVy+sXbsWAHD+/HkUFRVh0KBBKCoqQlRUFORyOcLDw7k6ly5dinHjxqFPnz74+++/ER8fj9TU1E57sIIQQggh5E2ipKSEuLg4LFq0CIwxvP322zhx4gSsrKw6O7R/nLS0NIwbN67JfKlU+gqjaZ02dwh8fX3x4MEDrFixAnfv3uWmf6590Pj27dsKY6kqKioQGRmJP//8EwKBAB4eHti1axd0dXW5Mvfv38f06dNRXFwMHR0d2NraIikpCf/6179efA8JIYQQQkizTExMGryJh7SPk5MTxGJxZ4fRJm16hqAra2wMIiGEEEK6tpf9DAEhb7LWfpf++Y9FE0IIIYQQQtqNOgSEEEIIIYS8wahDQAghhBBCyBuMOgSEEEIIIYS8wahDQAghhBBCyBuMOgSEEEIIIV2Im5sbwsLCuHUzMzPExMQ0uw2Px8Phw4dfuO2OqudNlZqaCh6Ph6dPn7Z6m9Z8vi8bdQgIIYQQQjqAp6cn3N3dG81LS0sDj8fD1atX21xvZmYmgoODXzQ8BVFRURg0aFCD9OLi4mYn1SJdA2MM48aN67AOHHUICCGEEEI6QGBgIJKTk3Hnzp0GeTt27ICTkxNsbW3bXK++vj40NDQ6IsQWGRoaQk1N7ZW0RdovJiYGPB6vw+qjDkEzZHIZUm+mYs+1PUi9mQqZXNbZIRFCCCGki3r//fehr6+PuLg4hXSpVIoDBw4gMDAQjx49gp+fH3r16gUNDQ0IhULs2bOn2XrrDynJy8vDiBEjoK6uDmtrayQnJzfYJiIiAv3794eGhgb69euH5cuXo7q6GgAQFxeHVatWISsrCzweDzwej4u5/i/O165dw6hRo8Dn89GjRw8EBwdDKpVy+TNmzMCECRMQHR0NIyMj9OjRA3PnzuXaaoxEIoGXlxcMDAwgEAgwePBgnDhxQqFMZWUlIiIiYGJiAjU1NVhYWOCHH37g8n///Xe8//770NbWhpaWFlxcXCCRSBptr3YYT1JSEuzt7cHn8zFq1Cjcv38fx44dg5WVFbS1teHv749nz54pxDB//nz07NkT6urqePfdd5GZmalQ92+//Yb+/fuDz+dj5MiRuHnzZoP2z5w5AxcXF/D5fJiYmGD+/PkoKytr8vi0RCwW4+uvv8aPP/7Y7jrq69ZhNb1mEnISEJoYijul/+3l99bujVj3WEyymtSJkRFCCCFvHsYY5PJnLRd8CZSUNFr1a2y3bt0wffp0xMXFYdmyZdw2Bw4cgEwmg5+fH6RSKRwdHREREQFtbW0cPXoU06ZNg7m5OYYMGdJiG3K5HJMmTYKBgQHOnz+PkpIShecNamlpaSEuLg7Gxsa4du0agoKCoKWlhfDwcPj6+uL69etITEzkLsR1dHQa1FFWVgaRSIRhw4YhMzMT9+/fx8cff4yQkBCFTk9KSgqMjIyQkpKC/Px8+Pr6YtCgQQgKCmp0H6RSKTw8PLBmzRqoqalh586d8PT0RG5uLvr06QMAmD59Os6ePYtNmzbBzs4OBQUFePjwIQCgqKgII0aMgJubG06dOgVtbW2kp6ejpqam2WMXFRWFLVu2QENDAz4+PvDx8YGamhri4+MhlUoxceJEbN68GREREQCA8PBwHDx4ED/99BNMTU3x1VdfQSQSIT8/H927d0dhYSEmTZqEuXPnIjg4GBcvXsTChQsV2pRIJHB3d8e///1v/Pjjj3jw4AFCQkIQEhKCHTt2NBtvY549ewZ/f39s3boVhoaGbd6+Sew1UVJSwgCwkpKSF67rYPZBxoviMURBYeFF8RgviscOZh/sgIgJIYQQ0tjf7/Lycpadnc3Ky8u5tJoaKUtJQacsNTXSVu9PTk4OA8BSUlK4NBcXFzZ16tQmt3nvvffYwoULuXVXV1cWGhrKrZuamrKNGzcyxhhLSkpi3bp1Y0VFRVz+sWPHGAB26NChJttYv349c3R05NZXrlzJ7OzsGpSrW893333H9PT0mFT63/0/evQoU1JSYnfv3mWMMRYQEMBMTU1ZTU0NV+aDDz5gvr6+TcbSGBsbG7Z582bGGGO5ubkMAEtOTm607NKlS1nfvn1ZVVVVq+pOSUlhANiJEye4tLVr1zIATCKRcGmzZs1iIpGIMcaYVCplKioqbPfu3Vx+VVUVMzY2Zl999RUXh7W1tUJbERERDAB78uQJY4yxwMBAFhwcrFAmLS2NKSkpced33c+3JcHBwSwwMJBbb+lzb+y71BgaMlSPTC5DaGIoGFiDvNq0sMQwGj5ECCGEkAYGDhyI4cOHc8M58vPzkZaWhsDAQACATCbD6tWrIRQK0b17dwgEAiQlJeH27dutqj8nJwcmJiYwNjbm0oYNG9ag3L59++Ds7AxDQ0MIBAJERka2uo26bdnZ2UFTU5NLc3Z2hlwuR25uLpdmY2MDZWVlbt3IyAj3799vsl6pVIpFixbBysoKurq6EAgEyMnJ4eITi8VQVlaGq6tro9uLxWK4uLhARUWlTftT9/kNAwMDbjhV3bTauCUSCaqrq+Hs7Mzlq6ioYMiQIcjJyQHw/PgMHTpUoY36n0VWVhbi4uIgEAi4RSQSQS6Xo6CgoE3xHzlyBKdOnXopbySiIUP1pN1OUxgmVB8DQ2FpIdJup8HNzO3VBUYIIYS8wZSUNODiIm254Etquy0CAwMxb948bN26FTt27IC5uTl3cbt+/XrExsYiJiYGQqEQmpqaCAsLQ1VVVYfFe/bsWUyZMgWrVq2CSCSCjo4O9u7di6+//rrD2qir/oU5j8eDXC5vsvyiRYuQnJyM6OhoWFhYgM/nw9vbmzsGfD6/2fZaym9NnDwer81xt4dUKsWsWbMwf/78Bnm1w6Na69SpU5BIJNDV1VVInzx5MlxcXJCamtruOKlDUE/x38UdWo4QQgghL47H40FZWbPlgl2Aj48PQkNDER8fj507d2LOnDnc8wTp6enw8vLC1KlTATx/JuDGjRuwtrZuVd1WVlYoLCxEcXExjIyMAADnzp1TKJORkQFTU1MsW7aMS7t165ZCGVVVVchkzY92sLKyQlxcHMrKyri7BOnp6VBSUsKAAQNaFW9j0tPTMWPGDEycOBHA84vmug/jCoVCyOVynD59GmPGjGmwva2tLX766SdUV1e3+S5Ba5mbm0NVVRXp6ekwNTUFAFRXVyMzM5N7ZsPKygpHjhxR2K7+Z+Hg4IDs7GxYWFi8cExLlizBxx9/rJAmFAqxceNGeHp6vlDdNGSoHiMtow4tRwghhJA3i0AggK+vL5YuXYri4mLMmDGDy7O0tERycjIyMjKQk5ODWbNm4d69e62ue8yYMejfvz8CAgKQlZWFtLQ0hQv/2jZu376NvXv3QiKRYNOmTTh06JBCGTMzMxQUFEAsFuPhw4eorKxs0NaUKVOgrq6OgIAAXL9+HSkpKZg3bx6mTZsGAwODth2UevElJCRALBYjKysL/v7+Cr/Mm5mZISAgAB999BEOHz6MgoICpKamYv/+/QCAkJAQlJaW4sMPP8TFixeRl5eHXbt2KQxjelGampqYM2cOFi9ejMTERGRnZyMoKAjPnj3jhn/Nnj0beXl5WLx4MXJzcxEfH9/gDVMRERHIyMhASEgIxGIx8vLy8MsvvyAkJKTNMRkaGuLtt99WWIDndxr69u37QvtLHYJ6XPq4oLd2b/DQ+NsEeODBRNsELn1cXnFkhBBCCPmnCAwMxJMnTyASiRTG+0dGRsLBwQEikQhubm4wNDTEhAkTWl2vkpISDh06hPLycgwZMgQff/wx1qxZo1Bm/Pjx+PTTTxESEoJBgwYhIyMDy5cvVygzefJkuLu7Y+TIkdDX12/01acaGhpISkrC48ePMXjwYHh7e2P06NHYsmVL2w5GPRs2bICenh6GDx8OT09PiEQiODg4KJT55ptv4O3tjU8++QQDBw5EUFAQ96rOHj164NSpU5BKpXB1dYWjoyO2b9/e4XcL1q1bh8mTJ2PatGlwcHBAfn4+kpKSoKenB+D5hfjBgwdx+PBh2NnZYdu2bfjiiy8U6rC1tcXp06dx48YNuLi4wN7eHitWrFA4J7oC3v89ofyPV1paCh0dHZSUlEBbW/uF6krISYD3fm8AUHi4uLaT8LPPz/TqUUIIIaQDNPb3u6KiAgUFBejbty/U1dU7OUJC/rla+12iOwSNmGQ1CT/7/Ixe2r0U0ntr96bOACGEEEIIea3QQ8VNmGQ1CV4DvJB2Ow3FfxfDSMsILn1coKyk3PLGhBBCCCGEtMHu3bsxa9asRvNMTU3x+++/v7S2qUPQDGUlZXq1KCGEEEIIeenGjx/fYF6DWi/rbUq1qENACCGEEEJIJ9PS0oKWllantE3PEBBCCCGEEPIGow4BIYQQQgghbzDqEBBCCCGEEPIGow4BIYQQQgghbzDqEBBCCCGEEPIGow4BIYQQQkgXZmZmhpiYmFaXT01NBY/Hw9OnT19aTK+7mzdvgsfjQSwWt3obNzc3hIWFvbSYXibqEBBCCCHktSWTyZCamoo9e/YgNTUVMpnspbXF4/GaXaKiotpVb2ZmJoKDg1tdfvjw4SguLoaOjk672iMv34wZMxqcH+7u7p0WD81DQAghhJDXUkJCAkJDQ3Hnzh0urXfv3oiNjcWkSZM6vL3i4mLu3/v27cOKFSuQm5vLpQkEAu7fjDHIZDJ069bypZi+vn6b4lBVVYWhoWGbtiGvnru7O3bs2MGtq6mpdVosr02HgDEGACgtLe3kSAghhBDSWrV/t2v/jneUhIQEeHt7N6i3qKgI3t7e+Pnnnzu8U1D3IlxHRwc8Ho9LS01NxciRI/Hbb78hMjIS165dw/Hjx2FiYoIFCxbg3LlzKCsrg5WVFdauXYsxY8ZwdZmZmSEsLIwbjsLj8bB9+3YcPXoUSUlJ6NWrF77++muMHz9eoa0nT55AV1cXcXFxCAsLw759+xAWFobCwkK8++672LFjB4yMjAAANTU1WLBgAXbu3AllZWV8/PHHuHv3LkpKSnD48OFG9/fRo0cICQnBf/7zHzx58gTm5ub47LPP4Ofnx5WRy+WIjo7Gd999h8LCQhgYGGDWrFlYtmwZAODOnTtYvHgxkpKSUFlZCSsrK2zdurXRGXtv3ryJvn37Yt++fdi8eTMuXryIt99+G7t370ZJSQnmzJmDP/74Ay4uLti5cyfXkZLL5fj3v/+N7777Dg8ePICVlRXWrVun8Iv8hQsXMGvWLOTk5ODtt9/m4qvr+vXrWLx4MdLS0qCpqYmxY8di48aNeOutt1o8NxqjpqbWdTpu7DVRWFjIANBCCy200EILLf/ApbCwkPubXl5ezrKzs1l5eXm7rglqampY7969m2yLx+MxExMTVlNT01GXIQ3s2LGD6ejocOspKSkMALO1tWXHjx9n+fn57NGjR0wsFrNt27axa9eusRs3brDIyEimrq7Obt26xW1ramrKNm7cyK0DYL1792bx8fEsLy+PzZ8/nwkEAvbo0SOFtp48ecLFoqKiwsaMGcMyMzPZpUuXmJWVFfP39+fq/Pe//826d+/OEhISWE5ODps9ezbT1tZmXl5eTe7jnTt32Pr169mVK1eYRCJhmzZtYsrKyuz8+fNcmfDwcKanp8fi4uJYfn4+S0tLY9u3b2eMMfb333+zfv36MRcXF5aWlsby8vLYvn37WEZGRqPtFRQUMABs4MCBLDExkWVnZ7N33nmHOTo6Mjc3N3bmzBl2+fJlZmFhwWbPns1tt2HDBqatrc327NnD/vjjDxYeHs5UVFTYjRs3uDj09fWZv78/u379Ovv1119Zv379GAB25coVxhhjT548Yfr6+mzp0qUsJyeHXb58mf3rX/9iI0eO5NpxdXVloaGhTR6vugICApiOjg7T19dn/fv3Z7Nnz2YPHz5s1bZt0drv0mtzh8DY2BiFhYXQ0tICj8dTyCstLYWJiQkKCwuhra3dSRH+s9Axax86bu1Dx6196Li1HR2z9nmZx40xhr///hvGxsYdVmdaWprCMKHG2iwsLERaWhrc3Nw6rN3W+Pzzz/Gvf/2LW+/evTvs7Oy49dWrV+PQoUM4cuQIQkJCmqxnxowZ3C/xX3zxBTZt2oQLFy40OQ69uroa27Ztg7m5OQAgJCQEn3/+OZe/efNmLF26FBMnTgQAbNmyBb/99luz+9KrVy8sWrSIW583bx6SkpKwf/9+DBkyBH///TdiY2OxZcsWBAQEAADMzc3x7rvvAgDi4+Px4MEDZGZmonv37gAACwuLZtsEgEWLFkEkEgEAQkND4efnh5MnT8LZ2RkAEBgYiLi4OK58dHQ0IiIi8OGHHwIAvvzyS6SkpCAmJgZbt25FfHw85HI5fvjhB6irq8PGxgZ37tzBnDlzuDq2bNkCe3t7fPHFF1zajz/+CBMTE9y4cQP9+/dvMe663N3dMWnSJPTt2xcSiQSfffYZxo0bh7Nnz0JZWblNdXWE16ZDoKSkhN69ezdbRltbm/4AtBEds/ah49Y+dNzah45b29Exa5+Xddw6+uHXumP5O6JcR3JyclJYl0qliIqKwtGjR1FcXIyamhqUl5fj9u3bzdZja2vL/VtTUxPa2tq4f/9+k+U1NDS4zgAAGBkZceVLSkpw7949DBkyhMtXVlaGo6Mj5HJ5k3XKZDJ88cUX2L9/P4qKilBVVYXKykpoaGgAAHJyclBZWYnRo0c3ur1YLIa9vT3XGWituvtuYGAAABAKhQpptftWWlqKv/76i+ss1HJ2dkZWVhYXp62tLdTV1bn8YcOGKZTPyspCSkqKwnMgtSQSSZs7BLWdk9rYbW1tYW5ujtTU1CaP18v02nQICCGEEEIAcOPiO6pcR9LU1FRYX7RoEZKTkxEdHQ0LCwvw+Xx4e3ujqqqq2XpUVFQU1nk8XrMX742VZy/43Mb69esRGxuLmJgYCIVCaGpqIiwsjIudz+c3u31L+U2puy+1o0LqpzV3LNpDKpXC09MTX375ZYO8jjiP+vXrh7feegv5+fmd0iGg144SQggh5LXi4uKC3r17NxhCXIvH48HExAQuLi6vOLKG0tPTMWPGDEycOBFCoRCGhoa4efPmK41BR0cHBgYGyMzM5NJkMhkuX77c7Hbp6enw8vLC1KlTYWdnh379+uHGjRtcvqWlJfh8Pk6ePNno9ra2thCLxXj8+HHH7EgjtLW1YWxsjPT09AaxW1tbAwCsrKxw9epVVFRUcPnnzp1TKO/g4IDff/8dZmZmsLCwUFjqd/La486dO3j06FGndFKBN6RDoKamhpUrV3bq65z+aeiYtQ8dt/ah49Y+dNzajo5Z+/zTjpuysjJiY2MBoEGnoHY9JiamU8Zq12dpaYmEhASIxWJkZWXB39+/w3/dbo158+Zh7dq1+OWXX5Cbm4vQ0FA8efKkyU4V8Dz25ORkZGRkICcnB7NmzcK9e/e4fHV1dURERCA8PBw7d+6ERCLBuXPn8MMPPwAA/Pz8YGhoiAkTJiA9PR1//vknDh48iLNnz3bovi1evBhffvkl9u3bh9zcXCxZsgRisRihoaEAAH9/f/B4PAQFBSE7Oxu//fYboqOjFeqYO3cuHj9+DD8/P2RmZkIikSApKQkzZ85s89wWUqkUixcvxrlz53Dz5k2cPHkSXl5esLCw4J6NeNXemA5BVFTUP+Z/ZF0BHbP2oePWPnTc2oeOW9vRMWuff+JxmzRpEn7++Wf06tVLIb13794v5ZWj7bVhwwbo6elh+PDh8PT0hEgkgoODwyuPIyIiAn5+fpg+fTqGDRsGgUAAkUikMK6+vsjISDg4OEAkEsHNzY27uK9r+fLlWLhwIVasWAErKyv4+vpy4/tVVVVx/Phx9OzZEx4eHhAKhVi3bl2Hd9Tmz5+PBQsWYOHChRAKhUhMTMSRI0dgaWkJ4Pn8EL/++iuuXbsGe3t7LFu2rMHQoNq7DDKZDGPHjoVQKERYWBh0dXWhpNS2y2llZWVcvXoV48ePR//+/REYGAhHR0ekpaV12neMx150ABkhhBBCSAeqqKhAQUEB+vbt2+wFaWvIZDKkpaWhuLgYRkZGcHFx6RJ3Bro6uVwOKysr+Pj4YPXq1Z0dDmmn1n6X6KFiQgghhLy2lJWVX/mrRf+Jbt26hePHj8PV1RWVlZXYsmULCgoK4O/v39mhkVfgjRgyRAghhBBCmqakpIS4uDgMHjwYzs7OuHbtGk6cOAErK6vODu0fJy0tDQKBoMmlK6I7BIQQQgghbzgTE5MGb+Ih7ePk5ASxWNzZYbTJa3+HYOvWrTAzM4O6ujqGDh2KCxcudHZIXVpUVBR4PJ7CMnDgwM4Oq8v5z3/+A09PTxgbG4PH4+Hw4cMK+YwxrFixAkZGRuDz+RgzZgzy8vI6J9gupKXjNmPGjAbnX1Ozbr4p1q5di8GDB0NLSws9e/bEhAkTkJubq1CmoqICc+fORY8ePSAQCDB58mSFN328iVpz3Nzc3Bqcb7Nnz+6kiDvfN998A1tbW27ysWHDhuHYsWNcPp1nhLQOn89v8GrSuktX9Fp3CPbt24cFCxZg5cqVuHz5Muzs7CASiZqdyY8ANjY2KC4u5pYzZ850dkhdTllZGezs7LB169ZG87/66its2rQJ27Ztw/nz56GpqQmRSKTwjuM3UUvHDXg+nXvd82/Pnj2vMMKu5/Tp05g7dy7OnTuH5ORkVFdXY+zYsSgrK+PKfPrpp/j1119x4MABnD59Gn/99VeXeYNKZ2nNcQOAoKAghfPtq6++6qSIO1/v3r2xbt06XLp0CRcvXsSoUaPg5eWF33//HQCdZ4S81thrbMiQIWzu3LncukwmY8bGxmzt2rWdGFXXtnLlSmZnZ9fZYfyjAGCHDh3i1uVyOTM0NGTr16/n0p4+fcrU1NTYnj17OiHCrqn+cWOMsYCAAObl5dUp8fxT3L9/nwFgp0+fZow9P7dUVFTYgQMHuDI5OTkMADt79mxnhdnl1D9ujDHm6urKQkNDOy+ofwA9PT32/fffv/LzrLy8nGVnZ7Py8vIOr5uQN0lrv0uv7R2CqqoqXLp0CWPGjOHSlJSUMGbMmA6f8OJ1k5eXB2NjY/Tr1w9TpkzB7du3Ozukf5SCggLcvXtX4dzT0dHB0KFD6dxrhdTUVPTs2RMDBgzAnDlz8OjRo84OqUspKSkBAHTv3h0AcOnSJVRXVyucbwMHDkSfPn3ofKuj/nGrtXv3brz11lt4++23sXTpUjx79qwzwutyZDIZ9u7di7KyMgwbNozOM0Jec6/tQ8UPHz6ETCaDgYGBQrqBgQH++OOPToqq6xs6dCji4uIwYMAAFBcXY9WqVXBxccH169ehpaXV2eH9I9y9excAGj33avNI49zd3TFp0iT07dsXEokEn332GcaNG4ezZ8/Se8Px/L3gYWFhcHZ2xttvvw3g+fmmqqoKXV1dhbJ0vv1XY8cNeD47qampKYyNjXH16lVEREQgNzcXCQkJnRht57p27RqGDRuGiooKCAQCHDp0CNbW1hCLxXSeEfIae207BKR9xo0bx/3b1tYWQ4cOhampKfbv34/AwMBOjIy8CT788EPu30KhELa2tjA3N0dqaipGjx7diZF1DXPnzsX169fpuZ42auq4BQcHc/8WCoUwMjLC6NGjIZFIYG5u/qrD7BIGDBgAsViMkpIS/PzzzwgICMDp06c7OyxCyEv22g4Zeuutt6CsrNzgDQj37t2DoaFhJ0X1z6Orq4v+/fsjPz+/s0P5x6g9v+jce3H9+vXDW2+9RecfgJCQEPzv//4vUlJS0Lt3by7d0NAQVVVVePr0qUJ5Ot+ea+q4NWbo0KEA8Eafb6qqqrCwsICjoyPWrl0LOzs7xMbG0nlGyGvute0QqKqqwtHRESdPnuTS5HI5Tp48iWHDhnViZP8sUqkUEokERkZGnR3KP0bfvn1haGiocO6Vlpbi/PnzdO610Z07d/Do0aM3+vxjjCEkJASHDh3CqVOn0LdvX4V8R0dHqKioKJxvubm5uH379ht9vrV03BpT+97wN/l8q08ul6OyspLOs1fMzc0NYWFh3LqZmRliYmKa3aaxVzm3R0fV86ZKTU0Fj8dr0HluTms+35fttR4ytGDBAgQEBMDJyQlDhgxBTEwMysrKMHPmzM4OrctatGgRPD09YWpqir/++gsrV66EsrIy/Pz8Oju0LkUqlSr8ilhQUACxWIzu3bujT58+CAsLw7///W9YWlqib9++WL58OYyNjTFhwoTOC7oLaO64de/eHatWrcLkyZNhaGgIiUSC8PBwWFhYQCQSdWLUnWvu3LmIj4/HL7/8Ai0tLW68to6ODvh8PnR0dBAYGIgFCxage/fu0NbWxrx58zBs2DC88847nRx952npuEkkEsTHx8PDwwM9evTA1atX8emnn2LEiBGwtbXt5Og7x9KlSzFu3Dj06dMHf//9N+Lj45GamoqkpCQ6z1rJ09MT1dXVSExMbJCXlpaGESNGICsrq83nWGZmJjQ1NTsqTADP5x06fPhwgwm0iouLoaen16FtkY7j5ubWYBjfrFmzsG3bther+JW886gTbd68mfXp04epqqqyIUOGsHPnznV2SF2ar68vMzIyYqqqqqxXr17M19eX5efnd3ZYXU5KSgoD0GAJCAhgjD1/9ejy5cuZgYEBU1NTY6NHj2a5ubmdG3QX0Nxxe/bsGRs7dizT19dnKioqzNTUlAUFBbG7d+92dtidqrHjBYDt2LGDK1NeXs4++eQTpqenxzQ0NNjEiRNZcXFx5wXdBbR03G7fvs1GjBjBunfvztTU1JiFhQVbvHgxKykp6dzAO9FHH33ETE1NmaqqKtPX12ejR49mx48f5/Jf5Xn2T33t6KFDh5iSkhIrLCxskDdz5kzm5OTUqnra80pcNPIq5+bQa8Zfjtq/c0+ePGn1Nqampmzjxo2tKuvq6sqCgoJYcXExtzT3/63Wfpde+w4BIYQQQv5ZGruIkcvlTCqVdsoil8tbFXd1dTUzMDBgq1evVkj/+++/mUAgYN988w17+PAh+/DDD5mxsTHj8/ns7bffZvHx8Qrl63cI6l8w3rhxg7m4uDA1NTVmZWXFjh8/3qBDEB4eziwtLRmfz2d9+/ZlkZGRrKqqijHG2I4dO5rsLNev5+rVq2zkyJFMXV2dde/enQUFBbG///6by6+dP2b9+vXM0NCQde/enX3yySdcW43Jz89n48ePZz179mSamprMycmJJScnK5SpqKhg4eHhrHfv3kxVVZWZm5uz77//nsu/fv06e++995iWlhYTCATs3XffbfIHzNqL9MTERDZo0CCmrq7ORo4cye7du8d+++03NnDgQKalpcX8/PxYWVmZQgzz5s1j+vr6TE1NjTk7O7MLFy4o1H306FFmaWnJ1NXVmZubG3ds63YI0tLS2LvvvsvU1dVZ79692bx585hUKuXy29ohaEtn8Y2fh4AQQgghr49nz55BIBB0ytLa+Sm6deuG6dOnIy4uDowxLv3AgQOQyWTw8/NDRUUFHB0dcfToUVy/fh3BwcGYNm0aLly40Ko25HI5Jk2aBFVVVZw/fx7btm1DREREg3JaWlqIi4tDdnY2YmNjsX37dmzcuBEA4Ovri4ULF8LGxoabpdvX17dBHWVlZRCJRNDT00NmZiYOHDiAEydOICQkRKFcSkoKJBIJUlJS8NNPPyEuLg5xcXFN7oNUKoWHhwdOnjyJK1euwN3dHZ6engrzHk2fPh179uzBpk2bkJOTg2+//RYCgQAAUFRUhBEjRkBNTQ2nTp3CpUuX8NFHH6GmpqbZYxcVFYUtW7YgIyMDhYWF8PHxQUxMDOLj43H06FEcP34cmzdv5sqHh4fj4MGD+Omnn3D58mVuCOvjx48BAIWFhZg0aRI8PT0hFovx8ccfY8mSJQptSiQSuLu7Y/Lkybh69Sr27duHM2fONDiGbfFS5k9pdReDEEIIIeQVaOxXTalU2uRQsJe91P01tyW1MzinpKRwaS4uLmzq1KlNbvPee++xhQsXcuvN3SFISkpi3bp1Y0VFRVz+sWPHWhwytH79eubo6MitNzVkqG493333HdPT01PY/6NHjzIlJSVuOGdAQAAzNTVlNTU1XJkPPviA+fr6NhlLY2xsbNjmzZsZY4zl5uYyAA3uGtRaunQp69u3b7N3IeqqvUNw4sQJLm3t2rUMAJNIJFzarFmzmEgkYow9P99UVFTY7t27ufyqqipmbGzMvvrqKy4Oa2trhbYiIiIU7hAEBgay4OBghTJpaWlMSUmJO7/bcofg22+/ZYmJiezq1avsf/7nf1ivXr3YxIkTmyzf2jsEr/VDxYQQQgh5PWhoaEAqlXZa2601cOBADB8+HD/++CPc3NyQn5+PtLQ0fP755wCezwL9xRdfYP/+/SgqKkJVVRUqKytb3UZOTg5MTExgbGzMpTX2pqd9+/Zh06ZNkEgkkEqlqKmpgba2dqv3o7YtOzs7hQeanZ2dIZfLkZuby03AaWNjozB5pJGREa5du9ZkvVKpFFFRUTh69CiKi4tRU1OD8vJy7g6BWCyGsrIyXF1dG91eLBbDxcUFKioqbdqfug9zGxgYQENDA/369VNIq71TI5FIUF1dDWdnZy5fRUUFQ4YMQU5ODoDnx6f2dcW16n8WWVlZuHr1Knbv3s2lMcYgl8tRUFAAKyurNu3Dy5o/hToEhBBCCOnyeDxeh79p52UJDAzEvHnzsHXrVuzYsQPm5ubcxe369esRGxuLmJgYCIVCaGpqIiwsDFVVVR3W/tmzZzFlyhSsWrUKIpEIOjo62Lt3L77++usOa6Ou+hfmPB4Pcrm8yfKLFi1CcnIyoqOjYWFhAT6fD29vb+4Y8Pn8ZttrKb81cfJ4vDbH3R5SqRSzZs3C/PnzG+T16dPnheuvO3/Ki3QI6BkCQgghhJAO5OPjAyUlJcTHx2Pnzp346KOPwOPxAADp6enw8vLC1KlTYWdnh379+uHGjRutrtvKygqFhYUoLi7m0s6dO6dQJiMjA6ampli2bBmcnJxgaWmJW7duKZRRVVWFTCZrsa2srCyUlZVxaenp6VBSUsKAAQNaHXN96enpmDFjBiZOnAihUAhDQ0PcvHmTyxcKhZDL5U3Okm1ra4u0tDRUV1e3O4aWmJubQ1VVFenp6VxadXU1MjMzYW1tDeD58an/7Ef9z8LBwQHZ2dmwsLBosKiqqr5wnB01fwp1CAghhBBCOpBAIICvry+WLl2K4uJizJgxg8uztLREcnIyMjIykJOTg1mzZjWY2b45Y8aMQf/+/REQEICsrCykpaVh2bJlCmUsLS1x+/Zt7N27FxKJBJs2bcKhQ4cUypiZmXFzwTx8+BCVlZUN2poyZQrU1dUREBCA69evIyUlBfPmzcO0adO44ULtYWlpiYSEBIjFYmRlZcHf31/hl3kzMzMEBATgo48+wuHDh1FQUIDU1FTs378fwPMZyEtLS/Hhhx/i4sWLyMvLw65du5Cbm9vumOrT1NTEnDlzsHjxYiQmJiI7OxtBQUF49uwZAgMDAQCzZ89GXl4eFi9ejNzcXMTHxzd4mDoiIgIZGRkICQmBWCxGXl4efvnll3Y9VCyRSLB69WpcunQJN2/exJEjRzB9+vQOmT+FOgSEEEIIIR0sMDAQT548gUgkUhjvHxkZCQcHB4hEIri5ucHQ0LBNk1YqKSnh0KFDKC8vx5AhQ/Dxxx9jzZo1CmXGjx+PTz/9FCEhIRg0aBAyMjKwfPlyhTKTJ0+Gu7s7Ro4cCX19fezZs6dBWxoaGkhKSsLjx48xePBgeHt7Y/To0diyZUvbDkY9GzZsgJ6eHoYPHw5PT0+IRCI4ODgolPnmm2/g7e2NTz75BAMHDkRQUBB3p6JHjx44deoUpFIpXF1d4ejoiO3bt7f5mYKWrFu3DpMnT8a0adPg4OCA/Px8JCUlcRO39enTBwcPHsThw4dhZ2eHbdu24YsvvlCow9bWFqdPn8aNGzfg4uICe3t7rFixQuGcaC1VVVWcOHECY8eOxcCBA7Fw4UJMnjwZv/766wvvK4+xOu/FIoQQQgjpZBUVFSgoKEDfvn2hrq7e2eEQ8o/V2u8S3SEghBBCCCHkDUYdAkIIIYQQQjrZ7t27m5wcz8bG5qW2Ta8dJYQQQgghpJONHz++wbwGtTr6+Yj6qENACCGEEEJIJ9PS0oKWllantE1DhgghhBDSJdF7Twh5Ma39DlGHgBBCCCFdSu3wiGfPnnVyJIT8Zpab5QAAANBJREFUs9V+h1oackRDhgghhBDSpSgrK0NXVxf3798H8Px9+LUz/RJCWsYYw7Nnz3D//n3o6upCWVm52fI0DwEhhBBCuhzGGO7evYunT592diiE/GPp6urC0NCwxQ41dQgIIYQQ0mXJZDJUV1d3dhiE/OOoqKi0eGegFnUICCGEEEIIeYPRQ8WEEEIIIYS8wahDQAghhBBCyBuMOgSEEEIIIYS8wahDQAghhBBCyBuMOgSEEEIIIYS8wahDQAghhBBCyBuMOgSEEEIIIYS8wf4/ncJGHW2pOTkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc_1 = history_1.history['acc']\n",
    "val_acc_1 = history_1.history['val_acc']\n",
    "loss_1 = history_1.history['loss']\n",
    "val_loss_1 = history_1.history['val_loss']\n",
    "\n",
    "acc_2 = history_2.history['acc']\n",
    "val_acc_2 = history_2.history['val_acc']\n",
    "loss_2 = history_2.history['loss']\n",
    "val_loss_2 = history_2.history['val_loss']\n",
    "\n",
    "acc_3 = history_3.history['acc']\n",
    "val_acc_3 = history_3.history['val_acc']\n",
    "loss_3 = history_3.history['loss']\n",
    "val_loss_3 = history_3.history['val_loss']\n",
    "\n",
    "acc_4 = history_4.history['acc']\n",
    "val_acc_4 = history_4.history['val_acc']\n",
    "loss_4 = history_4.history['loss']\n",
    "val_loss_4 = history_4.history['val_loss']\n",
    "\n",
    "acc_5 = history_5.history['acc']\n",
    "val_acc_5 = history_5.history['val_acc']\n",
    "loss_5 = history_5.history['loss']\n",
    "val_loss_5 = history_5.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc_1) + 1)\n",
    "\n",
    "plt.plot(epochs, acc_1, 'bo', label='Training acc model_1')\n",
    "plt.plot(epochs, val_acc_1, 'b', label='Validation acc model_1')\n",
    "plt.plot(epochs, acc_2, 'ro', label='Training acc model_2')\n",
    "plt.plot(epochs, val_acc_2, 'r', label='Validation acc model_2')\n",
    "plt.plot(epochs, acc_3, 'go', label='Training acc model_3')\n",
    "plt.plot(epochs, val_acc_3, 'g', label='Validation acc model_3')\n",
    "plt.plot(epochs, acc_4, 'yo', label='Training acc model_4')\n",
    "plt.plot(epochs, val_acc_4, 'y', label='Validation acc model_4')\n",
    "plt.plot(epochs, acc_5, 'ko', label='Training acc model_5')\n",
    "plt.plot(epochs, val_acc_5, 'k', label='Validation acc model_5')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend( bbox_to_anchor=(1.45, 0.5), fontsize=10)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss_1, 'bo', label='Training loss model_1')\n",
    "plt.plot(epochs, val_loss_1, 'b', label='Validation loss model_1')\n",
    "plt.plot(epochs, loss_2, 'ro', label='Training loss model_2')\n",
    "plt.plot(epochs, val_loss_2, 'r', label='Validation loss model_2')\n",
    "plt.plot(epochs, loss_3, 'go', label='Training loss model_3')\n",
    "plt.plot(epochs, val_loss_3, 'g', label='Validation loss model_3')\n",
    "plt.plot(epochs, loss_4, 'yo', label='Training loss model_4')\n",
    "plt.plot(epochs, val_loss_4, 'y', label='Validation loss model_4')\n",
    "plt.plot(epochs, loss_5, 'ko', label='Training loss model_5')\n",
    "plt.plot(epochs, val_loss_5, 'k', label='Validation loss model_5')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend( bbox_to_anchor=(1, 0.5), fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5354/758715730.py:1: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  models.save_model(model_1, model_1_filename)\n",
      "/tmp/ipykernel_5354/758715730.py:2: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  models.save_model(model_2, model_2_filename)\n",
      "/tmp/ipykernel_5354/758715730.py:3: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  models.save_model(model_3, model_3_filename)\n",
      "/tmp/ipykernel_5354/758715730.py:4: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  models.save_model(model_4, model_4_filename)\n",
      "/tmp/ipykernel_5354/758715730.py:5: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  models.save_model(model_5, model_5_filename)\n"
     ]
    }
   ],
   "source": [
    "models.save_model(model_1, model_1_filename)\n",
    "models.save_model(model_2, model_2_filename)\n",
    "models.save_model(model_3, model_3_filename)\n",
    "models.save_model(model_4, model_4_filename)\n",
    "models.save_model(model_5, model_5_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "48\n",
      "82\n",
      "133\n",
      "145\n",
      "215\n",
      "294\n",
      "325\n",
      "326\n",
      "410\n",
      "450\n",
      "481\n",
      "497\n",
      "515\n",
      "583\n",
      "584\n",
      "604\n",
      "613\n",
      "644\n",
      "649\n",
      "838\n",
      "856\n",
      "902\n",
      "977\n",
      "989\n",
      "1068\n",
      "1182\n",
      "1224\n",
      "1232\n",
      "1308\n",
      "1348\n",
      "1464\n",
      "1485\n",
      "1501\n",
      "1531\n",
      "1546\n",
      "1563\n",
      "1577\n",
      "1597\n",
      "1617\n",
      "1742\n",
      "1770\n",
      "1792\n",
      "1850\n",
      "1862\n",
      "1926\n",
      "1931\n",
      "1981\n",
      "2000\n",
      "2040\n",
      "2056\n",
      "2062\n",
      "2064\n",
      "2068\n",
      "2091\n",
      "2143\n",
      "2145\n",
      "2189\n",
      "2193\n",
      "2237\n",
      "2241\n",
      "2246\n",
      "2262\n",
      "2301\n",
      "2350\n",
      "2377\n",
      "2408\n",
      "2419\n",
      "2457\n",
      "2470\n",
      "2476\n",
      "2510\n",
      "2545\n",
      "2589\n",
      "2624\n",
      "2633\n",
      "2651\n",
      "2672\n",
      "2695\n",
      "2757\n",
      "2780\n",
      "2784\n",
      "2835\n",
      "2862\n",
      "2883\n",
      "2931\n",
      "2934\n",
      "2951\n",
      "2963\n",
      "2970\n",
      "3007\n",
      "3012\n",
      "3044\n",
      "3083\n",
      "3211\n",
      "3224\n",
      "3246\n",
      "3267\n",
      "3336\n",
      "3426\n",
      "3441\n",
      "3475\n",
      "3514\n",
      "3561\n",
      "3599\n",
      "3601\n",
      "3613\n",
      "3656\n",
      "3662\n",
      "3665\n",
      "3693\n",
      "3735\n",
      "3741\n",
      "3786\n",
      "3809\n",
      "3835\n",
      "3862\n",
      "3868\n",
      "3923\n",
      "3952\n",
      "3993\n",
      "3994\n",
      "4001\n",
      "4028\n",
      "4042\n",
      "4097\n",
      "4112\n",
      "4123\n",
      "4146\n",
      "4147\n",
      "4167\n",
      "4193\n",
      "4225\n",
      "4244\n",
      "4272\n",
      "4296\n",
      "4346\n",
      "4355\n",
      "4407\n",
      "4415\n",
      "4484\n",
      "4492\n",
      "4500\n",
      "4512\n",
      "4522\n",
      "4536\n",
      "4546\n",
      "4553\n",
      "4560\n",
      "4595\n",
      "4620\n",
      "4633\n",
      "4829\n",
      "4851\n",
      "4892\n",
      "4897\n",
      "4934\n",
      "4990\n",
      "5039\n",
      "5061\n",
      "5070\n",
      "5083\n",
      "5169\n",
      "5223\n",
      "5241\n",
      "5248\n",
      "5253\n",
      "5285\n",
      "5296\n",
      "5300\n",
      "5302\n",
      "5346\n",
      "5356\n",
      "5377\n",
      "5392\n",
      "5446\n",
      "5454\n",
      "5473\n",
      "5488\n",
      "5490\n",
      "5498\n",
      "5592\n",
      "5600\n",
      "5604\n",
      "5663\n",
      "5677\n",
      "5678\n",
      "5697\n",
      "5699\n",
      "5795\n",
      "5811\n",
      "5818\n",
      "5853\n",
      "5858\n",
      "5859\n",
      "5890\n",
      "5902\n",
      "5937\n",
      "5959\n",
      "5984\n",
      "5986\n",
      "5992\n",
      "6034\n",
      "6067\n",
      "6073\n",
      "6092\n",
      "6117\n",
      "6121\n",
      "6131\n",
      "6136\n",
      "6193\n",
      "6217\n",
      "6236\n",
      "6251\n",
      "6253\n",
      "6258\n",
      "6396\n",
      "6400\n",
      "6411\n",
      "6420\n",
      "6423\n",
      "6442\n",
      "6461\n",
      "6464\n",
      "6519\n",
      "6554\n",
      "6558\n",
      "6595\n",
      "6659\n",
      "6672\n",
      "6779\n",
      "6811\n",
      "6812\n",
      "6845\n",
      "6854\n",
      "6872\n",
      "6874\n",
      "6918\n",
      "6921\n",
      "6973\n",
      "7000\n",
      "7003\n",
      "7023\n",
      "7105\n",
      "7135\n",
      "7176\n",
      "7191\n",
      "7216\n",
      "7238\n",
      "7242\n",
      "7265\n",
      "7292\n",
      "7302\n",
      "7313\n",
      "7328\n",
      "7331\n",
      "7334\n",
      "7348\n",
      "7357\n",
      "7390\n",
      "7455\n",
      "7461\n",
      "7510\n",
      "7581\n",
      "7582\n",
      "7587\n",
      "7616\n",
      "7662\n",
      "7673\n",
      "7695\n",
      "7745\n",
      "7748\n",
      "7753\n",
      "7819\n",
      "7896\n",
      "7940\n",
      "8066\n",
      "8090\n",
      "8098\n",
      "8102\n",
      "8110\n",
      "8123\n",
      "8137\n",
      "8142\n",
      "8211\n",
      "8265\n",
      "8274\n",
      "8288\n",
      "8300\n",
      "8346\n",
      "8360\n",
      "8371\n",
      "8375\n",
      "8389\n",
      "8390\n",
      "8395\n",
      "8416\n",
      "8456\n",
      "8460\n",
      "8465\n",
      "8482\n",
      "8494\n",
      "8499\n",
      "8520\n",
      "8545\n",
      "8573\n",
      "8597\n",
      "8661\n",
      "8684\n",
      "8702\n",
      "8722\n",
      "8726\n",
      "8728\n",
      "8763\n",
      "8799\n",
      "8816\n",
      "8828\n",
      "8838\n",
      "8867\n",
      "8870\n",
      "8893\n",
      "8939\n",
      "8947\n",
      "8956\n",
      "8968\n",
      "9078\n",
      "9091\n",
      "9162\n",
      "9203\n",
      "9228\n",
      "9265\n",
      "9294\n",
      "9297\n",
      "9313\n",
      "9369\n",
      "9402\n",
      "9439\n",
      "9455\n",
      "9470\n",
      "9508\n",
      "9511\n",
      "9534\n",
      "9546\n",
      "9548\n",
      "9586\n",
      "9656\n",
      "9659\n",
      "9718\n",
      "348\n"
     ]
    }
   ],
   "source": [
    "# See which are 'go'\n",
    "count = 0\n",
    "for idx, y in enumerate(y_test):\n",
    "    if y == 1:\n",
    "        count += 1\n",
    "        print(idx)\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-22 15:33:23.204392: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 823ms/step\n",
      "Answer: 0.0  Prediction: [[1.8907798e-06]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Answer: 0.0  Prediction: [[3.985172e-10]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[1.5026956e-05]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Answer: 0.0  Prediction: [[2.7249132e-06]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Answer: 0.0  Prediction: [[9.4245305e-09]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Answer: 0.0  Prediction: [[7.3325293e-07]]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Answer: 0.0  Prediction: [[0.00010669]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Answer: 1.0  Prediction: [[0.9697887]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[5.7286707e-11]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Answer: 0.0  Prediction: [[2.7031568e-09]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Answer: 0.0  Prediction: [[1.0586304e-08]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[8.8055085e-10]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[1.9686737e-12]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[1.181921e-11]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[0.00392968]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Answer: 0.0  Prediction: [[0.00233386]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Answer: 0.0  Prediction: [[1.4754977e-09]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[1.4326518e-12]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Answer: 0.0  Prediction: [[1.9211661e-09]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Answer: 0.0  Prediction: [[2.3121633e-09]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Answer: 0.0  Prediction: [[1.3759766e-06]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Answer: 0.0  Prediction: [[6.275528e-09]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Answer: 0.0  Prediction: [[0.00042419]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Answer: 0.0  Prediction: [[5.0023763e-11]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Answer: 0.0  Prediction: [[0.00293794]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Answer: 0.0  Prediction: [[6.795258e-12]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Answer: 0.0  Prediction: [[2.9653906e-05]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[0.50345474]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[4.9014966e-11]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[6.397609e-08]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Answer: 0.0  Prediction: [[9.420107e-06]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[9.8308257e-14]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[1.5045833e-06]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Answer: 0.0  Prediction: [[0.00882572]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Answer: 0.0  Prediction: [[4.0474702e-19]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[1.0838163e-07]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Answer: 0.0  Prediction: [[0.45037213]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Answer: 0.0  Prediction: [[1.3880106e-11]]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Answer: 0.0  Prediction: [[1.2069759e-15]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Answer: 0.0  Prediction: [[3.4274294e-07]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[0.00618988]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Answer: 0.0  Prediction: [[1.307739e-05]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[2.2890505e-10]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[1.6235228e-05]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[1.8825427e-08]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Answer: 0.0  Prediction: [[1.5498338e-06]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[6.928338e-10]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[0.00047553]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 1.0  Prediction: [[0.9871454]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[3.5956e-11]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Answer: 0.0  Prediction: [[2.030251e-05]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[2.4313476e-05]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Answer: 0.0  Prediction: [[1.0740074e-09]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[1.465222e-09]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[7.542684e-08]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Answer: 0.0  Prediction: [[1.3344058e-12]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Answer: 0.0  Prediction: [[7.490207e-05]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[4.5668016e-17]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[0.00017201]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[7.3620184e-05]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[4.4261463e-16]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[3.2656273e-09]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[0.00142208]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[0.00461277]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Answer: 0.0  Prediction: [[5.607249e-11]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[1.3318272e-06]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Answer: 0.0  Prediction: [[8.1555256e-05]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Answer: 0.0  Prediction: [[3.014424e-15]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Answer: 0.0  Prediction: [[0.20594129]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Answer: 0.0  Prediction: [[0.19748501]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[5.7745875e-09]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Answer: 0.0  Prediction: [[2.1880114e-08]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Answer: 0.0  Prediction: [[0.05860153]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[0.00019197]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Answer: 0.0  Prediction: [[0.00056547]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[2.2507248e-08]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[0.00579262]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Answer: 0.0  Prediction: [[0.00395437]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[2.7334314e-08]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[3.436601e-06]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Answer: 0.0  Prediction: [[1.2200127e-07]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[0.00666057]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Answer: 1.0  Prediction: [[0.9991942]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Answer: 0.0  Prediction: [[1.9653311e-05]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Answer: 0.0  Prediction: [[1.1440293e-10]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Answer: 0.0  Prediction: [[4.74769e-13]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[5.0386517e-10]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[0.00186875]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[0.00037887]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Answer: 0.0  Prediction: [[0.00100796]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Answer: 0.0  Prediction: [[0.22463946]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Answer: 0.0  Prediction: [[3.6543427e-10]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Answer: 0.0  Prediction: [[1.771139e-06]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Answer: 0.0  Prediction: [[8.7231334e-13]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[1.0534588e-06]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[2.1526494e-06]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[2.4081656e-13]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[0.00596108]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 0.0  Prediction: [[2.2484197e-09]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Answer: 0.0  Prediction: [[1.0034045e-08]]\n"
     ]
    }
   ],
   "source": [
    "# Loading model and run it against test set\n",
    "model_1 = models.load_model(model_1_filename)\n",
    "for i in range(0, 100):\n",
    "    print('Answer:', y_test[i], ' Prediction:', model_1.predict(np.expand_dims(x_test[i], 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305/305 [==============================] - 1s 2ms/step - loss: 0.0287 - acc: 0.9905\n",
      "305/305 [==============================] - 1s 2ms/step - loss: 0.0357 - acc: 0.9874\n",
      "305/305 [==============================] - 0s 1ms/step - loss: 0.1216 - acc: 0.9643\n",
      "305/305 [==============================] - 1s 2ms/step - loss: 0.0456 - acc: 0.9839\n",
      "305/305 [==============================] - 1s 1ms/step - loss: 0.0862 - acc: 0.9696\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08620060235261917, 0.9695603251457214]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model with test set\n",
    "model_1 = models.load_model(model_1_filename)\n",
    "model_2 = models.load_model(model_2_filename)\n",
    "model_3 = models.load_model(model_3_filename)\n",
    "model_4 = models.load_model(model_4_filename)\n",
    "model_5 = models.load_model(model_5_filename)\n",
    "model_1.evaluate(x=x_test, y=y_test)\n",
    "model_2.evaluate(x=x_test, y=y_test)\n",
    "model_3.evaluate(x=x_test, y=y_test)\n",
    "model_4.evaluate(x=x_test, y=y_test)\n",
    "model_5.evaluate(x=x_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4736 4736\n"
     ]
    }
   ],
   "source": [
    "test_sets_path = '/home/pmedur/strojnoUcenje/env/bin/Tensorflow_speech_recognition/tflite-speech-recognition-master'\n",
    "test_sets_filename = 'further_test_data.npz'\n",
    "test_sets = np.load(join(test_sets_path, test_sets_filename))\n",
    "#x_test = test_sets['x_test.npy']\n",
    "#y_test = test_sets['y_test.npy']\n",
    "x_test = test_sets['x_test']\n",
    "y_test = test_sets['y_test']\n",
    "print(len(x_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4736,)\n",
      "(4736, 16, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "wake_word_index = all_targets.index(wake_word)\n",
    "y_test = np.equal(y_test, wake_word_index).astype('float64')\n",
    "x_test = x_test.reshape(x_test.shape[0], \n",
    "                        x_test.shape[1], \n",
    "                        x_test.shape[2], \n",
    "                        1)\n",
    "print(y_test.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model_1 = load_model(best_model_1_filename, custom_objects={'precision_m': precision_m, 'recall_m': recall_m, 'f1_m': f1_m})\n",
    "model_2 = load_model(best_model_2_filename, custom_objects={'precision_m': precision_m, 'recall_m': recall_m, 'f1_m': f1_m})\n",
    "model_3 = load_model(best_model_3_filename, custom_objects={'precision_m': precision_m, 'recall_m': recall_m, 'f1_m': f1_m})\n",
    "model_4 = load_model(best_model_4_filename, custom_objects={'precision_m': precision_m, 'recall_m': recall_m, 'f1_m': f1_m})\n",
    "model_5 = load_model(best_model_5_filename, custom_objects={'precision_m': precision_m, 'recall_m': recall_m, 'f1_m': f1_m})\n",
    "model_6 = load_model(best_model_6_filename, custom_objects={'precision_m': precision_m, 'recall_m': recall_m, 'f1_m': f1_m})\n",
    "model_7 = load_model(best_model_7_filename, custom_objects={'precision_m': precision_m, 'recall_m': recall_m, 'f1_m': f1_m})\n",
    "model_8 = load_model(best_model_8_filename, custom_objects={'precision_m': precision_m, 'recall_m': recall_m, 'f1_m': f1_m})\n",
    "model_9 = load_model(best_model_9_filename, custom_objects={'precision_m': precision_m, 'recall_m': recall_m, 'f1_m': f1_m})\n",
    "model_10 = load_model(best_model_10_filename, custom_objects={'precision_m': precision_m, 'recall_m': recall_m, 'f1_m': f1_m})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 2ms/step - loss: 0.0727 - acc: 0.9797\n",
      "303/303 [==============================] - 0s 2ms/step - loss: 0.0693 - acc: 0.9809\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 0.1262 - acc: 0.9613\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 0.0601 - acc: 0.9812\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 0.0890 - acc: 0.9696\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Assuming model_x and x_test, y_test are already defined and imported\n",
    "acc_values = []\n",
    "acc_values.append(model_1.evaluate(x=x_test, y=y_test)[1])\n",
    "acc_values.append(model_2.evaluate(x=x_test, y=y_test)[1])\n",
    "acc_values.append(model_3.evaluate(x=x_test, y=y_test)[1])\n",
    "acc_values.append(model_4.evaluate(x=x_test, y=y_test)[1])\n",
    "acc_values.append(model_5.evaluate(x=x_test, y=y_test)[1])\n",
    "acc_values.append(model_6.evaluate(x=x_test, y=y_test)[1])\n",
    "acc_values.append(model_7.evaluate(x=x_test, y=y_test)[1])\n",
    "acc_values.append(model_8.evaluate(x=x_test, y=y_test)[1])\n",
    "acc_values.append(model_9.evaluate(x=x_test, y=y_test)[1])\n",
    "acc_values.append(model_10.evaluate(x=x_test, y=y_test)[1])\n",
    "\n",
    "f1_values = []\n",
    "acc_values.append(model_1.evaluate(x=x_test, y=y_test)[4])\n",
    "acc_values.append(model_2.evaluate(x=x_test, y=y_test)[4])\n",
    "acc_values.append(model_3.evaluate(x=x_test, y=y_test)[4])\n",
    "acc_values.append(model_4.evaluate(x=x_test, y=y_test)[4])\n",
    "acc_values.append(model_5.evaluate(x=x_test, y=y_test)[4])\n",
    "acc_values.append(model_6.evaluate(x=x_test, y=y_test)[4])\n",
    "acc_values.append(model_7.evaluate(x=x_test, y=y_test)[4])\n",
    "acc_values.append(model_8.evaluate(x=x_test, y=y_test)[4])\n",
    "acc_values.append(model_9.evaluate(x=x_test, y=y_test)[4])\n",
    "acc_values.append(model_10.evaluate(x=x_test, y=y_test)[4])\n",
    "\n",
    "model_size = []\n",
    "model_size.append(os.path.getsize('wake_word_stop_model_1.h5') / 1024)\n",
    "model_size.append(os.path.getsize('wake_word_stop_model_2.h5') / 1024)\n",
    "model_size.append(os.path.getsize('wake_word_stop_model_3.h5') / 1024)\n",
    "model_size.append(os.path.getsize('wake_word_stop_model_4.h5') / 1024)\n",
    "model_size.append(os.path.getsize('wake_word_stop_model_5.h5') / 1024)\n",
    "model_size.append(os.path.getsize('wake_word_stop_model_6.h5') / 1024)\n",
    "model_size.append(os.path.getsize('wake_word_stop_model_7.h5') / 1024)\n",
    "model_size.append(os.path.getsize('wake_word_stop_model_8.h5') / 1024)\n",
    "model_size.append(os.path.getsize('wake_word_stop_model_9.h5') / 1024)\n",
    "model_size.append(os.path.getsize('wake_word_stop_model_10.h5') / 1024)\n",
    "\n",
    "# Plot accuracy against model size\n",
    "plt.figure()\n",
    "plt.plot(model_size, acc_values, 'bo-')\n",
    "plt.xlabel('Model Size (KB)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Size vs Accuracy')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0726 - accuracy: 0.9791 - f1_m: 0.2517\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0682 - accuracy: 0.9770 - f1_m: 0.2398\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 0.1769 - accuracy: 0.9635 - f1_m: 0.0000e+00\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0680 - accuracy: 0.9776 - f1_m: 0.2307\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 0.0944 - accuracy: 0.9694 - f1_m: 0.1063\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.9827 - f1_m: 0.2751\n",
      "148/148 [==============================] - 1s 2ms/step - loss: 0.0922 - accuracy: 0.9709 - f1_m: 0.1834\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 0.0964 - accuracy: 0.9688 - f1_m: 0.1497\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0781 - accuracy: 0.9770 - f1_m: 0.2423\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_files = [\n",
    "    'models/best_model_1_fold_10.h5',\n",
    "    'models/best_model_2_fold_10.h5',\n",
    "    'models/best_model_3_fold_4.h5',\n",
    "    'models/best_model_4_fold_2.h5',\n",
    "    'models/best_model_5_fold_4.h5',\n",
    "    'models/best_model_6_fold_10.h5',\n",
    "    None,  # Placeholder for missing model\n",
    "    'models/best_model_8_fold_6.h5',\n",
    "    'models/best_model_9_fold_3.h5',\n",
    "    'models/best_model_10_fold_2.h5'\n",
    "]\n",
    "\n",
    "# Model sizes\n",
    "model_h5_size = [\n",
    "    os.path.getsize(file) / 1024 if file is not None else 0 for file in model_files\n",
    "]\n",
    "\n",
    "# Load models with custom metrics\n",
    "models = [\n",
    "    load_model(file, custom_objects={'precision_m': precision_m, 'recall_m': recall_m, 'f1_m': f1_m}) if file is not None else None for file in model_files\n",
    "]\n",
    "# Evaluate models to get accuracy and F1 score\n",
    "acc_values = []\n",
    "f1_values = []\n",
    "\n",
    "for model in models:\n",
    "    if model is not None:\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', f1_m])\n",
    "        results = model.evaluate(x=x_test, y=y_test)\n",
    "        acc_values.append(results[1])\n",
    "        f1_values.append(results[2])\n",
    "    else:\n",
    "        acc_values.append(None)\n",
    "        f1_values.append(None)\n",
    "\n",
    "# Define colors for each model\n",
    "colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'tab:orange', 'tab:brown', 'tab:pink']\n",
    "\n",
    "# Plot accuracy vs. model size\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(len(model_h5_size)):\n",
    "    if acc_values[i] is not None:\n",
    "        plt.scatter(model_h5_size[i], acc_values[i], color=colors[i], label=f'Model {i+1}')\n",
    "plt.xlabel('Model Size (KB)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Size vs Accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot F1 score vs. model size\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(len(model_h5_size)):\n",
    "    if f1_values[i] is not None:\n",
    "        plt.scatter(model_h5_size[i], f1_values[i], color=colors[i], label=f'Model {i+1}')\n",
    "plt.xlabel('Model Size (KB)')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('Model Size vs F1 Score')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Model sizes in KB\n",
    "model_h5_size = [\n",
    "    os.path.getsize('models/best_model_1_fold_10.h5') / 1024,\n",
    "    os.path.getsize('models/best_model_2_fold_10.h5') / 1024,\n",
    "    os.path.getsize('models/best_model_3_fold_4.h5') / 1024,\n",
    "    os.path.getsize('models/best_model_4_fold_2.h5') / 1024,\n",
    "    os.path.getsize('models/best_model_5_fold_4.h5') / 1024,\n",
    "    os.path.getsize('models/best_model_6_fold_10.h5') / 1024,\n",
    "    0,\n",
    "    os.path.getsize('models/best_model_8_fold_6.h5') / 1024,\n",
    "    os.path.getsize('models/best_model_9_fold_3.h5') / 1024,\n",
    "    os.path.getsize('models/best_model_10_fold_2.h5') / 1024\n",
    "]\n",
    "\n",
    "model_tflite_size = [\n",
    "    os.path.getsize('Converted_models/wake_word_stop_lite_1.tflite') / 1024,\n",
    "    os.path.getsize('Converted_models/wake_word_stop_lite_2.tflite') / 1024,\n",
    "    os.path.getsize('Converted_models/wake_word_stop_lite_3.tflite') / 1024,\n",
    "    os.path.getsize('Converted_models/wake_word_stop_lite_4.tflite') / 1024,\n",
    "    os.path.getsize('Converted_models/wake_word_stop_lite_5.tflite') / 1024,\n",
    "    os.path.getsize('Converted_models/wake_word_stop_lite_6.tflite') / 1024,\n",
    "    0,\n",
    "    os.path.getsize('Converted_models/wake_word_stop_lite_8.tflite') / 1024,\n",
    "    os.path.getsize('Converted_models/wake_word_stop_lite_9.tflite') / 1024,\n",
    "    os.path.getsize('Converted_models/wake_word_stop_lite_10.tflite') / 1024\n",
    "]\n",
    "\n",
    "# Filter out pairs where either value is zero\n",
    "filtered_h5_size = []\n",
    "filtered_tflite_size = []\n",
    "model_indices = []\n",
    "\n",
    "for idx, (h5, tflite) in enumerate(zip(model_h5_size, model_tflite_size)):\n",
    "    if h5 != 0 and tflite != 0:\n",
    "        filtered_h5_size.append(h5)\n",
    "        filtered_tflite_size.append(tflite)\n",
    "        model_indices.append(idx + 1)\n",
    "\n",
    "# Define colors for each model\n",
    "colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'tab:orange', 'tab:brown', 'tab:pink']\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Scatter plot with different colors for each model\n",
    "for i in range(len(filtered_h5_size)):\n",
    "    plt.scatter(filtered_tflite_size[i], filtered_h5_size[i], color=colors[i], label=f'Model {model_indices[i]}')\n",
    "\n",
    "plt.xlabel('Model TFLite Size (KB)')\n",
    "plt.ylabel('Model H5 Size (KB)')\n",
    "plt.title('H5 Model Size vs TFLite Model Size')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/IAAAIjCAYAAACgdyAGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABorUlEQVR4nO3dfVxUZf7/8Tcg9wJa3oFroKAOppWQqSjebKamloRupZH3N5mtuZWVtaZpSVnubje7Zq1mK6l9Q8K00qxdDZOyhaxQUDRJU9Tu5EbIGzi/P/ox2wToDDIMB17Px2Me7py5znU+52pwfXOdcx03wzAMAQAAAAAAU3B3dQEAAAAAAMB+BHkAAAAAAEyEIA8AAAAAgIkQ5AEAAAAAMBGCPAAAAAAAJkKQBwAAAADARAjyAAAAAACYCEEeAAAAAAATIcgDAAAAAGAiBHkAgCRpwoQJCgsLq9G+CxYskJubW+0WBNSAvd/jvLw8ubm5adWqVRdtm5ubq8GDBysoKEhubm5KTU295DrrmwkTJqhp06auLsNhq1atkpubm/Ly8hzel7+3AJgZQR4A6jk3Nze7Xtu2bXN1qUCNTJgwodrv9ebNm11dnsaPH6+vvvpKTz75pFavXq1rr73Waceq+AVDda+nnnrKace+FAMGDJCbm5s6duxY5edbt261nkNycnIdVwcADU8TVxcAALiw1atX27z/17/+pa1bt1baHhkZeUnHeeWVV1ReXl6jff/85z/r4YcfvqTjo3Hz9vbWP//5z0rbr776ahdU8z+lpaVKT0/Xo48+qnvuuafOjjtmzBgNGzas0vbu3bvXWQ2O8vHx0YEDB7Rr1y5dd911Np+9/vrr8vHx0c8//+yi6gCgYSHIA0A9l5CQYPP+k08+0datWytt/62SkhL5+fnZfRxPT88a1SdJTZo0UZMm/F/KxRiGoZ9//lm+vr6uLqVO2XPeTZo0ueh32hW+++47SVKzZs1qrc/Tp0/L39//gm2ioqLq5XhcSHh4uM6fP6+1a9faBPmff/5Zb731loYPH67169e7sEIAaDi4tB4AGoABAwaoa9euysjIUL9+/eTn56dHHnlEkrRhwwYNHz5cISEh8vb2Vnh4uBYtWqSysjKbPn57b3HFJb7PPvusXn75ZYWHh8vb21s9evTQZ599ZrNvVfeaurm56Z577lFqaqq6du0qb29vXXnllVVeKr1t2zZde+218vHxUXh4uJYvX273/atpaWn6wx/+oCuuuELe3t5q166d/vSnP6m0tLRS25ycHN16661q2bKlfH191blzZz366KM2bY4eParJkydbx6t9+/aaMWOGzp49W+25SlXfqxsWFqYRI0Zoy5Ytuvbaa+Xr66vly5dLkl599VX9/ve/V6tWreTt7a0uXbpo2bJlVZ7je++9p/79+ysgIECBgYHq0aOH1qxZI0maP3++PD09rYHz16ZNm6ZmzZpdcBa04t7or7/+WkOGDJG/v79CQkK0cOFCGYZh07a8vFx/+9vfdOWVV8rHx0etW7fW9OnT9dNPP9m0u9B5X4p//OMfuvLKK+Xt7a2QkBDNnDlTp06duuh+p06d0oQJExQUFKRmzZpp/Pjxdu23YMEChYaGSpLmzJkjNzc3m5+Rzz//XDfeeKMCAwPVtGlTXX/99frkk09s+qj4Xmzfvl133323WrVqpd/97neOnHa17P3ZlqRPP/1Uw4YNU/PmzeXv76+rrrpKzz33XKV2R48eVVxcnJo2baqWLVvqgQceqLK/6owZM0ZvvPGGzdU9GzduVElJiW699dYq97FnHCVpz549+v3vfy9fX1/97ne/0xNPPFHtVUTvvfeeYmNj5e/vr4CAAA0fPlx79uyx+zwAoL5j+gQAGogffvhBN954o26//XYlJCSodevWkn4JEk2bNtV9992npk2b6t///rcee+wxFRYW6plnnrlov2vWrFFRUZGmT58uNzc3LVmyRPHx8fr6668vOou/Y8cOpaSk6O6771ZAQICef/55jRo1SocPH9bll18u6Zd/xA8dOlTBwcF6/PHHVVZWpoULF6ply5Z2nfebb76pkpISzZgxQ5dffrl27dqlF154Qd9++63efPNNa7svv/xSsbGx8vT01LRp0xQWFqaDBw9q48aNevLJJyVJx44d03XXXadTp05p2rRpslgsOnr0qJKTk1VSUiIvLy+7avq1ffv2acyYMZo+fbqmTp2qzp07S5KWLVumK6+8UjfffLOaNGmijRs36u6771Z5eblmzpxp3X/VqlWaNGmSrrzySs2dO1fNmjXT559/rs2bN2vs2LG68847tXDhQr3xxhs2l36fPXtWycnJGjVqlHx8fC5YY1lZmYYOHapevXppyZIl2rx5s+bPn6/z589r4cKF1nbTp0/XqlWrNHHiRM2aNUuHDh3Siy++qM8//1wff/yxzfehuvO+kO+//97mvaenp4KCgiT9Eqoff/xxDRo0SDNmzNC+ffu0bNkyffbZZ5WO/WuGYWjkyJHasWOH7rrrLkVGRuqtt97S+PHjL1pPfHy8mjVrpj/96U/WS90rFoTbs2ePYmNjFRgYqAcffFCenp5avny5BgwYoO3bt6tnz542fd19991q2bKlHnvsMZ0+ffqixy4pKak0HtIvVwZUXP1i78/21q1bNWLECAUHB+vee+9VmzZtlJ2drU2bNunee++1tisrK9OQIUPUs2dPPfvss/rggw+0dOlShYeHa8aMGRetWZLGjh2rBQsWaNu2bfr9738v6Ze/Q66//nq1atWqUnt7x/H48eMaOHCgzp8/r4cfflj+/v56+eWXq7zKY/Xq1Ro/fryGDBmip59+WiUlJVq2bJn69u2rzz//vMaLegJAvWIAAExl5syZxm//+u7fv78hyXjppZcqtS8pKam0bfr06Yafn5/x888/W7eNHz/eCA0Ntb4/dOiQIcm4/PLLjR9//NG6fcOGDYYkY+PGjdZt8+fPr1STJMPLy8s4cOCAddsXX3xhSDJeeOEF67abbrrJ8PPzM44ePWrdlpubazRp0qRSn1Wp6vwSExMNNzc345tvvrFu69evnxEQEGCzzTAMo7y83Pq/x40bZ7i7uxufffZZpT4r2lV1roZhGK+++qohyTh06JB1W2hoqCHJ2Lx5s111DxkyxOjQoYP1/alTp4yAgACjZ8+eRmlpabV19+7d2+jZs6fN5ykpKYYk4z//+U+l4/za+PHjDUnGH//4R5u+hw8fbnh5eRnfffedYRiGkZaWZkgyXn/9dZv9N2/eXGn7hc77QjX89tW/f3/DMAzj5MmThpeXlzF48GCjrKzMut+LL75oSDJWrlxp09evv8epqamGJGPJkiXWbefPnzdiY2MNScarr756wdoqfg6eeeYZm+1xcXGGl5eXcfDgQeu2Y8eOGQEBAUa/fv2s2yq+F3379jXOnz9/0bGoOF51r/T0dGtbe362z58/b7Rv394IDQ01fvrpJ5u2v/4OVfw3WLhwoU2b7t27G9HR0Retu3///saVV15pGIZhXHvttcbkyZMNwzCMn376yfDy8jJee+014z//+Y8hyXjzzTet+9k7jrNnzzYkGZ9++ql128mTJ42goCCbn7uioiKjWbNmxtSpU23qO378uBEUFGSzvbqfZQAwAy6tB4AGwtvbWxMnTqy0/dczVkVFRfr+++8VGxurkpIS5eTkXLTf2267Tc2bN7e+j42NlSR9/fXXF9130KBBCg8Pt76/6qqrFBgYaN23rKxMH3zwgeLi4hQSEmJtFxERoRtvvPGi/Uu253f69Gl9//33iomJkWEY+vzzzyX9cp/zRx99pEmTJumKK66w2b/iMvny8nKlpqbqpptuqnJV8po+pqp9+/YaMmTIBesuKCjQ999/r/79++vrr79WQUGBpF9mUouKivTwww9XmlX/dT3jxo3Tp59+qoMHD1q3vf7662rXrp369+9vV52/ns2vuC3i7Nmz+uCDDyT9cuVDUFCQbrjhBn3//ffWV3R0tJo2bar//Oc/dp13dXx8fLR161ab19KlSyVJH3zwgc6ePavZs2fL3f1//3SZOnWqAgMD9c4771Tb77vvvqsmTZrYzCh7eHjoj3/8o921/VZZWZnef/99xcXFqUOHDtbtwcHBGjt2rHbs2KHCwkKbfaZOnSoPDw+7jzFt2rRK47F161Z16dLF2saen+3PP/9chw4d0uzZsyvd51/Vd/quu+6yeR8bG2vXz/qvjR07VikpKdarQjw8PHTLLbdUaufIOL777rvq1auXzb33LVu21B133GHT59atW3Xq1CmNGTPG5nvq4eGhnj17VvqeAoBZcWk9ADQQbdu2rfLS7z179ujPf/6z/v3vf1cKFxWB8UJ+G3wrQv1v74u2Z9+K/Sv2PXnypEpLSxUREVGpXVXbqnL48GE99thjevvttyvVVHF+FUGka9eu1fbz3XffqbCw8IJtaqJ9+/ZVbv/44481f/58paenq6SkxOazgoICBQUFWYP5xWq67bbbNHv2bL3++ut67LHHVFBQoE2bNulPf/qTXb+AcHd3twlSktSpUydJst7zn5ubq4KCgiovj5Z++W/5a9Wdd3U8PDw0aNCgKj/75ptvJKnS5fleXl7q0KGD9fPq9g0ODq70jHR7LvWvznfffaeSkpIq+4iMjFR5ebmOHDmiK6+80rrd0fHo2LFjteNRwZ6fbXu/Q9Ivv0z57S0tv/55tdftt9+uBx54QO+9955ef/11jRgxQgEBAZXaOTKO33zzTaXbFaTK/x1zc3MlyXpZ/28FBgY6dC4AUF8R5AGggajqXtFTp06pf//+CgwM1MKFCxUeHi4fHx9lZmbqoYcesutxc9XNIhq/WQittve1R1lZmW644Qb9+OOPeuihh2SxWOTv76+jR49qwoQJNX6c3oVUF4yrWxCsqv8uBw8e1PXXXy+LxaK//OUvateunby8vPTuu+/qr3/9q8N1N2/eXCNGjLAG+eTkZJ05c6ZWVz0vLy9Xq1at9Prrr1f5+W8DYGNbmf9ians8auNn+7ccuWLgQoKDgzVgwAAtXbpUH3/8cZ2uVF9x3qtXr1abNm0qfc7TNQA0FPxtBgAN2LZt2/TDDz8oJSVF/fr1s24/dOiQC6v6n1atWlmfPf1bVW37ra+++kr79+/Xa6+9pnHjxlm3b9261aZdxWxzVlZWtX21bNlSgYGBF2wj/e+KhFOnTtlcqnyhWeHf2rhxo86cOaO3337b5qqF3172W3FbQlZW1kWvUBg3bpxGjhypzz77TK+//rq6d+9uMyN8IeXl5fr666+ts/CStH//fkmyLgwWHh6uDz74QH369KnzkF6xcvy+fftsrhw4e/asDh06dMGZ69DQUH344YcqLi62mZXft29fjetp2bKl/Pz8quwjJydH7u7uateuXY37t4e9P9u//g5dbIa/No0dO1ZTpkxRs2bNNGzYsCrbODKOoaGh1tn2X/vtvhXn26pVqzo9XwCoa9wjDwANWMUM269nwM+ePat//OMfrirJRsXl1KmpqTp27Jh1+4EDB/Tee+/Ztb9ke36GYVR6rFbLli3Vr18/rVy5UocPH7b5rGJfd3d3xcXFaePGjfrvf/9b6VgV7SqCwkcffWT97PTp03rttdcuWu+F6i4oKNCrr75q027w4MEKCAhQYmJipUfI/faqhhtvvFEtWrTQ008/re3btzs8G//iiy/a9P3iiy/K09NT119/vSTp1ltvVVlZmRYtWlRp3/Pnz9v1OLeaGjRokLy8vPT888/bnPeKFStUUFCg4cOHV7vvsGHDdP78eZtH+5WVlemFF16ocT0eHh4aPHiwNmzYYPO4wRMnTmjNmjXq27ev0y/htvdnOyoqSu3bt9ff/va3Sv+NauvKmKqMHj1a8+fP1z/+8Y9qn/bgyDgOGzZMn3zyiXbt2mVt991331W6QmTIkCEKDAzU4sWLde7cuUrHrOoxjQBgRszIA0ADFhMTo+bNm2v8+PGaNWuW3NzctHr1aqf+A95RCxYs0Pvvv68+ffpoxowZKisr04svvqiuXbtq9+7dF9zXYrEoPDxcDzzwgI4eParAwECtX7++ynt6n3/+efXt21dRUVGaNm2a2rdvr7y8PL3zzjvW4yxevFjvv/+++vfvr2nTpikyMlL5+fl68803tWPHDjVr1kyDBw/WFVdcocmTJ2vOnDny8PDQypUr1bJly0q/JKjO4MGD5eXlpZtuuknTp09XcXGxXnnlFbVq1Ur5+fnWdoGBgfrrX/+qKVOmqEePHho7dqyaN2+uL774QiUlJTa/PPD09NTtt9+uF198UR4eHhozZoxdtUi/3Bu9efNmjR8/Xj179tR7772nd955R4888oj1kvn+/ftr+vTpSkxM1O7duzV48GB5enoqNzdXb775pp577jmNHj3a7mM6omXLlpo7d64ef/xxDR06VDfffLP27dunf/zjH+rRo8cFf2lx0003qU+fPnr44YeVl5enLl26KCUlxa71IS7kiSee0NatW9W3b1/dfffdatKkiZYvX64zZ85oyZIll9S3JGVmZiopKanS9vDwcPXu3dvun213d3ctW7ZMN910k6655hpNnDhRwcHBysnJ0Z49e7Rly5ZLrrUqQUFBWrBgwUXb2TuODz74oFavXq2hQ4fq3nvvtT5+LjQ0VF9++aW1XWBgoJYtW6Y777xTUVFRuv32260/m++884769Olj80srADCtul8oHwBwKap7/FzFo59+6+OPPzZ69epl+Pr6GiEhIcaDDz5obNmypdKjyap7/NxvH7tlGL88Wm7+/PnW99U9fm7mzJmV9g0NDTXGjx9vs+3DDz80unfvbnh5eRnh4eHGP//5T+P+++83fHx8qhmF/9m7d68xaNAgo2nTpkaLFi2MqVOnWh9z99tHi2VlZRm33HKL0axZM8PHx8fo3LmzMW/ePJs233zzjTFu3DijZcuWhre3t9GhQwdj5syZxpkzZ6xtMjIyjJ49expeXl7GFVdcYfzlL3+p9vFzw4cPr7Lut99+27jqqqsMHx8fIywszHj66aeNlStXVuqjom1MTIzh6+trBAYGGtddd52xdu3aSn3u2rXLkGQMHjz4ouNWYfz48Ya/v79x8OBBY/DgwYafn5/RunVrY/78+TaPeqvw8ssvG9HR0Yavr68REBBgdOvWzXjwwQeNY8eO2XXeF6rhYl588UXDYrEYnp6eRuvWrY0ZM2ZUeqTab7/HhmEYP/zwg3HnnXcagYGBRlBQkHHnnXcan3/++SU9fs4wDCMzM9MYMmSI0bRpU8PPz88YOHCgsXPnTps2Fd+Lqh5peKHjVff69c+OvT/bhmEYO3bsMG644QYjICDA8Pf3N6666iqbx0BW99/A3ke0XejvoApVPX7OMOwbR8MwjC+//NLo37+/4ePjY7Rt29ZYtGiRsWLFiip/Zv7zn/8YQ4YMMYKCggwfHx8jPDzcmDBhgvHf//7X4XMDgPrIzTDq0bQMAAD/X1xcnPbs2VPlfbGo2hdffKFrrrlG//rXv3TnnXfatc+ECROUnJys4uJiJ1cHAABqC/fIAwBcrrS01OZ9bm6u3n33XQ0YMMA1BZnUK6+8oqZNmyo+Pt7VpQAAACfiHnkAgMt16NBBEyZMsD4TfNmyZfLy8tKDDz7o6tJMYePGjdq7d69efvll3XPPPfL393d1SQAAwIkI8gAAlxs6dKjWrl2r48ePy9vbW71799bixYvVsWNHV5dmCn/84x914sQJDRs2TI8//rirywEAAE7GPfIAAAAAAJgI98gDAAAAAGAiBHkAAAAAAEyEe+SrUF5ermPHjikgIEBubm6uLgcAAAAA0MAZhqGioiKFhITI3f3Cc+4E+SocO3ZM7dq1c3UZAAAAAIBG5siRI/rd7353wTYE+SoEBARI+mUAAwMDXVwNAAAAAKChKywsVLt27ax59EII8lWouJw+MDCQIA8AAAAAqDP23N7t0sXuioqKNHv2bIWGhsrX11cxMTH67LPPrJ8XFxfrnnvu0e9+9zv5+vqqS5cueumlly7Y56pVq+Tm5mbz8vHxcfapAAAAAABQJ1w6Iz9lyhRlZWVp9erVCgkJUVJSkgYNGqS9e/eqbdu2uu+++/Tvf/9bSUlJCgsL0/vvv6+7775bISEhuvnmm6vtNzAwUPv27bO+Z8E6AAAAAEBD4bIZ+dLSUq1fv15LlixRv379FBERoQULFigiIkLLli2TJO3cuVPjx4/XgAEDFBYWpmnTpunqq6/Wrl27Lti3m5ub2rRpY321bt36gu3PnDmjwsJCmxcAAAAAAPWRy4L8+fPnVVZWVumyd19fX+3YsUOSFBMTo7fffltHjx6VYRj6z3/+o/3792vw4MEX7Lu4uFihoaFq166dRo4cqT179lywfWJiooKCgqwvVqwHAAAAANRXboZhGK46eExMjLy8vLRmzRq1bt1aa9eu1fjx4xUREaF9+/bpzJkzmjZtmv71r3+pSZMmcnd31yuvvKJx48ZV22d6erpyc3N11VVXqaCgQM8++6w++ugj7dmzp9ol/M+cOaMzZ85Y31esFlhQUMBidwAAAAAApyssLFRQUJBdOdSl98ivXr1akyZNUtu2beXh4aGoqCiNGTNGGRkZkqQXXnhBn3zyid5++22Fhobqo48+0syZMxUSEqJBgwZV2Wfv3r3Vu3dv6/uYmBhFRkZq+fLlWrRoUZX7eHt7y9vbu/ZPEAAAAACAWubSGfkKp0+fVmFhoYKDg3XbbbepuLhYycnJCgoK0ltvvaXhw4db206ZMkXffvutNm/ebHf/f/jDH9SkSROtXbvWrvaO/CYEAAAAAIBL5UgOdenj5yr4+/srODhYP/30k7Zs2aKRI0fq3LlzOnfunNzdbUv08PBQeXm53X2XlZXpq6++UnBwcG2XDQAAAABAnXPppfVbtmyRYRjq3LmzDhw4oDlz5shisWjixIny9PRU//79NWfOHPn6+io0NFTbt2/Xv/71L/3lL3+x9jFu3Di1bdtWiYmJkqSFCxeqV69eioiI0KlTp/TMM8/om2++0ZQpU1x1mgAAAAAA1BqXBvmCggLNnTtX3377rS677DKNGjVKTz75pDw9PSVJ69at09y5c3XHHXfoxx9/VGhoqJ588knddddd1j4OHz5sM2v/008/aerUqTp+/LiaN2+u6Oho7dy5U126dKnz8wMAAAAAoLbVi3vk6xvukQcAAAAA1CXT3SMPAAAAAADsQ5AHAAAAAMBEXHqPPAAAQH1QVlamtLQ05efnKzg4WLGxsfLw8HB1WQAAVIkZeQAA0KilpKQoIiJCAwcO1NixYzVw4EBFREQoJSXF1aUBAFAlgjwAAGi0UlJSNHr0aHXr1k3p6ekqKipSenq6unXrptGjRxPmAQD1EqvWV4FV6wEAaPjKysoUERGhbt26KTU11eZxtuXl5YqLi1NWVpZyc3O5zB4A4HSsWg8AAHARaWlpysvL0yOPPGIT4iXJ3d1dc+fO1aFDh5SWluaiCgEAqBpBHgAANEr5+fmSpK5du1b5ecX2inYAANQXBHkAANAoBQcHS5KysrKq/Lxie0U7AADqC4I8AABolGJjYxUWFqbFixervLzc5rPy8nIlJiaqffv2io2NdVGFAABUjSAPAAAaJQ8PDy1dulSbNm1SXFyczar1cXFx2rRpk5599lkWugMA1DtNXF0AAACAq8THxys5OVn333+/YmJirNvbt2+v5ORkxcfHu7A6AACqxuPnqsDj5wAAaFzKysqUlpam/Px8BQcHKzY2lpl4AECdciSHMiMPAAAaPQ8PDw0YMMDVZQAAYBfukQcAAAAAwEQI8gAAAAAAmAhBHgAAAAAAEyHIAwAAAABgIgR5AAAAAABMhCAPAAAAAICJEOQBAAAAADARgjwAAAAAACZCkAcAAAAAwEQI8gAAAAAAmAhBHgAAAAAAEyHIAwAAAABgIgR5AAAAAABMhCAPAAAAAICJEOQBAAAAADARgjwAAAAAACZCkAcAAAAAwEQI8gAAAAAAmAhBHgAAAAAAEyHIAwAAAABgIgR5AAAAAABMpImrCwAAAHCGkpIS5eTk2N2+tLRUeXl5CgsLk6+vr137WCwW+fn51bREAABqhCAPAAAapJycHEVHRzv1GBkZGYqKinLqMQAA+C2CPAAAaJAsFosyMjLsbp+dna2EhAQlJSUpMjLS7mMAAFDXCPIAAKBB8vPzq9FseWRkJLPsAIB6jcXuAAAAAAAwEYI8AAAAAAAmQpAHAAAAAMBECPIAAAAAAJgIQR4AAAAAABMhyAMAAAAAYCIEeQAAAAAATIQgDwAAAACAiRDkAQAAAAAwEYI8AAAAAAAmQpAHAAAAAMBECPIAAAAAAJhIE1cXAJhZWVmZ0tLSlJ+fr+DgYMXGxsrDw8PVZQEAAABowJiRB2ooJSVFERERGjhwoMaOHauBAwcqIiJCKSkpri4NAAAAQAPGjDxQAykpKRo9erRGjBihtWvXqmvXrsrKytLixYs1evRoJScnKz4+3tVlAkCDk5ubq6KiIqf0nZ2dbfNnbQsICFDHjh2d0jcAoHFxMwzDcHUR9U1hYaGCgoJUUFCgwMBAV5eDeqasrEwRERHq1q2bUlNT5e7+vwtbysvLFRcXp6ysLOXm5nKZPQDUotzcXHXq1MnVZVyS/fv3E+YBAFVyJIcyIw84KC0tTXl5eVq7dq1NiJckd3d3zZ07VzExMUpLS9OAAQNcUyQANEAVM/FJSUmKjIys9f5LS0uVl5ensLAw+fr61mrf2dnZSkhIcNrVBACAxoUgX8+VlJQoJyfH7vY1+UeIxWKRn59fTUtsdPLz8yVJXbt2rfLziu0V7QAAtSsyMlJRUVFO6btPnz5O6RcAgNpEkK/ncnJyFB0d7dRjZGRkOO0fRA1RcHCwJCkrK0u9evWq9HlWVpZNOwAAAACoTQT5es5isSgjI8Pu9hWX7jly2aHFYqlpeY1SbGyswsLCtHjx4irvkU9MTFT79u0VGxvrwioBAAAANFQE+XrOz8+vRrPlzrzssLHz8PDQ0qVLNXr0aMXFxWnu3LnWVesTExO1adMmJScns9AdAAAAAKcgyAM1EB8fr+TkZN1///2KiYmxbm/fvj2PngMAAADgVAR5oIbi4+M1cuRIpaWlKT8/X8HBwYqNjWUmHgCcqE1TN/me2i8dc79443rE99R+tWnq5uoyAAANBEEeuAQeHh48Yg4A6tD0aC9FfjRd+sjVlTgmUr/UDgBAbSDIAwAA01iecVa3PbZKkSZbqDU7J0fLl47Vza4uBADQIBDkAQAXVFZWxi0kqDeOFxsqbdZJCrnG1aU4pPR4uY4XG64uAwDQQJjrBjMAQJ1KSUlRRESEBg4cqLFjx2rgwIGKiIhQSkqKq0sDAABotAjyAIAqpaSkaPTo0erWrZvS09NVVFSk9PR0devWTaNHjybMAwAAuAhBHgBQSVlZme6//36NGDFCqamp6tWrl5o2bapevXopNTVVI0aM0AMPPKCysjJXlwoAANDoEOQBAJWkpaUpLy9PjzzyiNzdbf+vwt3dXXPnztWhQ4eUlpbmogoBAAAaL4I8AKCS/Px8SVLXrl2r/Lxie0U7AAAA1B1WrQcAVBIcHCxJysrKUq9evSp9npWVZdMOqAslJSWSpMzMTLval5aWKi8vz4kVSWFhYfL19b1ou+zsbKfWAQBoXAjyAIBKYmNjFRYWpsWLFys1NdXm8vry8nIlJiaqffv2io2NdWGVaGxycnIkSVOnTnVxJTUXEBDg6hIAAA0AQR74jZKSEus/Fu1RMeNj76yMJFksFvn5+dW0RMDpPDw8tHTpUo0ePVpxcXGaO3euunbtqqysLCUmJmrTpk1KTk7mefKoU3FxcZLs/zu0Ps3IS7+E+I4dOzq1HgBA40CQB34jJydH0dHRTj1GRkaGoqKinHoM4FLFx8crOTlZ999/v2JiYqzb27dvr+TkZMXHx7uwOjRGLVq00JQpUxzap0+fPk6qBgAA1yHIu0Bubq6Kioqc0nfFPXjOuhevMcwmWCwWZWRk2N0+OztbCQkJSkpKUmRkpN3HAMwgPj5eI0eOVFpamvLz8xUcHKzY2Fhm4gEAAFyIIF/HcnNz1alTJ6cfJyEhwWl979+/v0GHeT8/vxrNlkdGRjLLjgbJw8NDAwYMcHUZAAAA+P9cGuSLioo0b948vfXWWzp58qS6d++u5557Tj169JAkFRcX6+GHH1Zqaqp++OEHtW/fXrNmzdJdd911wX7ffPNNzZs3T3l5eerYsaOefvppDRs2rC5O6aIqZuIdmb11RE3u17ZXxcyzs64mAAAAAABcnEuD/JQpU5SVlaXVq1crJCRESUlJGjRokPbu3au2bdvqvvvu07///W8lJSUpLCxM77//vu6++26FhITo5ptvrrLPnTt3asyYMUpMTNSIESO0Zs0axcXFKTMzs9rnIbuCM2dvuR8QwMWwqCMAAIB5uSzIl5aWav369dqwYYP69esnSVqwYIE2btyoZcuW6YknntDOnTs1fvx46yWd06ZN0/Lly7Vr165qg/xzzz2noUOHas6cOZKkRYsWaevWrXrxxRf10ksv1cm5AUB9x6KOAAAA5uWyIH/+/HmVlZXJx8fHZruvr6927NghSYqJidHbb7+tSZMmKSQkRNu2bdP+/fv117/+tdp+09PTdd9999lsGzJkiFJTU6vd58yZMzpz5oz1fWFhYQ3OCADMg0UdAQAAzMtlQT4gIEC9e/fWokWLFBkZqdatW2vt2rVKT09XRESEJOmFF17QtGnT9Lvf/U5NmjSRu7u7XnnlFesMflWOHz+u1q1b22xr3bq1jh8/Xu0+iYmJevzxx2vnxFAv8aQAwBaLOgIAAJiXS++RX716tSZNmqS2bdvKw8NDUVFRGjNmjHWW6IUXXtAnn3yit99+W6Ghofroo480c+ZMhYSEaNCgQbVWx9y5c21m8QsLC9WuXbta6x+uxZMCAAAAADQkLg3y4eHh2r59u06fPq3CwkIFBwfrtttuU4cOHVRaWqpHHnlEb731loYPHy5Juuqqq7R79249++yz1Qb5Nm3a6MSJEzbbTpw4oTZt2lRbh7e3t7y9vWvvxFCv8KQAAAAAAA1JvXiOvL+/v/z9/fXTTz9py5YtWrJkic6dO6dz587J3d3dpq2Hh4fKy8ur7at379768MMPNXv2bOu2rVu3qnfv3s4qHybBkwLQ0HELCQAAQOPg0iC/ZcsWGYahzp0768CBA5ozZ44sFosmTpwoT09P9e/fX3PmzJGvr69CQ0O1fft2/etf/9Jf/vIXax/jxo1T27ZtlZiYKEm699571b9/fy1dulTDhw/XunXr9N///lcvv/yyq04TAJyOW0gAAAAaD5cG+YKCAs2dO1fffvutLrvsMo0aNUpPPvmkPD09JUnr1q3T3Llzdccdd+jHH39UaGionnzySd11113WPg4fPmwzax8TE6M1a9boz3/+sx555BF17NhRqamp9eoZ8gBQ27iFBAAAoPFwaZC/9dZbdeutt1b7eZs2bfTqq69esI9t27ZV2vaHP/xBf/jDHy61PAAwHW4hAQAAaPjcL94EAAAAAADUF/VisTvA2do0dZPvqf3SMXP97sr31H61aerm6jIAAAAA1CMEeTQK06O9FPnRdOkjV1fimEj9UjsAAAAAVCDIuwCzw3VvecZZ3fbYKkVaLK4uxSHZOTlavnSsbnZ1IQAAAADqDYK8CzA7XPeOFxsqbdZJCrnG1aU4pPR4uY4XG64uAybBLwkBAAAaB4K8CzA7DMAZ+CUhAABA40CQr2MlJSU6Xmzo46+LVdqsvNb7d+qznvPLmB0G6jF+SQjUXFlZmdLS0pSfn6/g4GDFxsbKw8PD1WUBAFAlgnwdy8nJkSRNnTrVxZXUXEBAgKtLcEhJSYkkKTMz0yn9O/WXJ9nZtdofGi5+SQjUXEpKiu6//37l5eVZt4WFhWnp0qWKj493XWEAAFSDIF/H4uLiJEkWi0V+fn613n92drYSEhKUlJSkyMjIWu8/ICBAHTt2rPV+nYlfnqAx4HsO1ExKSopGjx6tESNGaO3ateratauysrK0ePFijR49WsnJyYR5AEC942YYBtMgv1FYWKigoCAVFBQoMDDQ1eU4JDMzU9HR0crIyFBUVJSry6kXvv/+e6WmpvLLEzRojn7PK2bY7XXo0CHNmzdPixYtUvv27e3ax5HZe77ncIWysjJFRESoW7duSk1Nlbv7/xaKLC8vV1xcnLKyspSbm8tl9gAAp3MkhzIjjwavRYsWmjJlitOPExkZyS9P4DKOfs8zMzOVkJDg8HHmzZtnd1t+oYj6Li0tTXl5eVq7dq1NiJckd3d3zZ07VzExMUpLS9OAAQNcUyQAAFUgyANAI2SxWJSRkWF3+5rcI28x2aJ7aHzy8/MlSV27dq3y84rtFe0AAKgvCPIA0Aj5+fk5PFvep08fJ1UDuEZwcLAkKSsrS7169ar0eVZWlk07AADqC/eLNwEAAGh4YmNjFRYWpsWLF6u83PZpD+Xl5UpMTFT79u0VGxvrogoBAKgaQR4AADRKHh4eWrp0qTZt2qS4uDilp6erqKhI6enpiouL06ZNm/Tss8+y0B0AoN7h0noAANBoxcfHKzk5Wffff79iYmKs29u3b8+j5wAA9RZBHgAANGrx8fEaOXKk0tLSlJ+fr+DgYMXGxjITDwCotwjyAACg0fPw8OARcwAA0+AeeQAAAAAATIQgDwAAAACAiRDkAQAAAAAwEe6RB36jpKREOTk5drfPzs62+dMeFotFfn5+DtcGAHCOsrIyFrsDAJgGQR74jZycHEVHRzu8X0JCgt1tMzIyFBUV5fAxAAC1LyUlRffff7/y8vKs28LCwrR06VIePwcAqJcI8sBvWCwWZWRk2N2+tLRUeXl5CgsLk6+vr93HAMyCmUo0ZCkpKRo9erRGjBihtWvXqmvXrsrKytLixYs1evRoniUPAKiX3AzDMFxdRH1TWFiooKAgFRQUKDAw0NXlOCQzM1PR0dHM+AKoFcxUoiErKytTRESEunXrptTUVLm7/2/poPLycsXFxSkrK0u5ubn88goA4HSO5FAWuwMAVKliprJbt25KT09XUVGR0tPT1a1bN40ePVopKSmuLhG4JGlpacrLy9MjjzxiE+Ilyd3dXXPnztWhQ4eUlpbmogoBAKgaQR4AUElZWZnuv/9+jRgxQqmpqerVq5eaNm2qXr16KTU1VSNGjNADDzygsrIyV5cK1Fh+fr4kqWvXrlV+XrG9oh0AAPUFQR4AUAkzlWgMgoODJUlZWVlVfl6xvaIdAAD1BUEeAFAJM5VoDGJjYxUWFqbFixervLzc5rPy8nIlJiaqffv2io2NdVGFAABUjSAPAKiEmUo0Bh4eHlq6dKk2bdqkuLg4m7Ug4uLitGnTJj377LMsdAcAqHcI8gCASpipRGMRHx+v5ORkffXVV4qJiVFgYKBiYmKUlZXFo+cAAPUWz5EHAFRSMVM5evRoxcXFae7cudbnaycmJmrTpk1KTk5mphINQnx8vEaOHKm0tDTl5+crODhYsbGxfL8BAPUWQR4AUKWKmcr7779fMTEx1u3t27dnphINjoeHhwYMGODqMgAAsAtBHgBQLWYqAQAA6h+CPADggpipBAAAqF8I8vVcSUmJcnJy7G6fnZ1t86c9LBaL/Pz8HK4NAAAAAFD3CPL1XE5OjqKjox3eLyEhwe62GRkZioqKcvgYAAAAAIC6R5Cv5ywWizIyMuxuX1paqry8PIWFhcnX19fuYwAAAAAAzMHNMAzD1UXUN4WFhQoKClJBQYECAwNdXQ4AAAAAoIFzJIcyIw8AAAAAaBDKysoaxdN23F1dAAAAAAAAlyolJUUREREaOHCgxo4dq4EDByoiIkIpKSmuLq3WEeQBAAAAAKaWkpKi0aNHq1u3bkpPT1dRUZHS09PVrVs3jR49usGFee6RrwL3yAMAAACAOZSVlSkiIkLdunVTamqq3N3/N19dXl6uuLg4ZWVlKTc3t15fZu9IDmVGHgAAAABgWmlpacrLy9MjjzxiE+Ilyd3dXXPnztWhQ4eUlpbmogprH0EeAAAAAGBa+fn5kqSuXbtW+XnF9op2DQFBHgAAAABgWsHBwZKkrKysKj+v2F7RriEgyAMAAAAATCs2NlZhYWFavHixysvLbT4rLy9XYmKi2rdvr9jYWBdVWPsI8gAAAAAA0/Lw8NDSpUu1adMmxcXF2axaHxcXp02bNunZZ5+t1wvdOaqJqwsAAAAAAOBSxMfHKzk5Wffff79iYmKs29u3b6/k5GTFx8e7sLrax+PnqsDj5wAAAADAfMrKypSWlqb8/HwFBwcrNjbWNDPxjuRQZuQBAAAAAA2Ch4eHBgwY4OoynI575AEAAAAAMBGCPAAAAAAAJkKQBwAAAADARAjyAAAAAACYCEEeAAAAAAATIcgDAAAAAGAiBHkAAAAAAEyEIA8AAAAAgIkQ5AEAAAAAMBGCPAAAAAAAJkKQBwAAAADARAjyAAAAAACYCEEeAAAAAAATIcgDAAAAAGAiBHkAAAAAAEyEIA8AAAAAgIkQ5AEAAAAAMJEmri4AAAAAAIDqlJSUKCcnx+72paWlysvLU1hYmHx9fe3ax2KxyM/Pr6Yl1jmCPAAAAACg3srJyVF0dLRTj5GRkaGoqCinHqM2EeQBAAAAAPWWxWJRRkaG3e2zs7OVkJCgpKQkRUZG2n0MMyHIAwAAAADqLT8/vxrNlkdGRppqlt0RLHYHAAAAAICJEOQBAAAAADARgjwAAAAAACbCPfIAAAAAgDqVm5uroqIip/SdnZ1t82dtCwgIUMeOHZ3St73cDMMwXFpBPVRYWKigoCAVFBQoMDDQ1eUAAAAAQIORm5urflGdFdzUzdWl1Eh+saGPMvfVeph3JIe6fEa+qKhI8+bN01tvvaWTJ0+qe/fueu6559SjRw9Jkptb1f9xlyxZojlz5lT52YIFC/T444/bbOvcubNycnJqt3gAAAAAgEOKioo0PdpLCwZ4u7qUGlmw7YzTriawl8uD/JQpU5SVlaXVq1crJCRESUlJGjRokPbu3au2bdsqPz/fpv17772nyZMna9SoURfs98orr9QHH3xgfd+kictPFQAAAAAgaXnGWd322CpFmuz57dk5OVq+dKxudnEdLk23paWlWr9+vTZs2KB+/fpJ+mU2fePGjVq2bJmeeOIJtWnTxmafDRs2aODAgerQocMF+27SpEmlfQEAAAAArne82FBps05SyDWuLsUhpcfLdbzY9Xenu3TV+vPnz6usrEw+Pj422319fbVjx45K7U+cOKF33nlHkydPvmjfubm5CgkJUYcOHXTHHXfo8OHD1bY9c+aMCgsLbV4AAAAAANRHLg3yAQEB6t27txYtWqRjx46prKxMSUlJSk9Pr3RJvSS99tprCggIUHx8/AX77dmzp1atWqXNmzdr2bJlOnTokGJjY6u9jyExMVFBQUHWV7t27Wrl/AAAAAAAqG0uf4786tWrZRiG2rZtK29vbz3//PMaM2aM3N0rl7Zy5UrdcccdlWbwf+vGG2/UH/7wB1111VUaMmSI3n33XZ06dUr/93//V2X7uXPnqqCgwPo6cuRIrZwbAAAAAAC1zeUrwIWHh2v79u06ffq0CgsLFRwcrNtuu63SPfBpaWnat2+f3njjDYeP0axZM3Xq1EkHDhyo8nNvb295e5tzxUQAAAAAQOPi8hn5Cv7+/goODtZPP/2kLVu2aOTIkTafr1ixQtHR0br66qsd7ru4uFgHDx5UcHBwbZULAAAAAIBLuDzIb9myRZs3b9ahQ4e0detWDRw4UBaLRRMnTrS2KSws1JtvvqkpU6ZU2cf111+vF1980fr+gQce0Pbt25WXl6edO3fqlltukYeHh8aMGeP08wEAAAAAwJlcfml9QUGB5s6dq2+//VaXXXaZRo0apSeffFKenp7WNuvWrZNhGNUG8YMHD+r777+3vv/22281ZswY/fDDD2rZsqX69u2rTz75RC1btnT6+QAAAAAA4EwuD/K33nqrbr311gu2mTZtmqZNm1bt53l5eTbv161bVxulAQAAAABQ77j80noAAAAAAGA/gjwAAAAAACZCkAcAAAAAwEQI8gAAAAAAmAhBHgAAAAAAE3H5qvUAAAAAgMajpKREkpSZmemU/ktLS5WXl6ewsDD5+vrWat/Z2dm12l9NEeQBAAAAAHUmJydHkjR16lQXV1JzAQEBLj0+QR4AAAAAUGfi4uIkSRaLRX5+frXef3Z2thISEpSUlKTIyMha7z8gIEAdO3as9X4dQZAHAAAAANSZFi1aaMqUKU4/TmRkpKKiopx+HFdgsTsAAAAAAEyEIA8AAAAAgIkQ5AEAAAAAMBGCPAAAAAAAJuJwkA8LC9PChQt1+PBhZ9QDAAAAAAAuwOFV62fPnq1Vq1Zp4cKFGjhwoCZPnqxbbrlF3t7ezqgPAAAAANCIlZSUWJ89b4/s7GybP+3hrEfhOYubYRhGTXbMzMzUqlWrtHbtWpWVlWns2LGaNGlSg1jev7CwUEFBQSooKFBgYKCrywEAAAAuWVlZmdLS0pSfn6/g4GDFxsbKw8PD1WUBF5WZmano6GinHiMjI8PlWdaRHFrjIF/h3Llz+sc//qGHHnpI586dU7du3TRr1ixNnDhRbm5ul9K1yxDkAQAA0JCkpKTo/vvvV15ennVbWFiYli5dqvj4eNcVBtjB0Rn50tJS5eXlKSwsTL6+vnbtUx9m5B3JoQ5fWl/h3Llzeuutt/Tqq69q69at6tWrlyZPnqxvv/1WjzzyiD744AOtWbOmpt0DAAAAqAUpKSkaPXq0RowYobVr16pr167KysrS4sWLNXr0aCUnJxPmUa/5+fk5PFvep08fJ1VTPzg8I5+ZmalXX31Va9eulbu7u8aNG6cpU6bIYrFY22RlZalHjx4qLS2t9YLrAjPyAAAAaAjKysoUERGhbt26KTU1Ve7u/1vrury8XHFxccrKylJubi6X2QMu5tQZ+R49euiGG27QsmXLFBcXJ09Pz0pt2rdvr9tvv93RrgEAAADUorS0NOXl5Vkn4X7N3d1dc+fOVUxMjNLS0jRgwADXFAnAYQ4H+a+//lqhoaEXbOPv769XX321xkUBAAAAuHT5+fmSpK5du1b5ecX2inYAzMHh58ifPHlSn376aaXtn376qf773//WSlEAAAAALl1wcLCkX259rUrF9op2AMzB4SA/c+ZMHTlypNL2o0ePaubMmbVSFAAAAIBLFxsbq7CwMC1evFjl5eU2n5WXlysxMVHt27dXbGysiyoEUBMOB/m9e/dWuWJg9+7dtXfv3lopCgAAAMCl8/Dw0NKlS7Vp0ybFxcUpPT1dRUVFSk9PV1xcnDZt2qRnn32Whe4Ak3E4yHt7e+vEiROVtufn56tJkxo/zQ4AAACAE8THxys5OVlfffWVYmJiFBgYqJiYGGVlZfHoOcCkHH783JgxY5Sfn68NGzYoKChIknTq1CnFxcWpVatW+r//+z+nFFqXePwcAAAAGpqysjKlpaUpPz9fwcHBio2NZSYeqEccyaEOB/mjR4+qX79++uGHH9S9e3dJ0u7du9W6dWtt3bpV7dq1q3nl9QRBHgAAAABQl5z6HPm2bdvqyy+/1Ouvv64vvvhCvr6+mjhxosaMGVPlM+UBAAAAAEDtqdFN7f7+/po2bVpt1wIAAAAAAC6ixqvT7d27V4cPH9bZs2dttt98882XXBQAAAAAAKiaw0H+66+/1i233KKvvvpKbm5uqrjF3s3NTdIvi2gAAAAAAADncPjxc/fee6/at2+vkydPys/PT3v27NFHH32ka6+9Vtu2bXNCiQAAAAAAoILDM/Lp6en697//rRYtWsjd3V3u7u7q27evEhMTNWvWLH3++efOqBMAAAAAAKgGM/JlZWUKCAiQJLVo0ULHjh2TJIWGhmrfvn21Wx0AAAAAALDh8Ix8165d9cUXX6h9+/bq2bOnlixZIi8vL7388svq0KGDM2oEAAAAAAD/n8NB/s9//rNOnz4tSVq4cKFGjBih2NhYXX755XrjjTdqvUAAAAAAAPA/bkbFsvOX4Mcff1Tz5s2tK9ebXWFhoYKCglRQUKDAwEBXlwMAAAAAaOAcyaEO3SN/7tw5NWnSRFlZWTbbL7vssgYT4gEAAAAAqM8cCvKenp664ooreFY8AAAAAAAu4vCq9Y8++qgeeeQR/fjjj86oBwAAAAAAXIDDi929+OKLOnDggEJCQhQaGip/f3+bzzMzM2utOAAAAACoT0pKSpSTk2N3+9LSUuXl5SksLEy+vr527WOxWOTn51fTEtEIOBzk4+LinFAGAAAAANR/OTk5io6OduoxMjIyFBUV5dRjwNxqZdX6hoZV6wEAAABUxdEZ+ezsbCUkJCgpKUmRkZF27cOMfOPkSA51eEYeAAA4jksxAaBh8PPzq9FseWRkJLPsqDUOB3l3d/cLPmqOFe0BAKiMSzEBAEBtcTjIv/XWWzbvz507p88//1yvvfaaHn/88VorDACAhsRisSgjI8Pu9jW9FBMAADR8Dgf5kSNHVto2evRoXXnllXrjjTc0efLkWikMAICGhEsxAQBAbam1e+R79eqladOm1VZ3AAAAAC6C9TeAxqlWgnxpaamef/55tW3btja6AwAAAGAH1t8AGieHg3zz5s1tFrszDENFRUXy8/NTUlJSrRYHAAAAoHqsvwE0Tg4H+b/+9a82Qd7d3V0tW7ZUz5491bx581otDgAAAED1WH8DaJwcDvITJkxwQhkAAAAAAMAe7o7u8Oqrr+rNN9+stP3NN9/Ua6+9VitFAQAAAACAqjk8I5+YmKjly5dX2t6qVStNmzZN48ePr5XCAAAAgMYoNzdXRUVFTuk7Ozvb5s/aFhAQoI4dOzqlbwD/43CQP3z4sNq3b19pe2hoqA4fPlwrRQEAAACNUW5urjp16uT04yQkJDit7/379xPmASdzOMi3atVKX375pcLCwmy2f/HFF7r88strqy4AAACg0amYiXdkVXlH1OQ58vaqWBHfWVcTAPgfh4P8mDFjNGvWLAUEBKhfv36SpO3bt+vee+/V7bffXusFAgAAAI2NM1eV79Onj1P6BVB3HA7yixYtUl5enq6//no1afLL7uXl5Ro3bpwWL15c6wUCAAAAAID/cTjIe3l56Y033tATTzyh3bt3y9fXV926dVNoaKgz6gMAAAAAAL/icJCv0LFjRxaxAAAAAGB6PCkAZuNwkB81apSuu+46PfTQQzbblyxZos8++6zKZ8wDAAAAQH3EkwJgRg4H+Y8++kgLFiyotP3GG2/U0qVLa6MmAAAAoNFq09RNvqf2S8fcXV2KQ3xP7Vebpm6uLsNhPCkAZuRwkC8uLpaXl1el7Z6eniosLKyVogAAAIDGanq0lyI/mi595OpKHBOpX2o3K54UADNxOMh369ZNb7zxhh577DGb7evWrVOXLl1qrTAAAACgMVqecVa3PbZKkRaLq0txSHZOjpYvHaubXV0I0Ag4HOTnzZun+Ph4HTx4UL///e8lSR9++KHWrFmj5OTkWi8QAAAAaEyOFxsqbdZJCrnG1aU4pPR4uY4XG64uA2gUHA7yN910k1JTU7V48WIlJyfL19dXV199tf7973/rsssuc0aNAAAAAADg/6vR4+eGDx+u4cOHS5IKCwu1du1aPfDAA8rIyFBZWVmtFggAQH3F44oAoGFggUGYTY2fI//RRx9pxYoVWr9+vUJCQhQfH6+///3vtVkbAAD1Fo8rAuAMJSUlkqTMzEyn9O/sFdTNigUGYTYOBfnjx49r1apVWrFihQoLC3XrrbfqzJkzSk1NZaE7AECjwuOKADhDTk6OJGnq1KkurqTmAgICXF2Cw1hgEGZjd5C/6aab9NFHH2n48OH629/+pqFDh8rDw0MvvfSSM+sDAKBe43FFAGpTXFycJMliscjPz6/W+6/4RZ6zfglp1tt2WGAQZmN3kH/vvfc0a9YszZgxw5Q/nAAAAEB916JFC02ZMsXpx3HmLyEBOJ/dqzns2LFDRUVFio6OVs+ePfXiiy/q+++/d2ZtAAAAAADgN+wO8r169dIrr7yi/Px8TZ8+XevWrVNISIjKy8u1detW7rMDAAAAAKAOOLxqvb+/vyZNmqRJkyZp3759WrFihZ566ik9/PDDuuGGG/T22287o04AAOodHlcEAABcocaPn5Okzp07a8mSJUpMTNTGjRu1cuXK2qoLAIB6j8cVAQAAV7ikIF/Bw8NDcXFx1lU2AQBoDHhcEQAAcIVaCfIAADRGPK4IAAC4gstv6isqKtLs2bMVGhoqX19fxcTE6LPPPrN+7ubmVuXrmWeeuWC/f//73xUWFiYfHx/17NlTu3btcvapAAAAAADgdC4P8lOmTNHWrVu1evVqffXVVxo8eLAGDRqko0ePSpLy8/NtXitXrpSbm5tGjRpVbZ9vvPGG7rvvPs2fP1+ZmZm6+uqrNWTIEJ08ebKuTgsAAAAAAKdwaZAvLS3V+vXrtWTJEvXr108RERFasGCBIiIitGzZMklSmzZtbF4bNmzQwIED1aFDh2r7/ctf/qKpU6dq4sSJ6tKli1566SX5+flVuxjfmTNnVFhYaPMCAAAAAKA+cmmQP3/+vMrKyuTj42Oz3dfXVzt27KjU/sSJE3rnnXc0efLkavs8e/asMjIyNGjQIOs2d3d3DRo0SOnp6VXuk5iYqKCgIOurXbt2NTwjAAAAAACcy6VBPiAgQL1799aiRYt07NgxlZWVKSkpSenp6crPz6/U/rXXXlNAQIDi4+Or7fP7779XWVmZWrdubbO9devWOn78eJX7zJ07VwUFBdbXkSNHLu3EAAAAAABwEpffI7969WoZhqG2bdvK29tbzz//vMaMGSN398qlrVy5UnfccUelGfxL5e3trcDAQJsXAAAAAAD1kcuDfHh4uLZv367i4mIdOXJEu3bt0rlz5yrdA5+WlqZ9+/ZpypQpF+yvRYsW8vDw0IkTJ2y2nzhxQm3atKn1+gEAAAAAqEsuD/IV/P39FRwcrJ9++klbtmzRyJEjbT5fsWKFoqOjdfXVV1+wHy8vL0VHR+vDDz+0bisvL9eHH36o3r17O6V2AAAAAADqisuD/JYtW7R582YdOnRIW7du1cCBA2WxWDRx4kRrm8LCQr355pvVzsZff/31evHFF63v77vvPr3yyit67bXXlJ2drRkzZuj06dM2fQIAAAAAYEZNXF1AQUGB5s6dq2+//VaXXXaZRo0apSeffFKenp7WNuvWrZNhGBozZkyVfRw8eFDff/+99f1tt92m7777To899piOHz+ua665Rps3b660AB4AAABgZiUlJcrJybG7fXZ2ts2f9rBYLPLz83O4NgDO4/Igf+utt+rWW2+9YJtp06Zp2rRp1X6el5dXads999yje+6551LLAwAAAOqtnJwcRUdHO7xfQkKC3W0zMjIUFRXl8DEAOI/LgzwAAGZUUlIiScrMzHRK/6WlpcrLy1NYWJh8fX1rtW9HZuIA1G8Wi0UZGRl2t6/J3y0Wi6Wm5QFwEoI8AAA1UHEp69SpU11cSc0FBAS4ugQAl8jPz8/h2fI+ffo4qRoAdYUgDwBADcTFxUly3r2j2dnZSkhIUFJSkiIjI2u9/4CAAHXs2LHW+wUAAM5HkAcAoAZatGhR7dNUalNkZCT3pgIAABsuf/wcAAAAAACwH0EeAAAAAAATIcgDAAAAAGAiBHkAAAAAAEyEIA8AAAAAgIkQ5AEAAAAAMBGCPAAAAAAAJkKQBwAAAADARAjyAAAAAACYCEEeAAAAAAATIcgDAAAAAGAiBHkAAAAAAEyEIA8AAAAAgIkQ5AEAAAAAMBGCPAAAAAAAJkKQBwAAAADARAjyAAAAAACYCEEeAAAAAAATaeLqAgAAaAxKSkqUk5Njd/vs7GybP+1hsVjk5+fncG0AAMBcCPIAANSBnJwcRUdHO7xfQkKC3W0zMjIUFRXl8DEAAIC5EOQBAKgDFotFGRkZdrcvLS1VXl6ewsLC5Ovra/cxAABAw0eQBwCgDvj5+Tk8W96nTx8nVQMAAMyMxe4AAAAAADARgjwAAAAAACZCkAcAAAAAwEQI8gAAAAAAmAiL3QEAAABotEpKSiRJmZmZTum/Jk8hsVd2dnat9gfzIMgDAAAAaLRycnIkSVOnTnVxJTUXEBDg6hJQxwjyAAAAABqtuLg4SZLFYpGfn1+t95+dna2EhAQlJSUpMjKy1vsPCAhQx44da71f1G8EeQAAAACNVosWLTRlyhSnHycyMlJRUVFOPw4aBxa7AwAAAADARAjyAAAAAACYCEEeAAAAAAATIcgDAAAAAGAiBHkAAAAAAEyEIA8AAAAAgIkQ5AEAAAAAMBGCPAAAAAAAJkKQBwAAAADARAjyAAAAAACYCEEeAAAAAAATIcgDAAAAAGAiBHkAAAAAAEyEIA8AAAAAgIkQ5AEAAAAAMBGCPAAAAAAAJkKQBwAAAADARAjyAAAAAACYCEEeAAAAAAATIcgDAAAAAGAiBHkAAAAAAEyEIA8AAAAAgIkQ5AEAAAAAMBGCPAAAAAAAJkKQBwAAAADARAjyAAAAAACYCEEeAAAAAAATIcgDAAAAAGAiBHkAAAAAAEyEIA8AAAAAgIkQ5AEAAAAAMBGCPAAAAAAAJkKQBwAAAADARAjyAAAAAACYCEEeAAAAAAATIcgDAAAAAGAiTVxdAAAAABqGkpIS5eTk2N2+tLRUeXl5CgsLk6+vr137WCwW+fn51bREAGgQCPIAAACoFTk5OYqOjnbqMTIyMhQVFeXUYwBAfUeQBwAAQK2wWCzKyMiwu312drYSEhKUlJSkyMhIu48BAI0dQR4AAAC1ws/Pr0az5ZGRkcyyA4ADWOwOAAAAAAATIcgDAAAAAGAiLg3yRUVFmj17tkJDQ+Xr66uYmBh99tlnNm2ys7N18803KygoSP7+/urRo4cOHz5cbZ+rVq2Sm5ubzcvHx8fZpwIAAAAAQJ1w6T3yU6ZMUVZWllavXq2QkBAlJSVp0KBB2rt3r9q2bauDBw+qb9++mjx5sh5//HEFBgZqz549Fw3mgYGB2rdvn/W9m5ubs08FAAAAAIA64bIgX1paqvXr12vDhg3q16+fJGnBggXauHGjli1bpieeeEKPPvqohg0bpiVLllj3Cw8Pv2jfbm5uatOmjdNqBwAAAADAVVx2af358+dVVlZWaXbd19dXO3bsUHl5ud555x116tRJQ4YMUatWrdSzZ0+lpqZetO/i4mKFhoaqXbt2GjlypPbs2XPB9mfOnFFhYaHNCwAAAACA+shlQT4gIEC9e/fWokWLdOzYMZWVlSkpKUnp6enKz8/XyZMnVVxcrKeeekpDhw7V+++/r1tuuUXx8fHavn17tf127txZK1eu1IYNG5SUlKTy8nLFxMTo22+/rXafxMREBQUFWV/t2rVzxikDAAAAAHDJXLrY3erVq2UYhtq2bStvb289//zzGjNmjNzd3VVeXi5JGjlypP70pz/pmmuu0cMPP6wRI0bopZdeqrbP3r17a9y4cbrmmmvUv39/paSkqGXLllq+fHm1+8ydO1cFBQXW15EjR2r9XAEAAAAAqA0uDfLh4eHavn27iouLdeTIEe3atUvnzp1Thw4d1KJFCzVp0kRdunSx2ScyMvKCq9b/lqenp7p3764DBw5U28bb21uBgYE2LwAAAAAA6iOXrlpfwd/fX/7+/vrpp5+0ZcsWLVmyRF5eXurRo4fN6vOStH//foWGhtrdd1lZmb766isNGzastssGAABo8HJzc1VUVOSUvrOzs23+rG0BAQHq2LGjU/oGAFdyaZDfsmWLDMNQ586ddeDAAc2ZM0cWi0UTJ06UJM2ZM0e33Xab+vXrp4EDB2rz5s3auHGjtm3bZu1j3Lhxatu2rRITEyVJCxcuVK9evRQREaFTp07pmWee0TfffKMpU6a44hQBAABMKzc3V506dXL6cRISEpzW9/79+wnzABoclwb5goICzZ07V99++60uu+wyjRo1Sk8++aQ8PT0lSbfccoteeuklJSYmatasWercubPWr1+vvn37Wvs4fPiw3N3/d4fATz/9pKlTp+r48eNq3ry5oqOjtXPnzkqX6AMAAODCKmbik5KSFBkZWev9l5aWKi8vT2FhYfL19a3VvrOzs5WQkOC0qwkAwJXcDMMwXF1EfVNYWKigoCAVFBRwvzwAAGi0MjMzFR0drYyMDEVFRbm6HIeYuXY0LHwXYS9HcqhLF7sDAAAAAACOIcgDAAAAAGAiBHkAAAAAAEyEIA8AAAAAgIkQ5AEAAAAAMBGCPAAAAAAAJkKQBwAAAADARAjyAAAAAACYCEEeAAAAAAATIcgDAAAAAGAiBHkAAAAAAEyEIA8AAAAAgIk0cXUBAAAAqL/aNHWT76n90jFzzf/4ntqvNk3dXF0GADgFQR4AAADVmh7tpciPpksfuboSx0Tql9oBoCEiyAMAAKBayzPO6rbHVinSYnF1KQ7JzsnR8qVjdbOrCwEAJyDIA3C5kpIS5eTk2N2+tLRUeXl5CgsLk6+vr137WCwW+fn51bREAGi0jhcbKm3WSQq5xtWlOKT0eLmOFxuuLgMAnIIgD8DlcnJyFB0d7dRjZGRkKCoqyqnHAAAAAOoCQR6Ay1ksFmVkZNjdPjs7WwkJCUpKSlJkZKTdxwAAAAAaAoI8AJfz8/Or0Wx5ZGQks+wAAABodMz1HBEAAAAAABo5gjwAAAAAACZCkAcAAAAAwEQI8gAAAAAAmAhBHgAAAAAAEyHIAwAAAABgIjx+DgAAAADsVFJSopycHLvbZ2dn2/xpD4vFIj8/P4drQ+NBkAcAAAAAO+Xk5Cg6Otrh/RISEuxum5GRoaioKIePgcaDIA8AAIAqlZSUSJIyMzOd0n9paany8vIUFhYmX1/fWu3bkdlPwBEWi0UZGRl2t6/J99xisdS0PDQSBHkAAABUqeLy4alTp7q4kpoLCAhwdQloYPz8/ByeLe/Tp4+TqkFjRZAHAABAleLi4iQ5737d7OxsJSQkKCkpSZGRkbXef0BAgDp27Fjr/QKAqxHkAThFbm6uioqKnNJ3TRaNcQT/8AOAX7Ro0UJTpkxx+nEiIyO5HxgAHECQB1DrcnNz1alTJ6cfx5FFYxy1f/9+wjwAAADqJYI8gFpXMRPvrEslnb04UkJCgtOuJgAAAAAuFUEegNM481JJFo0BAABAY+Xu6gIAAAAAAID9CPIAAAAAAJgIQR4AAAAAABMhyAMAAAAAYCIEeQAAAAAATIQgDwAAAACAiRDkAQAAAAAwEYI8AAAAAAAmQpAHAAAAAMBECPIAAAAAAJgIQR4AAAAAABNp4uoCADRMbZq6yffUfumYuX5f6Htqv9o0dXN1GQAAAEC1CPIAnGJ6tJciP5oufeTqShwTqV9qBwAAAOorgjwAp1iecVa3PbZKkRaLq0txSHZOjpYvHaubXV0IAAAAUA2CPACnOF5sqLRZJynkGleX4pDS4+U6Xmy4ugwAAACgWua6eRUAAAAAgEaOIA8AAAAAgIkQ5AEAAAAAMBGCPAAAAAAAJsJidwAAAKgVJSUlysnJsbt9dna2zZ/2sFgs8vPzc7g2AGhICPIAAACoFTk5OYqOjnZ4v4SEBLvbZmRkKCoqyuFjAEBDQpAHAABArbBYLMrIyLC7fWlpqfLy8hQWFiZfX1+7jwEAjR1BHgAAALXCz8/P4dnyPn36OKkaAGi4WOwOAAAAAAATIcgDAAAAAGAiBHkAAAAAAEyEIA8AAAAAgIkQ5AEAAAAAMBGCPAAAAAAAJkKQBwAAAADARAjyAAAAAACYCEEeAAAAAAATaeLqAgA0PCUlJZKkzMxMp/RfWlqqvLw8hYWFydfXt1b7zs7OrtX+AAAAgNpGkAdQ63JyciRJU6dOdXElNRcQEODqEgAAAIAqEeQB1Lq4uDhJksVikZ+fX633n52drYSEBCUlJSkyMrLW+w8ICFDHjh1rvV8AAACgNhDkAdS6Fi1aaMqUKU4/TmRkpKKiopx+HAAAAKA+YbE7AAAAAABMhCAPAAAAAICJEOQBAAAAADARgjwAAAAAACZCkAcAAAAAwEQI8gAAAAAAmAiPnwPgciUlJcrJybG7fXZ2ts2f9nDWM+0BAACAuubSIF9UVKR58+bprbfe0smTJ9W9e3c999xz6tGjh7VNdna2HnroIW3fvl3nz59Xly5dtH79el1xxRXV9vvmm29q3rx5ysvLU8eOHfX0009r2LBhdXFKAGogJydH0dHRDu+XkJBgd9uMjAyeOQ8AAIAGwaVBfsqUKcrKytLq1asVEhKipKQkDRo0SHv37lXbtm118OBB9e3bV5MnT9bjjz+uwMBA7dmzRz4+PtX2uXPnTo0ZM0aJiYkaMWKE1qxZo7i4OGVmZqpr1651eHYA7GWxWJSRkWF3+9LSUuXl5SksLEy+vr52HwMAAABoCNwMwzBcceDS0lIFBARow4YNGj58uHV7dHS0brzxRj3xxBO6/fbb5enpqdWrV9vd72233abTp09r06ZN1m29evXSNddco5deesmuPgoLCxUUFKSCggIFBgbaf1IAAAAAANSAIznUZYvdnT9/XmVlZZVm1319fbVjxw6Vl5frnXfeUadOnTRkyBC1atVKPXv2VGpq6gX7TU9P16BBg2y2DRkyROnp6dXuc+bMGRUWFtq8AAAAAACoj1wW5AMCAtS7d28tWrRIx44dU1lZmZKSkpSenq78/HydPHlSxcXFeuqppzR06FC9//77uuWWWxQfH6/t27dX2+/x48fVunVrm22tW7fW8ePHq90nMTFRQUFB1le7du1q7TwBAAAAAKhNLn383OrVq2UYhtq2bStvb289//zzGjNmjNzd3VVeXi5JGjlypP70pz/pmmuu0cMPP6wRI0bYfYm8vebOnauCggLr68iRI7XaPwAAAAAAtcWlQT48PFzbt29XcXGxjhw5ol27duncuXPq0KGDWrRooSZNmqhLly42+0RGRurw4cPV9tmmTRudOHHCZtuJEyfUpk2bavfx9vZWYGCgzQsAAAAAgPrIpUG+gr+/v4KDg/XTTz9py5YtGjlypLy8vNSjRw/t27fPpu3+/fsVGhpabV+9e/fWhx9+aLNt69at6t27t1NqBwAAAACgLrn08XNbtmyRYRjq3LmzDhw4oDlz5shisWjixImSpDlz5ui2225Tv379NHDgQG3evFkbN27Utm3brH2MGzdObdu2VWJioiTp3nvvVf/+/bV06VINHz5c69at03//+1+9/PLLrjhFAAAAAABqlUtn5AsKCjRz5kxZLBaNGzdOffv21ZYtW+Tp6SlJuuWWW/TSSy9pyZIl6tatm/75z39q/fr16tu3r7WPw4cPKz8/3/o+JiZGa9as0csvv6yrr75aycnJSk1N5RnyAAAAAIAGwWXPka/PeI48AAAAAKAumeI58gAAAAAAwHEEeQAAAAAATIQgDwAAAACAiRDkAQAAAAAwEYI8AAAAAAAmQpAHAAAAAMBECPIAAAAAAJgIQR4AAAAAABMhyAMAAAAAYCJNXF1AfWQYhiSpsLDQxZUAAAAAABqDivxZkUcvhCBfhaKiIklSu3btXFwJAAAAAKAxKSoqUlBQ0AXbuBn2xP1Gpry8XMeOHVNAQIDc3NxcXY5DCgsL1a5dOx05ckSBgYGuLqdRYMzrHmNe9xjzuseY1z3GvO4x5nWPMa97jHndM+uYG4ahoqIihYSEyN39wnfBMyNfBXd3d/3ud79zdRmXJDAw0FRf2oaAMa97jHndY8zrHmNe9xjzuseY1z3GvO4x5nXPjGN+sZn4Cix2BwAAAACAiRDkAQAAAAAwEYJ8A+Pt7a358+fL29vb1aU0Gox53WPM6x5jXvcY87rHmNc9xrzuMeZ1jzGve41hzFnsDgAAAAAAE2FGHgAAAAAAEyHIAwAAAABgIgR5AAAAAABMhCDfgGzbtk1ubm46deqU3fuEhYXpb3/7m9NqaugY87rHmNc9xrzuMeZ1jzGve4x53WPM6x5j7nyNdYwJ8nVkwoQJcnNz01133VXps5kzZ8rNzU0TJkyo+8IuYs+ePRo1apTCwsLk5uZmqi+8Wcf8lVdeUWxsrJo3b67mzZtr0KBB2rVrl6vLsotZxzwlJUXXXnutmjVrJn9/f11zzTVavXq1q8uyi1nH/NfWrVsnNzc3xcXFuboUu5h1zFetWiU3Nzebl4+Pj6vLsotZx1ySTp06pZkzZyo4OFje3t7q1KmT3n33XVeXdVFmHfMBAwZU+p67ublp+PDhri7tosw65pL0t7/9TZ07d5avr6/atWunP/3pT/r5559dXdZFmXXMz507p4ULFyo8PFw+Pj66+uqrtXnzZleXVSWzjrG9Gejvf/+7wsLC5OPjo549e9bpv9kJ8nWoXbt2WrdunUpLS63bfv75Z61Zs0ZXXHGFCyurXklJiTp06KCnnnpKbdq0cXU5DjPjmG/btk1jxozRf/7zH6Wnp6tdu3YaPHiwjh496urS7GLGMb/sssv06KOPKj09XV9++aUmTpyoiRMnasuWLa4uzS5mHPMKeXl5euCBBxQbG+vqUhxi1jEPDAxUfn6+9fXNN9+4uiS7mXHMz549qxtuuEF5eXlKTk7Wvn379Morr6ht27auLs0uZhzzlJQUm+94VlaWPDw89Ic//MHVpdnFjGO+Zs0aPfzww5o/f76ys7O1YsUKvfHGG3rkkUdcXZpdzDjmf/7zn7V8+XK98MIL2rt3r+666y7dcsst+vzzz11dWpXMOMb2ZKA33nhD9913n+bPn6/MzExdffXVGjJkiE6ePFknNRLk61BUVJTatWunlJQU67aUlBRdccUV6t69u03bM2fOaNasWWrVqpV8fHzUt29fffbZZzZt3n33XXXq1Em+vr4aOHCg8vLyKh1zx44dio2Ntf6GdNasWTp9+rTdNffo0UPPPPOMbr/9dlM+h9GMY/7666/r7rvv1jXXXCOLxaJ//vOfKi8v14cffujYybuIGcd8wIABuuWWWxQZGanw8HDde++9uuqqq7Rjxw7HTt5FzDjmklRWVqY77rhDjz/+uDp06ODQvq5m1jF3c3NTmzZtrK/WrVs7tL8rmXHMV65cqR9//FGpqanq06ePwsLC1L9/f1199dWOnbyLmHHML7vsMpvv+NatW+Xn52eaIG/GMd+5c6f69OmjsWPHKiwsTIMHD9aYMWNMczWhGcd89erVeuSRRzRs2DB16NBBM2bM0LBhw7R06VLHTr6OmHGM7clAf/nLXzR16lRNnDhRXbp00UsvvSQ/Pz+tXLnS7uNcCoJ8HZs0aZJeffVV6/uVK1dq4sSJldo9+OCDWr9+vV577TVlZmYqIiJCQ4YM0Y8//ihJOnLkiOLj43XTTTdp9+7dmjJlih5++GGbPg4ePKihQ4dq1KhR+vLLL/XGG29ox44duueee5x7kvWM2ce8pKRE586d02WXXVbjPuqamcfcMAx9+OGH2rdvn/r161ejPlzBjGO+cOFCtWrVSpMnT67BGbueGce8uLhYoaGhateunUaOHKk9e/bU4Mxdx2xj/vbbb6t3796aOXOmWrdura5du2rx4sUqKyur4QjUPbON+W+tWLFCt99+u/z9/WvcR10z25jHxMQoIyPDGty//vprvfvuuxo2bFhNTt8lzDbmZ86cqXRrlK+vb72egDDbGF/M2bNnlZGRoUGDBlm3ubu7a9CgQUpPT6+141yQgToxfvx4Y+TIkcbJkycNb29vIy8vz8jLyzN8fHyM7777zhg5cqQxfvx4wzAMo7i42PD09DRef/116/5nz541QkJCjCVLlhiGYRhz5841unTpYnOMhx56yJBk/PTTT4ZhGMbkyZONadOm2bRJS0sz3N3djdLSUsMwDCM0NNT461//atc5ONK2PmgIY24YhjFjxgyjQ4cO1v3rMzOP+alTpwx/f3+jSZMmhre3t7FixYpLGIm6Y9YxT0tLM9q2bWt89913NudhBmYd8507dxqvvfaa8fnnnxvbtm0zRowYYQQGBhpHjhy5xBFxPrOOeefOnQ1vb29j0qRJxn//+19j3bp1xmWXXWYsWLDgEkfE+cw65r/26aefGpKMTz/9tAYjUPfMPObPPfec4enpaTRp0sSQZNx1112XMBJ1x6xjPmbMGKNLly7G/v37jbKyMuP99983fH19DS8vr0sckdpn1jH+taraHj161JBk7Ny502b7nDlzjOuuu86ufi9Vk7r5dQEqtGzZUsOHD9eqVatkGIaGDx+uFi1a2LQ5ePCgzp07pz59+li3eXp66rrrrlN2drYkKTs7Wz179rTZr3fv3jbvv/jiC3355Zd6/fXXrdsMw1B5ebkOHTqkyMjI2j69esnMY/7UU09p3bp12rZtm2kWpZLMOeYBAQHavXu3iouL9eGHH+q+++5Thw4dNGDAAEdO3WXMNOZFRUW688479corr1Sq0UzMNOYVff6635iYGEVGRmr58uVatGiR/SfuQmYb8/LycrVq1Uovv/yyPDw8FB0draNHj+qZZ57R/PnzHT5/VzDbmP/aihUr1K1bN1133XUO7edqZhvzbdu2afHixfrHP/6hnj176sCBA7r33nu1aNEizZs3z+HzdwWzjflzzz2nqVOnymKxyM3NTeHh4Zo4cWKdXdJdE2YbYzMgyLvApEmTrJd2/P3vf3facYqLizV9+nTNmjWr0mf1dWEJZzHjmD/77LN66qmn9MEHH+iqq66qrRLrjNnG3N3dXREREZKka665RtnZ2UpMTDRNkJfMM+YHDx5UXl6ebrrpJuu28vJySVKTJk20b98+hYeH117BTmSWMa+Kp6enunfvrgMHDlxqeXXKTGMeHBwsT09PeXh4WLdFRkbq+PHjOnv2rLy8vGqtXmcy05hXOH36tNatW6eFCxfWVnl1ykxjPm/ePN15552aMmWKJKlbt246ffq0pk2bpkcffVTu7ua4k9dMY96yZUulpqbq559/1g8//KCQkBA9/PDD9X69GTON8cW0aNFCHh4eOnHihM32EydO1NkC4QR5Fxg6dKjOnj0rNzc3DRkypNLn4eHh8vLy0scff6zQ0FBJvzxm4rPPPtPs2bMl/fIPgbfffttmv08++cTmfVRUlPbu3WsNJ42Z2cZ8yZIlevLJJ7VlyxZde+21l9SXq5htzH+rvLxcZ86cqdU+nc0sY26xWPTVV1/ZbPvzn/+soqIiPffcc2rXrl2N+nUFs4x5VcrKyvTVV1+Z6j5WyVxj3qdPH61Zs0bl5eXWMLN//34FBwebJsRL5hrzCm+++abOnDmjhISES+7LFcw05iUlJZXCesUvrwzDqHG/dc1MY17Bx8dHbdu21blz57R+/Xrdeuutl9ynM5lxjKvj5eWl6Ohoffjhh9bH51YsTl1X65GZ41dkDYyHh4eys7O1d+9em9/SV/D399eMGTM0Z84cbd68WXv37tXUqVNVUlJiXRTqrrvuUm5urubMmaN9+/ZpzZo1WrVqlU0/Dz30kHbu3Kl77rlHu3fvVm5urjZs2ODQl+vs2bPavXu3du/erbNnz+ro0aPavXu36WZwzDTmTz/9tObNm6eVK1cqLCxMx48f1/Hjx1VcXHxJY1DXzDTmiYmJ2rp1q77++mtlZ2dr6dKlWr16ten+AWiWMffx8VHXrl1tXs2aNVNAQIC6du1qqoBjljGXfllc8P3339fXX3+tzMxMJSQk6JtvvrHOopmFmcZ8xowZ+vHHH3Xvvfdq//79euedd7R48WLNnDnzksagrplpzCusWLFCcXFxuvzyy2t0zq5mpjG/6aabtGzZMq1bt06HDh3S1q1bNW/ePN10001V1l5fmWnMP/30U6WkpOjrr79WWlqahg4dqvLycj344IOXNAbOZqYxticD3XfffXrllVf02muvKTs7WzNmzNDp06erXMTPKerkTnxcdCGnXy/0YBiGUVpaavzxj380WrRoYXh7ext9+vQxdu3aZbPPxo0bjYiICMPb29uIjY01Vq5cabPQg2EYxq5du4wbbrjBaNq0qeHv729cddVVxpNPPmn9/GILPRw6dMiQVOnVv39/B0eg7pl1zENDQ6sc8/nz5zs4AnXPrGP+6KOPGhEREYaPj4/RvHlzo3fv3sa6descPX2XMOuYO3oe9YlZx3z27NnGFVdcYXh5eRmtW7c2hg0bZmRmZjp6+i5h1jE3jF8WGezZs6fh7e1tdOjQwXjyySeN8+fPO3L6LmHmMc/JyTEkGe+//74jp+xyZh3zc+fOGQsWLDDCw8MNHx8fo127dsbdd99tc4z6yqxjvm3bNiMyMtLw9vY2Lr/8cuPOO+80jh496ujp1wmzjrG9GeiFF16w/n/rddddZ3zyySf2DEutcDMME13zAgAAAABAI8el9QAAAAAAmAhBHgAAAAAAEyHIAwAAAABgIgR5AAAAAABMhCAPAAAAAICJEOQBAAAAADARgjwAAAAAACZCkAcAAAAAwEQI8gAAwOm2bdsmNzc3nTp1yu59wsLC9Le//c1pNQEAYFYEeQAAoAkTJsjNzU133XVXpc9mzpwpNzc3TZgwoe4LAwAAlRDkAQCAJKldu3Zat26dSktLrdt+/vlnrVmzRldccYULKwMAAL9GkAcAAJKkqKgotWvXTikpKdZtKSkpuuKKK9S9e3frtjNnzmjWrFlq1aqVfHx81LdvX3322Wc2fb377rvq1KmTfH19NXDgQOXl5VU63o4dOxQbGytfX1+1a9dOs2bN0unTp512fgAANBQEeQAAYDVp0iS9+uqr1vcrV67UxIkTbdo8+OCDWr9+vV577TVlZmYqIiJCQ4YM0Y8//ihJOnLkiOLj43XTTTdp9+7dmjJlih5++GGbPg4ePKihQ4dq1KhR+vLLL/XGG29ox44duueee5x/kgAAmBxBHgAAWCUkJGjHjh365ptv9M033+jjjz9WQkKC9fPTp09r2bJleuaZZ3TjjTeqS5cueuWVV+Tr66sVK1ZIkpYtW6bw8HAtXbpUnTt31h133FHp/vrExETdcccdmj17tjp27KiYmBg9//zz+te//qWff/65Lk8ZAADTaeLqAgAAQP3RsmVLDR8+XKtWrZJhGBo+fLhatGhh/fzgwYM6d+6c+vTpY93m6emp6667TtnZ2ZKk7Oxs9ezZ06bf3r1727z/4osv9OWXX+r111+3bjMMQ+Xl5Tp06JAiIyOdcXoAADQIBHkAAGBj0qRJ1kvc//73vzvlGMXFxZo+fbpmzZpV6TMW1gMA4MII8gAAwMbQoUN19uxZubm5aciQITafhYeHy8vLSx9//LFCQ0MlSefOndNnn32m2bNnS5IiIyP19ttv2+z3ySef2LyPiorS3r17FRER4bwTAQCggeIeeQAAYMPDw0PZ2dnau3evPDw8bD7z9/fXjBkzNGfOHG3evFl79+7V1KlTVVJSosmTJ0uS7rrrLuXm5mrOnDnat2+f1qxZo1WrVtn089BDD2nnzp265557tHv3buXm5mrDhg0sdgcAgB0I8gAAoJLAwEAFBgZW+dlTTz2lUaNG6c4771RUVJQOHDigLVu2qHnz5pJ+uTR+/fr1Sk1N1dVXX62XXnpJixcvtunjqquu0vbt27V//37Fxsaqe/fueuyxxxQSEuL0cwMAwOzcDMMwXF0EAAAAAACwDzPyAAAAAACYCEEeAAAAAAATIcgDAAAAAGAiBHkAAAAAAEyEIA8AAAAAgIkQ5AEAAAAAMBGCPAAAAAAAJkKQBwAAAADARAjyAAAAAACYCEEeAAAAAAATIcgDAAAAAGAi/w98IfvQgksMLQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+QAAAIjCAYAAACKx9GpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABUW0lEQVR4nO3dfVxUZf7/8feAcqeAeQdaKCrajKkVVIpEamthWcmqu93Rep+aZma3tpXpttpWbtaWZq6pZa5tRnazpZVlYWkZrpU5KJWo3xSrdQEVBIPz+8Mfs01AzsAMFwOv5+MxD5rrnHOdz7mcxPecc65jsyzLEgAAAAAAqFdBpgsAAAAAAKApIpADAAAAAGAAgRwAAAAAAAMI5AAAAAAAGEAgBwAAAADAAAI5AAAAAAAGEMgBAAAAADCAQA4AAAAAgAEEcgAAAAAADCCQAwB8YvTo0YqPj6/Vtg888IBsNptvC/LC888/L7vdrubNm6tVq1bG6mjIbDabHnjggVOu582fZVMYd5vNpqlTp5ouw2sDBw7UwIEDa7VtfHy8Ro8e7dN6AKCxIpADQCNns9k8em3cuNF0qUbk5ORo9OjR6tatm5YsWaJnnnlGkvTpp5/qpptuUlJSkpo3b270C4PaqunPOjY21nRpNY67v1R+UVDTKz8/36/7r428vDxXfQ8++GC161x//fWy2Wxq2bJlPVcHAPCFZqYLAAD41/PPP+/2/rnnntM777xTpd3hcNRpP0uWLFFFRUWttr333nt1991312n/tbVx40ZVVFTo8ccfV0JCgqv9zTff1N///nf16dNHXbt21e7du43UV1eXXHKJ/vCHP7i1hYeHG6rmf2oad39btGhRteG1IZ+hDwsL0z/+8Q/de++9bu3Hjh3Tq6++qrCwMEOVAQDqikAOAI1cRkaG2/stW7bonXfeqdL+S8XFxYqIiPB4P82bN69VfZLUrFkzNWtm5lfS999/L6lqIJs8ebLuuusuhYeHa+rUqQ0ykB8/flwhISEKCqr5grcePXqc8s/ahJrGvS48+cyOHDlSbdu29dk+68Pll1+uzMxMff755zr77LNd7a+++qrKyso0ZMgQvffeewYrBADUFpesAwA0cOBA9erVS9nZ2brooosUERGhe+65R9LJf/QPHTpUHTt2VGhoqLp166Y//elPKi8vd+vjl/eQV15u++ijj+qZZ55Rt27dFBoaqvPPP19bt25127a6+44r771du3atevXqpdDQUJ111llat25dlfo3btyo8847T2FhYerWrZsWL17s0b3M8fHxmjVrliSpXbt2bvdJx8TE1OlMcmX9L7zwgs4880yFhYUpKSlJH374YZV1v/vuO40dO1YxMTGu43z22WerHKPNZtPq1at177336vTTT1dERISKiopqXaN0MhiPGzdOMTExCgsL09lnn60VK1Z4tO2mTZt0/vnnu427J35t3CVp4cKFOuussxQaGqqOHTtqypQpKigocOvj1z6zdVFWVqb7779fSUlJio6OVosWLZSamqr333+/yrqVZ/h79+6tsLAwtWvXTkOGDNFnn31WZV1PPsc1SU5OVpcuXbRq1Sq39hdeeEFDhgxR69atq93Ok3GU5Pr/Mzw8XBdccIGysrKq7a+0tFSzZs1SQkKCQkNDFRcXpzvvvFOlpaUeHwsAwB1nyAEAkqT//Oc/uuyyy3TNNdcoIyNDMTExkqTly5erZcuWmjFjhlq2bKn33ntP999/v4qKivTII4+cst9Vq1bpyJEjmjhxomw2mx5++GENHz5c33777SnPqm/atEmZmZm66aabFBkZqSeeeEIjRozQvn371KZNG0nSv//9bw0ZMkQdOnTQ7NmzVV5erjlz5qhdu3anrG3BggV67rnn9Morr7guZe7Tp48Ho+WZDz74QC+++KKmTZum0NBQLVy4UEOGDNGnn36qXr16SZIOHTqkfv36uQJ8u3bt9NZbb2ncuHEqKirS9OnT3fr805/+pJCQEN1+++0qLS1VSEjIr9Zw/Phx/fjjj25tkZGRCg0NVUlJiQYOHKivv/5aU6dOVZcuXfTSSy9p9OjRKigo0C233FJjv19++aUuvfRStWvXTg888IB++uknzZo1y/W5+TW/Nu4PPPCAZs+ercGDB2vy5MnatWuXFi1apK1bt+qjjz5y+8zU9Jn9NYcPH67S1qxZM9eZ+qKiIv3973/XtddeqwkTJujIkSNaunSp0tLS9Omnn+qcc85xbTdu3DgtX75cl112mcaPH6+ffvpJWVlZ2rJli8477zzXep58jk/l2muv1cqVK/XQQw/JZrPpxx9/1Ntvv63nn3++2nDv6TguXbpUEydOVP/+/TV9+nR9++23uuqqq9S6dWvFxcW5+quoqNBVV12lTZs26cYbb5TD4dCXX36pxx57TLt379batWs9Og4AwC9YAIAmZcqUKdYv//ofMGCAJcl6+umnq6xfXFxcpW3ixIlWRESEdfz4cVfbqFGjrM6dO7ve79mzx5JktWnTxjp8+LCr/dVXX7UkWa+//rqrbdasWVVqkmSFhIRYX3/9tavt888/tyRZf/vb31xtV155pRUREWF99913rrbc3FyrWbNmVfqsTuW+f/jhhxrXqW7MTkWSJcn67LPPXG179+61wsLCrN/+9reutnHjxlkdOnSwfvzxR7ftr7nmGis6Oto1/u+//74lyeratWu1fya/VsMvX8uWLbMsy7IWLFhgSbJWrlzp2qasrMxKTk62WrZsaRUVFbn1NWvWLNf79PR0KywszNq7d6+rbefOnVZwcHCtx/3777+3QkJCrEsvvdQqLy93tT/55JOWJOvZZ591tf3aZ/bX9lfd68wzz3St99NPP1mlpaVu2/73v/+1YmJirLFjx7ra3nvvPUuSNW3atCr7qqiocP23p5/j6lT+P/TII49YO3bssCRZWVlZlmVZ1lNPPWW1bNnSOnbsmDVq1CirRYsWru08HceysjKrffv21jnnnON2zM8884wlyRowYICr7fnnn7eCgoJc+6/09NNPW5Ksjz76yNXWuXNna9SoUb96bACAk7hkHQAgSQoNDdWYMWOqtP/8su0jR47oxx9/VGpqqoqLi5WTk3PKfq+++mqddtpprvepqamSpG+//faU2w4ePFjdunVzve/Tp4+ioqJc25aXl+vdd99Venq6Onbs6FovISFBl1122Sn797fk5GQlJSW53nfq1EnDhg3T+vXrVV5eLsuy9PLLL+vKK6+UZVn68ccfXa+0tDQVFhZq27Ztbn2OGjXKq0vphw0bpnfeecftlZaWJunkxHWxsbG69tprXes3b95c06ZN09GjR/XBBx9U22d5ebnWr1+v9PR0derUydXucDhcfdfGu+++q7KyMk2fPt3tvvgJEyYoKipK//rXv9zWr+kz+2tefvnlKuOxbNky1/Lg4GDXVQcVFRU6fPiwfvrpJ5133nlufxYvv/yybDab69L7n/vlrRKn+hx74qyzzlKfPn30j3/8Q9LJK0+GDRtW7T3zno7jZ599pu+//16TJk1yu9Ji9OjRio6OduvzpZdeksPhkN1ud/ucXnzxxZJU7SX9AIBT45J1AIAk6fTTT6/28uevvvpK9957r957770q9ysXFhaest+fBzZJrnD+3//+1+ttK7ev3Pb7779XSUlJtbN01+fM3TXp3r17lbYePXqouLhYP/zwg4KCglRQUKBnnnmmxsd+VU5+VqlLly5e1XDGGWdo8ODB1S7bu3evunfvXmVSuMoZ9/fu3Vvtdj/88INKSkqqPb4zzzxTb775plc1/ryeyj5+LiQkRF27dq1ST02f2V9z0UUXnXJStxUrVmj+/PnKycnRiRMnXO0/H/tvvvlGHTt2rPH+7Z871efYU9ddd53mz5+vW2+9VR9//HGN98x7Oo6VP3/559i8eXN17drVrS03N1dOp7PGW0F++TkFAHiGQA4AkFT9o7AKCgo0YMAARUVFac6cOerWrZvCwsK0bds23XXXXR495iw4OLjadsuy/LptIKgcv4yMDI0aNaradX55T3tDeGRZQ+GPsVi5cqVGjx6t9PR03XHHHWrfvr2Cg4M1b948ffPNN7Xq01ef42uvvVYzZ87UhAkT1KZNG1166aW1qqc2Kioq1Lt3b/31r3+tdvnP7zcHAHiOQA4AqNHGjRv1n//8R5mZmbroootc7Xv27DFY1f+0b99eYWFh+vrrr6ssq66tvuXm5lZp2717tyIiIlxnGiMjI1VeXl7jWWx/6ty5s7744gtVVFS4nSWvvBWhc+fO1W7Xrl07hYeHV3t8u3btqlM9lX38/AxtWVmZ9uzZUy9jtGbNGnXt2lWZmZlul57/8tL0bt26af369Tp8+LBHZ8l9oVOnTkpJSdHGjRs1efLkGh8V6Ok4Vq6Xm5vruvRckk6cOKE9e/a4PWKtW7du+vzzz/Wb3/zmlE8vAAB4jnvIAQA1qjyz9/MzeWVlZVq4cKGpktwEBwdr8ODBWrt2rQ4cOOBq//rrr/XWW28ZrOykzZs3u913vH//fr366qu69NJLFRwcrODgYI0YMUIvv/yyduzYUWX7H374wa/1XX755crPz9eLL77oavvpp5/0t7/9TS1bttSAAQOq3S44OFhpaWlau3at9u3b52p3Op1av359resZPHiwQkJC9MQTT7h95pYuXarCwkINHTq01n17qrrP/CeffKLNmze7rTdixAhZlqXZs2dX6cOfV3A8+OCDmjVrlm6++eYa1/F0HM877zy1a9dOTz/9tMrKylzrLV++vMrj0X7/+9/ru+++05IlS6rsr6SkRMeOHavjkQFA08QZcgBAjfr376/TTjtNo0aN0rRp02Sz2fT88883qEvGH3jgAb399ttKSUnR5MmTVV5erieffFK9evXS9u3ba93v3r179fzzz0uS67nSDz74oKSTZxZvuOGGU/bRq1cvpaWluT32TJJbiHvooYf0/vvvq2/fvpowYYJ69uypw4cPa9u2bXr33XerfUyXr9x4441avHixRo8erezsbMXHx2vNmjX66KOPtGDBAkVGRta47ezZs7Vu3TqlpqbqpptucgX5s846S1988UWt6mnXrp1mzpyp2bNna8iQIbrqqqu0a9cuLVy4UOeff74yMjJqe6gua9asUcuWLau0X3LJJYqJidEVV1yhzMxM/fa3v9XQoUO1Z88ePf300+rZs6eOHj3qWn/QoEG64YYb9MQTTyg3N1dDhgxRRUWFsrKyNGjQIE2dOrXOtVZnwIABNX5RUsnTcWzevLkefPBBTZw4URdffLGuvvpq7dmzR8uWLatyD/kNN9ygf/7zn5o0aZLef/99paSkqLy8XDk5OfrnP/+p9evXuz3qDQDgGQI5AKBGbdq00RtvvKHbbrtN9957r0477TRlZGToN7/5TZ1m0/alpKQkvfXWW7r99tt13333KS4uTnPmzJHT6fRoFvia7NmzR/fdd59bW+X7AQMGeBTIBwwYoOTkZM2ePVv79u1Tz549tXz5crf7wmNiYvTpp59qzpw5yszM1MKFC9WmTRudddZZ+stf/lLr+j0RHh6ujRs36u6779aKFStUVFSkM888U8uWLdPo0aN/dds+ffpo/fr1mjFjhu6//36dccYZmj17tg4ePFjrQC6d/IKlXbt2evLJJ3XrrbeqdevWuvHGGzV37txTPrfeE5MnT662/f3331dMTIxGjx6t/Px8LV68WOvXr1fPnj21cuVKvfTSS9q4caPbNsuWLVOfPn20dOlS3XHHHYqOjtZ5552n/v3717nOuvJ0HG+88UaVl5frkUce0R133KHevXvrtddeq/LZDwoK0tq1a/XYY4+5niEfERGhrl276pZbblGPHj3q+xABoFGwWQ3pNAcAAD6Snp6ur776qtr7nOuDzWbTlClT9OSTTxrZPwAAaPi4hxwAEPBKSkrc3ufm5urNN9/UwIEDzRQEAADgAS5ZBwAEvK5du2r06NGuZywvWrRIISEhuvPOO02XBgAAUCMCOQAg4A0ZMkT/+Mc/lJ+fr9DQUCUnJ2vu3Lnq3r276dIAAABqxD3kAAAAAAAYwD3kAAAAAAAYQCAHAAAAAMCARn8PeUVFhQ4cOKDIyEjZbDbT5QAAAAAAGjnLsnTkyBF17NhRQUE1nwdv9IH8wIEDiouLM10GAAAAAKCJ2b9/v84444walzf6QB4ZGSnp5EBERUUZrgYAAAAA0NgVFRUpLi7OlUdr0ugDeeVl6lFRUQRyAAAAAEC9OdVt00zqBgAAAACAAQRyAAAAAAAMIJADAAAAAGAAgRwAAAAAAAMI5AAAAAAAGEAgBwAAAADAAAI5AAAAAAAGEMgBAAAAADCAQA4AAAAAgAEEcgAAAAAADCCQAwAAAABgAIEcAAAAAAADCOQAAAAAABhAIAcAAAAAwAACOQAAAAAABhDIAQAAAAAwgEAOAAAAAIABzUwXAPhTcXGxcnJyPFq3pKREeXl5io+PV3h4uMf7sNvtioiIqG2JAAAAAJooAjkatZycHCUlJfl1H9nZ2UpMTPTrPgAAAAA0PgRyNGp2u13Z2dkeret0OpWRkaGVK1fK4XB4tQ8AAAAA8BaBHI1aRESE12evHQ4HZ7wBoIHhFiQAQGNEIAcAAA0etyABABojAjkAAGjwuAUJANAYEcgBAECDxy1IAIDGiOeQAwAAAABggNFAHh8fL5vNVuU1ZcoUSdLx48c1ZcoUtWnTRi1bttSIESN06NAhkyUDAAAAAOATRgP51q1bdfDgQdfrnXfekST97ne/kyTdeuutev311/XSSy/pgw8+0IEDBzR8+HCTJQMAAAAA4BNG7yFv166d2/uHHnpI3bp104ABA1RYWKilS5dq1apVuvjiiyVJy5Ytk8Ph0JYtW9SvXz8TJQMAAAAA4BMN5h7ysrIyrVy5UmPHjpXNZlN2drZOnDihwYMHu9ax2+3q1KmTNm/eXGM/paWlKioqcnsBAAAAANDQNJhAvnbtWhUUFGj06NGSpPz8fIWEhKhVq1Zu68XExCg/P7/GfubNm6fo6GjXKy4uzo9VAwAAAABQOw0mkC9dulSXXXaZOnbsWKd+Zs6cqcLCQtdr//79PqoQAAAAAADfaRDPId+7d6/effddZWZmutpiY2NVVlamgoICt7Pkhw4dUmxsbI19hYaGKjQ01J/lAgAAAABQZw0ikC9btkzt27fX0KFDXW1JSUlq3ry5NmzYoBEjRkiSdu3apX379ik5OdlUqQDQ4BQXFysnJ8ejdUtKSpSXl6f4+HiFh4d7vA+73a6IiIjalggAAIBqGA/kFRUVWrZsmUaNGqVmzf5XTnR0tMaNG6cZM2aodevWioqK0s0336zk5GRmWAeAn8nJyVFSUpJf95Gdna3ExES/7gMAAKCpMR7I3333Xe3bt09jx46tsuyxxx5TUFCQRowYodLSUqWlpWnhwoUGqgSAhstutys7O9ujdZ1OpzIyMrRy5Uo5HA6v9gH4Wm5uro4cOeLzfp1Op9tPf4iMjFT37t391j8AoGmwWZZlmS7Cn4qKihQdHa3CwkJFRUWZLgcN2LZt25SUlMSZQDRqfM7RUOTm5qpHjx6my6iT3bt3E8oBANXyNIcaP0PelHCfJwAAJ1WeGff2ag1P1PZ3qKcqrzTxx9l9AEDTQiCvR9znCQCAO4fD4ZffWykpKT7vEwAAXyOQ1yPu8wQAAAAAVCKQ16OIiAivzwL468wBAAAAAMCsINMFAAAAAADQFBHIAQAAAAAwgEAOAAAAAIAB3EMOAACMiG1pU3jBbulAYJ0fCC/YrdiWNtNlAAAaAQI5AAAwYmJSiBwfTpQ+NF2Jdxw6WTsAAHVFIAcAAEYszi7T1fcvlyPAHtnpzMnR4vnX6SrThQAAAh6BvI5yc3N15MgRn/frdDrdfvpDZGSkunfv7rf+/YUxB4DGIf+opZJWPaSO55guxSsl+RXKP2qZLgMA0AgQyOsgNzdXPXr08Os+MjIy/Nr/7t27AyogMuYAAAAAGgsCeR1UnqVduXKlHA6HT/suKSlRXl6e4uPjFR4e7tO+pZNngTMyMvxyptmfGHMAAAAAjQWB3AccDocSExN93m9KSorP+2wsGHMAAAAAgS6wnjMCAAAAAEAjQSAHAAAAAMAALlkHgAaIpwmgsSsuLpYkbdu2zed918ecIAAA+AKBHAAaGJ4mgKYgJydHkjRhwgTDldReZGSk6RIAAAGOQA4ADQxPE0BTkJ6eLkmy2+2KiIjwad+Vn0N//D9UiStBAAC+QCAHgAaKpwmgMWvbtq3Gjx/v13346/8hAAB8hUndAAAAAAAwgEAOAAAAAIABBHIAAAAAAAwgkAMAAAAAYACBHAAAAAAAA5hlvY5iW9oUXrBbOhBY322EF+xWbEub6TIA1IC/WwAAABo/AnkdTUwKkePDidKHpivxjkMnawfQMPF3CwAAQONHIK+jxdlluvr+5XLY7aZL8YozJ0eL51+nq0wXAqBa/N0CAADQ+BHI6yj/qKWSVj2kjueYLsUrJfkVyj9qmS4DQA34uwUAAKDxI5Aj4HBvLQAAAIDGgECOgMO9tQAAAAAaAwI5Ag731gIAAABoDAjkdVBcXCxJ2rZtm8/7LikpUV5enuLj4xUeHu7z/p1Op8/7rC/cWwsAAACgMSCQ10FOTo4kacKECYYrqb3IyEjTJXiFL0EAAAAANBYE8jpIT0+XJNntdkVERPi0b6fTqYyMDK1cuVIOh8OnfVeKjIxU9+7d/dK3v/AlCAAAAIDGgkBeB23bttX48eP9ug+Hw6HExES/7iOQ8CUIAAAAgMaCQI6AwpcgANA0FRcXu66SOpXKW4S8vVXIH1/2AgDwawjkAACgwcvJyVFSUpJX22RkZHi1fnZ2Nl/IAgDqFYEcAAA0eHa7XdnZ2R6tW9tJOu0B9jhNAEDgI5ADAIAGLyIiwquz1ykpKX6sBgAA3wgyXQAAAAAAAE0RZ8jRqDEJEAJRcXGxJGnbtm0+77u2l/J6ytv/fwAAAJoyAjkaNSYBQiCq/BJpwoQJhiupvcjISNMlAAAANHgEcjRqTAKEQJSeni7JP1dfOJ1OZWRkaOXKlXI4HD7tu1JkZKS6d+/ul74BAAAaEwJ5PeLy6frHJEAIRG3bttX48eP9ug+Hw8GVHQAAAIYRyOsRl08DAAAAACoRyOsRl08DAAAAACoZD+Tfffed7rrrLr311lsqLi5WQkKCli1bpvPOO0+SZFmWZs2apSVLlqigoEApKSlatGhRQN6fyOXTAAAAAIBKRgP5f//7X6WkpGjQoEF666231K5dO+Xm5uq0005zrfPwww/riSee0IoVK9SlSxfdd999SktL086dOxUWFmawegAAAACAN7yZV6suVw0HyrxaRgP5X/7yF8XFxWnZsmWuti5durj+27IsLViwQPfee6+GDRsmSXruuecUExOjtWvX6pprrqn3mgEAAAAAtVObebW8FUjzahkN5K+99prS0tL0u9/9Th988IFOP/103XTTTa5n7+7Zs0f5+fkaPHiwa5vo6Gj17dtXmzdvrjaQl5aWqrS01PW+qKjI/wcCAAAAADglb+bVqu3jWgNpXi2jgfzbb7/VokWLNGPGDN1zzz3aunWrpk2bppCQEI0aNUr5+fmSpJiYGLftYmJiXMt+ad68eZo9e7bfawcAAAAAeMfbebWkxv241iCTO6+oqFBiYqLmzp2rc889VzfeeKMmTJigp59+utZ9zpw5U4WFha7X/v37fVgxAAAAAAC+YTSQd+jQQT179nRrczgc2rdvnyQpNjZWknTo0CG3dQ4dOuRa9kuhoaGKiopyewEAAAAA0NAYDeQpKSnatWuXW9vu3bvVuXNnSScneIuNjdWGDRtcy4uKivTJJ58oOTm5XmsFAAAAAMCXjN5Dfuutt6p///6aO3eufv/73+vTTz/VM888o2eeeUaSZLPZNH36dD344IPq3r2767FnHTt2VHp6usnSAQAAAACoE6OB/Pzzz9crr7yimTNnas6cOerSpYsWLFig66+/3rXOnXfeqWPHjunGG29UQUGBLrzwQq1bt45nkAMAAAAAAprRQC5JV1xxha644ooal9tsNs2ZM0dz5sypx6oAAAAAAPAvo/eQAwAAAADQVBHIAQAAAAAwgEAOAAAAAIABBHIAAAAAAAwgkAMAAAAAYIDxWdYBAAAAAIErNzdXR44c8Xm/TqfT7ac/REZGqnv37n7r/1QI5AAQ4IqLi5WTk+PRurX9xWa32xUREeF1bQAAoHHLzc1Vjx49/LqPjIwMv/a/e/duY6GcQA4AAS4nJ0dJSUlebePtL7bs7GwlJiZ6tQ0AAGj8Ks+Mr1y5Ug6Hw6d9l5SUKC8vT/Hx8QoPD/dp39LJExQZGRl+ObvvKQI5AAQ4u92u7Oxsj9at7S82u91e2/IAAEAT4HA4/PLlfUpKis/7bEgI5AAQ4CIiIrz6BdjYf7EBAAAECmZZBwAAAADAAAI5AAAAAAAGEMgBAAAAADCAQA4AAAAAgAEEcgAAAAAADCCQAwAAAABgAIEcAAAAAAADeA45AAAAAKDWYlvaFF6wWzoQWOd7wwt2K7alzWgNBHIAAAAAQK1NTAqR48OJ0oemK/GOQydrN4lADgAAAACotcXZZbr6/uVy2O2mS/GKMydHi+dfp6sM1kAgBwAAAADUWv5RSyWtekgdzzFdildK8iuUf9QyWkNgXeQPAAAAAEAjQSAHAAAAAMAAAjkAAAAAAAYQyAEAAAAAMIBADgAAAACAAQRyAAAAAAAMIJADAAAAAGAAzyEHAAAAANRKcXGxJGnbtm0+77ukpER5eXmKj49XeHi4z/t3Op0+79NbBHIAAAAAQK3k5ORIkiZMmGC4ktqLjIw0tm8COQAAAACgVtLT0yVJdrtdERERPu3b6XQqIyNDK1eulMPh8GnflSIjI9W9e3e/9O0JAjkAAAAAoFbatm2r8ePH+3UfDodDiYmJft2HKUzqBgAAAACAAQRyAAAAAAAMIJADAAAAAGAAgRwAAAAAAAMI5AAAAAAAGEAgBwAAAADAAAI5AAAAAAAGEMgBAAAAADCAQA4AAAAAgAEEcgAAAAAADCCQAwAAAABgAIEcAAAAAAADCOQAAAAAABjQzHQBAAAAAICmobi4WDk5OR6t63Q63X56ym63KyIiwuvaTCCQAwAAAADqRU5OjpKSkrzaJiMjw6v1s7OzlZiY6NU2phDIAQAAAAD1wm63Kzs726N1S0pKlJeXp/j4eIWHh3u1j0BhsyzLMrXzBx54QLNnz3ZrO/PMM12XMBw/fly33XabVq9erdLSUqWlpWnhwoWKiYnxeB9FRUWKjo5WYWGhoqKifFo/AAAAAAC/5GkONT6p21lnnaWDBw+6Xps2bXItu/XWW/X666/rpZde0gcffKADBw5o+PDhBqsFAAAAAMA3jF+y3qxZM8XGxlZpLyws1NKlS7Vq1SpdfPHFkqRly5bJ4XBoy5Yt6tevX32XCgAAAACAzxg/Q56bm6uOHTuqa9euuv7667Vv3z5JJ2/EP3HihAYPHuxa1263q1OnTtq8eXON/ZWWlqqoqMjtBQAAAABAQ2M0kPft21fLly/XunXrtGjRIu3Zs0epqak6cuSI8vPzFRISolatWrltExMTo/z8/Br7nDdvnqKjo12vuLg4Px8FAAAAAADeM3rJ+mWXXeb67z59+qhv377q3Lmz/vnPf3o1i97PzZw5UzNmzHC9LyoqIpQDAAAAABoc45es/1yrVq3Uo0cPff3114qNjVVZWZkKCgrc1jl06FC195xXCg0NVVRUlNsLAAAAAICGpkEF8qNHj+qbb75Rhw4dlJSUpObNm2vDhg2u5bt27dK+ffuUnJxssEoAAAAAAOrO6CXrt99+u6688kp17txZBw4c0KxZsxQcHKxrr71W0dHRGjdunGbMmKHWrVsrKipKN998s5KTk5lhHQAAAAAQ8IwG8v/7v//Ttddeq//85z9q166dLrzwQm3ZskXt2rWTJD322GMKCgrSiBEjVFpaqrS0NC1cuNBkyQAAAIBfFBcXKycnx6N1S0pKlJeXp/j4eK/mXrLb7YqIiKhtiQB8zGZZlmW6CH8qKipSdHS0CgsLuZ8cAAAADda2bduUlJTk131kZ2crMTHRr/sA4HkONXqGHAAAAMBJdrtd2dnZHq3rdDqVkZGhlStXyuFweLUPAA0HgRwAAABoACIiIrw+e+1wODjjDQSwBjXLOgAAAAAATQWBHAAAAAAAAwjkAAAAAAAYwD3kAAAAAJokHjUH0wjkAAAAAJqknJwcHjUHowjkAAAAAJokHjUH0wjkAAAAAJokHjUH05jUDQAAAAAAAwjkAAAAAAAYQCAHAAAAAMAAAjkAAAAAAAYQyAEAAAAAMIBADgAAAACAAQRyAAAAAAAMIJADAAAAAGBAM9MFAAAQaIqLi5WTk+PRuiUlJcrLy1N8fLzCw8M93ofdbldERERtSwQAAAGAQA4AgJdycnKUlJTk131kZ2crMTHRr/sAAABmEcgBAPCS3W5Xdna2R+s6nU5lZGRo5cqVcjgcXu0DAAA0bgRyAAC8FBER4fXZa4fDwRlvAADghkndAAAAAAAwgEAOAAAAAIABBHIAAAAAAAzgHnIAAAAAjUZubq6OHDni836dTqfbT3+IjIxU9+7d/dY/Gh4COQAA4h9wANAY5ObmqkePHn7dR0ZGhl/73717N3+nNyEEcgBAk8c/4AD4C1/21a/Ksfb2UZOeKCkpUV5enuLj4xUeHu7TvqX/PSbTH58XNFwEcgBAk8c/4AD4A1/2meOvR02mpKT4vE80bQRyAAD+P/4BB8CX+LIPwKkQyAEAAAA/4ss+ADXhsWcAAAAAABhAIAcAAAAAwAAuWQcAQFJsS5vCC3ZLBwLru+rwgt2KbWkzXQYAAKgFAjkAAJImJoXI8eFE6UPTlXjHoZO1AwCAwEMgBwBA0uLsMl19/3I57HbTpXjFmZOjxfOv01WmCwEAAF4jkAMAICn/qKWSVj2kjueYLsUrJfkVyj9qmS4DAADUQmDdKAcAAAAAQCPBGXIAAADAT5gwEsCvIZADAAAAfsKEkQB+DYEcAAAA8BMmjATwawjkAAAAgJ8wYSSAXxNYN7MAAAAAANBIEMgBAAAAADCAQA4AAAAAgAEEcgAAAAAADCCQAwAAAABgAIEcAAAAAAADGsxjzx566CHNnDlTt9xyixYsWCBJOn78uG677TatXr1apaWlSktL08KFCxUTE2O2WAAAAOAUiouLJUnbtm3zed8lJSXKy8tTfHy8wsPDfd6/0+n0eZ8AqmoQgXzr1q1avHix+vTp49Z+66236l//+pdeeuklRUdHa+rUqRo+fLg++ugjQ5UCAAAAnsnJyZEkTZgwwXAltRcZGWm6BKBRMx7Ijx49quuvv15LlizRgw8+6GovLCzU0qVLtWrVKl188cWSpGXLlsnhcGjLli3q16+fqZIBAACAU0pPT5ck2e12RURE+LRvp9OpjIwMrVy5Ug6Hw6d9V4qMjFT37t390jeAk4wH8ilTpmjo0KEaPHiwWyDPzs7WiRMnNHjwYFeb3W5Xp06dtHnz5hoDeWlpqUpLS13vi4qK/Fc8AAAAUIO2bdtq/Pjxft2Hw+FQYmKiX/cBwH+MBvLVq1dr27Zt2rp1a5Vl+fn5CgkJUatWrdzaY2JilJ+fX2Of8+bN0+zZs31dKgAAAIAAENvSpvCC3dKBwJq/Orxgt2Jb2kyXgXpmLJDv379ft9xyi9555x2FhYX5rN+ZM2dqxowZrvdFRUWKi4vzWf8AAAAAGq6JSSFyfDhR+tB0Jd5x6GTtaFqMBfLs7Gx9//33bpfYlJeX68MPP9STTz6p9evXq6ysTAUFBW5nyQ8dOqTY2Nga+w0NDVVoaKg/SwcANDLMhAwAjcfi7DJdff9yOex206V4xZmTo8Xzr9NVpgtBvTIWyH/zm9/oyy+/dGsbM2aM7Ha77rrrLsXFxal58+basGGDRowYIUnatWuX9u3bp+TkZBMlAwAaKWZCBoDGI/+opZJWPaSO55guxSsl+RXKP2qZLgP1zFggj4yMVK9evdzaWrRooTZt2rjax40bpxkzZqh169aKiorSzTffrOTkZGZYBwD4FDMhAwAAE4zPsv5rHnvsMQUFBWnEiBEqLS1VWlqaFi5caLosAEAjw0zIAADAhAYVyDdu3Oj2PiwsTE899ZSeeuopMwUBAAAAAOAngfUsAAAAAAAAGgkCOQAAAAAABhDIAQAAAAAwgEAOAAAAAIABDWpSNwAAAKCpKi4uVk5OjkfrOp1Ot5+e8sfjHQHUHoEcAAAAaABycnKUlJTk1TYZGRlerZ+dnc0jGIEGhEAOAAAANAB2u13Z2dkerVtSUqK8vDzFx8crPDzcq30AaDgI5AAAAEADEBER4dXZ65SUFD9WA6A+MKkbAAAAAAAGEMgBAAAAADCAQA4AAAAAgAEEcgAAAAAADCCQAwAAAABggE8D+f79+zV27FhfdgkAAAAAQKPk00B++PBhrVixwpddAgAAAADQKHn1HPLXXnvtV5d/++23dSoGAAAAAGqruLhYkrRt2zaf911SUqK8vDzFx8crPDzc5/07nU6f94mGz6tAnp6eLpvNJsuyalzHZrPVuSgAAAAA8FZOTo4kacKECYYrqb3IyEjTJaAeeRXIO3TooIULF2rYsGHVLt++fbuSkpJ8UhgAAACAqsrLy5WVlaWDBw+qQ4cOSk1NVXBwsOmyGoT09HRJkt1uV0REhE/7djqdysjI0MqVK+VwOHzad6XIyEh1797dL32jYfIqkCclJSk7O7vGQH6qs+cAAAAAai8zM1O33Xab8vLyXG3x8fGaP3++hg8fbq6wBqJt27YaP368X/fhcDiUmJjo132g6fBqUrc77rhD/fv3r3F5QkKC3n///ToXBQAAAMBdZmamRo4cqd69e2vz5s06cuSINm/erN69e2vkyJHKzMw0XSIAL3l1hvz0009Xly5dalzeokULDRgwoM5FAQAAAPif8vJy3Xbbbbriiiu0du1aBQWdPK/Wr18/rV27Vunp6br99ts1bNgwLl8HAohXZ8i7d++uH374wfX+6quv1qFDh3xeFAAAAID/ycrKUl5enu655x5XGK8UFBSkmTNnas+ePcrKyjJUIYDa8OoM+S/vD3/zzTc1b948nxYEAEBDV1xc7JrJ91QqH2Pj7eNs/DEhEYDAdfDgQUlSr169ql1e2V65HoDA4FUgBwAAJx+r4+1TRTIyMrxaPzs7m0mDALh06NBBkrRjxw7169evyvIdO3a4rQcgMHgVyG02W5XnjPPccQBAU2O325Wdne3RuiUlJcrLy1N8fLzCw8O92gcAVEpNTVV8fLzmzp3rdg+5JFVUVGjevHnq0qWLUlNTDVYJwFteX7I+evRohYaGSpKOHz+uSZMmqUWLFm7rMcMjAKAxi4iI8OrsdUpKih+rAdAUBAcHa/78+Ro5cqTS09M1c+ZM9erVSzt27NC8efP0xhtvaM2aNUzoBgQYrwL5qFGj3N57e/kdAAAAgNoZPny41qxZo9tuu83tUcRdunTRmjVreA45EIC8CuTLli3zVx0AAAAATmH48OEaNmyYsrKydPDgQXXo0EGpqamcGQcCFJO6AQAAAAEkODhYAwcONF0GAB/w6jnkAAAAAADANwjkAAAAAAAYQCAHAAAAAMAAAjkAAAAAAAYQyAEAAAAAMIBADgAAAACAATz2DAAAAECTVFxcrJycHI/WdTqdbj89ZbfbFRER4XVtaBoI5AAAAACapJycHCUlJXm1TUZGhlfrZ2dnKzEx0att0HQQyAEAAAA0SXa7XdnZ2R6tW1JSory8PMXHxys8PNyrfQA1sVmWZZkuwp+KiooUHR2twsJCRUVFmS4HAAAAANDIeZpDmdQNAAAAAAADCOQAAAAAABhAIAcAAAAAwAACOQAAAAAABhDIAQAAAAAwgEAOAAAAAIABBHIAAAAAAAwgkAMAAAAAYACBHAAAAAAAA4wG8kWLFqlPnz6KiopSVFSUkpOT9dZbb7mWHz9+XFOmTFGbNm3UsmVLjRgxQocOHTJYMQAAAAAAvmE0kJ9xxhl66KGHlJ2drc8++0wXX3yxhg0bpq+++kqSdOutt+r111/XSy+9pA8++EAHDhzQ8OHDTZYMAAAAAIBP2CzLskwX8XOtW7fWI488opEjR6pdu3ZatWqVRo4cKUnKycmRw+HQ5s2b1a9fP4/6KyoqUnR0tAoLCxUVFeXP0gEAAAAA8DiHNph7yMvLy7V69WodO3ZMycnJys7O1okTJzR48GDXOna7XZ06ddLmzZtr7Ke0tFRFRUVuLwAAAAAAGhrjgfzLL79Uy5YtFRoaqkmTJumVV15Rz549lZ+fr5CQELVq1cpt/ZiYGOXn59fY37x58xQdHe16xcXF+fkIAAAAAADwnvFAfuaZZ2r79u365JNPNHnyZI0aNUo7d+6sdX8zZ85UYWGh67V//34fVgsAAAAAgG80M11ASEiIEhISJElJSUnaunWrHn/8cV199dUqKytTQUGB21nyQ4cOKTY2tsb+QkNDFRoa6u+yAQAAAACoE+NnyH+poqJCpaWlSkpKUvPmzbVhwwbXsl27dmnfvn1KTk42WCEAAAAAAHVn9Az5zJkzddlll6lTp046cuSIVq1apY0bN2r9+vWKjo7WuHHjNGPGDLVu3VpRUVG6+eablZyc7PEM6wAAAAAANFRGA/n333+vP/zhDzp48KCio6PVp08frV+/Xpdccokk6bHHHlNQUJBGjBih0tJSpaWlaeHChSZLBgAAAADAJxrcc8h9jeeQAwAAAADqU8A9hxwAAAAAgKaEQA4AAAAAgAEEcgAAAAAADCCQAwAAAABgAIEcAAAAAAADCOQAAAAAABhAIAcAAAAAwAACOQAAAAAABhDIAQAAAAAwoJnpAgAAANDwFBcXKycnx6N1S0pKlJeXp/j4eIWHh3u8D7vdroiIiNqWCAABj0AOAACAKnJycpSUlOTXfWRnZysxMdGv+wCAhoxADgAAgCrsdruys7M9WtfpdCojI0MrV66Uw+Hwah8A0JQRyAEAAFBFRESE12evHQ4HZ7wBwAtM6gYAAAAAgAEEcgAAAAAADCCQAwAAAABgAIEcAAAAAAADCOQAAAAAABhAIAcAAAAAwAACOQAAAAAABhDIAQAAAAAwgEAOAAAAAIABBHIAAAAAAAwgkAMAAAAAYACBHAAAAAAAAwjkAAAAAAAYQCAHAAAAAMAAAjkAAAAAAAYQyAEAAAAAMIBADgAAAACAAQRyAAAAAAAMIJADAAAAAGAAgRwAAAAAAAMI5AAAAAAAGEAgBwAAAADAAAI5AAAAAAAGEMgBAAAAADCAQA4AAAAAgAEEcgAAAAAADCCQAwAAAABgAIEcAAAAAAADCOQAAAAAABhAIAcAAAAAwAACOQAAAAAABhDIAQAAAAAwgEAOAAAAAIABBHIAAAAAAAwwGsjnzZun888/X5GRkWrfvr3S09O1a9cut3WOHz+uKVOmqE2bNmrZsqVGjBihQ4cOGaoYAAAAAADfMBrIP/jgA02ZMkVbtmzRO++8oxMnTujSSy/VsWPHXOvceuutev311/XSSy/pgw8+0IEDBzR8+HCDVQMAAAAAUHfNTO583bp1bu+XL1+u9u3bKzs7WxdddJEKCwu1dOlSrVq1ShdffLEkadmyZXI4HNqyZYv69etnomwAAAAAAOqsQd1DXlhYKElq3bq1JCk7O1snTpzQ4MGDXevY7XZ16tRJmzdvrraP0tJSFRUVub0AAAAAAGhoGkwgr6io0PTp05WSkqJevXpJkvLz8xUSEqJWrVq5rRsTE6P8/Pxq+5k3b56io6Ndr7i4OH+XDgAAAACA1xpMIJ8yZYp27Nih1atX16mfmTNnqrCw0PXav3+/jyoEAAAAAMB3jN5DXmnq1Kl644039OGHH+qMM85wtcfGxqqsrEwFBQVuZ8kPHTqk2NjYavsKDQ1VaGiov0sGAAAAAKBOjJ4htyxLU6dO1SuvvKL33ntPXbp0cVuelJSk5s2ba8OGDa62Xbt2ad++fUpOTq7vcgEAAAAA8BmjZ8inTJmiVatW6dVXX1VkZKTrvvDo6GiFh4crOjpa48aN04wZM9S6dWtFRUXp5ptvVnJyMjOsAwAAAAACmtFAvmjRIknSwIED3dqXLVum0aNHS5Iee+wxBQUFacSIESotLVVaWpoWLlxYz5UCAAAAAOBbRgO5ZVmnXCcsLExPPfWUnnrqqXqoCAAAAACA+tFgZlkHAAAAAKApaRCzrAMAAMD/cnNzdeTIEZ/363Q63X76Q2RkpLp37+63/gHABAI5AABAE5Cbm6sePXr4dR8ZGRl+7X/37t2EcgCNCoEcAACgCag8M75y5Uo5HA6f9l1SUqK8vDzFx8crPDzcp31LJ8+8Z2Rk+OXsPgCYRCAHAABoQhwOhxITE33eb0pKis/7BIDGjkndAAAAAAAwgEAOAAAAAIABBHIAAAAAAAwgkAMAAAAAYACBHAAAAAAAAwjkAAAAAAAYQCAHAAAAAMAAAjkAAAAAAAYQyAEAAAAAMIBADgAAAACAAc1MFwAAAAAADVl5ebmysrJ08OBBdejQQampqQoODjZdFhoBzpADAAAAQA0yMzOVkJCgQYMG6brrrtOgQYOUkJCgzMxM06WhESCQAwAAAEA1MjMzNXLkSPXu3VubN2/WkSNHtHnzZvXu3VsjR44klKPOCOQAAAAA8Avl5eW67bbbdMUVV2jt2rXq16+fWrZsqX79+mnt2rW64oordPvtt6u8vNx0qQhgBHIAAAAA+IWsrCzl5eXpnnvuUVCQe2wKCgrSzJkztWfPHmVlZRmqEI0BgRwAAAAAfuHgwYOSpF69elW7vLK9cj2gNgjkAAAAAPALHTp0kCTt2LGj2uWV7ZXrAbVBIAcAAACAX0hNTVV8fLzmzp2riooKt2UVFRWaN2+eunTpotTUVEMVojEgkAMAAADALwQHB2v+/Pl64403lJ6e7jbLenp6ut544w09+uijPI8cddLMdAEAAAAA0BANHz5ca9as0W233ab+/fu72rt06aI1a9Zo+PDhBqtDY0AgBwAAAIAaDB8+XMOGDVNWVpYOHjyoDh06KDU1lTPj8AkCOQAAAAD8iuDgYA0cONB0GWiEuIccAAAAAAADCOQAAAAAABhAIAcAAAAAwAACOQAAAAAABhDIAQAAAAAwgEAOAAAAAIABBHIAAAAAAAwgkAMAAAAAYACBHAAAAAAAAwjkAAAAAAAYQCAHAAAAAMAAAjkAAAAAAAY0M10AAAAA6kdsS5vCC3ZLBwLrnEx4wW7FtrSZLgMAfI5ADgAA0ERMTAqR48OJ0oemK/GOQydrB4DGhkAOAADQRCzOLtPV9y+Xw243XYpXnDk5Wjz/Ol1luhAA8DECOQAAQBORf9RSSaseUsdzTJfilZL8CuUftUyXAQA+F1g3EAEAAAAA0EgQyAEAAAAAMIBL1gEAAJqA4uJiSdK2bdt83ndJSYny8vIUHx+v8PBwn/fvdDp93icANAQEcgAAgCYgJydHkjRhwgTDldReZGSk6RIAwKeMBvIPP/xQjzzyiLKzs3Xw4EG98sorSk9Pdy23LEuzZs3SkiVLVFBQoJSUFC1atEjdu3c3VzQAAEAAqvw3lt1uV0REhE/7djqdysjI0MqVK+VwOHzad6XIyEj+DQig0TEayI8dO6azzz5bY8eO1fDhw6ssf/jhh/XEE09oxYoV6tKli+677z6lpaVp586dCgsLM1AxAABAYGrbtq3Gjx/v1304HA4lJib6dR8A0JgYDeSXXXaZLrvssmqXWZalBQsW6N5779WwYcMkSc8995xiYmK0du1aXXPNNfVZKgAAAAAAPtVgZ1nfs2eP8vPzNXjwYFdbdHS0+vbtq82bN9e4XWlpqYqKitxeAAAAAAA0NA02kOfn50uSYmJi3NpjYmJcy6ozb948RUdHu15xcXF+rRMAAAAAgNposIG8tmbOnKnCwkLXa//+/aZLAgAAAACgigYbyGNjYyVJhw4dcms/dOiQa1l1QkNDFRUV5fYCAAAAAKChabCBvEuXLoqNjdWGDRtcbUVFRfrkk0+UnJxssDIAAAAAAOrO6CzrR48e1ddff+16v2fPHm3fvl2tW7dWp06dNH36dD344IPq3r2767FnHTt2dHtWOQAAAAAAgchoIP/ss880aNAg1/sZM2ZIkkaNGqXly5frzjvv1LFjx3TjjTeqoKBAF154odatW8czyAEAAAAAAc9oIB84cKAsy6pxuc1m05w5czRnzpx6rAoAAAAAAP9rsPeQAwAAAADQmBHIAQAAAAAwgEAOAAAAAIABBHIAAAAAAAwwOqkbAAAAGqbi4mLl5OR4tK7T6XT76Sm73a6IiAivawOAxoJADgAAgCpycnKUlJTk1TYZGRlerZ+dna3ExESvtgGAxoRADgAAgCrsdruys7M9WrekpER5eXmKj49XeHi4V/sAgKbMZv3ag8AbgaKiIkVHR6uwsFBRUVGmywEAAAAANHKe5lAmdQMAAAAAwAACOQAAAAAABhDIAQAAAAAwgEAOAAAAAIABBHIAAAAAAAwgkAMAAAAAYACBHAAAAAAAAwjkAAAAAAAYQCAHAAAAAMAAAjkAAAAAAAYQyAEAAAAAMIBADgAAAACAAQRyAAAAAAAMIJADAAAAAGAAgRwAAAAAAAMI5AAAAAAAGEAgBwAAAADAAAI5AAAAAAAGEMgBAAAAADCAQA4AAAAAgAHNTBcAoGkqLy9XVlaWDh48qA4dOig1NVXBwcGmywIAAADqDWfIAdS7zMxMJSQkaNCgQbruuus0aNAgJSQkKDMz03RpAAAAQL0hkAOoV5mZmRo5cqR69+6tzZs368iRI9q8ebN69+6tkSNHEsoBAADQZNgsy7JMF+FPRUVFio6OVmFhoaKiokyXAzRp5eXlSkhIUO/evbV27VoFBf3vO8GKigqlp6drx44dys3N5fJ1AAAABCxPcyhnyAHUm6ysLOXl5emee+5xC+OSFBQUpJkzZ2rPnj3KysoyVCEAAABQfwjkAOrNwYMHJUm9evWqdnlle+V6AAAAQGNGIAdQbzp06CBJ2rFjR7XLK9sr1wMAAAAaMwI5gHqTmpqq+Ph4zZ07VxUVFW7LKioqNG/ePHXp0kWpqamGKgQAAADqD4EcQL0JDg7W/Pnz9cYbbyg9Pd1tlvX09HS98cYbevTRR5nQDQAAAE1CM9MFAGhahg8frjVr1ui2225T//79Xe1dunTRmjVrNHz4cIPVAQAAAPWHx54BMKK8vFxZWVk6ePCgOnTooNTUVM6MAwAAoFHwNIdyhhyAEcHBwRo4cKDpMgAAAABjuIccAAAAAAADCOQAAAAAABjAJesAjOAecgAAADR1nCEHUO8yMzOVkJCgQYMG6brrrtOgQYOUkJCgzMxM06UBAAAA9YZADqBeZWZmauTIkerdu7fbc8h79+6tkSNHEsoBAADQZPDYMwD1pry8XAkJCerdu7fWrl2roKD/fSdYUVGh9PR07dixQ7m5uVy+DgAAgIDlaQ7lDDmAepOVlaW8vDzdc889bmFckoKCgjRz5kzt2bNHWVlZhioEAAAA6g+BHEC9OXjwoCSpV69e1S6vbK9cDwAAAGjMAiKQP/XUU4qPj1dYWJj69u2rTz/91HRJAGqhQ4cOkqQdO3ZUu7yyvXI9AAAAoDFr8IH8xRdf1IwZMzRr1ixt27ZNZ599ttLS0vT999+bLg2Al1JTUxUfH6+5c+eqoqLCbVlFRYXmzZunLl26KDU11VCFAAAAQP1p8IH8r3/9qyZMmKAxY8aoZ8+eevrppxUREaFnn33WdGkAvBQcHKz58+frjTfeUHp6utss6+np6XrjjTf06KOPMqEbAAAAmoQGPct6WVmZIiIitGbNGqWnp7vaR40apYKCAr366qtVtiktLVVpaanrfVFRkeLi4phlHailH3/8Uetffk4R5UUerV9cfEzffPPtr65z4MAB7dixQ8XFxa62Fi1a6KyzzlLHjh1PuY9u3boqIqKFR/W07XKWUi/7nUfrAgAAAL7g6SzrzeqxJq/9+OOPKi8vV0xMjFt7TEyMcnJyqt1m3rx5mj17dn2UBzQJa9eu1f/94x49MDDU841iPFh+bpCklr9YsPP/v07h6P9/eeCBf5aqXZfestvtnm0AAAAA1JMGHchrY+bMmZoxY4brfeUZcgC1k56ervXlRXrFh2fI68qbM+S/uesswjgAAAAapAYdyNu2bavg4GAdOnTIrf3QoUOKjY2tdpvQ0FCFhnpxJg/Ar2rbtq2unzjj1CsCAAAA8EqDntQtJCRESUlJ2rBhg6utoqJCGzZsUHJyssHKAAAAAAComwZ9hlySZsyYoVGjRum8887TBRdcoAULFujYsWMaM2aM6dIAAAAAAKi1Bh/Ir776av3www+6//77lZ+fr3POOUfr1q2rMtEbAAAAAACBpEE/9swXPJ1uHgAAAAAAX/A0hzboe8gBAAAAAGisCOQAAAAAABhAIAcAAAAAwAACOQAAAAAABhDIAQAAAAAwgEAOAAAAAIABBHIAAAAAAAwgkAMAAAAAYACBHAAAAAAAAwjkAAAAAAAYQCAHAAAAAMAAAjkAAAAAAAYQyAEAAAAAMKCZ6QL8zbIsSVJRUZHhSgAAAAAATUFl/qzMozVp9IH8yJEjkqS4uDjDlQAAAAAAmpIjR44oOjq6xuU261SRPcBVVFTowIEDioyMlM1mM12Ox4qKihQXF6f9+/crKirKdDlNAmNe/xjz+seY1z/GvP4x5vWPMa9/jHn9Y8zrXyCPuWVZOnLkiDp27KigoJrvFG/0Z8iDgoJ0xhlnmC6j1qKiogLuwxfoGPP6x5jXP8a8/jHm9Y8xr3+Mef1jzOsfY17/AnXMf+3MeCUmdQMAAAAAwAACOQAAAAAABhDIG6jQ0FDNmjVLoaGhpktpMhjz+seY1z/GvP4x5vWPMa9/jHn9Y8zrH2Ne/5rCmDf6Sd0AAAAAAGiIOEMOAAAAAIABBHIAAAAAAAwgkAMAAAAAYACBvIHauHGjbDabCgoKPN4mPj5eCxYs8FtNjR1jXv8Y8/rHmNc/xrz+Meb1jzGvf4x5/WPM/a8pjjGBvBZGjx4tm82mSZMmVVk2ZcoU2Ww2jR49uv4LO4WvvvpKI0aMUHx8vGw2W0B9cAN1zJcsWaLU1FSddtppOu200zR48GB9+umnpsvySKCOeWZmps477zy1atVKLVq00DnnnKPnn3/edFkeCdQx/7nVq1fLZrMpPT3ddCkeCdQxX758uWw2m9srLCzMdFkeCdQxl6SCggJNmTJFHTp0UGhoqHr06KE333zTdFmnFKhjPnDgwCqfc5vNpqFDh5ou7ZQCdcwlacGCBTrzzDMVHh6uuLg43XrrrTp+/Ljpsk4pUMf8xIkTmjNnjrp166awsDCdffbZWrdunemyqhWoY+xpBnrqqacUHx+vsLAw9e3bt97+zU4gr6W4uDitXr1aJSUlrrbjx49r1apV6tSpk8HKalZcXKyuXbvqoYceUmxsrOlyvBaIY75x40Zde+21ev/997V582bFxcXp0ksv1XfffWe6NI8E4pi3bt1af/zjH7V582Z98cUXGjNmjMaMGaP169ebLs0jgTjmlfLy8nT77bcrNTXVdCleCdQxj4qK0sGDB12vvXv3mi7JY4E45mVlZbrkkkuUl5enNWvWaNeuXVqyZIlOP/1006V5JBDHPDMz0+0zvmPHDgUHB+t3v/ud6dI8EohjvmrVKt19992aNWuWnE6nli5dqhdffFH33HOP6dI8Eohjfu+992rx4sX629/+pp07d2rSpEn67W9/q3//+9+mS6tWII6xJxnoxRdf1IwZMzRr1ixt27ZNZ599ttLS0vT999/7vT4CeS0lJiYqLi5OmZmZrrbMzEx16tRJ5557rtu6paWlmjZtmtq3b6+wsDBdeOGF2rp1q9s6b775pnr06KHw8HANGjRIeXl5Vfa5adMmpaamur6xnDZtmo4dO+Zxzeeff74eeeQRXXPNNQH5LL9AHPMXXnhBN910k8455xzZ7Xb9/e9/V0VFhTZs2ODdwRsSiGM+cOBA/fa3v5XD4VC3bt10yy23qE+fPtq0aZN3B29III65JJWXl+v666/X7Nmz1bVrV6+2NS1Qx9xmsyk2Ntb1iomJ8Wp7kwJxzJ999lkdPnxYa9euVUpKiuLj4zVgwACdffbZ3h28IYE45q1bt3b7jL/zzjuKiIgImEAeiGP+8ccfKyUlRdddd53i4+N16aWX6tprrw2Yq/sCccyff/553XPPPbr88svVtWtXTZ48WZdffrnmz5/v3cHXk0AcY08y0F//+ldNmDBBY8aMUc+ePfX0008rIiJCzz77rMf7qS0CeR2MHTtWy5Ytc71/9tlnNWbMmCrr3XnnnXr55Ze1YsUKbdu2TQkJCUpLS9Phw4clSfv379fw4cN15ZVXavv27Ro/frzuvvtutz6++eYbDRkyRCNGjNAXX3yhF198UZs2bdLUqVP9e5ANTKCPeXFxsU6cOKHWrVvXuo/6FshjblmWNmzYoF27dumiiy6qVR8mBOKYz5kzR+3bt9e4ceNqccTmBeKYHz16VJ07d1ZcXJyGDRumr776qhZHbk6gjflrr72m5ORkTZkyRTExMerVq5fmzp2r8vLyWo5A/Qu0Mf+lpUuX6pprrlGLFi1q3Ud9C7Qx79+/v7Kzs10B/Ntvv9Wbb76pyy+/vDaHb0SgjXlpaWmVW47Cw8Mb9ImEQBvjUykrK1N2drYGDx7sagsKCtLgwYO1efNmn+2nRha8NmrUKGvYsGHW999/b4WGhlp5eXlWXl6eFRYWZv3www/WsGHDrFGjRlmWZVlHjx61mjdvbr3wwguu7cvKyqyOHTtaDz/8sGVZljVz5kyrZ8+ebvu46667LEnWf//7X8uyLGvcuHHWjTfe6LZOVlaWFRQUZJWUlFiWZVmdO3e2HnvsMY+OwZt1G4LGMOaWZVmTJ0+2unbt6tq+IQvkMS8oKLBatGhhNWvWzAoNDbWWLl1ah5GoP4E65llZWdbpp59u/fDDD27HEQgCdcw//vhja8WKFda///1va+PGjdYVV1xhRUVFWfv376/jiPhfoI75mWeeaYWGhlpjx461PvvsM2v16tVW69atrQceeKCOI+J/gTrmP/fJJ59YkqxPPvmkFiNQ/wJ5zB9//HGrefPmVrNmzSxJ1qRJk+owEvUnUMf82muvtXr27Gnt3r3bKi8vt95++20rPDzcCgkJqeOI+F6gjvHPVbfud999Z0myPv74Y7f2O+64w7rgggs86rcumvk/8jde7dq109ChQ7V8+XJZlqWhQ4eqbdu2but88803OnHihFJSUlxtzZs31wUXXCCn0ylJcjqd6tu3r9t2ycnJbu8///xzffHFF3rhhRdcbZZlqaKiQnv27JHD4fD14TVIgTzmDz30kFavXq2NGzcGzORLUmCOeWRkpLZv366jR49qw4YNmjFjhrp27aqBAwd6c+jGBNKYHzlyRDfccIOWLFlSpcZAEkhjXtnnz/vt37+/HA6HFi9erD/96U+eH7hBgTbmFRUVat++vZ555hkFBwcrKSlJ3333nR555BHNmjXL6+M3IdDG/OeWLl2q3r1764ILLvBqO9MCbcw3btyouXPnauHCherbt6++/vpr3XLLLfrTn/6k++67z+vjNyHQxvzxxx/XhAkTZLfbZbPZ1K1bN40ZM6ZeLpWurUAb44aOQF5HY8eOdV0y8dRTT/ltP0ePHtXEiRM1bdq0Kssa6gQK/hKIY/7oo4/qoYce0rvvvqs+ffr4qsR6E2hjHhQUpISEBEnSOeecI6fTqXnz5gVMIJcCZ8y/+eYb5eXl6corr3S1VVRUSJKaNWumXbt2qVu3br4r2I8CZcyr07x5c5177rn6+uuv61pevQqkMe/QoYOaN2+u4OBgV5vD4VB+fr7KysoUEhLis3r9KZDGvNKxY8e0evVqzZkzx1fl1atAGvP77rtPN9xwg8aPHy9J6t27t44dO6Ybb7xRf/zjHxUUFBh3uwbSmLdr105r167V8ePH9Z///EcdO3bU3Xff3eDnYwmkMT6Vtm3bKjg4WIcOHXJrP3ToUL1MhE0gr6MhQ4aorKxMNptNaWlpVZZ369ZNISEh+uijj9S5c2dJJx9vsHXrVk2fPl3SyV/or732mtt2W7ZscXufmJionTt3ukJGUxZoY/7www/rz3/+s9avX6/zzjuvTn2ZEmhj/ksVFRUqLS31aZ/+Fihjbrfb9eWXX7q13XvvvTpy5Igef/xxxcXF1apfEwJlzKtTXl6uL7/8MqDu85QCa8xTUlK0atUqVVRUuELJ7t271aFDh4AJ41JgjXmll156SaWlpcrIyKhzXyYE0pgXFxdXCd2VX0JZllXrfutbII15pbCwMJ1++uk6ceKEXn75Zf3+97+vc5/+FIhjXJOQkBAlJSVpw4YNrse2Vk7CXB/zdQXG11wNWHBwsJxOp3bu3On2rXmlFi1aaPLkybrjjju0bt067dy5UxMmTFBxcbFr8qNJkyYpNzdXd9xxh3bt2qVVq1Zp+fLlbv3cdddd+vjjjzV16lRt375dubm5evXVV736kJSVlWn79u3avn27ysrK9N1332n79u0Bd0YlkMb8L3/5i+677z49++yzio+PV35+vvLz83X06NE6jUF9C6Qxnzdvnt555x19++23cjqdmj9/vp5//vmA+4dcoIx5WFiYevXq5fZq1aqVIiMj1atXr4AKKoEy5tLJSfTefvttffvtt9q2bZsyMjK0d+9e11mtQBFIYz558mQdPnxYt9xyi3bv3q1//etfmjt3rqZMmVKnMahvgTTmlZYuXar09HS1adOmVsdsWiCN+ZVXXqlFixZp9erV2rNnj9555x3dd999uvLKK6utvaEKpDH/5JNPlJmZqW+//VZZWVkaMmSIKioqdOedd9ZpDPwtkMbYkww0Y8YMLVmyRCtWrJDT6dTkyZN17Nixaier8zm/36XeCJ1qwqKfT2hgWZZVUlJi3XzzzVbbtm2t0NBQKyUlxfr000/dtnn99dethIQEKzQ01EpNTbWeffZZtwkNLMuyPv30U+uSSy6xWrZsabVo0cLq06eP9ec//9m1/FQTGuzZs8eSVOU1YMAAL0eg/gXqmHfu3LnaMZ81a5aXI1D/AnXM//jHP1oJCQlWWFiYddppp1nJycnW6tWrvT18IwJ1zL09joYkUMd8+vTpVqdOnayQkBArJibGuvzyy61t27Z5e/hGBOqYW9bJyfT69u1rhYaGWl27drX+/Oc/Wz/99JM3h29EII95Tk6OJcl6++23vTlk4wJ1zE+cOGE98MADVrdu3aywsDArLi7Ouummm9z20VAF6phv3LjRcjgcVmhoqNWmTRvrhhtusL777jtvD79eBOoYe5qB/va3v7l+t15wwQXWli1bPBmWOrNZVgBdfwIAAAAAQCPBJesAAAAAABhAIAcAAAAAwAACOQAAAAAABhDIAQAAAAAwgEAOAAAAAIABBHIAAAAAAAwgkAMAAAAAYACBHAAAAAAAAwjkAADAYxs3bpTNZlNBQYHH28THx2vBggV+qwkAgEBFIAcAoBEZPXq0bDabJk2aVGXZlClTZLPZNHr06PovDAAAVEEgBwCgkYmLi9Pq1atVUlLiajt+/LhWrVqlTp06GawMAAD8HIEcAIBGJjExUXFxccrMzHS1ZWZmqlOnTjr33HNdbaWlpZo2bZrat2+vsLAwXXjhhdq6datbX2+++aZ69Oih8PBwDRo0SHl5eVX2t2nTJqWmpio8PFxxcXGaNm2ajh075rfjAwCgsSCQAwDQCI0dO1bLli1zvX/22Wc1ZswYt3XuvPNOvfzyy1qxYoW2bdumhIQEpaWl6fDhw5Kk/fv3a/jw4bryyiu1fft2jR8/XnfffbdbH998842GDBmiESNG6IsvvtCLL76oTZs2aerUqf4/SAAAAhyBHACARigjI0ObNm3S3r17tXfvXn300UfKyMhwLT927JgWLVqkRx55RJdddpl69uypJUuWKDw8XEuXLpUkLVq0SN26ddP8+fN15pln6vrrr69y//m8efN0/fXXa/r06erevbv69++vJ554Qs8995yOHz9en4cMAEDAaWa6AAAA4Hvt2rXT0KFDtXz5clmWpaFDh6pt27au5d98841OnDihlJQUV1vz5s11wQUXyOl0SpKcTqf69u3r1m9ycrLb+88//1xffPGFXnjhBVebZVmqqKjQnj175HA4/HF4AAA0CgRyAAAaqbFjx7ouHX/qqaf8so+jR49q4sSJmjZtWpVlTCAHAMCvI5ADANBIDRkyRGVlZbLZbEpLS3Nb1q1bN4WEhOijjz5S586dJUknTpzQ1q1bNX36dEmSw+HQa6+95rbdli1b3N4nJiZq586dSkhI8N+BAADQSHEPOQAAjVRwcLCcTqd27typ4OBgt2UtWrTQ5MmTdccdd2jdunXauXOnJkyYoOLiYo0bN06SNGnSJOXm5uqOO+7Qrl27tGrVKi1fvtytn7vuuksff/yxpk6dqu3btys3N1evvvoqk7oBAOABAjkAAI1YVFSUoqKiql320EMPacSIEbrhhhuUmJior7/+WuvXr9dpp50m6eQl5y+//LLWrl2rs88+W08//bTmzp3r1kefPn30wQcfaPfu3UpNTdW5556r+++/Xx07dvT7sQEAEOhslmVZposAAAAAAKCp4Qw5AAAAAAAGEMgBAAAAADCAQA4AAAAAgAEEcgAAAAAADCCQAwAAAABgAIEcAAAAAAADCOQAAAAAABhAIAcAAAAAwAACOQAAAAAABhDIAQAAAAAwgEAOAAAAAIAB/w917//gkh+S6wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+QAAAIjCAYAAACKx9GpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABbcElEQVR4nO3de1xU1f7/8feAclPAvCCYKAraTKmVdDIlTMvyUhaheUqp1LymWWo3O5V5Oko3z7GLaVe11KyULD2llWVhaRfMzCMompipqF0UBESD/fujH/NtBHUGZmYzw+v5eMzDZu81a39mMaTvWXuvbTEMwxAAAAAAAPCqALMLAAAAAACgLiKQAwAAAABgAgI5AAAAAAAmIJADAAAAAGACAjkAAAAAACYgkAMAAAAAYAICOQAAAAAAJiCQAwAAAABgAgI5AAAAAAAmIJADQB33yCOPyGKxmF1GrbB27VpZLBatXbvWpdfFxcVp6NChHqmpLnHls2ixWPTII4+csd2BAwc0cOBANWnSRBaLRbNmzapZkbVQxbj98ssvZpfikur+vknS/PnzZbFYlJeX5/a6AMCbCOQAYBKLxeLUozr/WD1ZcXGxHnnkEbf0BfxVRRis6jF37lyzy9PEiRO1evVqTZkyRa+//rr69Onj0eOd7nd5zJgxHj12dQ0dOlQWi0UREREqKSmptD83N9f+Hp566ikTKgQA/1XP7AIAoK56/fXXHZ6/9tpr+uijjyptt9lsNT5WcXGxpk2bJknq0aOHw74HH3xQ999/f42P4Q+6d++ukpISBQUFufS6bdu2KSCgbn/HPWfOHDVs2NBhW5cuXUyq5v988sknuu6663T33Xd77ZhXXnmlbrnllkrb27dv77UaXFWvXj0VFxdrxYoVGjRokMO+RYsWKSQkRMeOHTOpOgDwXwRyADBJWlqaw/MNGzboo48+qrTd0+rVq6d69Xzvr4Njx44pKCjIrUE4ICBAISEhLr8uODjYbTXURsXFxQoLCzttm4EDB6pp06Zeqsh5Bw8eVKNGjdzWnzOfu/bt23v997imgoODlZSUpDfeeKNSIF+8eLGuvvpqLVu2zKTqAMB/1e2v8wGglisvL9esWbN03nnnKSQkRM2bN9fo0aP1+++/O7T79ttv1bt3bzVt2lShoaFq06aNhg8fLknKy8tTs2bNJEnTpk2zn3pacf1tVdftWiwWjR8/XsuXL1eHDh0UHBys8847T6tWrapU49q1a3XRRRcpJCRE8fHxeuGFF5y+FrhHjx7q0KGDsrKy1K1bN3vtJ5/qXHGt6ZIlS/Tggw/q7LPPVlhYmAoKCiRJX331lfr06aPIyEiFhYXpsssu0xdffFHpeHv37tVtt92mFi1aKDg4WG3atNHYsWN1/Phxh+P89dT+3NxcDRgwQNHR0QoJCVHLli1144036siRI/Y2VV1D/uOPP+qGG25Q48aNFRYWpksuuUT//e9/q3xfb731lqZPn66WLVsqJCREV1xxhXbs2HHG8asY55ycHA0aNEgRERFq0qSJ7rzzzipnMxcuXKjExESFhoaqcePGuvHGG7Vnz55T/ky6d++usLAwPfDAA2es5Uzefvtt+7GbNm2qtLQ07d2794yvKy0t1cSJE9WsWTOFh4fr2muv1c8//3zG11VcY2wYhmbPnm3/3Fdw5edzqs9dTWRmZuqGG25Qq1atFBwcrNjYWE2cOLHKU8Yrfr7NmjVTaGiozjnnHP3jH/+o1O7w4cMaOnSoGjVqpMjISA0bNkzFxcVO1zR48GB98MEHOnz4sH3bN998o9zcXA0ePLjK1zgzjpL0888/KyUlRQ0aNFBUVJQmTpyo0tLSKvt09vcZAPyB702JAEAdMnr0aM2fP1/Dhg3ThAkTtGvXLj333HP67rvv9MUXX6h+/fo6ePCgrrrqKjVr1kz333+/GjVqpLy8PGVkZEiSmjVrpjlz5mjs2LG6/vrrlZqaKknq1KnTaY+9bt06ZWRk6Pbbb1d4eLieeeYZDRgwQD/99JOaNGkiSfruu+/Up08fxcTEaNq0aSorK9M///lP+xcAzvj999/Vr18/DRo0SDfddJPeeustjR07VkFBQfYvFSo8+uijCgoK0t13363S0lIFBQXpk08+Ud++fZWYmKipU6cqICBA8+bN0+WXX67MzExdfPHFkqR9+/bp4osv1uHDhzVq1ChZrVbt3btXS5cuVXFxcZWnqR8/fly9e/dWaWmp7rjjDkVHR2vv3r1auXKlDh8+rMjIyCrf04EDB9StWzcVFxdrwoQJatKkiRYsWKBrr71WS5cu1fXXX+/Q/rHHHlNAQIDuvvtuHTlyRE888YSGDBmir776yqkxHDRokOLi4pSenq4NGzbomWee0e+//67XXnvN3mb69Ol66KGHNGjQII0YMUKHDh3Ss88+q+7du+u7775zmEX+9ddf1bdvX914441KS0tT8+bNz1jDb7/95vA8MDBQZ511liTZP8N/+9vflJ6ergMHDujpp5/WF198UenYJxsxYoQWLlyowYMHq1u3bvrkk0909dVXn7Ge7t276/XXX9fNN99c6RRyV38+VX3uTufYsWNVLrAWERFhf+3bb7+t4uJijR07Vk2aNNHXX3+tZ599Vj///LPefvtt+2s2b96s5ORk1a9fX6NGjVJcXJx27typFStWaPr06Q79Dxo0SG3atFF6ero2btyol19+WVFRUXr88cfPOF6SlJqaqjFjxigjI8P+u7d48WJZrVZ17ty5Untnx7GkpERXXHGFfvrpJ02YMEEtWrTQ66+/rk8++aRSn87+PgOA3zAAALXCuHHjjL/+bzkzM9OQZCxatMih3apVqxy2v/POO4Yk45tvvjll34cOHTIkGVOnTq20b+rUqcbJfx1IMoKCgowdO3bYt33//feGJOPZZ5+1b+vfv78RFhZm7N27174tNzfXqFevXqU+q3LZZZcZkoyZM2fat5WWlhoXXHCBERUVZRw/ftwwDMP49NNPDUlG27ZtjeLiYnvb8vJyo127dkbv3r2N8vJy+/bi4mKjTZs2xpVXXmnfdssttxgBAQFVjlPFayuO8+mnnxqGYRjfffedIcl4++23T/s+Wrdubdx6663253fddZchycjMzLRvKywsNNq0aWPExcUZZWVlDsez2WxGaWmpve3TTz9tSDJ++OGH0x634md37bXXOmy//fbbDUnG999/bxiGYeTl5RmBgYHG9OnTHdr98MMPRr169Ry2V/xM5s6de9pjn1zDyY/WrVsbhmEYx48fN6KioowOHToYJSUl9tetXLnSkGQ8/PDDlfqqsGnTJkOScfvttzscc/Dgwaf8PJ9MkjFu3DiHba7+fE7+3J3peKd6vPHGG/Z2VfWXnp5uWCwWY/fu3fZt3bt3N8LDwx22GYbh8HmvGLfhw4c7tLn++uuNJk2anLHmW2+91WjQoIFhGIYxcOBA44orrjAMwzDKysqM6OhoY9q0acauXbsMScaTTz5pf52z4zhr1ixDkvHWW2/Z2xUVFRkJCQkOv2+u/D7PmzfPkGTs2rXrjO8PAGozTlkHgFrq7bffVmRkpK688kr98ssv9kdiYqIaNmyoTz/9VJLss4srV67UiRMn3Hb8Xr16KT4+3v68U6dOioiI0I8//ihJKisr08cff6yUlBS1aNHC3i4hIUF9+/Z1+jj16tXT6NGj7c+DgoI0evRoHTx4UFlZWQ5tb731VoWGhtqfb9q0yX467a+//mofo6KiIl1xxRX6/PPPVV5ervLyci1fvlz9+/fXRRddVKmGU51eXzEDvnr1apdO/X3//fd18cUX69JLL7Vva9iwoUaNGqW8vDxt3brVof2wYcMcZl2Tk5MlyT7WZzJu3DiH53fccYe9DknKyMhQeXm5Bg0a5PBZio6OVrt27eyfpQrBwcEaNmyYk+/2T8uWLdNHH31kfyxatEjSn5dTHDx4ULfffrvD9flXX321rFZrlac3V6iof8KECQ7b77rrLpdqq6pfV34+J3/uzuS6665zGIuKR8+ePe1t/tpfUVGRfvnlF3Xr1k2GYei7776TJB06dEiff/65hg8frlatWjkco6rP7MmruCcnJ+vXX3916RT7wYMHa+3atcrPz9cnn3yi/Pz8U56u7uw4vv/++4qJidHAgQPt7cLCwjRq1CiH/pz9fQYAf8Ip6wBQS+Xm5urIkSOKioqqcv/BgwclSZdddpkGDBigadOm6T//+Y969OihlJQUDR48uEaLjZ0cACTprLPOsl+/fvDgQZWUlCghIaFSu6q2nUqLFi3UoEEDh20Vq1Hn5eXpkksusW9v06aNQ7vc3FxJfwamUzly5IiOHz+ugoICdejQwem6Ko43adIk/fvf/9aiRYuUnJysa6+9Vmlpaac8XV2Sdu/eXeUK4xUr5u/evduhlpPHuuJU75PXCjiVdu3aOTyPj49XQECA/R7Nubm5MgyjUrsK9evXd3h+9tlnu7zSfPfu3atc1G337t2SpHPOOafSPqvVqnXr1p2yz927dysgIMDhi6FT9eUKV38+J3/uzqRly5bq1avXadv89NNPevjhh/Xee+9V+jlXrE9Q8YWMs5/b032OIiIinOqjX79+Cg8P15tvvqlNmzbpb3/7mxISEqq837ez47h7924lJCRU+hLh5J+js7/PFe8LAPwBgRwAaqny8nJFRUXZZxpPVnGdtsVi0dKlS7VhwwatWLFCq1ev1vDhwzVz5kxt2LCh0q2onBUYGFjldsMwqtWfO5w8S1kxW/bkk0/qggsuqPI1DRs2rHR9sytmzpypoUOH6t1339WHH36oCRMm2K/VbtmyZbX7/St3j/XJwae8vFwWi0UffPBBlcc6+TPiymxwXeDu8SgrK9OVV16p3377Tffdd5+sVqsaNGigvXv3aujQodWeBXbH5yg4OFipqalasGCBfvzxR/vij97g7O8zAPgTAjkA1FLx8fH6+OOPlZSU5FQguOSSS3TJJZdo+vTpWrx4sYYMGaIlS5ZoxIgRTq147qqoqCiFhIRUuRq4MyuEV9i3b5+KioocZsm3b98u6c/Vy0+nYuY0IiLitDOSzZo1U0REhLZs2eJ0XX/VsWNHdezYUQ8++KC+/PJLJSUlae7cufrXv/5VZfvWrVtr27Ztlbbn5OTY97tTbm6uwyzujh07VF5ebh+/+Ph4GYahNm3aeP1e2BXvddu2bbr88ssd9m3btu20Y9G6dWuVl5dr586dDrOpVY2tqzV58+dzsh9++EHbt2/XggULHBab++ijjxzatW3bVpKq/bmtrsGDB+vVV19VQECAbrzxxlO2c3YcW7durS1btsgwDIf/F538Wmd/nwHAn3ANOQDUUoMGDVJZWZkeffTRSvv++OMP+62Jfv/990ozYBWzSxW3Faq4h/Rfb2dUU4GBgerVq5eWL1+uffv22bfv2LFDH3zwgdP9/PHHH3rhhRfsz48fP64XXnhBzZo1U2Ji4mlfm5iYqPj4eD311FM6evRopf2HDh2S9Of9xVNSUrRixQp9++23ldqdagaxoKBAf/zxh8O2jh07KiAg4JS3bJL+PO3366+/1vr16+3bioqK9OKLLyouLk7nnnvuad+Xq2bPnu3w/Nlnn5Uk+7X8qampCgwM1LRp0yq9V8Mw9Ouvv7q1nr+66KKLFBUVpblz5zqM2QcffKDs7OzTrpheUf8zzzzjsH3WrFk1qsnbP5+TVcxk//VnYRiGnn76aYd2zZo1U/fu3fXqq6/qp59+ctjnyTNVevbsqUcffVTPPfecoqOjT9nO2XHs16+f9u3bp6VLl9rbFRcX68UXX3Toz9nfZwDwJ8yQA0Atddlll2n06NFKT0/Xpk2bdNVVV6l+/frKzc3V22+/raeffloDBw7UggUL9Pzzz+v6669XfHy8CgsL9dJLLykiIkL9+vWT9Ocpt+eee67efPNNtW/fXo0bN1aHDh1cvqb6ZI888og+/PBDJSUlaezYsSorK9Nzzz2nDh06aNOmTU710aJFCz3++OPKy8tT+/bt7deuvvjii5WubT5ZQECAXn75ZfXt21fnnXeehg0bprPPPlt79+7Vp59+qoiICK1YsUKSNGPGDH344Ye67LLLNGrUKNlsNu3fv19vv/221q1bV+Wttz755BONHz9eN9xwg9q3b68//vhDr7/+ugIDAzVgwIBT1nX//ffrjTfeUN++fTVhwgQ1btxYCxYs0K5du7Rs2TIFBLj3+/Bdu3bp2muvVZ8+fbR+/Xr7bcLOP/98SX/OPP7rX//SlClTlJeXp5SUFIWHh2vXrl165513NGrUKN19991uralC/fr19fjjj2vYsGG67LLLdNNNN9lvexYXF6eJEyee8rUXXHCBbrrpJj3//PM6cuSIunXrpjVr1rh0BkZVPP3z2b59uxYuXFhpe/PmzXXllVfKarUqPj5ed999t/bu3auIiAgtW7asyjUDnnnmGV166aXq3LmzRo0apTZt2igvL0///e9/nf4dc1VAQIAefPDBM7ZzdhxHjhyp5557TrfccouysrIUExOj119/3f5F4V+P6+zvMwD4DTOWdgcAVHbybc8qvPjii0ZiYqIRGhpqhIeHGx07djTuvfdeY9++fYZhGMbGjRuNm266yWjVqpURHBxsREVFGddcc43x7bffOvTz5ZdfGomJiUZQUJDDLaNOdduzk28VZRiVb+9lGIaxZs0a48ILLzSCgoKM+Ph44+WXXzYmT55shISEnPE9X3bZZcZ5551nfPvtt0bXrl2NkJAQo3Xr1sZzzz3n0K7i9lOnuv3Yd999Z6SmphpNmjQxgoODjdatWxuDBg0y1qxZ49Bu9+7dxi233GI0a9bMCA4ONtq2bWuMGzfOfsuxk2979uOPPxrDhw834uPjjZCQEKNx48ZGz549jY8//viM47Jz505j4MCBRqNGjYyQkBDj4osvNlauXOnU+6q4xdS8efNOO34VP7utW7caAwcONMLDw42zzjrLGD9+vMMtxiosW7bMuPTSS40GDRoYDRo0MKxWqzFu3Dhj27Zt9jYVPxNnVdRw6NCh07Z78803jQsvvNAIDg42GjdubAwZMsT4+eefq+zrr0pKSowJEyYYTZo0MRo0aGD079/f2LNnT41ue2YYNfv5nOl4p3pcdtll9nZbt241evXqZTRs2NBo2rSpMXLkSPutBU/+uW/ZssW4/vrr7bWec845xkMPPWTff6qfgbO3Bvvrbc9OparbnhmGc+NoGH/+7l177bVGWFiY0bRpU+POO++038Kx4vetgjO/z9z2DIC/sBiGiavzAAD8UkpKiv73v//ZV00+lR49euiXX37x+jWy/uKRRx7RtGnTdOjQoSpXOAcAALUb15ADAGqkpKTE4Xlubq7ef/999ejRw5yCAAAAfATXkAMAaqRt27YaOnSo2rZtq927d2vOnDkKCgrSvffea3ZpAAAAtRqBHABQI3369NEbb7yh/Px8BQcHq2vXrpoxY4batWtndmkAAAC1GteQAwAAAABgAq4hBwAAAADABARyAAAAAABM4PfXkJeXl2vfvn0KDw+XxWIxuxwAAAAAgJ8zDEOFhYVq0aKFAgJOPQ/u94F83759io2NNbsMAAAAAEAds2fPHrVs2fKU+/0+kIeHh0v6cyAiIiJMrgYAAAAA4O8KCgoUGxtrz6On4veBvOI09YiICAI5AAAAAMBrznTZNIu6AQAAAABgAgI5AAAAAAAmIJADAAAAAGACAjkAAAAAACYgkAMAAAAAYAICOQAAAAAAJjA1kM+ZM0edOnWy35Ksa9eu+uCDD+z7e/ToIYvF4vAYM2aMiRUDAAAAAOAept6HvGXLlnrsscfUrl07GYahBQsW6LrrrtN3332n8847T5I0cuRI/fOf/7S/JiwszKxyAQAAAABwG1MDef/+/R2eT58+XXPmzNGGDRvsgTwsLEzR0dFmlAcAAAAAgMfUmmvIy8rKtGTJEhUVFalr16727YsWLVLTpk3VoUMHTZkyRcXFxaftp7S0VAUFBQ4PAAAAAABqG1NnyCXphx9+UNeuXXXs2DE1bNhQ77zzjs4991xJ0uDBg9W6dWu1aNFCmzdv1n333adt27YpIyPjlP2lp6dr2rRp3iofAAAAAIBqsRiGYZhZwPHjx/XTTz/pyJEjWrp0qV5++WV99tln9lD+V5988omuuOIK7dixQ/Hx8VX2V1paqtLSUvvzgoICxcbG6siRI4qIiPDY+wAAAAAAQPozh0ZGRp4xh5oeyE/Wq1cvxcfH64UXXqi0r6ioSA0bNtSqVavUu3dvp/pzdiAAAAAAAHAHZ3Oo6aesn6y8vNxhhvuvNm3aJEmKiYnxYkUA4B/KysqUmZmp/fv3KyYmRsnJyQoMDDS7LAAAgDrL1EA+ZcoU9e3bV61atVJhYaEWL16stWvXavXq1dq5c6cWL16sfv36qUmTJtq8ebMmTpyo7t27q1OnTmaWDQA+JyMjQ5MnT1ZeXp59W1xcnGbOnKnU1FTzCgMAAKjDTF1l/eDBg7rlllt0zjnn6IorrtA333yj1atX68orr1RQUJA+/vhjXXXVVbJarZo8ebIGDBigFStWmFkyAPicjIwMDRw4UB07dtT69etVWFio9evXq2PHjho4cOBpF8oEAACA59S6a8jdjWvIAdRlZWVlSkhIUMeOHbV8+XIFBPzf97Dl5eVKSUnRli1blJuby+nrAAAAbuJsDq019yEHALhfZmam8vLy9MADDziEcUkKCAjQlClTtGvXLmVmZppUIQAAQN1FIAcAP7Z//35JUocOHarcX7G9oh0AAAC8h0AOAH6s4q4UW7ZsqXJ/xXbuXgEAAOB9BHIA8GPJycmKi4vTjBkzVF5e7rCvvLxc6enpatOmjZKTk02qEAAAoO4ikAOAHwsMDNTMmTO1cuVKpaSkOKyynpKSopUrV+qpp55iQTcAAAATmHofcgCA56Wmpmrp0qWaPHmyunXrZt/epk0bLV26lPuQAwAAmITbngFAHVFWVqbMzEzt379fMTExSk5OZmYcAADAA5zNocyQA0AdERgYqB49ephdBlAtxcXFysnJcaptSUmJ8vLyFBcXp9DQUKePYbVaFRYWVt0SAQBwGYEcAADUejk5OUpMTPToMbKystS5c2ePHgMAgL8ikAMAgFrParUqKyvLqbbZ2dlKS0vTwoULZbPZXDoGAADeRCAHAAC1XlhYmMuz1zabjRlvAECtxm3PAAAAAAAwAYEcAAAAAAATEMgBAAAAADABgRwAAAAAABMQyAEAAAAAMAGBHAAAAAAAE3DbMy8qLi5WTk6OU21LSkqUl5enuLg4hYaGOn0Mq9WqsLCw6pYIAAAAAPASArkX5eTkKDEx0aPHyMrK4p6rAAAAAOADCOReZLValZWV5VTb7OxspaWlaeHChbLZbC4dAwAAAABQ+xHIvSgsLMzl2WubzcaMNwAAAAD4IRZ1AwAAAADABARyAAAAAABMQCAHAAAAAMAEBHIAAAAAAExAIAcAAAAAwAQEcgAAAAAATEAgBwAAAADABARyAAAAAABMQCAHAAAAAMAE9cwuAPCk4uJi5eTkONW2pKREeXl5iouLU2hoqNPHsFqtCgsLq26JAAAAAOooAjn8Wk5OjhITEz16jKysLHXu3NmjxwAAAADgfwjk8GtWq1VZWVlOtc3OzlZaWpoWLlwom83m0jEAAAAAwFUEcvi1sLAwl2evbTYbM94AAAAAPI5F3QAAAAAAMAGBHAAAAAAAExDIAQAAAAAwAYEcAAAAAAATEMgBAAAAADABgRwAAAAAABMQyAEAAAAAMAGBHAAAAAAAExDIAQAAAAAwQT2zCwAAAHVTbm6uCgsL3d5vdna2w5+eEB4ernbt2nmsfwBA3UAgBwAAXpebm6v27dt79BhpaWke7X/79u2EcgBAjRDIAcDHFRcXKycnx6m2JSUlysvLU1xcnEJDQ50+htVqVVhYWHVLBCqpmBlfuHChbDabW/uu7ufcWdnZ2UpLS/PI7D4AoG4hkMPncIoj4CgnJ0eJiYkePUZWVpY6d+7s0WOgbrLZbB75bCUlJbm9TwAA3I1ADp/CKY5AZVarVVlZWU61rZjZc3VW0mq1Vrc8AAAAnAKBHD6FUxyBysLCwlyeYfTUrCQAAACcRyCHT+IURwAAAAC+ztT7kM+ZM0edOnVSRESEIiIi1LVrV33wwQf2/ceOHdO4cePUpEkTNWzYUAMGDNCBAwdMrBgAAAAAAPcwNZC3bNlSjz32mLKysvTtt9/q8ssv13XXXaf//e9/kqSJEydqxYoVevvtt/XZZ59p3759Sk1NNbNkAAAAAADcwtRT1vv37+/wfPr06ZozZ442bNigli1b6pVXXtHixYt1+eWXS5LmzZsnm82mDRs26JJLLjGjZAAAAAAA3MLUGfK/Kisr05IlS1RUVKSuXbsqKytLJ06cUK9evextrFarWrVqpfXr15+yn9LSUhUUFDg8AAAAAACobUwP5D/88IMaNmyo4OBgjRkzRu+8847OPfdc5efnKygoSI0aNXJo37x5c+Xn55+yv/T0dEVGRtofsbGxHn4HAAAAAAC4zvRAfs4552jTpk366quvNHbsWN16663aunVrtfubMmWKjhw5Yn/s2bPHjdUCAAAAAOAept/2LCgoSAkJCZKkxMREffPNN3r66af197//XcePH9fhw4cdZskPHDig6OjoU/YXHBys4OBgT5cNAAAAAECNmD5DfrLy8nKVlpYqMTFR9evX15o1a+z7tm3bpp9++kldu3Y1sUIAAAAAAGrO1BnyKVOmqG/fvmrVqpUKCwu1ePFirV27VqtXr1ZkZKRuu+02TZo0SY0bN1ZERITuuOMOde3alRXWAQAAAAA+z9RAfvDgQd1yyy3av3+/IiMj1alTJ61evVpXXnmlJOk///mPAgICNGDAAJWWlqp37956/vnnzSwZAAAAAAC3MDWQv/LKK6fdHxISotmzZ2v27NleqggAAAAAAO+oddeQAwAAAABQF5i+yrqvy83NVWFhodv7zc7OdvjTE8LDw9WuXTuP9Q8AAAAAODUCeQ3k5uaqffv2Hj1GWlqaR/vfvn07oRwAAAAATEAgr4GKmfGFCxfKZrO5te+SkhLl5eUpLi5OoaGhbu1b+nPmPS0tzSOz+wAAAABQleLiYuXk5DjVtrqZyGq1KiwsrLolehWB3A1sNps6d+7s9n6TkpLc3icAALVFdEOLQg9vl/b51pI2oYe3K7qhxewyAMAn5eTkKDEx0aPHyMrK8kg+8wQCOQAAMMXoxCDZPh8tfW52Ja6x6c/aAQCus1qtysrKcqptxVm9rp6RbLVaq1ue1xHIAQCAKV7IOq6/PzxfNh/6h5MkZefk6IWZg3Wt2YUAgA8KCwtzefbaU2ck1wYEcgAAYIr8o4ZKGrWXWlxgdikuKckvV/5Rw+wyAAB+wLcu2gIAAAAAwE8wQw4AtVBubq5H7oKQnZ3t8KcnhIeHcztFAAAAJxDIAaCWyc3NVfv27T16jLS0NI/2v337dkI5AADAGRDIAaCWqZgZd3VFUWdU936ezqpYDdUTs/sAAAD+hkAOALWUp1YUTUpKcnufAAAAcB2LugEAAAAAYAJmyOFzohtaFHp4u7TPt75PCj28XdENLWaXAQAAAKCWIJDXEOHQ+0YnBsn2+Wjpc7MrcY1Nf9YOAAAAABKBvMYIh973QtZx/f3h+bJZrWaX4pLsnBy9MHOwrjW7EAAAAAC1AoG8hgiH3pd/1FBJo/ZSiwvMLsUlJfnlyj9qmF0GfARn3wAAAPg/AnkNEQ4BeAJn3wAAAPg/AjkA1EKcfQMAAOD/COQAUAtx9g0AAID/862LEwEAAAAA8BMEcgAAAAAATEAgBwAAAADABFxDDgAAAACottzcXBUWFrq93+zsbIc/PSE8PFzt2rXzWP9nQiAHAAAAAFRLbm6u2rdv79FjpKWlebT/7du3mxbKCeQAAAAAgGqpmBlfuHChbDabW/suKSlRXl6e4uLiFBoa6ta+pT9n3tPS0jwyu+8sAjkAAAAAoEZsNps6d+7s9n6TkpLc3mdtwqJuAAAAAACYgEAOAAAAAIAJCOQAAAAAAJiAQA4AAAAAgAlY1A0AAHhdcXGxJGnjxo1u79sbq/ICAOAOBPIa4B8TAABUT05OjiRp5MiRJldSfeHh4WaXAADwcQTyGuAfEwAAVE9KSookyWq1KiwszK19V9xX1hP3xK0QHh6udu3aeaRvAEDdQSCvAf4xAQBA9TRt2lQjRozw6DE8dU9cAADchUBeA/xjwvu4TAAAAACAvyCQw6dwmQAAAAAAf0Egh0/hMgHUBZwJAgAAUDcQyOFTuEwAdQFnggAAANQNBHIAqGU4EwQAAKBuIJADQC3DmSAAAAB1Q4DZBQAAAAAAUBcRyAEAAAAAMAGBHAAAAAAAExDIAQAAAAAwAYu6AQAAAACqLbqhRaGHt0v7fGu+N/TwdkU3tJhaA4EcAAAAAFBtoxODZPt8tPS52ZW4xqY/azcTgRwAAAAAUG0vZB3X3x+eL5vVanYpLsnOydELMwfrWhNrIJADAAAAAKot/6ihkkbtpRYXmF2KS0ryy5V/1DC1Bt86yR8AAAAAAD9haiBPT0/X3/72N4WHhysqKkopKSnatm2bQ5sePXrIYrE4PMaMGWNSxQAAAAAAuIepgfyzzz7TuHHjtGHDBn300Uc6ceKErrrqKhUVFTm0GzlypPbv329/PPHEEyZVDAAAAACAe5h6DfmqVascns+fP19RUVHKyspS9+7d7dvDwsIUHR3tVJ+lpaUqLS21Py8oKHBPsQAAAAAAuFGtuob8yJEjkqTGjRs7bF+0aJGaNm2qDh06aMqUKSouLj5lH+np6YqMjLQ/YmNjPVozAAAAAADVUWtWWS8vL9ddd92lpKQkdejQwb598ODBat26tVq0aKHNmzfrvvvu07Zt25SRkVFlP1OmTNGkSZPszwsKCgjlAAAAAOABFZOlGzdudHvfJSUlysvLU1xcnEJDQ93ef3Z2ttv7dFWtCeTjxo3Tli1btG7dOofto0aNsv93x44dFRMToyuuuEI7d+5UfHx8pX6Cg4MVHBzs8XoBAAAAoK7LycmR9Oe6X74qPDzctGPXikA+fvx4rVy5Up9//rlatmx52rZdunSRJO3YsaPKQA4AAAAA8I6UlBRJktVqVVhYmFv7zs7OVlpamhYuXCibzebWviuEh4erXbt2HunbGaYGcsMwdMcdd+idd97R2rVr1aZNmzO+ZtOmTZKkmJgYD1cHAAAAADidpk2basSIER49hs1mU+fOnT16DLOYGsjHjRunxYsX691331V4eLjy8/MlSZGRkQoNDdXOnTu1ePFi9evXT02aNNHmzZs1ceJEde/eXZ06dTKzdAAAAAAAasTUQD5nzhxJUo8ePRy2z5s3T0OHDlVQUJA+/vhjzZo1S0VFRYqNjdWAAQP04IMPmlAtAAAAAADuY/op66cTGxurzz77zEvVAAAAAADgPbXqPuQAAAAAANQVtWKVdQBA9RUXF9tvOXImFffbdPW+m55YORUAAKCuI5ADgI/LyclRYmKiS69JS0tzqX1WVpbfrm4KAABgFgI5APg4q9WqrKwsp9qWlJQoLy9PcXFxCg0NdekYAAAAcC8COQD4uLCwMJdmr5OSkjxYDQAAAJzFom4AAAAAAJiAGXIAAFDrsXghAMAfEcgBAECtx+KFAAB/RCAHAAC1HosXAgD8EYEcAADUeixeCADwRyzqBgAAAACACZgh9yIWpAEAAABQl5GJHBHIvYgFaQAAAIDaw5VwWJP1KXwlHHoDmcgRgdyLWJAGAAAAp0I49L7qhENX+VI49AYykSMCuRexIA0AAABOhXDofa6Ew+zsbKWlpWnhwoWy2WwuHQP/h0zkiEAOAAAA1AKEQ+9zNRxKks1m40sNuA2BHAAAAKgFCIdA3cNtzwAAAAAAMAGBHAAAAAAAE3DKOgAAAAC/kZubq8LCQrf3W917YrsiPDxc7dq181j/qH0I5AAAAAD8Qm5urtq3b+/RY7h6T2xXbd++nVBehxDIAQAAAPiFiplxV1efd0Z174ntrIqV8z0xu4/ai0AOAAAAeAinT5vDU6vP+/s9seF9BHIAAADAAzh9GsCZEMgBAAAAD+D0aQBnQiAHAAAAPIjTpwGcCvchBwAAAADABARyAAAAAABMQCAHAAAAAMAEBHIAAAAAAExAIAcAAAAAwAQEcgAAAAAATEAgBwAAAADABARyAAAAAABMQCAHAAAAAMAE9cwuAPCk4uJi5eTkONU2Ozvb4U9nWa1WhYWFuVwbAAAAgLqNQA6/lpOTo8TERJdek5aW5lL7rKwsde7c2aXXAPBtrnzZV1JSory8PMXFxSk0NNTpY/BlHwAA/o9ADr9mtVqVlZXlVNua/KMZQN1SnS/7XMWXfQAA+D8COfxaWFiYS/+gTUpK8mA1APyFK1/2ZWdnKy0tTQsXLpTNZnPpGAAAwL8RyAEAcJGrX/ZJks1mY8YbAAA4YJV1AAAAAABMQCAHAAAAAMAEBHIAAAAAAEzANeQAAAAA/EZ0Q4tCD2+X9vnW3GPo4e2Kbmgxuwx4GYEcAAAAgN8YnRgk2+ejpc/NrsQ1Nv1ZO+oWAjkAAAAAv/FC1nH9/eH5svnY7SOzc3L0wszButbsQuBVBHIAAADAQzh92vvyjxoqadReanGB2aW4pCS/XPlHDbPLgJcRyAEAAAAP4fRpoHrKysqUmZmp/fv3KyYmRsnJyQoMDDS7LLcjkAMAAAAewunTgOsyMjI0efJk5eXl2bfFxcVp5syZSk1NNa8wDyCQAwAAAB7C6dOAazIyMjRw4EBdc801euONN9ShQwdt2bJFM2bM0MCBA7V06VK/CuWmXsySnp6uv/3tbwoPD1dUVJRSUlK0bds2hzbHjh3TuHHj1KRJEzVs2FADBgzQgQMHTKoYAAAAAOAJZWVlmjx5sq655hotX75cl1xyiRo2bKhLLrlEy5cv1zXXXKO7775bZWVlZpfqNqYG8s8++0zjxo3Thg0b9NFHH+nEiRO66qqrVFRUZG8zceJErVixQm+//bY+++wz7du3z6++EQEAAAAASJmZmcrLy9MDDzyggADHqBoQEKApU6Zo165dyszMNKlC9zP1lPVVq1Y5PJ8/f76ioqKUlZWl7t2768iRI3rllVe0ePFiXX755ZKkefPmyWazacOGDbrkkksq9VlaWqrS0lL784KCAs++CQAAAABAje3fv1+S1KFDhyr3V2yvaOcPatX9F44cOSJJaty4sSQpKytLJ06cUK9evextrFarWrVqpfXr11fZR3p6uiIjI+2P2NhYzxcOAAAAAKiRmJgYSdKWLVuq3F+xvaKdP6g1gby8vFx33XWXkpKS7N985OfnKygoSI0aNXJo27x5c+Xn51fZz5QpU3TkyBH7Y8+ePZ4uHQAAAABQQ8nJyYqLi9OMGTNUXl7usK+8vFzp6elq06aNkpOTTarQ/WpNIB83bpy2bNmiJUuW1Kif4OBgRUREODwAAAAAALVbYGCgZs6cqZUrVyolJUXr169XYWGh1q9fr5SUFK1cuVJPPfWUX92PvFYE8vHjx2vlypX69NNP1bJlS/v26OhoHT9+XIcPH3Zof+DAAUVHR3u5SgAAAACAJ6Wmpmrp0qX64Ycf1K1bN0VERKhbt27asmWL393yTDJ5UTfDMHTHHXfonXfe0dq1a9WmTRuH/YmJiapfv77WrFmjAQMGSJK2bdumn376SV27djWjZAAAAACAB6Wmpuq6665TZmam9u/fr5iYGCUnJ/vVzHgFUwP5uHHjtHjxYr377rsKDw+3XxceGRmp0NBQRUZG6rbbbtOkSZPUuHFjRURE6I477lDXrl2rXGEdAAAAAOD7AgMD1aNHD7PL8DhTA/mcOXMkqdJAz5s3T0OHDpUk/ec//1FAQIAGDBig0tJS9e7dW88//7yXKwUAAAAAwL1MP2X9TEJCQjR79mzNnj3bCxUBAAAAAOAd1QrkZWVlmj9/vtasWaODBw9WWpL+k08+cUtxAAAAAAD4q2oF8jvvvFPz58/X1VdfrQ4dOshisbi7LgAAvCo3N1eFhYVu7zc7O9vhT08IDw9Xu3btPNY/AADwjGoF8iVLluitt95Sv3793F0PAABel5ubq/bt23v0GGlpaR7tf/v27YRyAAB8TLUCeVBQkBISEtxdCwAApqiYGV+4cKFsNptb+y4pKVFeXp7i4uIUGhrq1r6lP2fe09LSPDK7DwAAPKtagXzy5Ml6+umn9dxzz3G6OgDAb9hsNnXu3Nnt/SYlJbm9TwAA4PuqFcjXrVunTz/9VB988IHOO+881a9f32F/RkaGW4oDAAAAAMBfVSuQN2rUSNdff727awEAAAAAoM6oViCfN2+eu+sAAAAAAKBOqVYgr3Do0CFt27ZNknTOOeeoWbNmbikKAAAAAAB/F1CdFxUVFWn48OGKiYlR9+7d1b17d7Vo0UK33XabiouL3V0jAAAAAAB+p1qBfNKkSfrss8+0YsUKHT58WIcPH9a7776rzz77TJMnT3Z3jQAAAAAA+J1qnbK+bNkyLV26VD169LBv69evn0JDQzVo0CDNmTPHXfUBAAAAAOCXqjVDXlxcrObNm1faHhUVxSnrAAAAAAA4oVoz5F27dtXUqVP12muvKSQkRJJUUlKiadOmqWvXrm4tEAAAAACcUTE5uHHjRrf3XVJSory8PMXFxSk0NNTt/WdnZ7u9T9R+1QrkTz/9tHr37q2WLVvq/PPPlyR9//33CgkJ0erVq91aIAAAAAA4IycnR5I0cuRIkyupvvDwcLNLgBdVK5B36NBBubm5WrRokf1Df9NNN2nIkCEe+bYIAAAAAM4kJSVFkmS1WhUWFubWvrOzs5WWlqaFCxfKZrO5te8K4eHhateunUf6Ru1U7fuQh4WF+fQ3TwAAAAD8S9OmTTVixAiPHsNms6lz584ePQbqDqcD+Xvvvae+ffuqfv36eu+9907b9tprr61xYQAAAAAA+DOnA3lKSory8/MVFRVlPxWkKhaLRWVlZe6oDQAAAAAAv+V0IC8vL6/yvwEAAAAAgOuqfQ35yQ4fPqxGjRq5qzsAALwquqFFoYe3S/sCzC7FJaGHtyu6ocXsMgAAQDVUK5A//vjjiouL09///ndJ0g033KBly5YpJiZG77//vv1WaAAA+IrRiUGyfT5a+tzsSlxj05+1AwBcV1xcbL9r1JlU3Cfc1fuFe2LFd/iPagXyuXPnatGiRZKkjz76SB9//LFWrVqlt956S/fcc48+/PBDtxYJAICnvZB1XH9/eL5sVqvZpbgkOydHL8wcLJZTBQDX5eTkKDEx0aXXpKWludQ+KyuLVdlxStUK5Pn5+YqNjZUkrVy5UoMGDdJVV12luLg4denSxa0FAgDgDflHDZU0ai+1uMDsUlxSkl+u/KOG2WUAgE+yWq3Kyspyqm1JSYny8vIUFxen0NBQl44BnEq1AvlZZ52lPXv2KDY2VqtWrdK//vUvSZJhGKywDgAAAMAnhIWFuTR7nZSU5MFqUBdVK5CnpqZq8ODBateunX799Vf17dtXkvTdd98pISHBrQUCAAAAAOCPqhXI//Of/yguLk579uzRE088oYYNG0qS9u/fr9tvv92tBQIAAAAA4I+qFcjr16+vu+++u9L2iRMn1rggAAAAAADqAqcD+Xvvvae+ffuqfv36eu+9907b9tprWesVAOA7iouLJUkbN250e9/VXQTIWa7efgcAANQeTgfylJQU5efnKyoqSikpKadsZ7FYWNgNAOBTKu5BO3LkSJMrqb7w8HCzSwAAAC5yOpCXl5dX+d8AAPi6ii+arVarwsLC3Np3dna20tLStHDhQtlsNrf2XSE8PFzt2rXzSN8AAMBzqnUNOQAA/qRp06YaMWKER49hs9lcurUOAADwf9UK5BMmTFBCQoImTJjgsP25557Tjh07NGvWLHfUBgAAAPgs1qcAcCbVCuTLli2rcmG3bt266bHHHiOQAwAAoM5jfQoAZ1KtQP7rr78qMjKy0vaIiAj98ssvNS4KAAAA8HWsTwHgTKoVyBMSErRq1SqNHz/eYfsHH3ygtm3buqUwAAAAwJexPgWAM6lWIJ80aZLGjx+vQ4cO6fLLL5ckrVmzRjNnzuR0dQAAAAAAnFCtQD58+HCVlpZq+vTpevTRRyVJcXFxmjNnjm655Ra3FggAAAAAgD+q9m3Pxo4dq7Fjx+rQoUMKDQ1Vw4YN3VkXAAAAAAB+LaC6L/zjjz/08ccfKyMjQ4ZhSJL27duno0ePuq04AAAAAAD8VbVmyHfv3q0+ffrop59+Umlpqa688kqFh4fr8ccfV2lpqebOnevuOgEAAAAA8CvVmiG/8847ddFFF+n3339XaGioffv111+vNWvWuK04AAAAAAD8VbVmyDMzM/Xll18qKCjIYXtcXJz27t3rlsIAAAAAAPBn1ZohLy8vV1lZWaXtP//8s8LDw2tcFAAAAAAA/q5agfyqq65yuN+4xWLR0aNHNXXqVPXr189dtQEAAAAA4Leqdcr6U089pT59+ujcc8/VsWPHNHjwYOXm5qpp06Z644033F0jAAAAAAB+p1qBPDY2Vt9//73efPNNff/99zp69Khuu+02DRkyxGGRNwAAAAAAUDWXA/mJEydktVq1cuVKDRkyREOGDPFEXQAAAAAA+DWXryGvX7++jh075olaAAAAAACoM6q1qNu4ceP0+OOP648//nB3PQAAAAAA1AnVCuTffPONMjIy1KpVK/Xu3VupqakOD2d9/vnn6t+/v1q0aCGLxaLly5c77B86dKgsFovDo0+fPtUpGQAAAACAWqVai7o1atRIAwYMqPHBi4qKdP7552v48OGnDPJ9+vTRvHnz7M+Dg4NrfFwAAAAAAMzmUiAvLy/Xk08+qe3bt+v48eO6/PLL9cgjj1R7ZfW+ffuqb9++p20THBys6OjoavUPAAAAAEBt5dIp69OnT9cDDzyghg0b6uyzz9YzzzyjcePGeao2SdLatWsVFRWlc845R2PHjtWvv/562valpaUqKChweAAAAAAAUNu4FMhfe+01Pf/881q9erWWL1+uFStWaNGiRSovL/dIcX369NFrr72mNWvW6PHHH9dnn32mvn37qqys7JSvSU9PV2RkpP0RGxvrkdoAAAAAAKgJl05Z/+mnn9SvXz/78169eslisWjfvn1q2bKl24u78cYb7f/dsWNHderUSfHx8Vq7dq2uuOKKKl8zZcoUTZo0yf68oKCAUA4AAAAAqHVcmiH/448/FBIS4rCtfv36OnHihFuLOpW2bduqadOm2rFjxynbBAcHKyIiwuEBAAAAAEBt49IMuWEYGjp0qMNK58eOHdOYMWPUoEED+7aMjAz3VfgXP//8s3799VfFxMR4pH8AAAAAALzFpUB+6623VtqWlpZW7YMfPXrUYbZ7165d2rRpkxo3bqzGjRtr2rRpGjBggKKjo7Vz507de++9SkhIUO/evat9TAAAaqq4uFg5OTlOtc3Oznb401lWq1VhYWEu1wYAAHyHS4H8r/cDd4dvv/1WPXv2tD+vuPb71ltv1Zw5c7R582YtWLBAhw8fVosWLXTVVVfp0Ucf5V7kAABT5eTkKDEx0aXXuPoFdlZWljp37uzSawAAgG9xKZC7W48ePWQYxin3r1692ovVAADgHKvVqqysLKfalpSUKC8vT3FxcQoNDXXpGAAAwL+ZGsgBAPBFYWFhLs1eJyUlebAaAADgq1xaZR0AAAAAALgHgRwAAAAAABMQyAEAAAAAMAHXkAMAAAC1ALdUBOoeAjkAAABQC3BLRaDuIZADAAAAtQC3VATqHotxuhuB+4GCggJFRkbqyJEjioiIMLscAAAAAICfczaHsqgbAAAAAAAmIJADAAAAAGACAjkAAAAAACYgkAMAAAAAYAICOQAAAAAAJiCQAwAAAABgAgI5AAAAAAAmIJADAAAAAGACAjkAAAAAACYgkAMAAAAAYAICOQAAAAAAJiCQAwAAAABgAgI5AAAAAAAmIJADAAAAAGACAjkAAAAAACYgkAMAAAAAYAICOQAAAAAAJiCQAwAAAABgAgI5AAAAAAAmIJADAAAAAGACAjkAAAAAACYgkAMAAAAAYAICOQAAAAAAJiCQAwAAAABgAgI5AAAAAAAmIJADAAAAAGACAjkAAAAAACYgkAMAAAAAYAICOQAAAAAAJiCQAwAAAABgAgI5AAAAAAAmIJADAAAAAGACAjkAAAAAACYgkAMAAAAAYAICOQAAAAAAJiCQAwAAAABgAgI5AAAAAAAmIJADAAAAAGACAjkAAAAAACYgkAMAAAAAYAICOQAAAAAAJiCQAwAAAABgAlMD+eeff67+/furRYsWslgsWr58ucN+wzD08MMPKyYmRqGhoerVq5dyc3PNKRYAAAAAADcyNZAXFRXp/PPP1+zZs6vc/8QTT+iZZ57R3Llz9dVXX6lBgwbq3bu3jh075uVKAQAAAABwr3pmHrxv377q27dvlfsMw9CsWbP04IMP6rrrrpMkvfbaa2revLmWL1+uG2+80ZulAgAAAADgVrX2GvJdu3YpPz9fvXr1sm+LjIxUly5dtH79+lO+rrS0VAUFBQ4PAAAAAABqm1obyPPz8yVJzZs3d9jevHlz+76qpKenKzIy0v6IjY31aJ0AAAAAAFRHrQ3k1TVlyhQdOXLE/tizZ4/ZJQEAAAAAUEmtDeTR0dGSpAMHDjhsP3DggH1fVYKDgxUREeHwAAAAAACgtqm1gbxNmzaKjo7WmjVr7NsKCgr01VdfqWvXriZWBgAAAABAzZm6yvrRo0e1Y8cO+/Ndu3Zp06ZNaty4sVq1aqW77rpL//rXv9SuXTu1adNGDz30kFq0aKGUlBTzigYAAKgDiouLlZOT41TbkpIS5eXlKS4uTqGhoU4fw2q1KiwsrLolAoDPMzWQf/vtt+rZs6f9+aRJkyRJt956q+bPn697771XRUVFGjVqlA4fPqxLL71Uq1atUkhIiFklAwAA1Ak5OTlKTEz06DGysrLUuXNnjx4DAGozi2EYhtlFeFJBQYEiIyN15MgRricHAABwkisz5NnZ2UpLS9PChQtls9mcPgYz5AD8lbM51NQZcgAAANROYWFhLs9e22w2ZrwBwAW1dlE3AAAAAAD8GYEcAAAAAAATEMgBAAAAADABgRwAAAAAABMQyAEAAAAAMAGBHAAAAAAAExDIAQAAAAAwAYEcAAAAAAATEMgBAAAAADBBPbMLAAAAgHfk5uaqsLDQ7f1mZ2c7/OkJ4eHhateuncf6BwAzEMgBAADqgNzcXLVv396jx0hLS/No/9u3byeUA/ArBHIAAIA6oGJmfOHChbLZbG7tu6SkRHl5eYqLi1NoaKhb+5b+nHlPS0vzyOw+AJiJQA4AAFCH2Gw2de7c2e39JiUlub1PAPB3LOoGAAAAAIAJCOQAAAAAAJiAQA4AAAAAgAkI5AAAAAAAmIBADgAAAACACQjkAAAAAACYgNueAQAAAMBplJWVKTMzU/v371dMTIySk5MVGBhodlnwA8yQAwAAAMApZGRkKCEhQT179tTgwYPVs2dPJSQkKCMjw+zS4AcI5AAAAABQhYyMDA0cOFAdO3bU+vXrVVhYqPXr16tjx44aOHAgoRw1RiAHAAAAgJOUlZVp8uTJuuaaa7R8+XJdcsklatiwoS655BItX75c11xzje6++26VlZWZXSp8GIEcAAAAAE6SmZmpvLw8PfDAAwoIcIxNAQEBmjJlinbt2qXMzEyTKoQ/IJADAAAAwEn2798vSerQoUOV+yu2V7QDqoNADgAAAAAniYmJkSRt2bKlyv0V2yvaAdVBIAcAAACAkyQnJysuLk4zZsxQeXm5w77y8nKlp6erTZs2Sk5ONqlC+AMCOQAAAACcJDAwUDNnztTKlSuVkpLisMp6SkqKVq5cqaeeeor7kaNG6pldAAAAAADURqmpqVq6dKkmT56sbt262be3adNGS5cuVWpqqonVwR8QyAEAAADgFFJTU3XdddcpMzNT+/fvV0xMjJKTk5kZh1sQyAEAAADgNAIDA9WjRw+zy4Af4hpyAAAAAABMQCAHAAAAAMAEBHIAAAAAAExAIAcAAAAAwAQEcgAAAAAATEAgBwAAAADABARyAAAAAABMQCAHAAAAAMAEBHIAAAAAAExQz+wCAAAA4B3RDS0KPbxd2udbczKhh7cruqHF7DIAwO0I5AAAAHXE6MQg2T4fLX1udiWusenP2gHA3xDIAQAA6ogXso7r7w/Pl81qNbsUl2Tn5OiFmYN1rdmFAICbEcgBAADqiPyjhkoatZdaXGB2KS4pyS9X/lHD7DIAwO186wIiAAAAAAD8BIEcAAAAAAATEMgBAAAAADABgRwAAAAAABMQyAEAAAAAMEGtDuSPPPKILBaLw8PqY7fpAAAAAACgKrX+tmfnnXeePv74Y/vzevVqfckAAAAAAJxRrU+39erVU3R0tNllAAAAAADgVrX6lHVJys3NVYsWLdS2bVsNGTJEP/3002nbl5aWqqCgwOEBAAAAAEBtU6sDeZcuXTR//nytWrVKc+bM0a5du5ScnKzCwsJTviY9PV2RkZH2R2xsrBcrBgAAAADAObU6kPft21c33HCDOnXqpN69e+v999/X4cOH9dZbb53yNVOmTNGRI0fsjz179nixYgAAAAAAnFPrryH/q0aNGql9+/basWPHKdsEBwcrODjYi1UBAAAAAOA6nwrkR48e1c6dO3XzzTebXQoAAIBPKS4uliRt3LjR7X2XlJQoLy9PcXFxCg0NdXv/2dnZbu8TAGqDWh3I7777bvXv31+tW7fWvn37NHXqVAUGBuqmm24yuzQAAACfkpOTI0kaOXKkyZVUX3h4uNklAIBb1epA/vPPP+umm27Sr7/+qmbNmunSSy/Vhg0b1KxZM7NLAwAA8CkpKSmSJKvVqrCwMLf2nZ2drbS0NC1cuFA2m82tfVcIDw9Xu3btPNI3AJilVgfyJUuWmF0CAACAX2jatKlGjBjh0WPYbDZ17tzZo8cAAH9Sq1dZBwAAAADAXxHIAQAAAAAwAYEcAAAAAAATEMgBAAAAADABgRwAAAAAABMQyAEAAAAAMAGBHAAAAAAAExDIAQAAAAAwAYEcAAAAAAATEMgBAAAAADABgRwAAAAAABMQyAEAAAAAMAGBHAAAAAAAExDIAQAAAAAwAYEcAAAAAAATEMgBAAAAADABgRwAAAAAABMQyAEAAAAAMAGBHAAAAAAAExDIAQAAAAAwAYEcAAAAAAATEMgBAAAAADABgRwAAAAAABPUM7sAAAAA1D7FxcXKyclxqm12drbDn86yWq0KCwtzuTYA8BcEcgAAAFSSk5OjxMREl16TlpbmUvusrCx17tzZpdcAgD8hkAMAAKASq9WqrKwsp9qWlJQoLy9PcXFxCg0NdekYAFCXWQzDMMwuwpMKCgoUGRmpI0eOKCIiwuxyAAAAAAB+ztkcyqJuAAAAAACYgEAOAAAAAIAJCOQAAAAAAJiAQA4AAAAAgAkI5AAAAAAAmIBADgAAAACACQjkAAAAAACYgEAOAAAAAIAJCOQAAAAAAJiAQA4AAAAAgAkI5AAAAAAAmIBADgAAAACACQjkAAAAAACYoJ7ZBQCom8rKypSZman9+/crJiZGycnJCgwMNLssAAAAwGuYIQfgdRkZGUpISFDPnj01ePBg9ezZUwkJCcrIyDC7NAAAAMBrCOQAvCojI0MDBw5Ux44dtX79ehUWFmr9+vXq2LGjBg4cSCgHAABAnWExDMMwuwhPKigoUGRkpI4cOaKIiAizywHqtLKyMiUkJKhjx45avny5AgL+7zvB8vJypaSkaMuWLcrNzeX0dQAAAPgsZ3MoM+QAvCYzM1N5eXl64IEHHMK4JAUEBGjKlCnatWuXMjMzTaoQAAAA8B4COQCv2b9/vySpQ4cOVe6v2F7RDgAAAPBnBHIAXhMTEyNJ2rJlS5X7K7ZXtAMAAAD8GYEcgNckJycrLi5OM2bMUHl5ucO+8vJypaenq02bNkpOTjapQgAAAMB7COQAvCYwMFAzZ87UypUrlZKS4rDKekpKilauXKmnnnqKBd0AAABQJ9QzuwAAdUtqaqqWLl2qyZMnq1u3bvbtbdq00dKlS5WammpidQAAAID3+MQM+ezZsxUXF6eQkBB16dJFX3/9tdklAaiB1NRU7dixQ59++qkWL16sTz/9VLm5uYRxAAAA1Cm1fob8zTff1KRJkzR37lx16dJFs2bNUu/evbVt2zZFRUWZXR6AagoMDFSPHj3MLgMAAAAwTa2fIf/3v/+tkSNHatiwYTr33HM1d+5chYWF6dVXXzW7NAAAAAAAqq1Wz5AfP35cWVlZmjJlin1bQECAevXqpfXr11f5mtLSUpWWltqfFxQUeLxOwJ/98ssvWr3sNYWVOfe7VFxcpJ07f/RoTfHxbRUW1sCptk3bnKfkvjd4tB4AAACgOmp1IP/ll19UVlam5s2bO2xv3ry5cnJyqnxNenq6pk2b5o3ygDph+fLl+vmNB/RIj2DnX9T8zE1q5Oj/fzjhkbdK1axNR1mtVo+WBAAAALiqVgfy6pgyZYomTZpkf15QUKDY2FgTKwJ8W0pKilaXFegdH50hv+K+8wjjAAAAqJVqdSBv2rSpAgMDdeDAAYftBw4cUHR0dJWvCQ4OVnCwCzN5AE6radOmGjJ60pkbAgAAAHBJrV7ULSgoSImJiVqzZo19W3l5udasWaOuXbuaWBkAAAAAADVTq2fIJWnSpEm69dZbddFFF+niiy/WrFmzVFRUpGHDhpldGgAAAAAA1VbrA/nf//53HTp0SA8//LDy8/N1wQUXaNWqVZUWegMAAAAAwJdYDMMwzC7CkwoKChQZGakjR44oIiLC7HIAAAAAAH7O2Rxaq68hBwAAAADAXxHIAQAAAAAwAYEcAAAAAAATEMgBAAAAADABgRwAAAAAABMQyAEAAAAAMAGBHAAAAAAAExDIAQAAAAAwAYEcAAAAAAATEMgBAAAAADABgRwAAAAAABMQyAEAAAAAMAGBHAAAAAAAE9QzuwBPMwxDklRQUGByJQAAAACAuqAif1bk0VPx+0BeWFgoSYqNjTW5EgAAAABAXVJYWKjIyMhT7rcYZ4rsPq68vFz79u1TeHi4LBaL2eU4raCgQLGxsdqzZ48iIiLMLqdOYMy9jzH3Psbc+xhz72PMvY8x9z7G3PsYc+/z5TE3DEOFhYVq0aKFAgJOfaW438+QBwQEqGXLlmaXUW0RERE+9+HzdYy59zHm3seYex9j7n2Mufcx5t7HmHsfY+59vjrmp5sZr8CibgAAAAAAmIBADgAAAACACQjktVRwcLCmTp2q4OBgs0upMxhz72PMvY8x9z7G3PsYc+9jzL2PMfc+xtz76sKY+/2ibgAAAAAA1EbMkAMAAAAAYAICOQAAAAAAJiCQAwAAAABgAgJ5LbV27VpZLBYdPnzY6dfExcVp1qxZHqvJ3zHm3seYex9j7n2Mufcx5t7HmHsfY+59jLnn1cUxJpBXw9ChQ2WxWDRmzJhK+8aNGyeLxaKhQ4d6v7Az+N///qcBAwYoLi5OFovFpz64vjrmL730kpKTk3XWWWfprLPOUq9evfT111+bXZZTfHXMMzIydNFFF6lRo0Zq0KCBLrjgAr3++utml+UUXx3zv1qyZIksFotSUlLMLsUpvjrm8+fPl8VicXiEhISYXZZTfHXMJenw4cMaN26cYmJiFBwcrPbt2+v99983u6wz8tUx79GjR6XPucVi0dVXX212aWfkq2MuSbNmzdI555yj0NBQxcbGauLEiTp27JjZZZ2Rr475iRMn9M9//lPx8fEKCQnR+eefr1WrVpldVpV8dYydzUCzZ89WXFycQkJC1KVLF6/9m51AXk2xsbFasmSJSkpK7NuOHTumxYsXq1WrViZWdmrFxcVq27atHnvsMUVHR5tdjst8cczXrl2rm266SZ9++qnWr1+v2NhYXXXVVdq7d6/ZpTnFF8e8cePG+sc//qH169dr8+bNGjZsmIYNG6bVq1ebXZpTfHHMK+Tl5enuu+9WcnKy2aW4xFfHPCIiQvv377c/du/ebXZJTvPFMT9+/LiuvPJK5eXlaenSpdq2bZteeuklnX322WaX5hRfHPOMjAyHz/iWLVsUGBioG264wezSnOKLY7548WLdf//9mjp1qrKzs/XKK6/ozTff1AMPPGB2aU7xxTF/8MEH9cILL+jZZ5/V1q1bNWbMGF1//fX67rvvzC6tSr44xs5koDfffFOTJk3S1KlTtXHjRp1//vnq3bu3Dh486PH6COTV1LlzZ8XGxiojI8O+LSMjQ61atdKFF17o0La0tFQTJkxQVFSUQkJCdOmll+qbb75xaPP++++rffv2Cg0NVc+ePZWXl1fpmOvWrVNycrL9G8sJEyaoqKjI6Zr/9re/6cknn9SNN97ok/fy88UxX7RokW6//XZdcMEFslqtevnll1VeXq41a9a49uZN4otj3qNHD11//fWy2WyKj4/XnXfeqU6dOmndunWuvXmT+OKYS1JZWZmGDBmiadOmqW3bti691my+OuYWi0XR0dH2R/PmzV16vZl8ccxfffVV/fbbb1q+fLmSkpIUFxenyy67TOeff75rb94kvjjmjRs3dviMf/TRRwoLC/OZQO6LY/7ll18qKSlJgwcPVlxcnK666irddNNNPnN2ny+O+euvv64HHnhA/fr1U9u2bTV27Fj169dPM2fOdO3Ne4kvjrEzGejf//63Ro4cqWHDhuncc8/V3LlzFRYWpldffdXp41QXgbwGhg8frnnz5tmfv/rqqxo2bFildvfee6+WLVumBQsWaOPGjUpISFDv3r3122+/SZL27Nmj1NRU9e/fX5s2bdKIESN0//33O/Sxc+dO9enTRwMGDNDmzZv15ptvat26dRo/frxn32Qt4+tjXlxcrBMnTqhx48bV7sPbfHnMDcPQmjVrtG3bNnXv3r1afZjBF8f8n//8p6KionTbbbdV4x2bzxfH/OjRo2rdurViY2N13XXX6X//+1813rl5fG3M33vvPXXt2lXjxo1T8+bN1aFDB82YMUNlZWXVHAHv87UxP9krr7yiG2+8UQ0aNKh2H97ma2PerVs3ZWVl2QP4jz/+qPfff1/9+vWrzts3ha+NeWlpaaVLjkJDQ2v1RIKvjfGZHD9+XFlZWerVq5d9W0BAgHr16qX169e77TinZMBlt956q3HdddcZBw8eNIKDg428vDwjLy/PCAkJMQ4dOmRcd911xq233moYhmEcPXrUqF+/vrFo0SL7648fP260aNHCeOKJJwzDMIwpU6YY5557rsMx7rvvPkOS8fvvvxuGYRi33XabMWrUKIc2mZmZRkBAgFFSUmIYhmG0bt3a+M9//uPUe3ClbW3gD2NuGIYxduxYo23btvbX12a+POaHDx82GjRoYNSrV88IDg42XnnllRqMhPf46phnZmYaZ599tnHo0CGH9+ELfHXMv/zyS2PBggXGd999Z6xdu9a45pprjIiICGPPnj01HBHP89UxP+ecc4zg4GBj+PDhxrfffmssWbLEaNy4sfHII4/UcEQ8z1fH/K+++uorQ5Lx1VdfVWMEvM+Xx/zpp5826tevb9SrV8+QZIwZM6YGI+E9vjrmN910k3Huueca27dvN8rKyowPP/zQCA0NNYKCgmo4Iu7nq2P8V1W13bt3ryHJ+PLLLx2233PPPcbFF1/sVL81Uc/zkd9/NWvWTFdffbXmz58vwzB09dVXq2nTpg5tdu7cqRMnTigpKcm+rX79+rr44ouVnZ0tScrOzlaXLl0cXte1a1eH599//702b96sRYsW2bcZhqHy8nLt2rVLNpvN3W+vVvLlMX/ssce0ZMkSrV271mcWX5J8c8zDw8O1adMmHT16VGvWrNGkSZPUtm1b9ejRw5W3bhpfGvPCwkLdfPPNeumllyrV6Et8acwr+vxrv926dZPNZtMLL7ygRx991Pk3biJfG/Py8nJFRUXpxRdfVGBgoBITE7V37149+eSTmjp1qsvv3wy+NuZ/9corr6hjx466+OKLXXqd2XxtzNeuXasZM2bo+eefV5cuXbRjxw7deeedevTRR/XQQw+5/P7N4Gtj/vTTT2vkyJGyWq2yWCyKj4/XsGHDvHKqdHX52hjXdgTyGho+fLj9lInZs2d77DhHjx7V6NGjNWHChEr7ausCCp7ii2P+1FNP6bHHHtPHH3+sTp06uatEr/G1MQ8ICFBCQoIk6YILLlB2drbS09N9JpBLvjPmO3fuVF5envr372/fVl5eLkmqV6+etm3bpvj4ePcV7EG+MuZVqV+/vi688ELt2LGjpuV5lS+NeUxMjOrXr6/AwED7NpvNpvz8fB0/flxBQUFuq9eTfGnMKxQVFWnJkiX65z//6a7yvMqXxvyhhx7SzTffrBEjRkiSOnbsqKKiIo0aNUr/+Mc/FBDgG1e7+tKYN2vWTMuXL9exY8f066+/qkWLFrr//vtr/XosvjTGZ9K0aVMFBgbqwIEDDtsPHDjglYWwCeQ11KdPHx0/flwWi0W9e/eutD8+Pl5BQUH64osv1Lp1a0l/3t7gm2++0V133SXpz7/Q33vvPYfXbdiwweF5586dtXXrVnvIqMt8bcyfeOIJTZ8+XatXr9ZFF11Uo77M4mtjfrLy8nKVlpa6tU9P85Uxt1qt+uGHHxy2PfjggyosLNTTTz+t2NjYavVrBl8Z86qUlZXphx9+8KnrPCXfGvOkpCQtXrxY5eXl9lCyfft2xcTE+EwYl3xrzCu8/fbbKi0tVVpaWo37MoMvjXlxcXGl0F3xJZRhGNXu19t8acwrhISE6Oyzz9aJEye0bNkyDRo0qMZ9epIvjvGpBAUFKTExUWvWrLHftrViEWZvrNflG19z1WKBgYHKzs7W1q1bHb41r9CgQQONHTtW99xzj1atWqWtW7dq5MiRKi4uti9+NGbMGOXm5uqee+7Rtm3btHjxYs2fP9+hn/vuu09ffvmlxo8fr02bNik3N1fvvvuuSx+S48ePa9OmTdq0aZOOHz+uvXv3atOmTT43o+JLY/7444/roYce0quvvqq4uDjl5+crPz9fR48erdEYeJsvjXl6ero++ugj/fjjj8rOztbMmTP1+uuv+9w/5HxlzENCQtShQweHR6NGjRQeHq4OHTr4VFDxlTGX/lxE78MPP9SPP/6ojRs3Ki0tTbt377bPavkKXxrzsWPH6rffftOdd96p7du367///a9mzJihcePG1WgMvM2XxrzCK6+8opSUFDVp0qRa79lsvjTm/fv315w5c7RkyRLt2rVLH330kR566CH179+/ytprK18a86+++koZGRn68ccflZmZqT59+qi8vFz33ntvjcbA03xpjJ3JQJMmTdJLL72kBQsWKDs7W2PHjlVRUVGVi9W5ncevUvdDZ1qw6K8LGhiGYZSUlBh33HGH0bRpUyM4ONhISkoyvv76a4fXrFixwkhISDCCg4ON5ORk49VXX3VY0MAwDOPrr782rrzySqNhw4ZGgwYNjE6dOhnTp0+37z/Tgga7du0yJFV6XHbZZS6OgPf56pi3bt26yjGfOnWqiyPgfb465v/4xz+MhIQEIyQkxDjrrLOMrl27GkuWLHH17ZvCV8fc1fdRm/jqmN91111Gq1atjKCgIKN58+ZGv379jI0bN7r69k3hq2NuGH8uptelSxcjODjYaNu2rTF9+nTjjz/+cOXtm8KXxzwnJ8eQZHz44YeuvGXT+eqYnzhxwnjkkUeM+Ph4IyQkxIiNjTVuv/12h2PUVr465mvXrjVsNpsRHBxsNGnSxLj55puNvXv3uvr2vcJXx9jZDPTss8/a/269+OKLjQ0bNjgzLDVmMQwfOv8EAAAAAAA/wSnrAAAAAACYgEAOAAAAAIAJCOQAAAAAAJiAQA4AAAAAgAkI5AAAAAAAmIBADgAAAACACQjkAAAAAACYgEAOAAAAAIAJCOQAAMBpa9eulcVi0eHDh51+TVxcnGbNmuWxmgAA8FUEcgAA/MjQoUNlsVg0ZsyYSvvGjRsni8WioUOHer8wAABQCYEcAAA/ExsbqyVLlqikpMS+7dixY1q8eLFatWplYmUAAOCvCOQAAPiZzp07KzY2VhkZGfZtGRkZatWqlS688EL7ttLSUk2YMEFRUVEKCQnRpZdeqm+++cahr/fff1/t27dXaGioevbsqby8vErHW7dunZKTkxUaGqrY2FhNmDBBRUVFHnt/AAD4CwI5AAB+aPjw4Zo3b579+auvvqphw4Y5tLn33nu1bNkyLViwQBs3blRCQoJ69+6t3377TZK0Z88epaamqn///tq0aZNGjBih+++/36GPnTt3qk+fPhowYIA2b96sN998U+vWrdP48eM9/yYBAPBxBHIAAPxQWlqa1q1bp927d2v37t364osvlJaWZt9fVFSkOXPm6Mknn1Tfvn117rnn6qWXXlJoaKheeeUVSdKcOXMUHx+vmTNn6pxzztGQIUMqXX+enp6uIUOG6K677lK7du3UrVs3PfPMM3rttdd07Ngxb75lAAB8Tj2zCwAAAO7XrFkzXX311Zo/f74Mw9DVV1+tpk2b2vfv3LlTJ06cUFJSkn1b/fr1dfHFFys7O1uSlJ2drS5dujj027VrV4fn33//vTZv3qxFixbZtxmGofLycu3atUs2m80Tbw8AAL9AIAcAwE8NHz7cfur47NmzPXKMo0ePavTo0ZowYUKlfSwgBwDA6RHIAQDwU3369NHx48dlsVjUu3dvh33x8fEKCgrSF198odatW0uSTpw4oW+++UZ33XWXJMlms+m9995zeN2GDRscnnfu3Flbt25VQkKC594IAAB+imvIAQDwU4GBgcrOztbWrVsVGBjosK9BgwYaO3as7rnnHq1atUpbt27VyJEjVVxcrNtuu02SNGbMGOXm5uqee+7Rtm3btHjxYs2fP9+hn/vuu09ffvmlxo8fr02bNik3N1fvvvsui7oBAOAEAjkAAH4sIiJCERERVe577LHHNGDAAN18883q3LmzduzYodWrV+uss86S9Ocp58uWLdPy5ct1/vnna+7cuZoxY4ZDH506ddJnn32m7du3Kzk5WRdeeKEefvhhtWjRwuPvDQAAX2cxDMMwuwgAAAAAAOoaZsgBAAAAADABgRwAAAAAABMQyAEAAAAAMAGBHAAAAAAAExDIAQAAAAAwAYEcAAAAAAATEMgBAAAAADABgRwAAAAAABMQyAEAAAAAMAGBHAAAAAAAExDIAQAAAAAwwf8DRZamujTi7wIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+QAAAIjCAYAAACKx9GpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABYjklEQVR4nO3dfXxT5f3/8XdaaJpAW0HuihYCbaHhRrF1KtRyo0xERSvgptiNG2GAIEOYKOi48YY6kanbFNEJqIg4saJjDkQULQJOW9EhCRQkDJHi3WgLrYW15/cHv+ZrbJGkTXqa9vV8PPLAnHOd63xyEZB3r3OuYzEMwxAAAAAAAKhXEWYXAAAAAABAU0QgBwAAAADABARyAAAAAABMQCAHAAAAAMAEBHIAAAAAAExAIAcAAAAAwAQEcgAAAAAATEAgBwAAAADABARyAAAAAABMQCAHANTa/PnzZbFYzC6jQRgzZowcDofPNovFovnz55tSj1k2b94si8WizZs3n7HtwIEDNXDgwDO2+9///qdZs2YpISFBERERyszMrHOdDU3VuK1Zs8bsUgJW2++5x+ORxWLRihUrgl4TAIQLAjkAhCGLxeLXy59QdCalpaWaP39+UPpCw1QVBmt63XjjjWaXp2XLlmnRokUaOXKknn32Wd1+++0hPd/AgQNPOx4pKSkhPXdtrVixwlvjli1bqu03DEMJCQmyWCy65pprTKgQAFCTZmYXAAAI3PPPP+/z/rnnntPGjRurbXc6nXU+V2lpqRYsWCBJ1WYz77nnHt111111PgcahmnTpulnP/uZz7Yfz/qb4e2339Y555yjRx55pN7Oee655yo7O7va9ri4uHqroTaio6O1atUqXXrppT7b3333XX3xxReyWq0mVQYAqAmBHADCUFZWls/77du3a+PGjdW2h1qzZs3UrFnD+V9JaWmp7Ha72WU0SMePH1eLFi1+sk1GRoZGjhxZTxX576uvvtJZZ50VtP4qKyt14sQJRUdHn7ZNXFxcvf95CoarrrpKL7/8sv70pz/5/NlctWqV0tLS9M0335hYHQDgx7hkHQAaqcrKSj366KPq2bOnoqOj1b59e02cOFH//e9/fdp99NFHGjJkiNq0aSObzaYuXbpo3Lhxkk7d49m2bVtJ0oIFC7yXxFbdL1rTPeQWi0VTp07V2rVr1atXL1mtVvXs2VPr16+vVuPmzZt14YUXKjo6WomJiVq6dKnf96UPHDhQvXr1Ul5envr37y+73a45c+ZIksrLyzVv3jwlJSXJarUqISFBs2bNUnl5ebV+Vq5cqYsuukh2u12tWrVS//799eabb3r3v/baa7r66qvVsWNHWa1WJSYm6r777lNFRcUZa/RH1eXiL730kubMmaMOHTqoRYsWuvbaa3Xw4MFq7T/44ANdeeWViouLk91u14ABA/T+++/7tKkaw127dmnUqFFq1apVtRnT2vj44481dOhQxcbGqmXLlrr88su1fft2v4596qmnlJiYKJvNposuuki5ublnPKbqHuN33nlHn332WbVbMY4fP66ZM2cqISFBVqtV3bt318MPPyzDMHz6qfpOvvDCC+rZs6esVmuN38dAHThwQLfeequ6d+8um82ms88+WzfccIM8Hk+1tkePHtXtt98uh8Mhq9Wqc889V7/+9a+rBeTKyko98MADOvfccxUdHa3LL79ce/fu9bumm266Sd9++602btzo3XbixAmtWbNGo0aNqvEYf8exvLxct99+u9q2bauYmBhde+21+uKLL2rs89ChQxo3bpzat2/v/Ttg2bJlfn8OAGgqGs60BgAgqCZOnKgVK1Zo7NixmjZtmvbv36+//OUv+vjjj/X++++refPm+uqrr3TFFVeobdu2uuuuu3TWWWfJ4/EoJydHktS2bVstWbJEkydP1vXXX6/hw4dLks4777yfPPeWLVuUk5OjW2+9VTExMfrTn/6kESNG6D//+Y/OPvtsSafC3ZVXXqn4+HgtWLBAFRUVuvfee70/APDHt99+q6FDh+rGG29UVlaW2rdvr8rKSl177bXasmWLfvOb38jpdOrf//63HnnkEe3Zs0dr1671Hr9gwQLNnz9f/fr107333quoqCh98MEHevvtt3XFFVdIOnVvbsuWLTVjxgy1bNlSb7/9tubOnavi4mItWrQokN+Sn/TAAw/IYrHozjvv1FdffaVHH31UgwcP1o4dO2Sz2SSdunR76NChSktL07x58xQREaHly5frsssuU25uri666CKfPm+44QYlJydr4cKF1cJVTUpKSqoFxNatWysiIkKfffaZMjIyFBsbq1mzZql58+ZaunSpBg4cqHfffVcXX3zxaft95plnNHHiRPXr10/Tp0/X559/rmuvvVatW7dWQkLCaY9r27atnn/+eT3wwAM6duyY9xJyp9MpwzB07bXX6p133tEtt9yiPn36aMOGDbrjjjt06NChape3v/322/rb3/6mqVOnqk2bNme8FL+ioqLG2WSbzea90uDDDz/U1q1bdeONN+rcc8+Vx+PRkiVLNHDgQO3atct7tcaxY8eUkZEhl8ulcePGKTU1Vd98841ef/11ffHFF2rTpo23/wcffFARERH63e9+p6KiIj300EO6+eab9cEHH/xkvVUcDof69u2rF198UUOHDpUk/fOf/1RRUZFuvPFG/elPf/JpH8g4jh8/XitXrtSoUaPUr18/vf3227r66qur1XDkyBFdcskl3h+EtG3bVv/85z91yy23qLi4WNOnT/frswBAk2AAAMLelClTjB/+lZ6bm2tIMl544QWfduvXr/fZ/uqrrxqSjA8//PC0fX/99deGJGPevHnV9s2bN8/48f9KJBlRUVHG3r17vds++eQTQ5Lx5z//2btt2LBhht1uNw4dOuTdVlBQYDRr1qxanzUZMGCAIcl48sknfbY///zzRkREhJGbm+uz/cknnzQkGe+//773XBEREcb1119vVFRU+LStrKz0/ndpaWm1c0+cONGw2+3G999/7902evRoo3Pnzj7tTjduP/TOO+8YkoxzzjnHKC4u9m7/29/+ZkgyHnvsMW9NycnJxpAhQ6rV16VLF+PnP/+5d1vV78tNN930k+f+cQ01vfbv328YhmFkZmYaUVFRxr59+7zHffnll0ZMTIzRv3//an298847hmEYxokTJ4x27doZffr0McrLy73tnnrqKUOSMWDAgDPWN2DAAKNnz54+29auXWtIMu6//36f7SNHjjQsFovP90+SERERYXz22Wd+jUfVd6um18SJE73tavpubNu2zZBkPPfcc95tc+fONSQZOTk51dpX/V5WjZvT6fQZp8cee8yQZPz73//+yZqXL1/u/bP8l7/8xYiJifHWd8MNNxiDBg0yDMMwOnfubFx99dXe4/wdxx07dhiSjFtvvdWn3ahRo6p9z2+55RYjPj7e+Oabb3za3njjjUZcXJy3rv379xuSjOXLl//kZwOAxoxL1gGgEXr55ZcVFxenn//85/rmm2+8r7S0NLVs2VLvvPOOJHnvy123bp1OnjwZtPMPHjxYiYmJ3vfnnXeeYmNj9fnnn0s6Nfv41ltvKTMzUx07dvS2S0pK8s7q+cNqtWrs2LE+215++WU5nU6lpKT4fPbLLrtMkryffe3ataqsrNTcuXMVEeH7v8MfXjJfNTst/d8MckZGhkpLS+V2u/2u9Ux+/etfKyYmxvt+5MiRio+P1xtvvCFJ2rFjhwoKCjRq1Ch9++233s91/PhxXX755XrvvfdUWVnp0+ekSZMCqmHu3LnauHGjz6tDhw6qqKjQm2++qczMTHXt2tXbPj4+XqNGjdKWLVtUXFxcY58fffSRvvrqK02aNElRUVHe7WPGjKnTAmlvvPGGIiMjNW3aNJ/tM2fOlGEY+uc//+mzfcCAAerRo4ff/TscjmpjsXHjRp/Z3R9+N06ePKlvv/1WSUlJOuuss5Sfn+/d98orr+j888/X9ddfX+08P749Y+zYsT7jlJGRIUnePzv++MUvfqGysjKtW7dOJSUlWrdu3WkvV/d3HKu+hz9u9+PZbsMw9Morr2jYsGEyDMPnz+CQIUNUVFTkMzYA0NRxyToANEIFBQUqKipSu3btatz/1VdfSToVUkaMGKEFCxbokUce0cCBA5WZmalRo0bVaTXmTp06VdvWqlUr7/3rX331lcrKypSUlFStXU3bTuecc87xCS/Sqc/ucrlOe+l71Wfft2+fIiIizhjSPvvsM91zzz16++23q4XOoqIiv2s9k+TkZJ/3FotFSUlJ3vuRCwoKJEmjR48+bR9FRUVq1aqV932XLl0CqqF3794aPHhwte2FhYUqLS1V9+7dq+1zOp2qrKzUwYMH1bNnz2r7Dxw4IKn652vevLlPuA/UgQMH1LFjR58fYlTV88PzVgl0LFq0aFHjWPxQWVmZsrOztXz5ch06dMjntoAffjf27dunESNG+HXeH//Zqfr9/PHaDz+lbdu2Gjx4sFatWqXS0lJVVFScdrE+f8fxwIEDioiI8PlBm6Rq34mvv/5aR48e1VNPPaWnnnqqxnNW/RkEABDIAaBRqqysVLt27fTCCy/UuL8qrFosFq1Zs0bbt2/X3//+d23YsEHjxo3T4sWLtX37drVs2bJW54+MjKxxu+HHfcyB+OEMZZXKykr17t1bf/zjH2s85qfuWf6xo0ePasCAAYqNjdW9996rxMRERUdHKz8/X3feeWe1GelQqjrXokWL1KdPnxrb/Pj3q6bxaapCMRa33Xabli9frunTp6tv376Ki4vzPru9tt+NYP3ZGTVqlCZMmKDCwkINHTo0qKvU/5Sqz52VlXXaHx6daQ0KAGhKCOQA0AglJibqrbfeUnp6ul9B5JJLLtEll1yiBx54QKtWrdLNN9+s1atXa/z48X6teB6odu3aKTo6usbVowNZUbomiYmJ+uSTT3T55Zf/ZO2JiYmqrKzUrl27ThtwN2/erG+//VY5OTnq37+/d/v+/fvrVGNNqmbAqxiGob1793rDS9XMZGxs7BlnboOtbdu2stvt2r17d7V9brdbERERp/1BR+fOnSWd+nxVtw1Ipy7x3r9/v84///xa1dS5c2e99dZbKikp8ZndrbqNoOq8obRmzRqNHj1aixcv9m77/vvvdfToUZ92iYmJ2rlzZ8jr+aHrr79eEydO1Pbt2/XSSy+dtp2/49i5c2dVVlZq3759PrPiP/5OVK3AXlFRUe/fUwAIR9xDDgCN0C9+8QtVVFTovvvuq7bvf//7nzcw/Pe//60281YVTqseEVa1UvSPQ0ZdREZGavDgwVq7dq2+/PJL7/a9e/dWu/c3UL/4xS906NAhPf3009X2lZWV6fjx45KkzMxMRURE6N577602m1k1JlWzlT8coxMnTuiJJ56oU401ee6551RSUuJ9v2bNGh0+fNh7T31aWpoSExP18MMP69ixY9WO//rrr4NeU5XIyEhdccUVeu2113we6XXkyBGtWrVKl156qWJjY2s89sILL1Tbtm315JNP6sSJE97tK1asqNN36qqrrlJFRYX+8pe/+Gx/5JFHZLFYAlqLoLYiIyOr/fn585//XO2ReCNGjNAnn3yiV199tVofwb5qpErLli21ZMkSzZ8/X8OGDTttO3/HserXH6/S/uijj/q8j4yM1IgRI/TKK6/U+EOIUH5PASAcMUMOAI3QgAEDNHHiRGVnZ2vHjh264oor1Lx5cxUUFOjll1/WY489ppEjR+rZZ5/VE088oeuvv16JiYkqKSnR008/rdjYWF111VWSTl3q26NHD7300kvq1q2bWrdurV69eqlXr151qnH+/Pl68803lZ6ersmTJ3tDQa9evbRjx45a9/urX/1Kf/vb3zRp0iS98847Sk9PV0VFhdxut/72t79pw4YNuvDCC5WUlKS7775b9913nzIyMjR8+HBZrVZ9+OGH6tixo7Kzs9WvXz+1atVKo0eP1rRp02SxWPT888+HJES1bt1al156qcaOHasjR47o0UcfVVJSkiZMmCBJioiI0F//+lcNHTpUPXv21NixY3XOOefo0KFDeueddxQbG6u///3vQa+ryv3336+NGzfq0ksv1a233qpmzZpp6dKlKi8v10MPPXTa45o3b677779fEydO1GWXXaZf/vKX2r9/v5YvX16ne8iHDRumQYMG6e6775bH49H555+vN998U6+99pqmT59e7V7nQBUVFWnlypU17svKypIkXXPNNXr++ecVFxenHj16aNu2bXrrrbe8j/arcscdd2jNmjW64YYbNG7cOKWlpem7777T66+/rieffLLWVwmcyU+tN1DF33Hs06ePbrrpJj3xxBMqKipSv379tGnTphqvaHnwwQf1zjvv6OKLL9aECRPUo0cPfffdd8rPz9dbb72l7777LuifFQDClhlLuwMAguvHjz2r8tRTTxlpaWmGzWYzYmJijN69exuzZs0yvvzyS8MwDCM/P9+46aabjE6dOhlWq9Vo166dcc011xgfffSRTz9bt2410tLSjKioKJ9HHJ3usWdTpkypVkvnzp2N0aNH+2zbtGmTccEFFxhRUVFGYmKi8de//tWYOXOmER0dfcbPXNOjsKqcOHHC+MMf/mD07NnTsFqtRqtWrYy0tDRjwYIFRlFRkU/bZcuWGRdccIG33YABA4yNGzd697///vvGJZdcYthsNqNjx47GrFmzjA0bNvg82ssw6v7YsxdffNGYPXu20a5dO8NmsxlXX321ceDAgWrtP/74Y2P48OHG2WefbVitVqNz587GL37xC2PTpk3eNlW/L19//fVPnvvHNbz88ss/2S4/P98YMmSI0bJlS8NutxuDBg0ytm7dWmNfPxwbwzCMJ554wujSpYthtVqNCy+80HjvvfeMAQMG1PqxZ4ZhGCUlJcbtt99udOzY0WjevLmRnJxsLFq0yOexcIZx+u/kT51Pp3ns2Q+/7//973+NsWPHGm3atDFatmxpDBkyxHC73TV+17/99ltj6tSpxjnnnGNERUUZ5557rjF69Gjvo8FO93vg76PBfvjYs5/y48eeGYb/41hWVmZMmzbNOPvss40WLVoYw4YNMw4ePFjj9/zIkSPGlClTjISEBKN58+ZGhw4djMsvv9x46qmnAv5sANCYWQwjRNdKAQBQC5mZmfrss8+q3VPdWG3evFmDBg3Syy+/fNqVsAEAQOPEPeQAANOUlZX5vC8oKNAbb7yhgQMHmlMQAABAPeIecgCAabp27aoxY8aoa9euOnDggJYsWaKoqCjNmjXL7NIAAABCjkAOADDNlVdeqRdffFGFhYWyWq3q27evFi5cqOTkZLNLAwAACDnuIQcAAAAAwATcQw4AAAAAgAkI5AAAAAAAmKDR30NeWVmpL7/8UjExMbJYLGaXAwAAAABo5AzDUElJiTp27KiIiNPPgzf6QP7ll18qISHB7DIAAAAAAE3MwYMHde655552v6mBfMmSJVqyZIk8Ho8kqWfPnpo7d66GDh0qSfr+++81c+ZMrV69WuXl5RoyZIieeOIJtW/f3u9zxMTESDo1ELGxsUH/DAAAAAAA/FBxcbESEhK8efR0TF1l/e9//7siIyOVnJwswzD07LPPatGiRfr444/Vs2dPTZ48Wf/4xz+0YsUKxcXFaerUqYqIiND777/v9zmKi4sVFxenoqIiAjkAAAAAIOT8zaEN7rFnrVu31qJFizRy5Ei1bdtWq1at0siRIyVJbrdbTqdT27Zt0yWXXOJXfwRyAAAAAEB98jeHNphV1isqKrR69WodP35cffv2VV5enk6ePKnBgwd726SkpKhTp07atm3bafspLy9XcXGxzwsAAAAAgIbG9ED+73//Wy1btpTVatWkSZP06quvqkePHiosLFRUVJTOOussn/bt27dXYWHhafvLzs5WXFyc98WCbgAAAACAhsj0QN69e3ft2LFDH3zwgSZPnqzRo0dr165dte5v9uzZKioq8r4OHjwYxGoBAAAAAAgO0x97FhUVpaSkJElSWlqaPvzwQz322GP65S9/qRMnTujo0aM+s+RHjhxRhw4dTtuf1WqV1WoNddkAAAAAANSJ6TPkP1ZZWany8nKlpaWpefPm2rRpk3ff7t279Z///Ed9+/Y1sUIAAAAAAOrO1Bny2bNna+jQoerUqZNKSkq0atUqbd68WRs2bFBcXJxuueUWzZgxQ61bt1ZsbKxuu+029e3b1+8V1gEAAAAAaKhMDeRfffWVfv3rX+vw4cOKi4vTeeedpw0bNujnP/+5JOmRRx5RRESERowYofLycg0ZMkRPPPGEmSUDAAAAABAUDe455MHGc8gBAAAAAPUp7J5DDgAAAABAU0IgBwAAAADABARyAAAAAABMQCAHAAAAAMAEBHIAAAAAAExAIAcAAAAAwAQEcgAAAAAATEAgBwAAAADABM3MLgAAAOBMSktL5Xa7/WpbVlYmj8cjh8Mhm83m9zlSUlJkt9trWyIAAAEjkAMAgAbP7XYrLS0tpOfIy8tTampqSM8BAMAPEcgBoImoqKhQbm6uDh8+rPj4eGVkZCgyMtLssgC/pKSkKC8vz6+2LpdLWVlZWrlypZxOZ0DnAACgPhHIAaAJyMnJ0cyZM+XxeLzbHA6HFi9erOHDh5tXGOAnu90e8Oy10+lkxhsA0KCxqBsANHI5OTkaOXKkevfurW3btqmkpETbtm1T7969NXLkSOXk5JhdIgAAQJNkMQzDMLuIUCouLlZcXJyKiooUGxtrdjkAUK8qKiqUlJSk3r17a+3atYqI+L+fw1ZWViozM1M7d+5UQUEBl6+j0cjPz1daWhr3hAMATONvDmWGHAAasdzcXHk8Hs2ZM8cnjEtSRESEZs+erf379ys3N9ekCgEAAJouAjkANGKHDx+WJPXq1avG/VXbq9oBAACg/rCoGxo1nluLpi4+Pl6StHPnTl1yySXV9u/cudOnHQAAAOoPgRyNGs+tRVOXkZEhh8OhhQsX1ngPeXZ2trp06aKMjAwTqwQAAGiaCORo1HhuLZq6yMhILV68WCNHjlRmZqZmz56tXr16aefOncrOzta6deu0Zs0aFnQDAAAwAYEcjRrPrQWk4cOHa82aNZo5c6b69evn3d6lSxetWbOG55ADAACYhEAOAE3A8OHDdd111yk3N1eHDx9WfHy8MjIymBkHAAAwEYEcAJqIyMhIDRw40OwyAAAA8P/x2DMAAAAAAExAIAcAAAAAwARcsl6PeCY2AAAAAKAKgbwe8UxsAAAAAEAVAnk94pnYAAAAAIAqBPJ6xDOxAQAAAABVWNQNAAAAAAATEMgBAAAAADABgRwAAAAAABMQyAEAAAAAMAGBHAAAAAAAExDIAQAAAAAwAYEcAAAAAAATEMgBAAAAADABgRwAAAAAABMQyAEAAAAAMAGBHAAAAAAAExDIAQAAAAAwAYEcAAAAAAATEMgBAAAAADABgRwAAAAAABMQyAEAAAAAMAGBHAAAAAAAExDIAQAAAAAwAYEcAAAAAAATEMgBAAAAADABgRwAAAAAABMQyAEAAAAAMAGBHAAAAAAAExDIAQAAAAAwAYEcAAAAAAATEMgBAAAAADABgRwAAAAAABMQyAEAAAAAMAGBHAAAAAAAEzQzuwAAANA0FRQUqKSkJOj9ulwun19DISYmRsnJySHrHwDQNBDIAQBAvSsoKFC3bt1Ceo6srKyQ9r9nzx5COQCgTgjkAACg3lXNjK9cuVJOpzOofZeVlcnj8cjhcMhmswW1b+nUzHtWVlZIZvcBAE0LgRwAAJjG6XQqNTU16P2mp6cHvU8AAILN1EXdsrOz9bOf/UwxMTFq166dMjMztXv3bp82AwcOlMVi8XlNmjTJpIoBAAAAAAgOUwP5u+++qylTpmj79u3auHGjTp48qSuuuELHjx/3aTdhwgQdPnzY+3rooYdMqhgAAAAAgOAw9ZL19evX+7xfsWKF2rVrp7y8PPXv39+73W63q0OHDvVdHgAAAAAAIdOgnkNeVFQkSWrdurXP9hdeeEFt2rRRr169NHv2bJWWlp62j/LychUXF/u8AAAAAABoaBrMom6VlZWaPn260tPT1atXL+/2UaNGqXPnzurYsaM+/fRT3Xnnndq9e7dycnJq7Cc7O1sLFiyor7IBAAAAAKiVBhPIp0yZop07d2rLli0+23/zm994/7t3796Kj4/X5Zdfrn379ikxMbFaP7Nnz9aMGTO874uLi5WQkBC6wgEAAAAAqIUGEcinTp2qdevW6b333tO55577k20vvvhiSdLevXtrDORWq1VWqzUkdQIAAAAAECymBnLDMHTbbbfp1Vdf1ebNm9WlS5czHrNjxw5JUnx8fIirAwAAAAAgdEwN5FOmTNGqVav02muvKSYmRoWFhZKkuLg42Ww27du3T6tWrdJVV12ls88+W59++qluv/129e/fX+edd56ZpQMAAAAAUCemBvIlS5ZIkgYOHOizffny5RozZoyioqL01ltv6dFHH9Xx48eVkJCgESNG6J577jGhWgAAAAAAgsf0S9Z/SkJCgt599916qgYAAAAAgPrToJ5DDgAAAABAU0EgBwAAAADABA3isWcAgNorLS2V2+32q21ZWZk8Ho8cDodsNpvf50hJSZHdbq9tiQAAAKgBgRxhp6CgQCUlJUHv1+Vy+fwaCjExMUpOTg5Z/2ia3G630tLSQnqOvLw8paamhvQcAAAATQ2BHGGloKBA3bp1C+k5srKyQtr/nj17COUIqpSUFOXl5fnV1uVyKSsrSytXrpTT6QzoHAAAAAguAjnCStXMeKBhwh+1vZTXX1VBKBSz+2ja7HZ7wLPXTqeTGW8AAACTEcjriMunzRGqMJGenh70PgEAAACgJgTyOuDyaQAAAABAbRHI64DLpwEAAAAAtUUgDwIunwYAAAAABCrC7AIAAAAAAGiKCOQAAAAAAJiAQA4AAAAAgAm4hxwAGiAeqQgAAND4EcgBoIHhkYoAAABNA4EcABoYHqmIpqJDS4tsR/dIX4bXHXS2o3vUoaXF7DIAAI0AgRwAGigeqYjGbmJalJzvTZTeM7uSwDh1qnYAAOqKQA4AAEyxNO+Efjl3hZwpKWaXEhCX262li0fpWrMLAQCEPQI5AAAwReExQ2VndZM69jG7lICUFVaq8JhhdhkAgEYgvG7aAgAAAACgkSCQAwAAAABgAgI5AAAAAAAmIJADAAAAAGACAjkAAAAAACYgkAMAAAAAYAICOQAAAAAAJiCQAwAAAABggmZmFwAAAAAAaBpKS0vldrv9altWViaPxyOHwyGbzeb3OVJSUmS322tbYr0ikNdRh5YW2Y7ukb4Mr4sNbEf3qENLi9llADgN/m4BAACNkdvtVlpaWkjPkZeXp9TU1JCeI1gI5HU0MS1KzvcmSu+ZXUlgnDpVezgiqKAp4O8WAADQGKWkpCgvL8+vti6XS1lZWVq5cqWcTmdA5wgXBPI6Wpp3Qr+cu0LOMPpNlySX262li0fpWrMLqQWCCpoC/m5BY1daWipJys/PD3rftb3E0V8ulyvofQJAU2G32wOevXY6nWEz4x0oAnkdFR4zVHZWN6ljH7NLCUhZYaUKjxlml1ErBBU0Bfzdgsau6v7BCRMmmFxJ7cXExJhdAgAgzBHIEXYIKgAQ/jIzMyWFZuGd2l7iGIiYmBglJyeHpG8AQNNBIAcAAPWuTZs2Gj9+fEjP0ZgvcQQANA7htSoWAAAAAACNBIEcAAAAAAATEMgBAAAAADAB95ADAAAAAGqtoKBAJSUlQe+36jGToXzcpNmLdBLIAQAAAAC1UlBQoG7duoX0HFlZWSHtf8+ePaaFcgI5AAAAAKBWqmbGQ/GoybKyMnk8HjkcDtlstqD2Lf3fYzJDMbvvLwI5AAAAAKBOQvWoyfT09KD32ZCwqBsAAAAAACYgkAMAAAAAYAICOQAAAAAAJiCQAwAAAABgAhZ1AwAAAADUWoeWFtmO7pG+DK/5XtvRPerQ0mJqDQRyAAAAAECtTUyLkvO9idJ7ZlcSGKdO1W4mAjnCSmlpqSQpPz8/6H3Xx3MOAQAAgMZmad4J/XLuCjlTUswuJSAut1tLF4/StSbWQCBHWHG73ZKkCRMmmFxJ7cXExJhdAgAAABA0hccMlZ3VTerYx+xSAlJWWKnCY4apNRDIEVYyMzMlSSkpKbLb7UHt2+VyKSsrSytXrpTT6Qxq31ViYmKUnJwckr4BAAAAhBcCOcJKmzZtNH78+JCew+l0KjU1NaTnAAAAAIDwWgYPAAAAAIBGgkAOAAAAAIAJCOQAAAAAAJiAQA4AAAAAgAkI5AAAAAAAmIBADgAAAACACXjsGQA0MKWlpZKk/Pz8oPddVlYmj8cjh8Mhm80W9P5dLlfQ+wQAAGisCOQA0MC43W5J0oQJE0yupPZiYmLMLgEAAKDBI5ADQAOTmZkpSUpJSZHdbg9q3y6XS1lZWVq5cqWcTmdQ+64SExOj5OTkkPQNAADQmBDIAaCBadOmjcaPHx/SczidTqWmpob0HAAAAPhpBPI64D5PAAAAAEBtmRrIs7OzlZOTI7fbLZvNpn79+ukPf/iDunfv7m3z/fffa+bMmVq9erXKy8s1ZMgQPfHEE2rfvr2JlZ/CfZ4AAAAAgNoyNZC/++67mjJlin72s5/pf//7n+bMmaMrrrhCu3btUosWLSRJt99+u/7xj3/o5ZdfVlxcnKZOnarhw4fr/fffN7N0SdznCQAAAACoPVMD+fr1633er1ixQu3atVNeXp769++voqIiPfPMM1q1apUuu+wySdLy5cvldDq1fft2XXLJJWaU7cV9ngAAAACA2oowu4AfKioqkiS1bt1akpSXl6eTJ09q8ODB3jYpKSnq1KmTtm3bVmMf5eXlKi4u9nkBAAAAANDQNJhAXllZqenTpys9PV29evWSJBUWFioqKkpnnXWWT9v27dursLCwxn6ys7MVFxfnfSUkJIS6dAAAAAAAAtZgAvmUKVO0c+dOrV69uk79zJ49W0VFRd7XwYMHg1QhAAAAAADB0yAeezZ16lStW7dO7733ns4991zv9g4dOujEiRM6evSozyz5kSNH1KFDhxr7slqtslqtoS4ZAAAAAIA6MTWQG4ah2267Ta+++qo2b96sLl26+OxPS0tT8+bNtWnTJo0YMUKStHv3bv3nP/9R3759zSgZYaa0tNT7eLozqXo2e6DPaA/FKvsAAAAAGj9TA/mUKVO0atUqvfbaa4qJifHeFx4XFyebzaa4uDjdcsstmjFjhlq3bq3Y2Fjddttt6tu3r+krrCM8uN1upaWlBXRMVlZWQO3z8vJYCR8AAABAwEwN5EuWLJEkDRw40Gf78uXLNWbMGEnSI488ooiICI0YMULl5eUaMmSInnjiiXquFOEqJSVFeXl5frUtKyuTx+ORw+GQzWYL6BwAAAAAECjTL1k/k+joaD3++ON6/PHH66EiNDZ2uz2g2ev09PQQVgMAAAAA/6fBrLIOAAAAAEBTQiAHAAAAAMAEBHIAAAAAAExAIAcAAAAAwASmLuoGAADgj9LSUrndbr/aulwun1/9lZKSIrvdHnBtAADUFoEcAAA0eG63W2lpaQEdk5WVFVD7vLy8gJ7MAQBAXRHIAQBAg5eSkqK8vDy/2paVlcnj8cjhcMhmswV0DgAA6hOBHAAANHh2uz2g2ev09PQQVgMAQHCwqBsAAAAAACYgkAMAAAAAYAICOQAAAAAAJiCQAwAAAABgAgI5AAAAAAAmYJV1AAhzpaWlcrvdfrV1uVw+v/orJSVFdrs94NoAAABwegRyAAhzbrdbaWlpAR2TlZUVUPu8vLyAHjkFAACAMyOQA0CYS0lJUV5enl9ty8rK5PF45HA4ZLPZAjoHAAAAgotAXo+4rBRAKNjt9oBmr9PT00NYDQAAAPxFIK9HXFYKAAAAAKhCIK9HXFYKAAAAoDEpLS2VJOXn5we979pmIn8FejVyKBDI6xGXlQIAAABoTKpuyZ0wYYLJldReTEyMaecmkAMAAAAAaiUzM1NSaNaycrlcysrK0sqVK+V0OoPad5WYmBglJyeHpG9/EMgBAAAAALXSpk0bjR8/PqTncDqdjXadrAizCwAAAAAAoCkikAMAAAAAYAICOQAAAAAAJiCQAwAAAABgAgI5AAAAAAAmIJADAAAAAGACAjkAAAAAACYgkAMAAAAAYAICOQAAAAAAJiCQAwAAAABgAgI5AAAAAAAmIJADAAAAAGACAjkAAAAAACZoZnYBQENQUVGh3NxcHT58WPHx8crIyFBkZKTZZQEAAABoxJghR5OXk5OjpKQkDRo0SKNGjdKgQYOUlJSknJwcs0sDAAAA0IgRyNGk5eTkaOTIkerdu7e2bdumkpISbdu2Tb1799bIkSMJ5QAAAABCxmIYhmF2EaFUXFysuLg4FRUVKTY21uxy0IBUVFQoKSlJvXv31tq1axUR8X8/n6qsrFRmZqZ27typgoICLl8HAAAA6ll+fr7S0tKUl5en1NRUs8sJiL85lHvI0WTl5ubK4/HoxRdf9AnjkhQREaHZs2erX79+ys3N1cCBA80pEgAANBmlpaVyu91+tS0rK5PH45HD4ZDNZvP7HCkpKbLb7bUtEUCQEcjRZB0+fFiS1KtXrxr3V22vagcAABBKbrdbaWlpIT1HOM40Ao0ZgRxNVnx8vCRp586duuSSS6rt37lzp087AACAUEpJSVFeXp5fbV0ul7KysrRy5Uo5nc6AzgGg4SCQo8nKyMiQw+HQwoULa7yHPDs7W126dFFGRoaJVQIAgKbCbrcHPHvtdDqZ8QbCGKuso8mKjIzU4sWLtW7dOmVmZvqssp6Zmal169bp4YcfZkE3AAAAACHBDDmatOHDh2vNmjWaOXOm+vXr593epUsXrVmzRsOHDzexOgAAAACNGYEcTd7w4cN13XXXKTc3V4cPH1Z8fLwyMjKYGQcAAGjkWNkeZiOQAzp1+TqPNgMAAGhaWNkeZiOQAwAAAGiSWNkeZiOQAwAAAGiSWNkeZmOVdQAAAAAATEAgBwAAAADABARyAAAAAABMQCAHAAAAAMAEBHIAAAAAAExAIAcAAAAAwAQEcgAAAAAATEAgBwAAAADABM38bfjpp5/63el5551Xq2IAAAAAAGgq/A7kffr0kcVikWEYNe6v2mexWFRRURG0AgEAAAAAaIz8DuT79+8PZR0AAAAAUGcFBQUqKSkJer8ul8vn11CIiYlRcnJyyPpHw+N3IO/cuXMo6wAAAAAaHcJh/SooKFC3bt1Ceo6srKyQ9r9nz56wG3fUnt+B/PXXX/e702uvvbZWxQAAAACNBeGw/lX98GPlypVyOp1B7busrEwej0cOh0M2my2ofUunfriSlZUVkh/goOHyO5BnZmb61S6Qe8jfe+89LVq0SHl5eTp8+LBeffVVn/OMGTNGzz77rM8xQ4YM0fr16/0tGwAAADAF4dA8TqdTqampQe83PT096H2iafM7kFdWVgb95MePH9f555+vcePGafjw4TW2ufLKK7V8+XLve6vVGvQ6AAAAgFAhHAI4Hb8DeSgMHTpUQ4cO/ck2VqtVHTp0qKeKAAAAAACoH7UO5MePH9e7776r//znPzpx4oTPvmnTptW5sCqbN29Wu3bt1KpVK1122WW6//77dfbZZ5+2fXl5ucrLy73vi4uLg1YLAAAAAADBUqtA/vHHH+uqq65SaWmpjh8/rtatW+ubb76R3W5Xu3btghbIr7zySg0fPlxdunTRvn37NGfOHA0dOlTbtm1TZGRkjcdkZ2drwYIFQTk/AAAAAAChElGbg26//XYNGzZM//3vf2Wz2bR9+3YdOHBAaWlpevjhh4NW3I033qhrr71WvXv3VmZmptatW6cPP/xQmzdvPu0xs2fPVlFRkfd18ODBoNUDAAAAAECw1CqQ79ixQzNnzlRERIQiIyNVXl6uhIQEPfTQQ5ozZ06wa/Tq2rWr2rRpo7179562jdVqVWxsrM8LAAAAAICGplaXrDdv3lwREaeyfLt27fSf//xHTqdTcXFxIZ2R/uKLL/Ttt98qPj4+ZOcAAAAAAIRGaWmp3G63X21dLpfPr/5KSUmR3W4PuDYz1CqQX3DBBfrwww+VnJysAQMGaO7cufrmm2/0/PPPq1evXn73c+zYMZ/Z7v3792vHjh1q3bq1WrdurQULFmjEiBHq0KGD9u3bp1mzZikpKUlDhgypTdkAAAAAABO53W6lpaUFdExWVlZA7fPy8kLyqMFQqFUgX7hwoUpKSiRJDzzwgH79619r8uTJSk5O1jPPPON3Px999JEGDRrkfT9jxgxJ0ujRo7VkyRJ9+umnevbZZ3X06FF17NhRV1xxhe677z6eRQ4AAAAAYSglJUV5eXl+tS0rK5PH45HD4ZDNZgvoHOGiVoH8wgsv9P53u3bttH79+lqdfODAgTIM47T7N2zYUKt+AQAAAAANj91uD2j2Oj09PYTVmK9Wi7rt379fBQUF1bYXFBTI4/HUtSYAAAAAABq9WgXyMWPGaOvWrdW2f/DBBxozZkxdawIAAAAAoNGrVSD/+OOPa7x04JJLLtGOHTvqWhMAAAAAAI1erQK5xWLxLur2Q0VFRaqoqKhzUQAAAAAANHa1CuT9+/dXdna2T/iuqKhQdna2Lr300qAVBwAAAABAY1WrVdb/8Ic/qH///urevbsyMjIkSbm5uSouLtbbb78d1AIBAGhoSktL5Xa7/Wpbl0e22O322pYIAADCQK0CeY8ePfTpp5/qL3/5iz755BPZbDb9+te/1tSpU9W6detg1wgAQIPidruVlpYW0nPk5eUF9FgYAAAQfmoVyCWpY8eOWrhwYTBrAQAgLKSkpCgvL8+vti6XS1lZWVq5cqWcTmdA5wAAAI1brQN5bm6uli5dqs8//1wvv/yyzjnnHD3//PPq0qUL95EDABo1u90e8Oy10+lkxhsAAPio1aJur7zyioYMGSKbzab8/HyVl5dLOrXKOrPmAAAAAACcWa0C+f33368nn3xSTz/9tJo3b+7dnp6ervz8/KAVBwAAAABAY1WrS9Z3796t/v37V9seFxeno0eP1rUmAAAAAKiVDi0tsh3dI31Zq7lH09iO7lGHlhazy0A9q1Ug79Chg/bu3SuHw+GzfcuWLeratWsw6gIAAADCHuGw/k1Mi5LzvYnSe2ZXEhinTtWOpqVWgXzChAn67W9/q2XLlslisejLL7/Utm3bNHPmTM2dOzfYNQIAAABhiXBY/5bmndAv566QM8yeVuFyu7V08Shda3YhqFe1CuR33XWXKisrdfnll6u0tFT9+/eX1WrVHXfcofHjxwe7RgAAACAsEQ7rX+ExQ2VndZM69jG7lICUFVaq8JhhdhmoZ7UK5BaLRXfffbfuuOMO7d27V8eOHVOPHj20dOlSdenSRYWFhcGuEwAAAAg7hEMAPyWgm1nKy8s1e/ZsXXjhhUpPT9cbb7yhHj166LPPPlP37t312GOP6fbbbw9VrQAAAAAANBoBzZDPnTtXS5cu1eDBg7V161bdcMMNGjt2rLZv367FixfrhhtuUGRkZKhqBQAAAACg0QgokL/88st67rnndO2112rnzp0677zz9L///U+ffPKJLJbwXIURAAAAAAAzBBTIv/jiC6WlpUmSevXqJavVqttvv50wDgAIewUFBSopKQl6vy6Xy+fXUIiJiVFycnLI+gcAAKERUCCvqKhQVNT/Pf6gWbNmatmyZdCLAgCgPhUUFKhbt24hPUdWVlZI+9+zZw+hHACAMBNQIDcMQ2PGjJHVapUkff/995o0aZJatGjh0y4nJyd4FQIAEGJVM+MrV66U0+kMat9lZWXyeDxyOByy2WxB7Vs6NfOelZUVktl9AAAQWgEF8tGjR/u8D/VP+wEAqE9Op1OpqalB7zc9PT3ofQIAgPAXUCBfvnx5qOoAAAAAAKBJCeg55AAAAAAAIDgI5AAAAAAAmIBADgAAAACACQjkAAAAAACYgEAOAAAAAIAJCOQAAAAAAJiAQA4AAAAAgAkI5AAAAAAAmIBADgAAAACACQjkAAAAAACYgEAOAAAAAIAJCOQAAAAAAJiAQA4AAAAAgAkI5AAAAAAAmKCZ2QUAAAAAQDCUlpZKkvLz84Ped1lZmTwejxwOh2w2W9D7d7lcQe8TDR+BHAAASR1aWmQ7ukf6MrwuHrMd3aMOLS1mlwEADYLb7ZYkTZgwweRKai8mJsbsElCPCOQAAEiamBYl53sTpffMriQwTp2qHQAgZWZmSpJSUlJkt9uD2rfL5VJWVpZWrlwpp9MZ1L6rxMTEKDk5OSR9o2EikAMAIGlp3gn9cu4KOVNSzC4lIC63W0sXj9K1ZhcCAA1AmzZtNH78+JCew+l0KjU1NaTnQNNBIAcAQFLhMUNlZ3WTOvYxu5SAlBVWqvCYYXYZAACgFsLrRjkAAAAAABoJAjkAAAAAACYgkAMAAAAAYAICOQAAAAAAJiCQAwAAAABgAgI5AAAAAAAmIJADAAAAAGACAjkAAAAAACYgkAMAAAAAYAICOQAAAAAAJiCQAwAAAABggmZmFwAAAAA0RqWlpZKk/Pz8oPddVlYmj8cjh8Mhm80W9P5dLlfQ+wRQHYEcANDk8Y9mAKHgdrslSRMmTDC5ktqLiYkxuwSgUSOQAwCaPP7RDCAUMjMzJUkpKSmy2+1B7dvlcikrK0srV66U0+kMat9VYmJilJycHJK+AZxCIAcANHn8oxlAKLRp00bjx48P6TmcTqdSU1NDeg4AoUMgBwA0efyjGQAAmIFV1gEAAAAAMAGBHAAAAAAAE5h6yfp7772nRYsWKS8vT4cPH9arr77qvY9PkgzD0Lx58/T000/r6NGjSk9P15IlS7hPDgAAAECdlZaWehf2PJOqp1oE+nSLUKxPgsbD1EB+/PhxnX/++Ro3bpyGDx9ebf9DDz2kP/3pT3r22WfVpUsX/f73v9eQIUO0a9cuRUdHm1AxAAAAgMbC7XYrLS0toGOysrICap+Xl8caIjgtUwP50KFDNXTo0Br3GYahRx99VPfcc4+uu+46SdJzzz2n9u3ba+3atbrxxhvrs1QAAAAAjUxKSory8vL8altWViaPxyOHwyGbzRbQOYDTabCrrO/fv1+FhYUaPHiwd1tcXJwuvvhibdu27bSBvLy8XOXl5d73xcXFIa8VAAAAQPix2+0BzV6np6eHsBo0RQ12UbfCwkJJUvv27X22t2/f3ruvJtnZ2YqLi/O+EhISQlonAAAAAAC10WADeW3Nnj1bRUVF3tfBgwfNLgkAAAAAgGoabCDv0KGDJOnIkSM+248cOeLdVxOr1arY2FifFwAAAAAADU2DDeRdunRRhw4dtGnTJu+24uJiffDBB+rbt6+JlQEAAAAAUHemLup27Ngx7d271/t+//792rFjh1q3bq1OnTpp+vTpuv/++5WcnOx97FnHjh19nlUOAAAAAEA4MjWQf/TRRxo0aJD3/YwZMyRJo0eP1ooVKzRr1iwdP35cv/nNb3T06FFdeumlWr9+Pc8gBwAAAACEPVMD+cCBA2UYxmn3WywW3Xvvvbr33nvrsSoAAAAAAEKvwd5DDgAAAABAY0YgBwAAAADABARyAAAAAABMQCAHAAAAAMAEBHIAAAAAAExAIAcAAAAAwAQEcgAAAAAATEAgBwAAAADABARyAAAAAABMQCAHAAAAAMAEBHIAAAAAAExAIAcAAAAAwATNzC4AAIBwU1paKrfb7Vdbl8vl86u/UlJSZLfbA64NAACEDwI5AAABcrvdSktLC+iYrKysgNrn5eUpNTU1oGMAAEB4IZADABCglJQU5eXl+dW2rKxMHo9HDodDNpstoHMAAIDGjUAOAECA7HZ7QLPX6enpIawGAACEKxZ1AwAAAADABARyAAAAAABMQCAHAAAAAMAEBHIAAAAAAEzAom4AAABAA1BaWiq32+1XW5fL5fOrv1JSUmS32wOuDUBoEMgBAACABsDtdistLS2gY7KysgJqn5eXF9BTIgCEFoEcAAAAaABSUlKUl5fnV9uysjJ5PB45HA7ZbLaAzgGg4bAYhmGYXUQoFRcXKy4uTkVFRYqNjTW7HAAAAABAI+dvDmVRNwAAAAAATEAgBwAAAADABARyAAAAAABMQCAHAAAAAMAEBHIAAAAAAExAIAcAAAAAwAQEcgAAAAAATEAgBwAAAADABARyAAAAAABMQCAHAAAAAMAEBHIAAAAAAExAIAcAAAAAwAQEcgAAAAAATEAgBwAAAADABARyAAAAAABMQCAHAAAAAMAEBHIAAAAAAExAIAcAAAAAwAQEcgAAAAAATEAgBwAAAADABARyAAAAAABMQCAHAAAAAMAEBHIAAAAAAExAIAcAAAAAwAQEcgAAAAAATEAgBwAAAADABARyAAAAAABMQCAHAAAAAMAEBHIAAAAAAExAIAcAAAAAwAQEcgAAAAAATEAgBwAAAADABARyAAAAAABMQCAHAAAAAMAEBHIAAAAAAExAIAcAAAAAwAQEcgAAAAAATEAgBwAAAADABA06kM+fP18Wi8XnlZKSYnZZAAAAAADUWTOzCziTnj176q233vK+b9aswZcMAAAAAMAZNfh026xZM3Xo0MHsMgAAAJqU0tJSud1uv9qWlZXJ4/HI4XDIZrP5fY6UlBTZ7fbalggAYa/BB/KCggJ17NhR0dHR6tu3r7Kzs9WpU6fTti8vL1d5ebn3fXFxcX2UCQAA0Ki43W6lpaWF9Bx5eXlKTU0N6TkAoCGzGIZhmF3E6fzzn//UsWPH1L17dx0+fFgLFizQoUOHtHPnTsXExNR4zPz587VgwYJq24uKihQbGxvqkgEAABqFQGbIXS6XsrKytHLlSjmdTr/PwQw5gMaquLhYcXFxZ8yhDTqQ/9jRo0fVuXNn/fGPf9Qtt9xSY5uaZsgTEhII5AAAACGSn5+vtLQ0ZrwB4P/zN5A3+EvWf+iss85St27dtHfv3tO2sVqtslqt9VgVAAAAAACBa9CPPfuxY8eOad++fYqPjze7FAAAAAAA6qRBB/Lf/e53evfdd+XxeLR161Zdf/31ioyM1E033WR2aQAAAAAA1EmDvmT9iy++0E033aRvv/1Wbdu21aWXXqrt27erbdu2ZpcGAAAAAECdNOhAvnr1arNLAAAAAAAgJBr0JesAAAAAADRWBHIAAAAAAExAIAcAAAAAwAQEcgAAAAAATNCgF3UDAABA8BQUFKikpCTo/bpcLp9fQyEmJkbJyckh6x/4KRUVFcrNzdXhw4cVHx+vjIwMRUZGml0WGgECOQAAQBNQUFCgbt26hfQcWVlZIe1/z549hHLUu5ycHM2cOVMej8e7zeFwaPHixRo+fLh5haFRIJADAAA0AVUz4ytXrpTT6Qxq32VlZfJ4PHI4HLLZbEHtWzo1856VlRWS2X3gp+Tk5GjkyJG65ppr9OKLL6pXr17auXOnFi5cqJEjR2rNmjWEctQJgRwAAKAJcTqdSk1NDXq/6enpQe8TMFNFRYVmzpypa665RmvXrlVExKnlty655BKtXbtWmZmZ+t3vfqfrrruOy9dRayzqBgAAAAA/kpubK4/Hozlz5njDeJWIiAjNnj1b+/fvV25urkkVojEgkAMAAADAjxw+fFiS1KtXrxr3V22vagfUBoEcAAAAAH4kPj5ekrRz584a91dtr2oH1AaBHAAAAAB+JCMjQw6HQwsXLlRlZaXPvsrKSmVnZ6tLly7KyMgwqUI0BgRyAAAAAPiRyMhILV68WOvWrVNmZqa2bdumkpISbdu2TZmZmVq3bp0efvhhFnRDnbDKOgAAAADUYPjw4VqzZo1mzpypfv36ebd36dKFR54hKAjkAAAAAHAaw4cP13XXXafc3FwdPnxY8fHxysjIYGYcQUEgBwAAAICfEBkZqYEDB5pdBhoh7iEHAAAAAMAEBHIAAAAAAExAIAcAAAAAwAQEcgAAAAAATEAgBwAAAADABARyAAAAAABMwGPPAAAAmogOLS2yHd0jfRleczK2o3vUoaXF7DIAIOgI5AAAAE3ExLQoOd+bKL1ndiWBcepU7QDQ2BDIAQAAmoileSf0y7kr5ExJMbuUgLjcbi1dPErXml0IAAQZgRwAAKCJKDxmqOysblLHPmaXEpCywkoVHjPMLgMAgi68biACAAAAAKCRIJADAAAAAGACAjkAAAAAACYgkAMAAAAAYAIWdQMAAGgCSktLJUn5+flB77usrEwej0cOh0M2my3o/btcrqD3CQANAYEcAACgCXC73ZKkCRMmmFxJ7cXExJhdAgAEFYEcAACgCcjMzJQkpaSkyG63B7Vvl8ulrKwsrVy5Uk6nM6h9V4mJiVFycnJI+gYAsxDIAQAAmoA2bdpo/PjxIT2H0+lUampqSM8BAI0Ji7oBAAAAAGACAjkAAAAAACYgkAMAAAAAYAICOQAAAAAAJiCQAwAAAABgAgI5AAAAAAAmIJADAAAAAGACAjkAAAAAACYgkAMAAAAAYAICOQAAAAAAJiCQAwAAAABgAgI5AAAAAAAmaGZ2AQAAAGh4SktL5Xa7/Wrrcrl8fvVXSkqK7HZ7wLUBQGNBIAcAAEA1brdbaWlpAR2TlZUVUPu8vDylpqYGdAwANCYEcgAAAFSTkpKivLw8v9qWlZXJ4/HI4XDIZrMFdA4AaMoshmEYZhcRSsXFxYqLi1NRUZFiY2PNLgcAAAAA0Mj5m0NZ1A0AAAAAABMQyAEAAAAAMAGBHAAAAAAAExDIAQAAAAAwAYEcAAAAAAATEMgBAAAAADABzyEHYIqKigrl5ubq8OHDio+PV0ZGhiIjI80uCwAAAKg3zJADqHc5OTlKSkrSoEGDNGrUKA0aNEhJSUnKyckxuzQAAACg3hDIAdSrnJwcjRw5Ur1799a2bdtUUlKibdu2qXfv3ho5ciShHAAAAE2GxTAMw+wiQqm4uFhxcXEqKipSbGys2eUATVpFRYWSkpLUu3dvrV27VhER//czwcrKSmVmZmrnzp0qKCjg8nUAAACELX9zKDPkAOpNbm6uPB6P5syZ4xPGJSkiIkKzZ8/W/v37lZuba1KFAAAAQP0hkAOoN4cPH5Yk9erVq8b9Vdur2gEAAACNWVgE8scff1wOh0PR0dG6+OKL9a9//cvskgDUQnx8vCRp586dNe6v2l7VDgAAAGjMGnwgf+mllzRjxgzNmzdP+fn5Ov/88zVkyBB99dVXZpcGIEAZGRlyOBxauHChKisrffZVVlYqOztbXbp0UUZGhkkVAgAAAPWnwQfyP/7xj5owYYLGjh2rHj166Mknn5TdbteyZcvMLg1AgCIjI7V48WKtW7dOmZmZPqusZ2Zmat26dXr44YdZ0A0AAABNQoNeZf3EiROy2+1as2aNMjMzvdtHjx6to0eP6rXXXqt2THl5ucrLy73vi4uLlZCQwCrrQC1988032vDKc7JXFPvVvrT0uPbt+/wn23z55ZfauXOnSktLvdtatGihnj17qmPHjmc8R2JiV9ntLfyqp02XnsoYeoNfbQEAAIBg8HeV9Wb1WFPAvvnmG1VUVKh9+/Y+29u3by+3213jMdnZ2VqwYEF9lAc0CWvXrtUXL87R/IFW/w9q78f+CyIktfzRjl3//3UGx/7/yw/z/1autl16KyUlxb8DAAAAgHrSoAN5bcyePVszZszwvq+aIQdQO5mZmdpQUaxXgzhDXleBzJBffmdPwjgAAAAapAYdyNu0aaPIyEgdOXLEZ/uRI0fUoUOHGo+xWq2yWgOYyQPwk9q0aaObJ844c0MAAAAAAWnQi7pFRUUpLS1NmzZt8m6rrKzUpk2b1LdvXxMrAwAAAACgbhr0DLkkzZgxQ6NHj9aFF16oiy66SI8++qiOHz+usWPHml0aAAAAAAC11uAD+S9/+Ut9/fXXmjt3rgoLC9WnTx+tX7++2kJvAAAAAACEkwb92LNg8He5eQAAAAAAgsHfHNqg7yEHAAAAAKCxIpADAAAAAGACAjkAAAAAACYgkAMAAAAAYAICOQAAAAAAJiCQAwAAAABgAgI5AAAAAAAmIJADAAAAAGACAjkAAAAAACYgkAMAAAAAYAICOQAAAAAAJiCQAwAAAABgAgI5AAAAAAAmaGZ2AaFmGIYkqbi42ORKAAAAAABNQVX+rMqjp9PoA3lJSYkkKSEhweRKAAAAAABNSUlJieLi4k6732KcKbKHucrKSn355ZeKiYmRxWIxuxy/FRcXKyEhQQcPHlRsbKzZ5TQJjHn9Y8zrH2Ne/xjz+seY1z/GvP4x5vWPMa9/4TzmhmGopKREHTt2VETE6e8Ub/Qz5BERETr33HPNLqPWYmNjw+7LF+4Y8/rHmNc/xrz+Meb1jzGvf4x5/WPM6x9jXv/Cdcx/ama8Cou6AQAAAABgAgI5AAAAAAAmIJA3UFarVfPmzZPVajW7lCaDMa9/jHn9Y8zrH2Ne/xjz+seY1z/GvP4x5vWvKYx5o1/UDQAAAACAhogZcgAAAAAATEAgBwAAAADABARyAAAAAABMQCBvoDZv3iyLxaKjR4/6fYzD4dCjjz4aspoaO8a8/jHm9Y8xr3+Mef1jzOsfY17/GPP6x5iHXlMcYwJ5LYwZM0YWi0WTJk2qtm/KlCmyWCwaM2ZM/Rd2Bp999plGjBghh8Mhi8USVl/ccB3zp59+WhkZGWrVqpVatWqlwYMH61//+pfZZfklXMc8JydHF154oc466yy1aNFCffr00fPPP292WX4J1zH/odWrV8tisSgzM9PsUvwSrmO+YsUKWSwWn1d0dLTZZfklXMdcko4ePaopU6YoPj5eVqtV3bp10xtvvGF2WWcUrmM+cODAat9zi8Wiq6++2uzSzihcx1ySHn30UXXv3l02m00JCQm6/fbb9f3335td1hmF65ifPHlS9957rxITExUdHa3zzz9f69evN7usGoXrGPubgR5//HE5HA5FR0fr4osvrrd/sxPIaykhIUGrV69WWVmZd9v333+vVatWqVOnTiZWdnqlpaXq2rWrHnzwQXXo0MHscgIWjmO+efNm3XTTTXrnnXe0bds2JSQk6IorrtChQ4fMLs0v4TjmrVu31t13361t27bp008/1dixYzV27Fht2LDB7NL8Eo5jXsXj8eh3v/udMjIyzC4lIOE65rGxsTp8+LD3deDAAbNL8ls4jvmJEyf085//XB6PR2vWrNHu3bv19NNP65xzzjG7NL+E45jn5OT4fMd37typyMhI3XDDDWaX5pdwHPNVq1bprrvu0rx58+RyufTMM8/opZde0pw5c8wuzS/hOOb33HOPli5dqj//+c/atWuXJk2apOuvv14ff/yx2aXVKBzH2J8M9NJLL2nGjBmaN2+e8vPzdf7552vIkCH66quvQl4fgbyWUlNTlZCQoJycHO+2nJwcderUSRdccIFP2/Lyck2bNk3t2rVTdHS0Lr30Un344Yc+bd544w1169ZNNptNgwYNksfjqXbOLVu2KCMjw/sTy2nTpun48eN+1/yzn/1MixYt0o033hiWz/ILxzF/4YUXdOutt6pPnz5KSUnRX//6V1VWVmrTpk2BfXiThOOYDxw4UNdff72cTqcSExP129/+Vuedd562bNkS2Ic3STiOuSRVVFTo5ptv1oIFC9S1a9eAjjVbuI65xWJRhw4dvK/27dsHdLyZwnHMly1bpu+++05r165Venq6HA6HBgwYoPPPPz+wD2+ScBzz1q1b+3zHN27cKLvdHjaBPBzHfOvWrUpPT9eoUaPkcDh0xRVX6Kabbgqbq/vCccyff/55zZkzR1dddZW6du2qyZMn66qrrtLixYsD+/D1JBzH2J8M9Mc//lETJkzQ2LFj1aNHDz355JOy2+1atmyZ3+epLQJ5HYwbN07Lly/3vl+2bJnGjh1brd2sWbP0yiuv6Nlnn1V+fr6SkpI0ZMgQfffdd5KkgwcPavjw4Ro2bJh27Nih8ePH66677vLpY9++fbryyis1YsQIffrpp3rppZe0ZcsWTZ06NbQfsoEJ9zEvLS3VyZMn1bp161r3Ud/CecwNw9CmTZu0e/du9e/fv1Z9mCEcx/zee+9Vu3btdMstt9TiE5svHMf82LFj6ty5sxISEnTdddfps88+q8UnN0+4jfnrr7+uvn37asqUKWrfvr169eqlhQsXqqKiopYjUP/Cbcx/7JlnntGNN96oFi1a1LqP+hZuY96vXz/l5eV5A/jnn3+uN954Q1dddVVtPr4pwm3My8vLq91yZLPZGvREQriN8ZmcOHFCeXl5Gjx4sHdbRESEBg8erG3btgXtPKdlIGCjR482rrvuOuOrr74yrFar4fF4DI/HY0RHRxtff/21cd111xmjR482DMMwjh07ZjRv3tx44YUXvMefOHHC6Nixo/HQQw8ZhmEYs2fPNnr06OFzjjvvvNOQZPz3v/81DMMwbrnlFuM3v/mNT5vc3FwjIiLCKCsrMwzDMDp37mw88sgjfn2GQNo2BI1hzA3DMCZPnmx07drVe3xDFs5jfvToUaNFixZGs2bNDKvVajzzzDN1GIn6E65jnpuba5xzzjnG119/7fM5wkG4jvnWrVuNZ5991vj444+NzZs3G9dcc40RGxtrHDx4sI4jEnrhOubdu3c3rFarMW7cOOOjjz4yVq9ebbRu3dqYP39+HUck9MJ1zH/ogw8+MCQZH3zwQS1GoP6F85g/9thjRvPmzY1mzZoZkoxJkybVYSTqT7iO+U033WT06NHD2LNnj1FRUWG8+eabhs1mM6Kiouo4IsEXrmP8QzW1PXTokCHJ2Lp1q8/2O+64w7jooov86rcumoU+8jdebdu21dVXX60VK1bIMAxdffXVatOmjU+bffv26eTJk0pPT/dua968uS666CK5XC5Jksvl0sUXX+xzXN++fX3ef/LJJ/r000/1wgsveLcZhqHKykrt379fTqcz2B+vQQrnMX/wwQe1evVqbd68OWwWX5LCc8xjYmK0Y8cOHTt2TJs2bdKMGTPUtWtXDRw4MJCPbppwGvOSkhL96le/0tNPP12txnASTmNe1ecP++3Xr5+cTqeWLl2q++67z/8PbqJwG/PKykq1a9dOTz31lCIjI5WWlqZDhw5p0aJFmjdvXsCf3wzhNuY/9Mwzz6h379666KKLAjrObOE25ps3b9bChQv1xBNP6OKLL9bevXv129/+Vvfdd59+//vfB/z5zRBuY/7YY49pwoQJSklJkcViUWJiosaOHVsvl0rXVriNcUNHIK+jcePGeS+ZePzxx0N2nmPHjmnixImaNm1atX0NdQGFUAnHMX/44Yf14IMP6q233tJ5550XrBLrTbiNeUREhJKSkiRJffr0kcvlUnZ2dtgEcil8xnzfvn3yeDwaNmyYd1tlZaUkqVmzZtq9e7cSExODV3AIhcuY16R58+a64IILtHfv3rqWV6/Caczj4+PVvHlzRUZGerc5nU4VFhbqxIkTioqKClq9oRROY17l+PHjWr16te69995glVevwmnMf//73+tXv/qVxo8fL0nq3bu3jh8/rt/85je6++67FRERHne7htOYt23bVmvXrtX333+vb7/9Vh07dtRdd93V4NdjCacxPpM2bdooMjJSR44c8dl+5MiRelkIm0BeR1deeaVOnDghi8WiIUOGVNufmJioqKgovf/+++rcubOkU483+PDDDzV9+nRJp/6H/vrrr/sct337dp/3qamp2rVrlzdkNGXhNuYPPfSQHnjgAW3YsEEXXnhhnfoyS7iN+Y9VVlaqvLw8qH2GWriMeUpKiv7973/7bLvnnntUUlKixx57TAkJCbXq1wzhMuY1qaio0L///e+wus9TCq8xT09P16pVq1RZWekNJXv27FF8fHzYhHEpvMa8yssvv6zy8nJlZWXVuS8zhNOYl5aWVgvdVT+EMgyj1v3Wt3Aa8yrR0dE655xzdPLkSb3yyiv6xS9+Uec+Qykcx/h0oqKilJaWpk2bNnkf21q1CHN9rNcVHj/masAiIyPlcrm0a9cun5+aV2nRooUmT56sO+64Q+vXr9euXbs0YcIElZaWehc/mjRpkgoKCnTHHXdo9+7dWrVqlVasWOHTz5133qmtW7dq6tSp2rFjhwoKCvTaa68F9CU5ceKEduzYoR07dujEiRM6dOiQduzYEXYzKuE05n/4wx/0+9//XsuWLZPD4VBhYaEKCwt17NixOo1BfQunMc/OztbGjRv1+eefy+VyafHixXr++efD7h9y4TLm0dHR6tWrl8/rrLPOUkxMjHr16hVWQSVcxlw6tYjem2++qc8//1z5+fnKysrSgQMHvLNa4SKcxnzy5Mn67rvv9Nvf/lZ79uzRP/7xDy1cuFBTpkyp0xjUt3Aa8yrPPPOMMjMzdfbZZ9fqM5stnMZ82LBhWrJkiVavXq39+/dr48aN+v3vf69hw4bVWHtDFU5j/sEHHygnJ0eff/65cnNzdeWVV6qyslKzZs2q0xiEWjiNsT8ZaMaMGXr66af17LPPyuVyafLkyTp+/HiNi9UFXcjvUm+EzrRg0Q8XNDAMwygrKzNuu+02o02bNobVajXS09ONf/3rXz7H/P3vfzeSkpIMq9VqZGRkGMuWLfNZ0MAwDONf//qX8fOf/9xo2bKl0aJFC+O8884zHnjgAe/+My1osH//fkNStdeAAQMCHIH6F65j3rlz5xrHfN68eQGOQP0L1zG/++67jaSkJCM6Otpo1aqV0bdvX2P16tWBfnxThOuYB/o5GpJwHfPp06cbnTp1MqKiooz27dsbV111lZGfnx/oxzdFuI65YZxaTO/iiy82rFar0bVrV+OBBx4w/ve//wXy8U0RzmPudrsNScabb74ZyEc2XbiO+cmTJ4358+cbiYmJRnR0tJGQkGDceuutPudoqMJ1zDdv3mw4nU7DarUaZ599tvGrX/3KOHToUKAfv16E6xj7m4H+/Oc/e//fetFFFxnbt2/3Z1jqzGIYYXT9CQAAAAAAjQSXrAMAAAAAYAICOQAAAAAAJiCQAwAAAABgAgI5AAAAAAAmIJADAAAAAGACAjkAAAAAACYgkAMAAAAAYAICOQAAAAAAJiCQAwAAv23evFkWi0VHjx71+xiHw6FHH300ZDUBABCuCOQAADQiY8aMkcVi0aRJk6rtmzJliiwWi8aMGVP/hQEAgGoI5AAANDIJCQlavXq1ysrKvNu+//57rVq1Sp06dTKxMgAA8EMEcgAAGpnU1FQlJCQoJyfHuy0nJ0edOnXSBRdc4N1WXl6uadOmqV27doqOjtall16qDz/80KevN954Q926dZPNZtOgQYPk8XiqnW/Lli3KyMiQzWZTQkKCpk2bpuPHj4fs8wEA0FgQyAEAaITGjRun5cuXe98vW7ZMY8eO9Wkza9YsvfLKK3r22WeVn5+vpKQkDRkyRN99950k6eDBgxo+fLiGDRumHTt2aPz48brrrrt8+ti3b5+uvPJKjRgxQp9++qleeuklbdmyRVOnTg39hwQAIMwRyAEAaISysrK0ZcsWHThwQAcOHND777+vrKws7/7jx49ryZIlWrRokYYOHaoePXro6aefls1m0zPPPCNJWrJkiRITE7V48WJ1795dN998c7X7z7Ozs3XzzTdr+vTpSk5OVr9+/fSnP/1Jzz33nL7//vv6/MgAAISdZmYXAAAAgq9t27a6+uqrtWLFChmGoauvvlpt2rTx7t+3b59Onjyp9PR077bmzZvroosuksvlkiS5XC5dfPHFPv327dvX5/0nn3yiTz/9VC+88IJ3m2EYqqys1P79++V0OkPx8QAAaBQI5AAANFLjxo3zXjr++OOPh+Qcx44d08SJEzVt2rRq+1hADgCAn0YgBwCgkbryyit14sQJWSwWDRkyxGdfYmKioqKi9P7776tz586SpJMnT+rDDz/U9OnTJUlOp1Ovv/66z3Hbt2/3eZ+amqpdu3YpKSkpdB8EAIBGinvIAQBopCIjI+VyubRr1y5FRkb67GvRooUmT56sO+64Q+vXr9euXbs0YcIElZaW6pZbbpEkTZo0SQUFBbrjjju0e/durVq1SitWrPDp584779TWrVs1depU7dixQwUFBXrttddY1A0AAD8QyAEAaMRiY2MVGxtb474HH3xQI0aM0K9+9SulpqZq79692rBhg1q1aiXp1CXnr7zyitauXavzzz9fTz75pBYuXOjTx3nnnad3331Xe/bsUUZGhi644ALNnTtXHTt2DPlnAwAg3FkMwzDMLgIAAAAAgKaGGXIAAAAAAExAIAcAAAAAwAQEcgAAAAAATEAgBwAAAADABARyAAAAAABMQCAHAAAAAMAEBHIAAAAAAExAIAcAAAAAwAQEcgAAAAAATEAgBwAAAADABARyAAAAAABM8P8AzzRZw4UYKu4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "# Put the accuracy data in a list of lists\n",
    "acc_data = [\n",
    "    acc_1_per_fold,\n",
    "    acc_2_per_fold,\n",
    "    acc_3_per_fold,\n",
    "    acc_4_per_fold,\n",
    "    acc_5_per_fold,\n",
    "    acc_6_per_fold,\n",
    "    acc_7_per_fold,\n",
    "    acc_8_per_fold,\n",
    "    acc_9_per_fold,\n",
    "    acc_10_per_fold,\n",
    "]\n",
    "\n",
    "# Put the loss data in a list of lists\n",
    "loss_data = [\n",
    "    loss_1_per_fold,\n",
    "    loss_2_per_fold,\n",
    "    loss_3_per_fold,\n",
    "    loss_4_per_fold,\n",
    "    loss_5_per_fold,\n",
    "    loss_6_per_fold,\n",
    "    loss_7_per_fold,\n",
    "    loss_8_per_fold,\n",
    "    loss_9_per_fold,\n",
    "    loss_10_per_fold,\n",
    "]\n",
    "\n",
    "precision_data = [\n",
    "    precision_1_per_fold,\n",
    "    precision_2_per_fold,\n",
    "    precision_3_per_fold,\n",
    "    precision_4_per_fold,\n",
    "    precision_5_per_fold,\n",
    "    precision_6_per_fold,\n",
    "    precision_7_per_fold,\n",
    "    precision_8_per_fold,\n",
    "    precision_9_per_fold,\n",
    "    precision_10_per_fold,\n",
    "]\n",
    "\n",
    "recall_data = [\n",
    "    recall_1_per_fold,\n",
    "    recall_2_per_fold,\n",
    "    recall_3_per_fold,\n",
    "    recall_4_per_fold,\n",
    "    recall_5_per_fold,\n",
    "    recall_6_per_fold,\n",
    "    recall_7_per_fold,\n",
    "    recall_8_per_fold,\n",
    "    recall_9_per_fold,\n",
    "    recall_10_per_fold,\n",
    "]\n",
    "\n",
    "f1_data = [\n",
    "    f1_1_per_fold,\n",
    "    f1_2_per_fold,\n",
    "    f1_3_per_fold,\n",
    "    f1_4_per_fold,\n",
    "    f1_5_per_fold,\n",
    "    f1_6_per_fold,\n",
    "    f1_7_per_fold,\n",
    "    f1_8_per_fold,\n",
    "    f1_9_per_fold,\n",
    "    f1_10_per_fold,\n",
    "]\n",
    "\n",
    "testing_acc_data = [\n",
    "    testing_acc_1_per_fold,\n",
    "    testing_acc_2_per_fold,\n",
    "    testing_acc_3_per_fold,\n",
    "    testing_acc_4_per_fold,\n",
    "    testing_acc_5_per_fold,\n",
    "    testing_acc_6_per_fold,\n",
    "    testing_acc_7_per_fold,\n",
    "    testing_acc_8_per_fold,\n",
    "    testing_acc_9_per_fold,\n",
    "    testing_acc_10_per_fold,\n",
    "]\n",
    "\n",
    "testing_precision_data = [\n",
    "    testing_precision_1_per_fold,\n",
    "    testing_precision_2_per_fold,\n",
    "    testing_precision_3_per_fold,\n",
    "    testing_precision_4_per_fold,\n",
    "    testing_precision_5_per_fold,\n",
    "    testing_precision_6_per_fold,\n",
    "    testing_precision_7_per_fold,\n",
    "    testing_precision_8_per_fold,\n",
    "    testing_precision_9_per_fold,\n",
    "    testing_precision_10_per_fold,\n",
    "]\n",
    "\n",
    "testing_recall_data = [\n",
    "    testing_recall_1_per_fold,\n",
    "    testing_recall_2_per_fold,\n",
    "    testing_recall_3_per_fold,\n",
    "    testing_recall_4_per_fold,\n",
    "    testing_recall_5_per_fold,\n",
    "    testing_recall_6_per_fold,\n",
    "    testing_recall_7_per_fold,\n",
    "    testing_recall_8_per_fold,\n",
    "    testing_recall_9_per_fold,\n",
    "    testing_recall_10_per_fold,\n",
    "]\n",
    "\n",
    "testing_f1_data = [\n",
    "    testing_f1_1_per_fold,\n",
    "    testing_f1_2_per_fold,\n",
    "    testing_f1_3_per_fold,\n",
    "    testing_f1_4_per_fold,\n",
    "    testing_f1_5_per_fold,\n",
    "    testing_f1_6_per_fold,\n",
    "    testing_f1_7_per_fold,\n",
    "    testing_f1_8_per_fold,\n",
    "    testing_f1_9_per_fold,\n",
    "    testing_f1_10_per_fold,\n",
    "]\n",
    "\n",
    "# Create the box plots for accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.boxplot(acc_data, labels=[f'Model {i+1}' for i in range(10)])\n",
    "plt.title('Training accuracy per Fold for Each Model')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Create the box plots for loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.boxplot(loss_data, labels=[f'Model {i+1}' for i in range(10)])\n",
    "plt.title('Loss per Fold for Each Model')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.boxplot(precision_data , labels=[f'Model {i+1}' for i in range(10)])\n",
    "plt.title('Training precision per Fold for Each Model')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Precision')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.boxplot(recall_data , labels=[f'Model {i+1}' for i in range(10)])\n",
    "plt.title('Training recall per Fold for Each Model')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Recall')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.boxplot(f1_data , labels=[f'Model {i+1}' for i in range(10)])\n",
    "plt.title('Training f1 per Fold for Each Model')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('F1')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.boxplot(testing_acc_data, labels=[f'Model {i+1}' for i in range(10)])\n",
    "plt.title('Testing accuracy per Fold for Each Model')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.boxplot(testing_precision_data , labels=[f'Model {i+1}' for i in range(10)])\n",
    "plt.title('Testing precision per Fold for Each Model')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Precision')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.boxplot(testing_recall_data , labels=[f'Model {i+1}' for i in range(10)])\n",
    "plt.title('Testing recall per Fold for Each Model')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Recall')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.boxplot(testing_f1_data , labels=[f'Model {i+1}' for i in range(10)])\n",
    "plt.title('Testing f1 per Fold for Each Model')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('F1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_acc_data = [\n",
    "    testing_acc_1_per_fold,\n",
    "    testing_acc_2_per_fold,\n",
    "    testing_acc_3_per_fold,\n",
    "    testing_acc_4_per_fold,\n",
    "    testing_acc_5_per_fold,\n",
    "    testing_acc_6_per_fold,\n",
    "    testing_acc_7_per_fold,\n",
    "    testing_acc_8_per_fold,\n",
    "    testing_acc_9_per_fold,\n",
    "    testing_acc_10_per_fold,\n",
    "]\n",
    "testing_f1_data = [\n",
    "    testing_f1_1_per_fold,\n",
    "    testing_f1_2_per_fold,\n",
    "    testing_f1_3_per_fold,\n",
    "    testing_f1_4_per_fold,\n",
    "    testing_f1_5_per_fold,\n",
    "    testing_f1_6_per_fold,\n",
    "    testing_f1_7_per_fold,\n",
    "    testing_f1_8_per_fold,\n",
    "    testing_f1_9_per_fold,\n",
    "    testing_f1_10_per_fold,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'tab:orange', 'tab:brown', 'tab:pink'] # define colors for each model\n",
    "\n",
    "for i in range(len(testing_acc_data)):\n",
    "    plt.scatter(testing_f1_data[i], testing_acc_data[i], color=colors[i], label=f'Model {i+1}')\n",
    "\n",
    "plt.xlabel('F1 Score')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('F1 Score vs. Accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_1_filename = 'models/best_model_1_fold_10.h5'\n",
    "best_model_2_filename = 'models/best_model_2_fold_10.h5'\n",
    "best_model_3_filename = 'models/best_model_3_fold_4.h5'\n",
    "best_model_4_filename = 'models/best_model_4_fold_2.h5'\n",
    "best_model_5_filename = 'models/best_model_5_fold_4.h5'\n",
    "best_model_6_filename = 'models/best_model_6_fold_10.h5'\n",
    "best_model_7_filename = 'models/best_model_7_fold_7.h5'\n",
    "best_model_8_filename = 'models/best_model_8_fold_6.h5'\n",
    "best_model_9_filename = 'models/best_model_9_fold_3.h5'\n",
    "best_model_10_filename = 'models/best_model_10_fold_2.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4736 4736\n"
     ]
    }
   ],
   "source": [
    "test_sets_path = '/home/pmedur/strojnoUcenje/env/bin/Tensorflow_speech_recognition/tflite-speech-recognition-master'\n",
    "test_sets_filename = 'further_test_data.npz'\n",
    "test_sets = np.load(join(test_sets_path, test_sets_filename))\n",
    "#x_test = test_sets['x_test.npy']\n",
    "#y_test = test_sets['y_test.npy']\n",
    "x_test = test_sets['x_test']\n",
    "y_test = test_sets['y_test']\n",
    "print(len(x_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4736,)\n",
      "(4736, 16, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "y_test = np.equal(y_test, wake_word_index).astype('float64')\n",
    "x_test = x_test.reshape(x_test.shape[0], \n",
    "                        x_test.shape[1], \n",
    "                        x_test.shape[2], \n",
    "                        1)\n",
    "print(y_test.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-15 15:29:07.720104: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 1s 2ms/step - loss: 0.0726 - acc: 0.9791 - precision_m: 0.2830 - recall_m: 0.2472 - f1_m: 0.2517      \n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0682 - acc: 0.9770 - precision_m: 0.2654 - recall_m: 0.2378 - f1_m: 0.2398     \n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.1769 - acc: 0.9635 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0680 - acc: 0.9776 - precision_m: 0.2521 - recall_m: 0.2249 - f1_m: 0.2307     \n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0944 - acc: 0.9694 - precision_m: 0.1565 - recall_m: 0.0874 - f1_m: 0.1063     \n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0647 - acc: 0.9827 - precision_m: 0.3078 - recall_m: 0.2656 - f1_m: 0.2751     \n",
      "148/148 [==============================] - 1s 2ms/step - loss: 0.1284 - acc: 0.9628 - precision_m: 0.0541 - recall_m: 0.0166 - f1_m: 0.0241    \n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0922 - acc: 0.9709 - precision_m: 0.2430 - recall_m: 0.1687 - f1_m: 0.1834     \n",
      "148/148 [==============================] - 0s 1ms/step - loss: 0.0964 - acc: 0.9688 - precision_m: 0.2033 - recall_m: 0.1385 - f1_m: 0.1497     \n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0781 - acc: 0.9770 - precision_m: 0.2804 - recall_m: 0.2291 - f1_m: 0.2423     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07808292657136917,\n",
       " 0.9769847989082336,\n",
       " 0.2804053723812103,\n",
       " 0.2290593981742859,\n",
       " 0.24225467443466187]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1 = load_model(best_model_1_filename, custom_objects={'precision_m': precision_m, 'recall_m': recall_m, 'f1_m': f1_m})\n",
    "model_2 = load_model(best_model_2_filename, custom_objects={'precision_m': precision_m, 'recall_m': recall_m, 'f1_m': f1_m})\n",
    "model_3 = load_model(best_model_3_filename, custom_objects={'precision_m': precision_m, 'recall_m': recall_m, 'f1_m': f1_m})\n",
    "model_4 = load_model(best_model_4_filename, custom_objects={'precision_m': precision_m, 'recall_m': recall_m, 'f1_m': f1_m})\n",
    "model_5 = load_model(best_model_5_filename, custom_objects={'precision_m': precision_m, 'recall_m': recall_m, 'f1_m': f1_m})\n",
    "model_6 = load_model(best_model_6_filename, custom_objects={'precision_m': precision_m, 'recall_m': recall_m, 'f1_m': f1_m})\n",
    "model_7 = load_model(best_model_7_filename, custom_objects={'precision_m': precision_m, 'recall_m': recall_m, 'f1_m': f1_m})\n",
    "model_8 = load_model(best_model_8_filename, custom_objects={'precision_m': precision_m, 'recall_m': recall_m, 'f1_m': f1_m})\n",
    "model_9 = load_model(best_model_9_filename, custom_objects={'precision_m': precision_m, 'recall_m': recall_m, 'f1_m': f1_m})\n",
    "model_10 = load_model(best_model_10_filename, custom_objects={'precision_m': precision_m, 'recall_m': recall_m, 'f1_m': f1_m})\n",
    "model_1.evaluate(x=x_test, y=y_test)\n",
    "model_2.evaluate(x=x_test, y=y_test)\n",
    "model_3.evaluate(x=x_test, y=y_test)\n",
    "model_4.evaluate(x=x_test, y=y_test)\n",
    "model_5.evaluate(x=x_test, y=y_test)\n",
    "model_6.evaluate(x=x_test, y=y_test)\n",
    "model_7.evaluate(x=x_test, y=y_test)\n",
    "model_8.evaluate(x=x_test, y=y_test)\n",
    "model_9.evaluate(x=x_test, y=y_test)\n",
    "model_10.evaluate(x=x_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4736 4736\n",
      "Accuracy: 97.95%\n",
      "Precision: 0.77\n",
      "Recall: 0.63\n",
      "F1 Score: 0.69\n",
      "True Positives: 109\n",
      "True Negatives: 4530\n",
      "False Positives: 33\n",
      "False Negatives: 64\n",
      "Sample Predictions and True Labels:\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction: 0.0, True Label: 0.0\n",
      "Prediction Distribution: {0.0: 4594, 1.0: 142}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tflite_runtime.interpreter as tflite\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from os.path import join\n",
    "\n",
    "# Load the TFLite model and allocate tensors\n",
    "interpreter = tflite.Interpreter(model_path='Converted_models/wake_word_stop_lite_1.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Load the test data\n",
    "test_sets_path = '/home/pmedur/strojnoUcenje/env/bin/Tensorflow_speech_recognition/tflite-speech-recognition-master'\n",
    "test_sets_filename = 'further_test_data.npz'\n",
    "test_sets = np.load(join(test_sets_path, test_sets_filename))\n",
    "X_test = test_sets['x_test']\n",
    "Y_test = test_sets['y_test']\n",
    "\n",
    "print(len(X_test), len(Y_test))\n",
    "\n",
    "wake_word_index = all_targets.index(wake_word)\n",
    "\n",
    "# Reshape X_test if needed\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "Y_test = np.equal(Y_test, wake_word_index).astype('float32')\n",
    "\n",
    "# Run inference\n",
    "predictions = []\n",
    "for i in range(len(X_test)):\n",
    "    input_data = np.expand_dims(X_test[i], axis=0).astype(np.float32)\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    interpreter.invoke()\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    predictions.append(np.round(output_data).flatten()[0])\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "\n",
    "# Evaluate the results\n",
    "accuracy = np.mean(predictions == Y_test)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision = precision_score(Y_test, predictions)\n",
    "recall = recall_score(Y_test, predictions)\n",
    "f1 = f1_score(Y_test, predictions)\n",
    "\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test, predictions).ravel()\n",
    "print(f'True Positives: {tp}')\n",
    "print(f'True Negatives: {tn}')\n",
    "print(f'False Positives: {fp}')\n",
    "print(f'False Negatives: {fn}')\n",
    "\n",
    "# Debugging: Print some predictions and their corresponding true labels\n",
    "print(\"Sample Predictions and True Labels:\")\n",
    "for i in range(100):\n",
    "    print(f\"Prediction: {predictions[i]}, True Label: {Y_test[i]}\")\n",
    "\n",
    "# Check the distribution of the predictions\n",
    "unique, counts = np.unique(predictions, return_counts=True)\n",
    "print(\"Prediction Distribution:\", dict(zip(unique, counts)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0s: 4563\n",
      "Number of 1s: 173\n",
      "Total samples: 4736\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from os.path import join\n",
    "\n",
    "# Load the test data\n",
    "test_sets_path = '/home/pmedur/strojnoUcenje/env/bin/Tensorflow_speech_recognition/tflite-speech-recognition-master'\n",
    "test_sets_filename = 'further_test_data.npz'\n",
    "test_sets = np.load(join(test_sets_path, test_sets_filename))\n",
    "X_test = test_sets['x_test']\n",
    "Y_test = test_sets['y_test']\n",
    "\n",
    "wake_word_index = all_targets.index(wake_word)\n",
    "\n",
    "# Convert Y_test to binary labels based on wake_word_index\n",
    "Y_test_binary = np.equal(Y_test, wake_word_index).astype('int')\n",
    "\n",
    "# Count the occurrences of 0s and 1s\n",
    "label_counts = np.bincount(Y_test_binary)\n",
    "\n",
    "# Print the counts\n",
    "print(f'Number of 0s: {label_counts[0]}')\n",
    "print(f'Number of 1s: {label_counts[1]}')\n",
    "\n",
    "# Ensure that the Y_test_binary contains only 0s and 1s\n",
    "assert len(label_counts) == 2, \"Y_test_binary should only contain 0s and 1s\"\n",
    "\n",
    "# For completeness, print the total number of samples\n",
    "print(f'Total samples: {len(Y_test_binary)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
